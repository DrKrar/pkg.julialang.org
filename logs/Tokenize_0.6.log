>>> 'Pkg.add("Tokenize")' log
INFO: Cloning cache of Tokenize from https://github.com/KristofferC/Tokenize.jl.git
INFO: Installing Tokenize v0.1.6
INFO: Package database updated

>>> 'Pkg.test("Tokenize")' log
Julia Version 0.6.0-pre.alpha.116
Commit 0e970f0 (2017-03-10 19:40 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-112-generic #159-Ubuntu SMP Fri Mar 3 15:26:07 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (1045.71875 MB free)
Uptime: 34944.0 sec
Load Avg:  1.1376953125  1.13427734375  1.08984375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3507 MHz    1970025 s       6472 s     169002 s     923389 s        225 s
#2  3507 MHz     716864 s        164 s      88392 s    2549538 s         10 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.9.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - JSON                          0.8.3
 - Tokenize                      0.1.6
1 additional packages:
 - Compat                        0.20.0
INFO: Testing Tokenize
Lexed 10 files in 0.2742 seconds with a total of 22256 tokens with 0 errors
Test Summary: | Pass  Total
lex yourself  |    1      1
Test Summary: | Pass  Total
tokens        |   18     18
Test Summary:    | Pass  Total
tokenize unicode |   48     48
Test Summary:                  | Pass  Total
tokenize complex piece of code |  132    132
Test Summary: | Pass  Total
issue 5, '..' |    1      1
Test Summary: | Pass  Total
issue 17, >>  |    1      1
Test Summary:        | Pass  Total
test added operators |   10     10
Test Summary: | Pass  Total
infix         |    4      4
Test Summary:                  | Pass  Total
tokenizing true/false literals |    4      4
Test Summary:                                                  | Pass  Total
tokenizing juxtaposed numbers and dotted operators/identifiers |    8      8
Test Summary:               | Pass  Total
lexing anon functions '->'  |    1      1
Test Summary: | Pass  Total
comments      |    1      1
Test Summary: | Pass  Total
primes        |    4      4
Test Summary:     | Pass  Total
in/isa bytelength |    1      1
Test Summary: | Pass  Total
keywords      |   33     33
Test Summary:   | Pass  Total
issue in PR #45 |    1      1
Test Summary: | Pass  Total
errors        |    5      5
INFO: Tokenize tests passed

>>> End of log
