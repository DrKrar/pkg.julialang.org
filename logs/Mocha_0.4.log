>>> 'Pkg.add("Mocha")' log
INFO: Cloning cache of Logging from git://github.com/kmsquire/Logging.jl.git
INFO: Cloning cache of Mocha from git://github.com/pluskid/Mocha.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing FileIO v0.2.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.5
INFO: Installing LegacyStrings v0.1.1
INFO: Installing Logging v0.3.1
INFO: Installing Mocha v0.1.2
INFO: Installing SHA v0.2.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building HDF5
INFO: Building Mocha
Running `g++ -fPIC -Wall -O3 -shared -fopenmp -o libmochaext.so im2col.cpp pooling.cpp`
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Mocha
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Mocha")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64
Memory: 2.939289093017578 GB (776.11328125 MB free)
Uptime: 4799.0 sec
Load Avg:  0.841796875  0.95361328125  1.00244140625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3501 MHz     200404 s         85 s      20008 s     216383 s         11 s
#2  3501 MHz     145438 s         62 s      17698 s     301921 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - JSON                          0.8.0
 - Mocha                         0.1.2
10 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Compat                        0.9.3
 - FileIO                        0.2.0
 - HDF5                          0.6.6
 - JLD                           0.6.5
 - LegacyStrings                 0.1.1
 - Logging                       0.3.1
 - SHA                           0.2.1
 - URIParser                     0.1.6
INFO: Testing Mocha
WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:115.
WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:115.
WARNING: Method definition info(Any...) in module Base at util.jl:334 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:115.
WARNING: Method definition warn(Any...) in module Base at util.jl:364 overwritten in module Logging at /home/vagrant/.julia/v0.4/Logging/src/Logging.jl:115.
Configuring Mocha...
 * CUDA       disabled by default
 * Native Ext disabled by default
Mocha configured, continue loading module...
DefaultBackend = Mocha.CPUBackend
-- Testing simple Adam solver call
27-Oct 05:41:06:INFO:root:Constructing net TEST on Mocha.CPUBackend...
27-Oct 05:41:06:INFO:root:Topological sorting 4 layers...
27-Oct 05:41:06:INFO:root:Setup layers...
27-Oct 05:41:08:INFO:root:Network constructed!
27-Oct 05:41:08:DEBUG:root:#DEBUG Checking network topology for back-propagation
27-Oct 05:41:08:DEBUG:root:Init network TEST
27-Oct 05:41:08:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:41:09:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:41:09:DEBUG:root:Init parameter weight for layer ip2
27-Oct 05:41:09:DEBUG:root:Init parameter bias for layer ip2
27-Oct 05:41:09:DEBUG:root:#DEBUG Initializing coffee breaks
27-Oct 05:41:09:DEBUG:root:#DEBUG Entering solver loop
27-Oct 05:41:10:DEBUG:root:Destroying network TEST
-- Testing simple SGD solver call
27-Oct 05:41:10:INFO:root:Constructing net TEST on Mocha.CPUBackend...
27-Oct 05:41:10:INFO:root:Topological sorting 4 layers...
27-Oct 05:41:10:INFO:root:Setup layers...
27-Oct 05:41:10:INFO:root:Network constructed!
27-Oct 05:41:10:DEBUG:root:#DEBUG Checking network topology for back-propagation
27-Oct 05:41:10:DEBUG:root:Init network TEST
27-Oct 05:41:10:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:41:10:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:41:10:DEBUG:root:Init parameter weight for layer ip2
27-Oct 05:41:10:DEBUG:root:Init parameter bias for layer ip2
27-Oct 05:41:10:DEBUG:root:#DEBUG Initializing coffee breaks
27-Oct 05:41:10:DEBUG:root:#DEBUG Entering solver loop
27-Oct 05:41:10:DEBUG:root:Destroying network TEST
-- Testing network topology with duplicated blobs
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 1 layers...
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 2 layers...
-- Testing network topology with missing blobs
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 1 layers...
-- Testing network topology with circular dependency
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 2 layers...
-- Testing network topology with multiple back-propagate path
    > Good blob sharing
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 5 layers...
27-Oct 05:41:11:INFO:root:Setup layers...
27-Oct 05:41:11:INFO:root:Network constructed!
27-Oct 05:41:11:DEBUG:root:Destroying network net
    > Bad blob sharing
27-Oct 05:41:11:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:11:INFO:root:Topological sorting 6 layers...
27-Oct 05:41:11:INFO:root:Setup layers...
27-Oct 05:41:11:INFO:root:Network constructed!
-- Testing network topology with dangling blob
    > Good case
27-Oct 05:41:12:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:12:INFO:root:Topological sorting 4 layers...
27-Oct 05:41:12:INFO:root:Setup layers...
27-Oct 05:41:12:INFO:root:Network constructed!
27-Oct 05:41:12:DEBUG:root:Destroying network net
    > Bad case
27-Oct 05:41:12:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:12:INFO:root:Topological sorting 4 layers...
27-Oct 05:41:12:INFO:root:Setup layers...
27-Oct 05:41:12:INFO:root:Network constructed!
27-Oct 05:41:12:DEBUG:root:Destroying network net
    > Good case 2
27-Oct 05:41:13:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:13:INFO:root:Topological sorting 5 layers...
27-Oct 05:41:13:INFO:root:Setup layers...
27-Oct 05:41:13:INFO:root:Network constructed!
27-Oct 05:41:13:DEBUG:root:Destroying network net
    > Bad case 2
27-Oct 05:41:13:INFO:root:Constructing net net on Mocha.CPUBackend...
27-Oct 05:41:13:INFO:root:Topological sorting 6 layers...
27-Oct 05:41:13:INFO:root:Setup layers...
27-Oct 05:41:13:INFO:root:Network constructed!
27-Oct 05:41:13:DEBUG:root:Destroying network net
-- Testing gradients on simple network (example for gradient checking code)
27-Oct 05:41:13:INFO:root:Constructing net TEST on Mocha.CPUBackend...
27-Oct 05:41:13:INFO:root:Topological sorting 4 layers...
27-Oct 05:41:13:INFO:root:Setup layers...
27-Oct 05:41:13:INFO:root:Network constructed!
-- Testing simple reference counting...
-- Testing glob Utilities
-- Testing RawBLAS{Float32} Utilities
-- Testing RawBLAS{Float64} Utilities
-- Testing blob reshape on Mocha.CPUBackend{Float32}...
-- Testing blob reshape on Mocha.CPUBackend{Float64}...
-- Testing ReLU neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing ReLU neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Sigmoid neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Sigmoid neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Tanh neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Tanh neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing Exponential neuron on Mocha.CPUBackend{Float32}...
    > Forward
    > Backward
-- Testing Exponential neuron on Mocha.CPUBackend{Float64}...
    > Forward
    > Backward
-- Testing L2 regularizer on Mocha.CPUBackend{Float32}...
-- Testing L2 regularizer on Mocha.CPUBackend{Float64}...
-- Testing L1 regularizer on Mocha.CPUBackend{Float32}...
-- Testing L1 regularizer on Mocha.CPUBackend{Float64}...
-- Testing L2 constraint on Mocha.CPUBackend{Float32}...
-- Testing L2 constraint on Mocha.CPUBackend{Float64}...
-- Testing DataTransformers on Mocha.CPUBackend{Float32}...
    > SubMean
    > Scale
-- Testing DataTransformers on Mocha.CPUBackend{Float64}...
    > SubMean
    > Scale
-- Testing TiedInnerProductLayer on Mocha.CPUBackend{Float32}...
    > Setup
27-Oct 05:41:21:INFO:root:Constructing net test-tied-ip on Mocha.CPUBackend...
27-Oct 05:41:21:INFO:root:Topological sorting 3 layers...
27-Oct 05:41:21:INFO:root:Setup layers...
27-Oct 05:41:21:INFO:root:Network constructed!
27-Oct 05:41:21:DEBUG:root:Init network test-tied-ip
27-Oct 05:41:21:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:41:22:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:41:22:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
27-Oct 05:41:22:DEBUG:root:Destroying network test-tied-ip
-- Testing TiedInnerProductLayer on Mocha.CPUBackend{Float64}...
    > Setup
27-Oct 05:41:22:INFO:root:Constructing net test-tied-ip on Mocha.CPUBackend...
27-Oct 05:41:22:INFO:root:Topological sorting 3 layers...
27-Oct 05:41:22:INFO:root:Setup layers...
27-Oct 05:41:22:INFO:root:Network constructed!
27-Oct 05:41:22:DEBUG:root:Init network test-tied-ip
27-Oct 05:41:22:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:41:22:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:41:22:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
27-Oct 05:41:22:DEBUG:root:Destroying network test-tied-ip
-- Testing RandomMask on Mocha.CPUBackend{Float64}
    > 3 input blobs with tensor dims [3,2,2]
    > Setup
    > Forward
    > Backward
-- Testing RandomMask on Mocha.CPUBackend{Float32}
    > 3 input blobs with tensor dims [2,6,4]
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max)  on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean)  on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max) with padding on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean) with padding on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max)  on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean)  on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Max) with padding on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing Pooling(Mocha.Pooling.Mean) with padding on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing  HDF5 Data Layer on Mocha.CPUBackend{Float32}...
    > (1,3,6,4)
-- Testing (Async) HDF5 Data Layer on Mocha.CPUBackend{Float32}...
    > (1,4,4,6,8,2)
27-Oct 05:41:36:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:36:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer on Mocha.CPUBackend{Float64}...
    > (6,5)
-- Testing (Async) HDF5 Data Layer on Mocha.CPUBackend{Float64}...
    > (7,6,2,2,3)
27-Oct 05:41:37:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:37:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float32}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float32}...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float32}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float32}...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float64}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=6,b=4) on Mocha.CPUBackend{Float64}...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing  HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float64}...
-- Testing (Async) HDF5 Data Layer (shuffle,n=4,b=6) on Mocha.CPUBackend{Float64}...
WARNING: data not shuffled, is today a lucky day or is there a bug?
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: Stopping IO task...
27-Oct 05:41:38:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 3 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 3 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 2 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 1 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float32}...
    > Setup (pool along dimension 2 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Max) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 6-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 1 for 2-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 3-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 3 for 4-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 5-D tensors)
    > Forward
    > Backward
-- Testing ChannelPooling(Mocha.Pooling.Mean) on Mocha.CPUBackend{Float64}...
    > Setup (pool along dimension 2 for 6-D tensors)
    > Forward
    > Backward
-- Testing SquareLossLayer on Mocha.CPUBackend{Float32}...
    > (9,8)
-- Testing SquareLossLayer on Mocha.CPUBackend{Float64}...
    > (9,6,11,6)
-- Testing SplitLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing SplitLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (11,11) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (9,7,7,7) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} ...
    > (8,7,10,7,6) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (11,9) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (8,9,9,11) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float64} (with weights)...
    > (9,11,9,10,6) (operate on dimension 4)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (10,7) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (9,6,6,7) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} ...
    > (6,6,7,11,10) (operate on dimension 2)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (7,6) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (11,8,9,8) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftmaxLossLayer on Mocha.CPUBackend{Float32} (with weights)...
    > (10,7,9,10,8) (operate on dimension 4)
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional input, normalize along dimension 3
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional input, normalize along dimension 2
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftmaxLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional input, normalize along dimension 1
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (9,9) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (9,8,6,8) (operate on dimension 3)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float64}...
    > (6,8,10,10,11) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (9,8) (operate on dimension 1)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (11,10,8,7) (operate on dimension 2)
    > Forward
    > Backward
-- Testing SoftlabelSoftmaxLossLayer on Mocha.CPUBackend{Float32}...
    > (8,6,6,9,6) (operate on dimension 4)
    > Forward
    > Backward
-- Testing convolution layer with shared param on Mocha.CPUBackend{Float64}...
27-Oct 05:42:33:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
27-Oct 05:42:33:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:33:INFO:root:Setup layers...
27-Oct 05:42:34:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias
27-Oct 05:42:34:INFO:root:Network constructed!
27-Oct 05:42:34:DEBUG:root:Init network test-shared-params
27-Oct 05:42:34:DEBUG:root:Init parameter filter for layer conv1
27-Oct 05:42:34:DEBUG:root:Init parameter bias for layer conv1
27-Oct 05:42:34:DEBUG:root:Destroying network test-shared-params
-- Testing inner-product layer with shared param on Mocha.CPUBackend{Float64}...
27-Oct 05:42:34:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
27-Oct 05:42:34:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:34:INFO:root:Setup layers...
27-Oct 05:42:34:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias
27-Oct 05:42:34:INFO:root:Network constructed!
27-Oct 05:42:34:DEBUG:root:Init network test-shared-params
27-Oct 05:42:34:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:42:34:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:42:34:DEBUG:root:Destroying network test-shared-params
-- Testing convolution layer with shared param on Mocha.CPUBackend{Float32}...
27-Oct 05:42:34:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
27-Oct 05:42:34:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:34:INFO:root:Setup layers...
27-Oct 05:42:34:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias
27-Oct 05:42:34:INFO:root:Network constructed!
27-Oct 05:42:34:DEBUG:root:Init network test-shared-params
27-Oct 05:42:34:DEBUG:root:Init parameter filter for layer conv1
27-Oct 05:42:34:DEBUG:root:Init parameter bias for layer conv1
27-Oct 05:42:34:DEBUG:root:Destroying network test-shared-params
-- Testing inner-product layer with shared param on Mocha.CPUBackend{Float32}...
27-Oct 05:42:34:INFO:root:Constructing net test-shared-params on Mocha.CPUBackend...
27-Oct 05:42:34:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:34:INFO:root:Setup layers...
27-Oct 05:42:34:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias
27-Oct 05:42:34:INFO:root:Network constructed!
27-Oct 05:42:34:DEBUG:root:Init network test-shared-params
27-Oct 05:42:34:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:42:34:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:42:35:DEBUG:root:Destroying network test-shared-params
-- Testing ReshapeLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing ReshapeLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing RandomNormal Layer on Mocha.CPUBackend{Float32}...
    > Random output 2[2,3]
-- Testing RandomNormal Layer on Mocha.CPUBackend{Float64}...
    > Random output 2[2,2]
-- Testing PowerLayer on Mocha.CPUBackend{Float32}...
    > scale=0.31, shift=0.53, power=2, tensor_dim=3
    > scale=0, shift=0.29, power=2, tensor_dim=2
    > scale=0.45, shift=0.34, power=2, tensor_dim=6
    > scale=0.99, shift=0, power=3, tensor_dim=1
    > scale=0.74, shift=0.95, power=4, tensor_dim=5
    > scale=0.9, shift=0.59, power=0, tensor_dim=6
    > scale=0.91, shift=0.08, power=1, tensor_dim=1
    > scale=0.32, shift=0.06, power=-1, tensor_dim=6
-- Testing PowerLayer on Mocha.CPUBackend{Float64}...
    > scale=0.28, shift=0.17, power=2, tensor_dim=4
    > scale=0, shift=0.63, power=5, tensor_dim=6
    > scale=0.74, shift=0.75, power=2, tensor_dim=4
    > scale=0.99, shift=0, power=3, tensor_dim=3
    > scale=0.24, shift=0.54, power=4, tensor_dim=2
    > scale=1.0, shift=0.37, power=0, tensor_dim=5
    > scale=0.08, shift=0.84, power=1, tensor_dim=4
    > scale=0.49, shift=0.76, power=-1, tensor_dim=4
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [11,10] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [7,6,10,10] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float64}...
    > [11,9,6,7,10] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [7,10] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [8,7,9,9] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float64}...
    > [7,11,8,9,7] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [7,8] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [6,8,7,6] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float64}...
    > [6,11,7,10,7] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [11,9] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [9,7,7,10] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float64}...
    > [9,10,7,10,9] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [7,6] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [11,8,11,11] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float64}...
    > [9,7,10,11,10] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [8,6] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [6,7,11,8] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{equal,local} on Mocha.CPUBackend{Float32}...
    > [9,7,6,7,11] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [6,8] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [6,8,8,11] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{local,local} on Mocha.CPUBackend{Float32}...
    > [11,9,6,7,10] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [8,11] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [8,9,8,11] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,global} on Mocha.CPUBackend{Float32}...
    > [6,6,11,10,6] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [11,8] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [9,11,8,8] (operate on dimension 3)
-- Testing MultinomialLogisticLossLayer{global,local} on Mocha.CPUBackend{Float32}...
    > [9,11,11,9,9] (operate on dimension 4)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [11,9] (operate on dimension 1)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [7,11,10,10] (operate on dimension 2)
-- Testing MultinomialLogisticLossLayer{no,no} on Mocha.CPUBackend{Float32}...
    > [8,9,10,9,6] (operate on dimension 3)
-- Testing Memory Output Layer on Mocha.CPUBackend{Float32}...
    > (4,8,1,7,4)
-- Testing Memory Output Layer on Mocha.CPUBackend{Float64}...
    > (4,2,1)
-- Testing Memory Data Layer on Mocha.CPUBackend{Float32}...
    > (5,2,5)
-- Testing Memory Data Layer on Mocha.CPUBackend{Float64}...
    > (2,2,1,3,4,5)
-- Testing LRN(Mocha.LRNMode.AcrossChannel) on Mocha.CPUBackend{Float32}...
    > Setup with dims (11,7,9,7)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.WithinChannel) on Mocha.CPUBackend{Float32}...
    > Setup with dims (6,7,11,6)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.AcrossChannel) on Mocha.CPUBackend{Float64}...
    > Setup with dims (6,8,10,9)
    > Forward
    > Backward
-- Testing LRN(Mocha.LRNMode.WithinChannel) on Mocha.CPUBackend{Float64}...
    > Setup with dims (11,6,8,9)
    > Forward
    > Backward
-- Testing InplaceLayer on Mocha.CPUBackend{Float64}...
    > Setup
27-Oct 05:42:46:INFO:root:Constructing net test-inplace on Mocha.CPUBackend...
27-Oct 05:42:46:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:46:INFO:root:Setup layers...
27-Oct 05:42:46:INFO:root:Network constructed!
27-Oct 05:42:46:DEBUG:root:Init network test-inplace
27-Oct 05:42:46:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:42:46:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:42:46:DEBUG:root:Init parameter weight for layer ip2
27-Oct 05:42:46:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
27-Oct 05:42:46:DEBUG:root:Destroying network test-inplace
-- Testing InplaceLayer on Mocha.CPUBackend{Float32}...
    > Setup
27-Oct 05:42:46:INFO:root:Constructing net test-inplace on Mocha.CPUBackend...
27-Oct 05:42:46:INFO:root:Topological sorting 5 layers...
27-Oct 05:42:46:INFO:root:Setup layers...
27-Oct 05:42:46:INFO:root:Network constructed!
27-Oct 05:42:46:DEBUG:root:Init network test-inplace
27-Oct 05:42:46:DEBUG:root:Init parameter weight for layer ip1
27-Oct 05:42:46:DEBUG:root:Init parameter bias for layer ip1
27-Oct 05:42:46:DEBUG:root:Init parameter weight for layer ip2
27-Oct 05:42:46:DEBUG:root:Init parameter bias for layer ip2
    > Forward
    > Backward
27-Oct 05:42:47:DEBUG:root:Destroying network test-inplace
-- Testing InnerProductLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
    > Backward
-- Testing InnerProductLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
    > Backward
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional input, expanding along dimension 2
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional input, expanding along dimension 2
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional input, expanding along dimension 1
-- Testing Index2OnehotLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional input, expanding along dimension 1
-- Testing IdentityLayer on Mocha.CPUBackend{Float32}...
    > Setup
    > Forward
-- Testing IdentityLayer on Mocha.CPUBackend{Float64}...
    > Setup
    > Forward
-- Testing HingeLossLayer on Mocha.CPUBackend{Float32}...
    > (8,7)
-- Testing HingeLossLayer on Mocha.CPUBackend{Float64}...
    > (8,11,6,6)
-- Testing HDF5 Output Layer on Mocha.CPUBackend{Float32}...
    > (6,4,3,2,4)
27-Oct 05:42:49:WARNING:root:HDF5OutputLayer: output file '/tmp/Mocha-32482-sU0vn7hjuJCA7bMwa8RIip4O7DWBKLYw.hdf5' already exists, overwriting
-- Testing HDF5 Output Layer on Mocha.CPUBackend{Float64}...
    > (8,2,5,2,8)
27-Oct 05:42:49:WARNING:root:HDF5OutputLayer: output file '/tmp/Mocha-32482-lGJ3BIVN0RAEhK6qMvNFimr7yVuP8flk.hdf5' already exists, overwriting
-- Testing GaussianKLLossLayer on Mocha.CPUBackend{Float32}...
    > (9,11,6,6,8)
-- Testing GaussianKLLossLayer on Mocha.CPUBackend{Float64}...
    > (8,11,8,8,8)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Add()} on Mocha.CPUBackend{Float32}...
    > (2,2,1,2,8)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Subtract()} on Mocha.CPUBackend{Float32}...
    > (1,)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Multiply()} on Mocha.CPUBackend{Float32}...
    > (7,)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Divide()} on Mocha.CPUBackend{Float32}...
    > (2,3)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Add()} on Mocha.CPUBackend{Float64}...
    > (7,)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Subtract()} on Mocha.CPUBackend{Float64}...
    > (3,2,3)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Multiply()} on Mocha.CPUBackend{Float64}...
    > (1,6,6,2,7)
-- Testing ElementWiseLayer{Mocha.ElementWiseFunctors.Divide()} on Mocha.CPUBackend{Float64}...
    > (2,2,3)
-- Testing Dropout on Mocha.CPUBackend{Float64}...
    > (3,2,2,8)
    > Setup
    > Forward
    > Backward
-- Testing Dropout on Mocha.CPUBackend{Float32}...
    > (8,8,3,2,7)
    > Setup
    > Forward
    > Backward
-- Testing CropLayer on Mocha.CPUBackend{Float64} ...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float64} with mirror...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float64} ...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float64} with mirror...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float32} ...
    > Setup
    > Forward
-- Testing CropLayer on Mocha.CPUBackend{Float32} with mirror...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float32} ...
    > Setup
    > Forward
-- Testing CropLayer{rnd} on Mocha.CPUBackend{Float32} with mirror...
    > Setup
    > Forward
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float64} filter=(3,4)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float64} filter=(3,4)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 3.410605131648481e-12
eps = 1.0e-5
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float64} filter=(1,1)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float64} filter=(1,1)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 7.73070496506989e-12
eps = 1.0e-5
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float32} filter=(3,4)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float32} filter=(3,4)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 0.0015869141f0
eps = 0.01
-- Testing Convolution(frozen=true) on Mocha.CPUBackend{Float32} filter=(1,1)...
    > Setup
    > Forward
    > Backward
-- Testing Convolution(frozen=false) on Mocha.CPUBackend{Float32} filter=(1,1)...
    > Setup
    > Forward
    > Backward
maximum(abs(grad_filter_exp - grad_filter_got)) = 0.00390625f0
eps = 0.01
-- Testing ConcatLayer(dim=1) on Mocha.CPUBackend{Float64}...
    > 3-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=2) on Mocha.CPUBackend{Float64}...
    > 4-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=3) on Mocha.CPUBackend{Float64}...
    > 5-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=4) on Mocha.CPUBackend{Float64}...
    > 6-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=5) on Mocha.CPUBackend{Float64}...
    > 6-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=1) on Mocha.CPUBackend{Float32}...
    > 5-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=2) on Mocha.CPUBackend{Float32}...
    > 7-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=3) on Mocha.CPUBackend{Float32}...
    > 3-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=4) on Mocha.CPUBackend{Float32}...
    > 4-dimensional tensor
    > Forward
    > Backward
-- Testing ConcatLayer(dim=5) on Mocha.CPUBackend{Float32}...
    > 5-dimensional tensor
    > Forward
    > Backward
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [3,2]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [6,6,7,2]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float32}...
    > [2,7,7,5,2]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [2,5]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [3,2,2,6]
-- Testing BinaryCrossEntropyLossLayer on Mocha.CPUBackend{Float64}...
    > [2,4,6,7,2]
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (7,6)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (6,11)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (9,7,9,11)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (8,7,9,7)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (6,10,6,10,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float32}...
    > (11,10,9,8,10)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (11,6)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (9,6)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (7,9,8,10)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (10,10,8,8)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (7,11,11,6,6)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing BinaryAccuracyLayer on Mocha.CPUBackend{Float64}...
    > (7,7,11,8,7)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 2-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 4-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float64}...
    > 5-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 2-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 4-dimensional tensor
    > Setup
    > Forward
-- Testing ArgmaxLayer on Mocha.CPUBackend{Float32}...
    > 5-dimensional tensor
    > Setup
    > Forward
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (9,6) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (6,6,9,9) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float32}...
    > (11,10,11,6,7) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (7,6) (operate on dimension 1)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (11,6,9,11) (operate on dimension 3)
    > Forward
    > Forward Again
    > Forward Again and Again
-- Testing AccuracyLayer on Mocha.CPUBackend{Float64}...
    > (10,11,7,7,6) (operate on dimension 3)
    > Forward
    > Forward Again
    > Forward Again and Again
INFO: Mocha tests passed

>>> End of log
