>>> 'Pkg.add("DecisionTree")' log
INFO: Cloning cache of DecisionTree from https://github.com/bensadeghi/DecisionTree.jl.git
INFO: Installing DecisionTree v0.4.2
INFO: Installing ScikitLearnBase v0.1.0
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of DecisionTree
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("DecisionTree")' log
Julia Version 0.5.0-dev+4826
Commit 979f4d8* (2016-06-17 00:17 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
INFO: Testing DecisionTree

WARNING: deprecated syntax "[a=>b for (a,b) in c]".
Use "Dict(a=>b for (a,b) in c)" instead.

WARNING: deprecated syntax "[a=>b for (a,b) in c]".
Use "Dict(a=>b for (a,b) in c)" instead.

WARNING: deprecated syntax "[a=>b for (a,b) in c]".
Use "Dict(a=>b for (a,b) in c)" instead.
Running tests...
Test: classification_rand.jl

##### nfoldCV Classification Tree #####

Fold 1
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 2 0 0 0; 1 63 11 0 0; 0 18 169 15 0; 0 0 10 41 1; 0 0 0 1 1]
Accuracy: 0.8228228228228228
Kappa:    0.689689484158322

Fold 2
Classes:  Any[-1,0,1,2]
Matrix:   [42 22 0 0; 14 176 16 0; 0 14 45 3; 0 0 1 0]
Accuracy: 0.7897897897897898
Kappa:    0.6101093901582308

Fold 3
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 2 0 0 0; 0 53 14 0 0; 0 9 162 21 0; 0 0 20 45 5; 0 0 0 1 1]
Accuracy: 0.7837837837837838
Kappa:    0.6269313955840478

Mean Accuracy: 0.7987987987987988

##### nfoldCV Classification Forest #####

Fold 1
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 1 0 0 0; 0 42 29 0 0; 0 6 192 4 0; 0 0 22 36 0; 0 0 0 0 1]
Accuracy: 0.8138138138138138
Kappa:    0.6313411781511704

Fold 2
Classes:  Any[-1,0,1]
Matrix:   [56 20 0; 2 198 4; 0 15 38]
Accuracy: 0.8768768768768769
Kappa:    0.7593039860374098

Fold 3
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 3 0 0 0; 0 32 27 0 0; 0 3 188 2 0; 0 0 38 36 0; 0 0 0 4 0]
Accuracy: 0.7687687687687688
Kappa:    0.5478575207194497

Mean Accuracy: 0.8198198198198199

##### nfoldCV Adaboosted Stumps #####

Fold 1
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 0 1 0 0; 0 1 72 0 0; 0 0 194 0 0; 0 0 63 0 0; 0 0 2 0 0]
Accuracy: 0.5855855855855856
Kappa:    0.009782796069643216

Fold 2
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 1 1 0 0; 0 0 70 0 0; 0 0 198 2 0; 0 0 60 0 0; 0 0 1 0 0]
Accuracy: 0.5945945945945946
Kappa:    -0.005727197476453453

Fold 3
Classes:  Any[-2,-1,0,1,2]
Matrix:   [0 0 1 0 0; 0 1 62 0 0; 0 0 205 0 0; 0 0 62 0 0; 0 0 2 0 0]
Accuracy: 0.6186186186186187
Kappa:    0.011106954122433971

Mean Accuracy: 0.5995995995995996
==================================================
Test: regression_rand.jl

##### nfoldCV Regression Tree #####

Fold 1
Mean Squared Error:     1.559945052369641
Correlation Coeff:      0.8775547564768988
Coeff of Determination: 0.7630081498434831

Fold 2
Mean Squared Error:     2.1473046015456623
Correlation Coeff:      0.8655996529198493
Coeff of Determination: 0.7383525471094439

Fold 3
Mean Squared Error:     2.3878048509208156
Correlation Coeff:      0.8638036104056254
Coeff of Determination: 0.7419710276610605

Mean Coeff of Determination: 0.7477772415379959

##### nfoldCV Regression Forest #####

Fold 1
Mean Squared Error:     1.108454697043893
Correlation Coeff:      0.948468567883996
Coeff of Determination: 0.8692094427178932

Fold 2
Mean Squared Error:     0.9622688509016862
Correlation Coeff:      0.9484521056461392
Coeff of Determination: 0.8665314456297021

Fold 3
Mean Squared Error:     1.2292211658977443
Correlation Coeff:      0.946285521101888
Coeff of Determination: 0.8519806989679366

Mean Coeff of Determination: 0.8625738624385106
==================================================
Test: classification_scikitlearn.jl
==================================================
Test: regression_scikitlearn.jl
==================================================
INFO: DecisionTree tests passed

>>> End of log
