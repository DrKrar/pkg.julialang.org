>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from git://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing Blosc v0.1.4
INFO: Installing Clustering v0.4.0
INFO: Installing Distances v0.2.0
INFO: Installing Distributions v0.8.7
INFO: Installing GaussianMixtures v0.0.10
INFO: Installing HDF5 v0.5.6
INFO: Installing JLD v0.5.4
INFO: Installing PDMats v0.3.6
INFO: Installing StatsBase v0.7.3
INFO: Installing StatsFuns v0.1.4
INFO: Building Blosc
INFO: Building HDF5
INFO: Package database updated

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.3.11
Commit 483dbf5* (2015-07-27 06:18 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E5-2650 0 @ 2.00GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Sandybridge)
  LAPACK: libopenblas
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing GaussianMixtures
INFO: Testing Data
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.670948e+03
      1       1.160866e+03      -5.100818e+02 |        7
      2       1.061847e+03      -9.901925e+01 |        6
      3       9.754868e+02      -8.635976e+01 |        2
      4       9.691591e+02      -6.327700e+00 |        0
      5       9.691591e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 969.1590899958119)
INFO: K-means with 272 data points using 5 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.068644
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.895780
INFO: iteration 2, lowerbound -3.817816
INFO: iteration 3, lowerbound -3.735944
INFO: iteration 4, lowerbound -3.624965
INFO: iteration 5, lowerbound -3.481702
INFO: iteration 6, lowerbound -3.316341
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -3.137761
INFO: iteration 8, lowerbound -2.960195
INFO: dropping number of Gaussions to 6
INFO: iteration 9, lowerbound -2.794857
INFO: iteration 10, lowerbound -2.648991
INFO: dropping number of Gaussions to 5
INFO: iteration 11, lowerbound -2.532660
INFO: iteration 12, lowerbound -2.447818
INFO: iteration 13, lowerbound -2.400931
INFO: dropping number of Gaussions to 3
INFO: iteration 14, lowerbound -2.362025
INFO: iteration 15, lowerbound -2.328334
INFO: iteration 16, lowerbound -2.311309
INFO: iteration 17, lowerbound -2.307838
INFO: dropping number of Gaussions to 2
INFO: iteration 18, lowerbound -2.302917
INFO: iteration 19, lowerbound -2.299259
INFO: iteration 20, lowerbound -2.299256
INFO: iteration 21, lowerbound -2.299254
INFO: iteration 22, lowerbound -2.299254
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: 31 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Sun 27 Sep 2015 01:29:34 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sun 27 Sep 2015 01:29:35 AM UTC: K-means with 272 data points using 5 iterations
11.3 data points per parameter
,Sun 27 Sep 2015 01:29:36 AM UTC: EM with 272 data points 0 iterations avll -2.068644
5.8 data points per parameter
,Sun 27 Sep 2015 01:29:37 AM UTC: GMM converted to Variational GMM
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 1, lowerbound -3.895780
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 2, lowerbound -3.817816
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 3, lowerbound -3.735944
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 4, lowerbound -3.624965
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 5, lowerbound -3.481702
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 6, lowerbound -3.316341
,Sun 27 Sep 2015 01:29:39 AM UTC: dropping number of Gaussions to 7
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 7, lowerbound -3.137761
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 8, lowerbound -2.960195
,Sun 27 Sep 2015 01:29:39 AM UTC: dropping number of Gaussions to 6
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 9, lowerbound -2.794857
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 10, lowerbound -2.648991
,Sun 27 Sep 2015 01:29:39 AM UTC: dropping number of Gaussions to 5
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 11, lowerbound -2.532660
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 12, lowerbound -2.447818
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 13, lowerbound -2.400931
,Sun 27 Sep 2015 01:29:39 AM UTC: dropping number of Gaussions to 3
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 14, lowerbound -2.362025
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 15, lowerbound -2.328334
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 16, lowerbound -2.311309
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 17, lowerbound -2.307838
,Sun 27 Sep 2015 01:29:39 AM UTC: dropping number of Gaussions to 2
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 18, lowerbound -2.302917
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 19, lowerbound -2.299259
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 20, lowerbound -2.299256
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 21, lowerbound -2.299254
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 22, lowerbound -2.299254
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 23, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 24, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 25, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 26, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 27, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 28, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 29, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: iteration 30, lowerbound -2.299253
,Sun 27 Sep 2015 01:29:39 AM UTC: 31 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450926905923,95.95490730940772]
β = [178.0450926905923,95.95490730940772]
m = [4.250300729501825 79.2868668889465
 2.000229253873062 53.85198715213852]
ν = [180.0450926905923,97.95490730940772]
W = [
[0.18404155495521546 -0.007644049091824958
 0.0 0.008581705096685406],

[0.3758763676818089 -0.008953123904361593
 0.0 0.012748664797147514]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9736205557680273
avll from llpg:  -0.9736205557680184
ERROR: MemoryError()
 in A_mul_Bt at linalg/matmul.jl:141
 in llpg at /home/vagrant/.julia/v0.3/GaussianMixtures/src/train.jl:294
 in avll at /home/vagrant/.julia/v0.3/GaussianMixtures/src/train.jl:336
 in anonymous at no file:15
 in include at ./boot.jl:245
 in include_from_node1 at ./loading.jl:128
 in include at ./boot.jl:245
 in include_from_node1 at loading.jl:128
 in process_options at ./client.jl:285
 in _start at ./client.jl:354
while loading /home/vagrant/.julia/v0.3/GaussianMixtures/test/train.jl, in expression starting on line 2
while loading /home/vagrant/.julia/v0.3/GaussianMixtures/test/runtests.jl, in expression starting on line 7
==========================[ ERROR: GaussianMixtures ]===========================

failed process: Process(`/home/vagrant/julia/bin/julia /home/vagrant/.julia/v0.3/GaussianMixtures/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
INFO: No packages to install, update or remove
ERROR: GaussianMixtures had test errors
 in error at error.jl:21
 in test at pkg/entry.jl:718
 in anonymous at pkg/dir.jl:28
 in cd at ./file.jl:20
 in cd at pkg/dir.jl:28
 in test at pkg.jl:67
 in process_options at ./client.jl:213
 in _start at ./client.jl:354

>>> End of log
