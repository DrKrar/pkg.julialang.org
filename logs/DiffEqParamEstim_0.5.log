>>> 'Pkg.add("DiffEqParamEstim")' log
INFO: Cloning cache of DiffEqParamEstim from https://github.com/JuliaDiffEq/DiffEqParamEstim.jl.git
INFO: Cloning cache of LearnBase from https://github.com/JuliaML/LearnBase.jl.git
INFO: Cloning cache of LossFunctions from https://github.com/JuliaML/LossFunctions.jl.git
INFO: Cloning cache of LsqFit from https://github.com/JuliaOpt/LsqFit.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Calculus v0.2.0
INFO: Installing DataStructures v0.5.2
INFO: Installing DiffBase v0.0.4
INFO: Installing DiffEqBase v0.8.0
INFO: Installing DiffEqParamEstim v0.1.0
INFO: Installing Distributions v0.12.0
INFO: Installing ForwardDiff v0.3.4
INFO: Installing LearnBase v0.1.1
INFO: Installing LineSearches v0.1.5
INFO: Installing LossFunctions v0.0.2
INFO: Installing LsqFit v0.1.1
INFO: Installing MacroTools v0.3.4
INFO: Installing NaNMath v0.2.2
INFO: Installing Optim v0.7.4
INFO: Installing PDMats v0.5.4
INFO: Installing Parameters v0.6.0
INFO: Installing PositiveFactorizations v0.0.4
INFO: Installing QuadGK v0.1.1
INFO: Installing Ranges v0.0.1
INFO: Installing RecipesBase v0.1.0
INFO: Installing RecursiveArrayTools v0.2.0
INFO: Installing Reexport v0.0.3
INFO: Installing Rmath v0.1.6
INFO: Installing SHA v0.3.0
INFO: Installing SimpleTraits v0.2.0
INFO: Installing StatsBase v0.13.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Rmath
INFO: Package database updated

>>> 'Pkg.test("DiffEqParamEstim")' log
Julia Version 0.5.0
Commit 3c9d753 (2016-09-19 18:14 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-107-generic #154-Ubuntu SMP Tue Dec 20 09:57:27 UTC 2016 x86_64 x86_64
Memory: 2.9392738342285156 GB (1672.8359375 MB free)
Uptime: 24683.0 sec
Load Avg:  0.923828125  0.9921875  1.029296875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3505 MHz    1432973 s       2510 s     149562 s     583750 s         76 s
#2  3505 MHz     501664 s       5801 s      78223 s    1807986 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - DiffEqParamEstim              0.1.0
 - JSON                          0.8.2
29 additional packages:
 - BinDeps                       0.4.5
 - Calculus                      0.2.0
 - Compat                        0.14.0
 - DataStructures                0.5.2
 - DiffBase                      0.0.4
 - DiffEqBase                    0.8.0
 - Distributions                 0.12.0
 - ForwardDiff                   0.3.4
 - LearnBase                     0.1.1
 - LineSearches                  0.1.5
 - LossFunctions                 0.0.2
 - LsqFit                        0.1.1
 - MacroTools                    0.3.4
 - NaNMath                       0.2.2
 - Optim                         0.7.4
 - PDMats                        0.5.4
 - Parameters                    0.6.0
 - PositiveFactorizations        0.0.4
 - QuadGK                        0.1.1
 - Ranges                        0.0.1
 - RecipesBase                   0.1.0
 - RecursiveArrayTools           0.2.0
 - Reexport                      0.0.3
 - Rmath                         0.1.6
 - SHA                           0.3.0
 - SimpleTraits                  0.2.0
 - StatsBase                     0.13.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Computing test dependencies for DiffEqParamEstim...
INFO: Cloning cache of LeastSquaresOptim from https://github.com/matthieugomez/LeastSquaresOptim.jl.git
INFO: Cloning cache of NLopt from https://github.com/JuliaOpt/NLopt.jl.git
INFO: Installing Combinatorics v0.3.2
INFO: Installing Conda v0.4.0
INFO: Downgrading DiffEqBase: v0.8.0 => v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing GenericSVD v0.0.2
INFO: Installing Hiccup v0.1.1
INFO: Installing InplaceOps v0.1.0
INFO: Installing Iterators v0.2.0
INFO: Installing Juno v0.2.5
INFO: Installing LeastSquaresOptim v0.2.1
INFO: Installing MathProgBase v0.5.10
INFO: Installing Media v0.2.5
INFO: Installing NLopt v0.3.3
INFO: Installing NLsolve v0.9.1
INFO: Installing OrdinaryDiffEq v1.1.0
INFO: Installing ParameterizedFunctions v0.6.0
INFO: Installing PolynomialFactors v0.0.3
INFO: Installing Polynomials v0.1.2
INFO: Installing Primes v0.1.2
INFO: Installing Roots v0.3.0
INFO: Installing SymEngine v0.1.2
INFO: Building Conda
INFO: Building NLopt
Installing dependency libnlopt0 via `sudo apt-get install libnlopt0`:
Reading package lists...
Building dependency tree...
Reading state information...
The following NEW packages will be installed:
  libnlopt0
0 upgraded, 1 newly installed, 0 to remove and 4 not upgraded.
Need to get 161 kB of archives.
After this operation, 468 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu/ trusty/universe libnlopt0 amd64 2.4.1+dfsg-1ubuntu1 [161 kB]
dpkg-preconfigure: unable to re-open stdin: No such file or directory
Fetched 161 kB in 0s (367 kB/s)
Selecting previously unselected package libnlopt0:amd64.
(Reading database ... 86190 files and directories currently installed.)
Preparing to unpack .../libnlopt0_2.4.1+dfsg-1ubuntu1_amd64.deb ...
Unpacking libnlopt0:amd64 (2.4.1+dfsg-1ubuntu1) ...
Setting up libnlopt0:amd64 (2.4.1+dfsg-1ubuntu1) ...
Processing triggers for libc-bin (2.19-0ubuntu6.9) ...
INFO: Building SymEngine
Warning: 'conda-forge' already in 'channels' list, moving to the top
Warning: 'symengine' already in 'channels' list, moving to the top
INFO: Testing DiffEqParamEstim
Use LM to fit the parameter
     0     2.814479e+03              NaN
 * lambda: 10000.0

     1     2.814476e+03     8.759775e+02
 * g(x): 875.977512780833
 * lambda: 1000.0
 * dx: [1.77405e-6]

     2     2.814445e+03     8.752073e+02
 * g(x): 875.2073383925207
 * lambda: 100.0
 * dx: [1.77247e-5]

     3     2.814137e+03     8.675246e+02
 * g(x): 867.5246401245004
 * lambda: 10.0
 * dx: [0.000175674]

     4     2.810278e+03     8.088337e+02
 * g(x): 808.8337046482011
 * lambda: 1.0
 * dx: [0.00161355]

     5     2.787323e+03     5.308497e+02
 * g(x): 530.8496786114838
 * lambda: 0.1
 * dx: [0.0101675]

     6     2.732608e+03     1.040750e+02
 * g(x): 104.07502138744468
 * lambda: 0.010000000000000002
 * dx: [0.0213257]

     7     2.645808e+03     6.446443e+01
 * g(x): 64.46443485151312
 * lambda: 0.0010000000000000002
 * dx: [0.0284713]

     8     2.532179e+03     7.460518e+01
 * g(x): 74.6051807110804
 * lambda: 0.00010000000000000003
 * dx: [0.0341982]

     9     2.397806e+03     1.143433e+02
 * g(x): 114.34325443685549
 * lambda: 1.0000000000000004e-5
 * dx: [0.0380117]

    10     2.247223e+03     1.433400e+02
 * g(x): 143.3400449585264
 * lambda: 1.0000000000000004e-6
 * dx: [0.040818]

    11     1.981626e+03     1.128495e+02
 * g(x): 112.84949462690315
 * lambda: 1.0000000000000005e-7
 * dx: [0.0488566]

    12     1.474757e+03     2.572492e+02
 * g(x): 257.2491980967805
 * lambda: 1.0000000000000005e-8
 * dx: [0.0636711]

    13     7.505073e+02     8.299717e+02
 * g(x): 829.9716938230273
 * lambda: 1.0000000000000005e-9
 * dx: [0.076301]

    14     1.163524e+02     8.573549e+02
 * g(x): 857.3549427791675
 * lambda: 1.0000000000000006e-10
 * dx: [0.0861846]

    15     9.024655e-01     1.778318e+02
 * g(x): 177.8318298948238
 * lambda: 1.0000000000000006e-11
 * dx: [0.0457611]

    16     4.212356e-02     2.772456e-01
 * g(x): 0.2772456361737228
 * lambda: 1.0000000000000006e-12
 * dx: [0.00437125]

    17     4.212218e-02     2.941116e-07
 * g(x): 2.941116057364468e-7
 * lambda: 1.0000000000000007e-13
 * dx: [5.55729e-6]

    18     4.212218e-02     4.402721e-09
 * g(x): 4.402720965579476e-9
 * lambda: 1.0000000000000008e-14
 * dx: [-5.72045e-10]

Use Optim Brent to fit the parameter
Use Optim BFGS to fit the parameter
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
Use LeastSquaresOptim to fit the parameter
Multivariate
Use LM to fit the parameter
     0     1.457174e+03              NaN
 * lambda: 10000.0

     1     1.457111e+03     2.844171e+03
 * g(x): 2844.170546422957
 * lambda: 1000.0
 * dx: [1.06447e-5,9.35374e-6]

     2     1.456483e+03     2.841386e+03
 * g(x): 2841.386230615268
 * lambda: 100.0
 * dx: [0.000106337,9.31241e-5]

     3     1.450259e+03     2.813933e+03
 * g(x): 2813.9332651447694
 * lambda: 10.0
 * dx: [0.00105253,0.000890652]

     4     1.392823e+03     2.574943e+03
 * g(x): 2574.94281512773
 * lambda: 1.0
 * dx: [0.00959042,0.00550991]

     5     1.072330e+03     1.712869e+03
 * g(x): 1712.8694297891795
 * lambda: 0.1
 * dx: [0.0570684,-0.0450024]

     6     5.073686e+02     1.212988e+03
 * g(x): 1212.988062487037
 * lambda: 0.010000000000000002
 * dx: [0.136273,-0.163796]

     7     4.149882e+01     2.146795e+02
 * g(x): 214.67950458102132
 * lambda: 0.0010000000000000002
 * dx: [0.0459799,0.323557]

     8     3.367174e+00     3.046793e+02
 * g(x): 304.67928642974687
 * lambda: 0.00010000000000000003
 * dx: [-0.0588927,0.280154]

     9     4.310261e-02     2.639183e+00
 * g(x): 2.639182544602521
 * lambda: 1.0000000000000004e-5
 * dx: [0.00905022,-0.00287542]

    10     4.209506e-02     2.811883e-02
 * g(x): 0.02811883024109041
 * lambda: 1.0000000000000004e-6
 * dx: [-0.000251194,0.00123089]

    11     4.209504e-02     1.701014e-07
 * g(x): 1.7010135799910842e-7
 * lambda: 1.0000000000000005e-7
 * dx: [-1.03275e-6,2.55087e-6]

    12     4.209504e-02     3.033227e-06
 * g(x): 3.03322656147742e-6
 * lambda: 1.0000000000000006e-6
 * dx: [-5.0279e-10,3.80124e-9]

Use Optim BFGS to fit the parameter
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
Use LeastSquaresOptim to fit the parameter
Use LM to fit the parameter
     0     8.957533e+02              NaN
 * lambda: 10000.0

     1     8.956264e+02     2.414588e+03
 * g(x): 2414.5875722047176
 * lambda: 1000.0
 * dx: [1.18839e-5,-9.18366e-7,4.36629e-5,1.71661e-5]

     2     8.943588e+02     2.409929e+03
 * g(x): 2409.9291159163276
 * lambda: 100.0
 * dx: [0.000118607,-8.8516e-6,0.000435877,0.000171287]

     3     8.818956e+02     2.364370e+03
 * g(x): 2364.3704732183173
 * lambda: 10.0
 * dx: [0.00116341,-5.63035e-5,0.00428542,0.00167623]

     4     7.758421e+02     1.999649e+03
 * g(x): 1999.6493464615733
 * lambda: 1.0
 * dx: [0.00979268,0.00186877,0.036943,0.0137327]

     5     3.459425e+02     1.021314e+03
 * g(x): 1021.3139285236359
 * lambda: 0.1
 * dx: [0.0387478,0.0567627,0.202127,0.0332003]

     6     1.751269e+01     1.655094e+02
 * g(x): 165.50944997684698
 * lambda: 0.010000000000000002
 * dx: [0.0430657,0.0887056,0.445203,-0.0901779]

     7     2.495961e+00     1.361220e+02
 * g(x): 136.12196495532925
 * lambda: 0.0010000000000000002
 * dx: [0.0424418,0.0130036,-0.0964849,-0.0896704]

     8     1.877304e-01     4.770483e+01
 * g(x): 47.704827411100595
 * lambda: 0.00010000000000000003
 * dx: [0.0523465,0.0358903,-0.161618,-0.0559645]

     9     4.539813e-02     7.301373e+00
 * g(x): 7.301373282808619
 * lambda: 1.0000000000000004e-5
 * dx: [0.00977804,0.00268205,-0.0230685,-0.010134]

    10     4.182884e-02     5.120117e-02
 * g(x): 0.051201172404381434
 * lambda: 1.0000000000000004e-6
 * dx: [0.00178359,0.000712201,-0.00599833,-0.00205297]

    11     4.182870e-02     3.353738e-07
 * g(x): 3.353738030065223e-7
 * lambda: 1.0000000000000005e-7
 * dx: [3.30658e-6,-4.25824e-6,-3.91343e-6,-3.77162e-6]

    12     4.182870e-02     2.223472e-08
 * g(x): 2.223471967655044e-8
 * lambda: 1.0000000000000005e-8
 * dx: [1.05228e-8,7.43834e-9,-3.36085e-8,-1.07076e-8]

    13     4.182870e-02     2.345376e-08
 * g(x): 2.3453761710534593e-8
 * lambda: 1.0000000000000005e-9
 * dx: [-2.50294e-10,-1.89253e-10,6.24274e-10,2.79435e-10]

Use Optim BFGS to fit the parameter
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Interrupted. Larger maxiters is needed.
WARNING: Linesearch failed, using alpha = 0.001491678335094473 and exiting optimization.
ERROR: LoadError: assertion failed: |result.minimizer - [1.5;1.0;3.0;1.0]| <= 0.3
  result.minimizer = [1.63229,1.07767,2.64605,0.878702]
  [1.5;1.0;3.0;1.0] = [1.5,1.0,3.0,1.0]
  difference = 0.35394516512364627 > 0.3
 in test_approx_eq(::Array{Float64,1}, ::Array{Float64,1}, ::Float64, ::String, ::String) at ./test.jl:863
 in include_from_node1(::String) at ./loading.jl:488
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/DiffEqParamEstim/test/runtests.jl, in expression starting on line 129
==========================[ ERROR: DiffEqParamEstim ]===========================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.5/DiffEqParamEstim/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
INFO: Upgrading DiffEqBase: v0.7.0 => v0.8.0
INFO: Removing Combinatorics v0.3.2
INFO: Removing Conda v0.4.0
INFO: Removing Distances v0.3.2
INFO: Removing GenericSVD v0.0.2
INFO: Removing Hiccup v0.1.1
INFO: Removing InplaceOps v0.1.0
INFO: Removing Iterators v0.2.0
INFO: Removing Juno v0.2.5
INFO: Removing LeastSquaresOptim v0.2.1
INFO: Removing MathProgBase v0.5.10
INFO: Removing Media v0.2.5
INFO: Removing NLopt v0.3.3
INFO: Removing NLsolve v0.9.1
INFO: Removing OrdinaryDiffEq v1.1.0
INFO: Removing ParameterizedFunctions v0.6.0
INFO: Removing PolynomialFactors v0.0.3
INFO: Removing Polynomials v0.1.2
INFO: Removing Primes v0.1.2
INFO: Removing Roots v0.3.0
INFO: Removing SymEngine v0.1.2
ERROR: DiffEqParamEstim had test errors
 in #test#61(::Bool, ::Function, ::Array{AbstractString,1}) at ./pkg/entry.jl:740
 in (::Base.Pkg.Entry.#kw##test)(::Array{Any,1}, ::Base.Pkg.Entry.#test, ::Array{AbstractString,1}) at ./<missing>:0
 in (::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}})() at ./pkg/dir.jl:31
 in cd(::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}, ::String) at ./file.jl:59
 in #cd#1(::Array{Any,1}, ::Function, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./pkg/dir.jl:31
 in (::Base.Pkg.Dir.#kw##cd)(::Array{Any,1}, ::Base.Pkg.Dir.#cd, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./<missing>:0
 in #test#3(::Bool, ::Function, ::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in test(::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in eval(::Module, ::Any) at ./boot.jl:234
 in process_options(::Base.JLOptions) at ./client.jl:239
 in _start() at ./client.jl:318

>>> End of log
