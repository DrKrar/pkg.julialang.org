>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.764
Commit de0833f (2016-09-25 00:11 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (661.78515625 MB free)
Uptime: 25617.0 sec
Load Avg:  0.9873046875  1.017578125  1.02392578125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1423875 s       7866 s     174900 s     625278 s         77 s
#2  3499 MHz     714666 s         54 s      95590 s    1604869 s          4 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-1.235908917552019e6,[81704.3,18295.7],
[-17658.2 -15842.2 1016.12; 17412.2 15955.0 -1299.63],

Array{Float64,2}[
[67668.5 -10391.8 -3907.23; -10391.8 78158.8 1784.7; -3907.23 1784.7 74974.2],

[32356.5 10620.4 3761.13; 10620.4 21544.5 -1521.91; 3761.13 -1521.91 25042.1]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.393346e+03
      1       9.841902e+02      -4.091556e+02 |        8
      2       9.117326e+02      -7.245756e+01 |        0
      3       9.117326e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 911.7326383690379)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.071191
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.775446
INFO: iteration 2, lowerbound -3.598281
INFO: iteration 3, lowerbound -3.409443
INFO: iteration 4, lowerbound -3.212288
INFO: iteration 5, lowerbound -3.034339
INFO: iteration 6, lowerbound -2.903657
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.833595
INFO: dropping number of Gaussions to 5
INFO: iteration 8, lowerbound -2.800679
INFO: dropping number of Gaussions to 3
INFO: iteration 9, lowerbound -2.775225
INFO: iteration 10, lowerbound -2.754374
INFO: iteration 11, lowerbound -2.733616
INFO: iteration 12, lowerbound -2.702110
INFO: iteration 13, lowerbound -2.656797
INFO: iteration 14, lowerbound -2.597330
INFO: iteration 15, lowerbound -2.529067
INFO: iteration 16, lowerbound -2.462605
INFO: iteration 17, lowerbound -2.407151
INFO: iteration 18, lowerbound -2.364912
INFO: iteration 19, lowerbound -2.333869
INFO: iteration 20, lowerbound -2.313872
INFO: iteration 21, lowerbound -2.307407
INFO: dropping number of Gaussions to 2
INFO: iteration 22, lowerbound -2.302935
INFO: iteration 23, lowerbound -2.299261
INFO: iteration 24, lowerbound -2.299257
INFO: iteration 25, lowerbound -2.299255
INFO: iteration 26, lowerbound -2.299254
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Sun 25 Sep 2016 11:37:09 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sun 25 Sep 2016 11:37:11 AM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Sun 25 Sep 2016 11:37:13 AM UTC: EM with 272 data points 0 iterations avll -2.071191
5.8 data points per parameter
,Sun 25 Sep 2016 11:37:14 AM UTC: GMM converted to Variational GMM
,Sun 25 Sep 2016 11:37:16 AM UTC: iteration 1, lowerbound -3.775446
,Sun 25 Sep 2016 11:37:16 AM UTC: iteration 2, lowerbound -3.598281
,Sun 25 Sep 2016 11:37:16 AM UTC: iteration 3, lowerbound -3.409443
,Sun 25 Sep 2016 11:37:16 AM UTC: iteration 4, lowerbound -3.212288
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 5, lowerbound -3.034339
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 6, lowerbound -2.903657
,Sun 25 Sep 2016 11:37:17 AM UTC: dropping number of Gaussions to 7
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 7, lowerbound -2.833595
,Sun 25 Sep 2016 11:37:17 AM UTC: dropping number of Gaussions to 5
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 8, lowerbound -2.800679
,Sun 25 Sep 2016 11:37:17 AM UTC: dropping number of Gaussions to 3
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 9, lowerbound -2.775225
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 10, lowerbound -2.754374
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 11, lowerbound -2.733616
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 12, lowerbound -2.702110
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 13, lowerbound -2.656797
,Sun 25 Sep 2016 11:37:17 AM UTC: iteration 14, lowerbound -2.597330
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 15, lowerbound -2.529067
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 16, lowerbound -2.462605
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 17, lowerbound -2.407151
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 18, lowerbound -2.364912
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 19, lowerbound -2.333869
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 20, lowerbound -2.313872
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 21, lowerbound -2.307407
,Sun 25 Sep 2016 11:37:18 AM UTC: dropping number of Gaussions to 2
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 22, lowerbound -2.302935
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 23, lowerbound -2.299261
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 24, lowerbound -2.299257
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 25, lowerbound -2.299255
,Sun 25 Sep 2016 11:37:18 AM UTC: iteration 26, lowerbound -2.299254
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 27, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 28, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 29, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 30, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 31, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 32, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 33, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 34, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 35, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 36, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 37, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:19 AM UTC: iteration 38, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 39, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 40, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 41, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 42, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 43, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 44, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 45, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 46, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 47, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 48, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 49, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: iteration 50, lowerbound -2.299253
,Sun 25 Sep 2016 11:37:20 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549,178.045]
β = [95.9549,178.045]
m = [2.00023 53.852; 4.2503 79.2869]
ν = [97.9549,180.045]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.375876 -0.00895312; 0.0 0.0127487],

[0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9754566792767246
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -0.9754566792753596
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -0.9754566792753596
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0030408377108753
avll from llpg:  -1.0030408377108753
avll direct:     -1.003040837710875
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.13909    -0.0214914    -0.264815     0.0491275   -0.0502196   -0.129073     0.180941    -0.0366128     0.0518102   -0.164552      0.0215521   -0.00364732   0.083163    -0.0181522    0.0279968   -0.084482    0.148712    -0.0828738    0.112553    -0.00158302  -0.0871282    0.0833991   -0.0333092   -0.0684153    0.0543777    0.0482415 
 -0.149809    0.0704787    -0.0956895    0.023523    -0.0145609   -0.0498197    0.110773    -0.00716504    0.120402     0.0294018    -0.0850915    0.0848025    0.115767    -0.286232     0.0497741   -0.107653   -0.0858799    0.0364217   -0.00695777  -0.0389591    0.0558381    0.0688213   -0.0814178   -0.0514855   -0.0246788   -0.138917  
 -0.145111   -0.102143      0.00943691  -0.0886385    0.133875     0.00482746   0.0732207    0.0428057    -0.040245     0.105348      0.0757951    0.04767     -0.027417    -0.105247     0.025365     0.0147452   0.0218809    0.0115867   -0.0382443    0.136306    -0.0316856   -0.099221     0.148964    -0.0489476   -0.0404337    0.0268054 
  0.0940814  -0.0956101     0.00226286   0.00425698   0.0754481    0.0173117   -0.153042    -0.128404      0.119058    -0.105822     -0.0352807   -0.074294     0.127469     0.214577    -0.0258115   -0.187242    0.182208     0.091591    -0.094645     0.0997947    0.0339718   -0.0508728   -0.044313    -0.128721    -0.00661927   0.0637244 
 -0.082012   -0.266091      0.159929     0.137896    -0.0159172   -0.0437047    0.0835453    0.0524911     0.148027    -0.133326      0.0338523    0.103962    -0.0792495    0.107493    -0.0144629   -0.0122995  -0.11571      0.0145384   -0.269598     0.0265198   -0.200114     0.119796    -0.117126    -0.152399    -0.0669691    0.0707692 
 -0.0277608  -0.0926206    -0.0682496    0.0733086   -0.110585     0.0199134   -0.0427561    0.0222196    -0.109313     0.0569719     0.00540289   0.0260732    0.106776     0.0410694   -0.0776719    0.102615    0.0323944    0.166603    -0.0750656   -0.0194246    0.0612892    0.081755    -0.090883     0.0611695    0.077565    -0.0117493 
  0.0207091   0.169231      0.136905    -0.0333619   -0.107549    -0.0649103   -0.029502    -0.0603428     0.0844872    0.107815     -0.142758     0.0614925    0.0636776   -0.273704     0.123035     0.0344028  -0.0613535    0.110885    -0.0281755    0.0269125    0.0808097   -0.101752    -0.00471562   0.0748712    0.0416392   -0.12111   
  0.0410106   0.0342973    -0.028879     0.0748151   -0.0670255   -0.0451102   -0.230142     0.176836      0.148122    -0.0716171     0.0973012    0.100634    -0.0323682   -0.258966     0.0718535    0.0122193   0.0694742    0.0923002   -0.00179015  -0.0768921    0.0216345   -0.0169891   -0.0370513   -0.0439237   -0.0302206    0.0619263 
  0.0185591   0.172171      0.190626    -0.077078     0.105774    -0.109901     0.0253393    0.0907586    -0.0328163    0.083179      0.0104988    0.0240868   -0.0959247   -0.0540873   -0.0254055    0.0753254   0.0705401    0.0560361    0.0735191    0.00411201   0.0190938    0.088467    -0.0647966   -0.325593     0.021165     0.0361669 
 -0.140176    0.115078     -0.131232    -0.0999406    0.0689351   -0.0533324    0.0610552   -0.287761      0.100433    -0.151296      0.0288712   -0.108656     0.139604    -0.0748869   -0.0437701    0.133423    0.0883255   -0.0636931    0.168463     0.0709337   -0.124969     0.056423     0.085613    -0.00629309   0.0280789   -0.0491927 
  0.045133    0.100379     -0.0866246   -0.00940968  -0.0689188    0.0106389    0.0626609    0.0774187     0.0401128   -0.139794      0.151117    -0.0506076   -0.0026174    0.0399872   -0.14923      0.0167567   0.0382219    0.125009     0.0378429   -0.043637    -0.0634818    0.0588435   -0.0121387   -0.0608075    0.0127227    0.200458  
 -0.0653271  -0.140484      0.00983375   0.0578861   -0.0207528   -0.00569896  -0.0678243    0.0562211     0.0377715    0.0293357     0.104666     0.00845873  -0.0329669    0.0703922    0.0058976   -0.0365265  -0.0806108   -0.0794161    0.0131296    0.00198369  -0.167403    -0.0343959   -0.0904061    0.130341    -0.10784     -0.0838458 
  0.0785563  -0.0590703    -0.0973345    0.0299364    0.0615807   -0.0164005   -0.0413689   -0.0886853     0.172547     0.151844     -0.16417      0.0247628   -0.179636     0.21459     -0.149376    -0.304525   -0.134998     0.00324651  -0.0793453   -0.11634     -0.0430168   -0.10512     -0.0609777    0.203278    -0.121245    -0.039085  
 -0.150588    0.0261332    -0.00850252  -0.118079     0.155365     0.0357427    0.0936286    0.0398341    -0.162625    -0.114247      0.00590929  -0.0151768    0.0530058   -0.0320446    0.0929083    0.107605   -0.0287852   -0.144302     0.115959    -0.0203096    0.0820454    0.0854603   -0.0525697   -0.0693348   -0.021252     0.171066  
 -0.115797   -0.0159654     0.0278241    0.0263713   -0.0526539    0.035362     0.0507717   -0.109468     -0.0422331    0.130594      0.0660836   -0.0373349   -0.0285649    0.132293    -0.0957282   -0.0336866   0.0103153   -0.0594945    0.00898037  -0.0032705   -0.0160944    0.0610378    0.0899973   -0.120496     0.073331     0.179574  
 -0.0528955   0.044988      0.110006    -0.141625    -0.0421182    0.0134249    0.199453    -0.0567881    -0.189474    -0.0745313    -0.0947702   -0.0255974    0.0181804    0.0767589   -0.0784531   -0.18225    -0.0204504   -0.053369     0.0091648    0.108269    -0.0257606   -0.162747     0.185844    -0.0174065    0.0397569   -0.0442879 
  0.0614441  -0.0692681    -0.161452     0.0796051    0.146452    -0.0329785   -0.0181251    0.128675     -0.183016    -0.0658844     0.0807444   -0.0843781    0.00782805   0.0291731    0.0735595   -0.0457324   0.147683    -0.00226722  -0.0939035    0.142799    -0.118756    -0.0426427   -0.0426501    0.0882       0.0401856   -0.124197  
 -0.0512819  -0.0849557     0.0369653   -0.0367478    0.0445616    0.0494216   -0.0184589    0.00429759   -0.0857438   -0.211545      0.0245018    0.0379149   -0.100285     0.207117    -0.192224    -0.0889318  -0.0363687    0.230798     0.0969938    0.115614     0.0548671   -0.0255998    0.0520188    0.0987498    0.0622009    0.0338971 
 -0.0904206   0.0920686     0.20365     -0.0935005   -0.00303838  -0.04614     -0.0659763   -0.0638526    -0.0390316    0.195725     -0.0508809   -0.075105     0.0477373    0.112584    -0.0762986    0.0760337   0.0248911   -0.0599588    0.03393      0.0627389   -0.179275     0.0481512   -0.0316647    0.0278763    0.123714     0.12151   
 -0.0951702  -0.0417057    -0.0712391   -0.0157896    0.0393855    0.00349899   0.0402376    0.117384     -0.168023     0.102453      0.00744906   0.0303323   -0.0601324    0.350431     0.0630544    0.261667   -0.0771688   -0.0391225   -0.0667702   -0.0126712   -0.00172809   0.00921673  -0.0825265   -0.0265045    0.00892931  -0.173069  
 -0.0434623   0.0807078    -0.0998269    0.170745     0.0663032    0.0103997    0.0491127    0.0172565     0.166526    -0.0104872     0.0976271   -0.129251     0.0476778   -0.0154503    0.0654845    0.149324    0.00442782  -0.107273     0.121046    -0.20315     -0.0978513   -0.0103513   -0.129355    -0.128288     0.132872     0.0555172 
  0.0983855   0.000344799  -0.0567768    0.168043     0.259895    -0.0648109    0.0324899   -0.028405     -0.0161513   -0.127241     -0.0211596   -0.0103108    0.132227     0.0280534   -0.200068     0.0600497   0.0170564   -0.195785    -0.0179241   -0.113111    -0.0417458    0.136752    -0.0351396   -0.148371     0.0413571   -0.0531383 
 -0.0236172   0.111308     -0.0717153    0.142        0.119119     0.0214264    0.0627701   -0.0626066    -0.0533426    0.0987603     0.108687    -0.13711      0.0121044    0.127006    -0.0723622   -0.123462    0.144405     0.147919     0.0870495    0.105619    -0.062184     0.0694603    0.0455859    0.012403     0.0110137   -0.158339  
  0.1145      0.00487379    0.0349436   -0.0315853    0.0098751    0.0457794    0.141033     0.10606      -0.113746    -0.0109477    -0.155291    -0.0871222   -0.0139179    0.0521744    0.177908     0.0336949   0.0342648   -0.171758    -0.0715493    0.0452485   -0.0862281   -0.0384757    0.0223836    0.0843796   -0.00783991  -0.00991643
 -0.0236598  -0.0104759     0.0315384   -0.0447885    0.0863813   -0.0574253    0.0763344   -0.0794979    -0.203511    -0.183142      0.0740154    0.0267131   -0.22491      0.0422815    0.00269809   0.0631824   0.178477    -0.0282872    0.059516    -0.0295087    0.0256637   -0.0131874   -0.0930365   -0.0635364    0.0215074    0.0831042 
 -0.0165451   0.00561112    0.0739329    0.00134136   0.048856    -0.101157    -0.239115    -0.0920072    -0.131748     0.000536142  -0.0240091    0.121783    -0.162857     0.0594123   -0.0361265    0.0526318   0.0412295    0.0901171    0.0208189   -0.0314995    0.287841    -0.114915    -0.0195611    0.130597    -0.0625794   -0.0711641 
  0.0358931  -0.116538      0.0881163    0.0945984   -0.159431     0.0992376    0.0570463   -0.0308389    -0.0650923   -0.141786     -0.163138     0.290053     0.106649     0.149354    -0.0830673   -0.0786329  -0.157272    -0.131211     0.100738    -0.0260296   -0.0499021    0.0340393   -0.0996322   -0.0201346   -0.0759444   -0.0130021 
 -0.168638    0.025236      0.149092     0.117401    -0.0181634    0.0338382   -0.00761156   0.000716725  -0.0464256    0.0446227     0.181639    -0.092904    -0.230543     0.00343899   0.108283     0.0267436  -0.0118366    0.022875    -0.0628805    0.161838     0.0777692    0.0150364   -0.110131    -0.0732154   -0.0236687    0.051631  
  0.234491    0.111991     -0.0552489   -0.0476395   -0.0987908    0.100851    -0.103188    -0.0629882     0.00604562  -0.0475214     0.0190365   -0.02276     -0.208035    -0.0115049    0.0245179    0.0332797   0.050706     0.0406648   -0.0839175   -0.0413318    0.0108405   -0.143102     0.00036533   0.028173     0.0604754   -0.0183415 
  0.305696    0.0140851     0.0219706    0.0535252    0.110063    -0.0119707   -0.145575     0.0493918     0.137216     0.0316233    -0.166019     0.0174905   -0.22831     -0.0149259   -0.0122291    0.1716     -0.122642    -0.170893    -0.114536    -0.169759    -0.00553569  -0.100721    -0.261825     0.137912    -0.0581257    0.0447492 
  0.0388167   0.165153     -0.117438     0.10419      0.130812     0.0436242    0.0310804    0.0808383    -0.0629991   -0.170504      0.0145075    0.0901942   -0.094288    -0.182765    -0.0420543   -0.0721805   0.0494233    0.159003    -0.109696     0.0415996    0.0376652   -0.177413    -0.108144     0.014362     0.171327     0.0443    
 -0.075651   -0.00658075    0.0227875   -0.223347    -0.138124    -0.138975     0.0134519    0.111043      0.0566829   -0.124493      0.046442    -0.0724877    0.077466    -0.186629    -0.131188     0.067021   -0.00473685  -0.0293129   -0.0195504   -0.147344    -0.0382936   -0.270751    -0.0592973   -0.0232765   -0.0439936   -0.0368499 kind diag, method split
0: avll = -1.3911589303466272
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.391220
INFO: iteration 2, average log likelihood -1.391096
INFO: iteration 3, average log likelihood -1.389753
INFO: iteration 4, average log likelihood -1.380196
INFO: iteration 5, average log likelihood -1.366020
INFO: iteration 6, average log likelihood -1.361311
INFO: iteration 7, average log likelihood -1.359798
INFO: iteration 8, average log likelihood -1.358887
INFO: iteration 9, average log likelihood -1.358276
INFO: iteration 10, average log likelihood -1.357841
INFO: iteration 11, average log likelihood -1.357509
INFO: iteration 12, average log likelihood -1.357235
INFO: iteration 13, average log likelihood -1.356992
INFO: iteration 14, average log likelihood -1.356767
INFO: iteration 15, average log likelihood -1.356549
INFO: iteration 16, average log likelihood -1.356342
INFO: iteration 17, average log likelihood -1.356145
INFO: iteration 18, average log likelihood -1.355964
INFO: iteration 19, average log likelihood -1.355802
INFO: iteration 20, average log likelihood -1.355663
INFO: iteration 21, average log likelihood -1.355543
INFO: iteration 22, average log likelihood -1.355435
INFO: iteration 23, average log likelihood -1.355341
INFO: iteration 24, average log likelihood -1.355263
INFO: iteration 25, average log likelihood -1.355200
INFO: iteration 26, average log likelihood -1.355147
INFO: iteration 27, average log likelihood -1.355103
INFO: iteration 28, average log likelihood -1.355065
INFO: iteration 29, average log likelihood -1.355032
INFO: iteration 30, average log likelihood -1.355004
INFO: iteration 31, average log likelihood -1.354980
INFO: iteration 32, average log likelihood -1.354960
INFO: iteration 33, average log likelihood -1.354944
INFO: iteration 34, average log likelihood -1.354932
INFO: iteration 35, average log likelihood -1.354922
INFO: iteration 36, average log likelihood -1.354915
INFO: iteration 37, average log likelihood -1.354910
INFO: iteration 38, average log likelihood -1.354907
INFO: iteration 39, average log likelihood -1.354904
INFO: iteration 40, average log likelihood -1.354902
INFO: iteration 41, average log likelihood -1.354901
INFO: iteration 42, average log likelihood -1.354900
INFO: iteration 43, average log likelihood -1.354900
INFO: iteration 44, average log likelihood -1.354899
INFO: iteration 45, average log likelihood -1.354899
INFO: iteration 46, average log likelihood -1.354899
INFO: iteration 47, average log likelihood -1.354899
INFO: iteration 48, average log likelihood -1.354899
INFO: iteration 49, average log likelihood -1.354899
INFO: iteration 50, average log likelihood -1.354899
INFO: EM with 100000 data points 50 iterations avll -1.354899
952.4 data points per parameter
1: avll = [-1.39122,-1.3911,-1.38975,-1.3802,-1.36602,-1.36131,-1.3598,-1.35889,-1.35828,-1.35784,-1.35751,-1.35723,-1.35699,-1.35677,-1.35655,-1.35634,-1.35615,-1.35596,-1.3558,-1.35566,-1.35554,-1.35543,-1.35534,-1.35526,-1.3552,-1.35515,-1.3551,-1.35506,-1.35503,-1.355,-1.35498,-1.35496,-1.35494,-1.35493,-1.35492,-1.35492,-1.35491,-1.35491,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.354977
INFO: iteration 2, average log likelihood -1.354887
INFO: iteration 3, average log likelihood -1.354349
INFO: iteration 4, average log likelihood -1.349088
INFO: iteration 5, average log likelihood -1.334117
INFO: iteration 6, average log likelihood -1.324539
INFO: iteration 7, average log likelihood -1.321394
INFO: iteration 8, average log likelihood -1.319607
INFO: iteration 9, average log likelihood -1.318119
INFO: iteration 10, average log likelihood -1.316766
INFO: iteration 11, average log likelihood -1.315516
INFO: iteration 12, average log likelihood -1.314331
INFO: iteration 13, average log likelihood -1.313248
INFO: iteration 14, average log likelihood -1.312341
INFO: iteration 15, average log likelihood -1.311639
INFO: iteration 16, average log likelihood -1.311120
INFO: iteration 17, average log likelihood -1.310712
INFO: iteration 18, average log likelihood -1.310371
INFO: iteration 19, average log likelihood -1.310074
INFO: iteration 20, average log likelihood -1.309811
INFO: iteration 21, average log likelihood -1.309587
INFO: iteration 22, average log likelihood -1.309405
INFO: iteration 23, average log likelihood -1.309258
INFO: iteration 24, average log likelihood -1.309137
INFO: iteration 25, average log likelihood -1.309031
INFO: iteration 26, average log likelihood -1.308927
INFO: iteration 27, average log likelihood -1.308820
INFO: iteration 28, average log likelihood -1.308707
INFO: iteration 29, average log likelihood -1.308583
INFO: iteration 30, average log likelihood -1.308449
INFO: iteration 31, average log likelihood -1.308311
INFO: iteration 32, average log likelihood -1.308172
INFO: iteration 33, average log likelihood -1.308029
INFO: iteration 34, average log likelihood -1.307878
INFO: iteration 35, average log likelihood -1.307719
INFO: iteration 36, average log likelihood -1.307551
INFO: iteration 37, average log likelihood -1.307372
INFO: iteration 38, average log likelihood -1.307184
INFO: iteration 39, average log likelihood -1.307000
INFO: iteration 40, average log likelihood -1.306822
INFO: iteration 41, average log likelihood -1.306648
INFO: iteration 42, average log likelihood -1.306467
INFO: iteration 43, average log likelihood -1.306276
INFO: iteration 44, average log likelihood -1.306078
INFO: iteration 45, average log likelihood -1.305867
INFO: iteration 46, average log likelihood -1.305636
INFO: iteration 47, average log likelihood -1.305376
INFO: iteration 48, average log likelihood -1.305071
INFO: iteration 49, average log likelihood -1.304730
INFO: iteration 50, average log likelihood -1.304356
INFO: EM with 100000 data points 50 iterations avll -1.304356
473.9 data points per parameter
2: avll = [-1.35498,-1.35489,-1.35435,-1.34909,-1.33412,-1.32454,-1.32139,-1.31961,-1.31812,-1.31677,-1.31552,-1.31433,-1.31325,-1.31234,-1.31164,-1.31112,-1.31071,-1.31037,-1.31007,-1.30981,-1.30959,-1.3094,-1.30926,-1.30914,-1.30903,-1.30893,-1.30882,-1.30871,-1.30858,-1.30845,-1.30831,-1.30817,-1.30803,-1.30788,-1.30772,-1.30755,-1.30737,-1.30718,-1.307,-1.30682,-1.30665,-1.30647,-1.30628,-1.30608,-1.30587,-1.30564,-1.30538,-1.30507,-1.30473,-1.30436]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.304070
INFO: iteration 2, average log likelihood -1.303469
INFO: iteration 3, average log likelihood -1.301974
INFO: iteration 4, average log likelihood -1.292435
INFO: iteration 5, average log likelihood -1.272158
INFO: iteration 6, average log likelihood -1.257580
INFO: iteration 7, average log likelihood -1.250199
INFO: iteration 8, average log likelihood -1.246355
INFO: iteration 9, average log likelihood -1.244255
INFO: iteration 10, average log likelihood -1.243046
INFO: iteration 11, average log likelihood -1.242187
INFO: iteration 12, average log likelihood -1.241495
INFO: iteration 13, average log likelihood -1.240885
INFO: iteration 14, average log likelihood -1.240326
INFO: iteration 15, average log likelihood -1.239840
INFO: iteration 16, average log likelihood -1.239482
INFO: iteration 17, average log likelihood -1.239246
INFO: iteration 18, average log likelihood -1.239084
INFO: iteration 19, average log likelihood -1.238961
INFO: iteration 20, average log likelihood -1.238858
INFO: iteration 21, average log likelihood -1.238764
INFO: iteration 22, average log likelihood -1.238675
INFO: iteration 23, average log likelihood -1.238592
INFO: iteration 24, average log likelihood -1.238510
INFO: iteration 25, average log likelihood -1.238410
INFO: iteration 26, average log likelihood -1.238255
INFO: iteration 27, average log likelihood -1.238000
INFO: iteration 28, average log likelihood -1.237591
INFO: iteration 29, average log likelihood -1.237048
INFO: iteration 30, average log likelihood -1.236569
INFO: iteration 31, average log likelihood -1.236257
INFO: iteration 32, average log likelihood -1.236099
INFO: iteration 33, average log likelihood -1.236026
INFO: iteration 34, average log likelihood -1.235988
INFO: iteration 35, average log likelihood -1.235965
INFO: iteration 36, average log likelihood -1.235950
INFO: iteration 37, average log likelihood -1.235938
INFO: iteration 38, average log likelihood -1.235928
INFO: iteration 39, average log likelihood -1.235919
INFO: iteration 40, average log likelihood -1.235911
INFO: iteration 41, average log likelihood -1.235904
INFO: iteration 42, average log likelihood -1.235897
INFO: iteration 43, average log likelihood -1.235891
INFO: iteration 44, average log likelihood -1.235886
INFO: iteration 45, average log likelihood -1.235881
INFO: iteration 46, average log likelihood -1.235876
INFO: iteration 47, average log likelihood -1.235872
INFO: iteration 48, average log likelihood -1.235867
INFO: iteration 49, average log likelihood -1.235863
INFO: iteration 50, average log likelihood -1.235858
INFO: EM with 100000 data points 50 iterations avll -1.235858
236.4 data points per parameter
3: avll = [-1.30407,-1.30347,-1.30197,-1.29243,-1.27216,-1.25758,-1.2502,-1.24636,-1.24426,-1.24305,-1.24219,-1.24149,-1.24089,-1.24033,-1.23984,-1.23948,-1.23925,-1.23908,-1.23896,-1.23886,-1.23876,-1.23867,-1.23859,-1.23851,-1.23841,-1.23826,-1.238,-1.23759,-1.23705,-1.23657,-1.23626,-1.2361,-1.23603,-1.23599,-1.23597,-1.23595,-1.23594,-1.23593,-1.23592,-1.23591,-1.2359,-1.2359,-1.23589,-1.23589,-1.23588,-1.23588,-1.23587,-1.23587,-1.23586,-1.23586]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.236037
INFO: iteration 2, average log likelihood -1.235773
INFO: iteration 3, average log likelihood -1.234214
WARNING: Variances had to be floored 11
INFO: iteration 4, average log likelihood -1.218569
WARNING: Variances had to be floored 10 11
INFO: iteration 5, average log likelihood -1.185721
WARNING: Variances had to be floored 9
INFO: iteration 6, average log likelihood -1.176909
WARNING: Variances had to be floored 10 11
INFO: iteration 7, average log likelihood -1.163239
WARNING: Variances had to be floored 9 11
INFO: iteration 8, average log likelihood -1.163133
WARNING: Variances had to be floored 10
INFO: iteration 9, average log likelihood -1.158768
WARNING: Variances had to be floored 9 11
INFO: iteration 10, average log likelihood -1.152932
WARNING: Variances had to be floored 10 11
INFO: iteration 11, average log likelihood -1.156245
WARNING: Variances had to be floored 9 11
INFO: iteration 12, average log likelihood -1.156128
WARNING: Variances had to be floored 10 11
INFO: iteration 13, average log likelihood -1.154539
WARNING: Variances had to be floored 9 11
INFO: iteration 14, average log likelihood -1.154487
WARNING: Variances had to be floored 10
INFO: iteration 15, average log likelihood -1.153365
WARNING: Variances had to be floored 9 11
INFO: iteration 16, average log likelihood -1.148409
WARNING: Variances had to be floored 10
INFO: iteration 17, average log likelihood -1.151575
WARNING: Variances had to be floored 9 11 16
INFO: iteration 18, average log likelihood -1.144672
WARNING: Variances had to be floored 10
INFO: iteration 19, average log likelihood -1.163445
WARNING: Variances had to be floored 9 11
INFO: iteration 20, average log likelihood -1.154067
WARNING: Variances had to be floored 10
INFO: iteration 21, average log likelihood -1.156284
WARNING: Variances had to be floored 9 11
INFO: iteration 22, average log likelihood -1.150996
WARNING: Variances had to be floored 10
INFO: iteration 23, average log likelihood -1.153756
WARNING: Variances had to be floored 9 11
INFO: iteration 24, average log likelihood -1.147775
WARNING: Variances had to be floored 10 16
INFO: iteration 25, average log likelihood -1.149519
WARNING: Variances had to be floored 9 11
INFO: iteration 26, average log likelihood -1.159250
WARNING: Variances had to be floored 10
INFO: iteration 27, average log likelihood -1.158020
WARNING: Variances had to be floored 9 11
INFO: iteration 28, average log likelihood -1.152179
WARNING: Variances had to be floored 10
INFO: iteration 29, average log likelihood -1.155107
WARNING: Variances had to be floored 9 11
INFO: iteration 30, average log likelihood -1.149349
WARNING: Variances had to be floored 10
INFO: iteration 31, average log likelihood -1.151881
WARNING: Variances had to be floored 9 11 16
INFO: iteration 32, average log likelihood -1.144864
WARNING: Variances had to be floored 10
INFO: iteration 33, average log likelihood -1.163398
WARNING: Variances had to be floored 9 11
INFO: iteration 34, average log likelihood -1.154069
WARNING: Variances had to be floored 10
INFO: iteration 35, average log likelihood -1.156287
WARNING: Variances had to be floored 9 11
INFO: iteration 36, average log likelihood -1.150980
WARNING: Variances had to be floored 10
INFO: iteration 37, average log likelihood -1.153716
WARNING: Variances had to be floored 9 11
INFO: iteration 38, average log likelihood -1.147653
WARNING: Variances had to be floored 10 16
INFO: iteration 39, average log likelihood -1.149268
WARNING: Variances had to be floored 9 11
INFO: iteration 40, average log likelihood -1.159235
WARNING: Variances had to be floored 10
INFO: iteration 41, average log likelihood -1.158022
WARNING: Variances had to be floored 9 11
INFO: iteration 42, average log likelihood -1.152174
WARNING: Variances had to be floored 10
INFO: iteration 43, average log likelihood -1.155107
WARNING: Variances had to be floored 9 11
INFO: iteration 44, average log likelihood -1.149331
WARNING: Variances had to be floored 10
INFO: iteration 45, average log likelihood -1.151828
WARNING: Variances had to be floored 9 11 16
INFO: iteration 46, average log likelihood -1.144754
WARNING: Variances had to be floored 10
INFO: iteration 47, average log likelihood -1.163388
WARNING: Variances had to be floored 9 11
INFO: iteration 48, average log likelihood -1.154064
WARNING: Variances had to be floored 10
INFO: iteration 49, average log likelihood -1.156289
WARNING: Variances had to be floored 9 11
INFO: iteration 50, average log likelihood -1.150982
INFO: EM with 100000 data points 50 iterations avll -1.150982
118.1 data points per parameter
4: avll = [-1.23604,-1.23577,-1.23421,-1.21857,-1.18572,-1.17691,-1.16324,-1.16313,-1.15877,-1.15293,-1.15625,-1.15613,-1.15454,-1.15449,-1.15336,-1.14841,-1.15158,-1.14467,-1.16344,-1.15407,-1.15628,-1.151,-1.15376,-1.14777,-1.14952,-1.15925,-1.15802,-1.15218,-1.15511,-1.14935,-1.15188,-1.14486,-1.1634,-1.15407,-1.15629,-1.15098,-1.15372,-1.14765,-1.14927,-1.15924,-1.15802,-1.15217,-1.15511,-1.14933,-1.15183,-1.14475,-1.16339,-1.15406,-1.15629,-1.15098]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 19 20
INFO: iteration 1, average log likelihood -1.154027
WARNING: Variances had to be floored 19 20 21 22
INFO: iteration 2, average log likelihood -1.141432
WARNING: Variances had to be floored 17 18 19 20 31 32
INFO: iteration 3, average log likelihood -1.141466
WARNING: Variances had to be floored 19 20 21 22
INFO: iteration 4, average log likelihood -1.139807
WARNING: Variances had to be floored 8 17 18 19 20 21 22 31
INFO: iteration 5, average log likelihood -1.095466
WARNING: Variances had to be floored 6 7 11 19 20 21 32
INFO: iteration 6, average log likelihood -1.074622
WARNING: Variances had to be floored 2 5 8 17 18 19 20 22 26
INFO: iteration 7, average log likelihood -1.068061
WARNING: Variances had to be floored 17 19 20 21 22 32
INFO: iteration 8, average log likelihood -1.066775
WARNING: Variances had to be floored 2 6 7 8 11 18 19 20 21 22 25 26
INFO: iteration 9, average log likelihood -1.029905
WARNING: Variances had to be floored 5 17 19 20 21 22 32
INFO: iteration 10, average log likelihood -1.078386
WARNING: Variances had to be floored 2 9 18 19 20 21 22 26
INFO: iteration 11, average log likelihood -1.064912
WARNING: Variances had to be floored 6 8 11 18 19 20 21 22 32
INFO: iteration 12, average log likelihood -1.046816
WARNING: Variances had to be floored 2 5 7 17 19 20 21 22 25 26
INFO: iteration 13, average log likelihood -1.055649
WARNING: Variances had to be floored 6 8 18 19 20 21 22 32
INFO: iteration 14, average log likelihood -1.063905
WARNING: Variances had to be floored 2 9 11 19 20 21 22 26
INFO: iteration 15, average log likelihood -1.062828
WARNING: Variances had to be floored 5 6 7 8 18 19 20 21 22 32
INFO: iteration 16, average log likelihood -1.043735
WARNING: Variances had to be floored 2 17 19 20 21 22 25 26
INFO: iteration 17, average log likelihood -1.069470
WARNING: Variances had to be floored 11 18 19 20 21 22 32
INFO: iteration 18, average log likelihood -1.068312
WARNING: Variances had to be floored 2 6 8 9 17 19 20 21 22 24 26
INFO: iteration 19, average log likelihood -1.052169
WARNING: Variances had to be floored 5 7 18 19 20 21 22 32
INFO: iteration 20, average log likelihood -1.052221
WARNING: Variances had to be floored 2 6 8 11 19 20 21 22 25 26
INFO: iteration 21, average log likelihood -1.057185
WARNING: Variances had to be floored 18 19 20 21 22 32
INFO: iteration 22, average log likelihood -1.067857
WARNING: Variances had to be floored 2 5 6 7 8 9 17 19 20 21 22 26
INFO: iteration 23, average log likelihood -1.040731
WARNING: Variances had to be floored 11 18 19 20 21 22 32
INFO: iteration 24, average log likelihood -1.073251
WARNING: Variances had to be floored 2 19 20 21 22 25 26
INFO: iteration 25, average log likelihood -1.069999
WARNING: Variances had to be floored 6 8 17 18 19 20 21 22 32
INFO: iteration 26, average log likelihood -1.043352
WARNING: Variances had to be floored 2 5 7 9 11 18 19 20 21 22 26
INFO: iteration 27, average log likelihood -1.054051
WARNING: Variances had to be floored 6 8 17 19 20 21 22 24 32
INFO: iteration 28, average log likelihood -1.068125
WARNING: Variances had to be floored 2 18 19 20 21 22 25 26
INFO: iteration 29, average log likelihood -1.057953
WARNING: Variances had to be floored 5 6 7 8 11 17 19 20 21 22 32
INFO: iteration 30, average log likelihood -1.038408
WARNING: Variances had to be floored 2 9 19 20 21 22 26
INFO: iteration 31, average log likelihood -1.083630
WARNING: Variances had to be floored 17 18 19 20 21 22 32
INFO: iteration 32, average log likelihood -1.064980
WARNING: Variances had to be floored 2 6 8 11 17 18 19 20 21 22 25 26
INFO: iteration 33, average log likelihood -1.038351
WARNING: Variances had to be floored 5 7 18 19 20 21 22 32
INFO: iteration 34, average log likelihood -1.066371
WARNING: Variances had to be floored 2 6 8 9 17 19 20 21 22 26
INFO: iteration 35, average log likelihood -1.059453
WARNING: Variances had to be floored 11 19 20 21 22 24 32
INFO: iteration 36, average log likelihood -1.064009
WARNING: Variances had to be floored 2 5 6 7 8 17 18 19 20 21 22 25 26
INFO: iteration 37, average log likelihood -1.035891
WARNING: Variances had to be floored 18 19 20 21 22 32
INFO: iteration 38, average log likelihood -1.081610
WARNING: Variances had to be floored 2 9 11 17 19 20 21 22 26
INFO: iteration 39, average log likelihood -1.061478
WARNING: Variances had to be floored 6 8 17 18 19 20 21 22 32
INFO: iteration 40, average log likelihood -1.053955
WARNING: Variances had to be floored 2 5 7 17 18 19 20 21 22 25 26
INFO: iteration 41, average log likelihood -1.050376
WARNING: Variances had to be floored 6 8 11 18 19 20 21 22 32
INFO: iteration 42, average log likelihood -1.066640
WARNING: Variances had to be floored 2 9 17 19 20 21 22 24 26
INFO: iteration 43, average log likelihood -1.064772
WARNING: Variances had to be floored 5 6 7 8 17 18 19 20 21 22 32
INFO: iteration 44, average log likelihood -1.043861
WARNING: Variances had to be floored 2 11 18 19 20 21 22 25 26
INFO: iteration 45, average log likelihood -1.069986
WARNING: Variances had to be floored 17 19 20 21 22 32
INFO: iteration 46, average log likelihood -1.073442
WARNING: Variances had to be floored 2 6 8 9 18 19 20 21 22 26
INFO: iteration 47, average log likelihood -1.046708
WARNING: Variances had to be floored 5 7 11 17 19 20 21 22 32
INFO: iteration 48, average log likelihood -1.049468
WARNING: Variances had to be floored 2 6 8 18 19 20 21 22 25 26
INFO: iteration 49, average log likelihood -1.065319
WARNING: Variances had to be floored 17 19 20 21 22 32
INFO: iteration 50, average log likelihood -1.061667
INFO: EM with 100000 data points 50 iterations avll -1.061667
59.0 data points per parameter
5: avll = [-1.15403,-1.14143,-1.14147,-1.13981,-1.09547,-1.07462,-1.06806,-1.06677,-1.02991,-1.07839,-1.06491,-1.04682,-1.05565,-1.0639,-1.06283,-1.04374,-1.06947,-1.06831,-1.05217,-1.05222,-1.05719,-1.06786,-1.04073,-1.07325,-1.07,-1.04335,-1.05405,-1.06813,-1.05795,-1.03841,-1.08363,-1.06498,-1.03835,-1.06637,-1.05945,-1.06401,-1.03589,-1.08161,-1.06148,-1.05396,-1.05038,-1.06664,-1.06477,-1.04386,-1.06999,-1.07344,-1.04671,-1.04947,-1.06532,-1.06167]
[-1.39116,-1.39122,-1.3911,-1.38975,-1.3802,-1.36602,-1.36131,-1.3598,-1.35889,-1.35828,-1.35784,-1.35751,-1.35723,-1.35699,-1.35677,-1.35655,-1.35634,-1.35615,-1.35596,-1.3558,-1.35566,-1.35554,-1.35543,-1.35534,-1.35526,-1.3552,-1.35515,-1.3551,-1.35506,-1.35503,-1.355,-1.35498,-1.35496,-1.35494,-1.35493,-1.35492,-1.35492,-1.35491,-1.35491,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.3549,-1.35498,-1.35489,-1.35435,-1.34909,-1.33412,-1.32454,-1.32139,-1.31961,-1.31812,-1.31677,-1.31552,-1.31433,-1.31325,-1.31234,-1.31164,-1.31112,-1.31071,-1.31037,-1.31007,-1.30981,-1.30959,-1.3094,-1.30926,-1.30914,-1.30903,-1.30893,-1.30882,-1.30871,-1.30858,-1.30845,-1.30831,-1.30817,-1.30803,-1.30788,-1.30772,-1.30755,-1.30737,-1.30718,-1.307,-1.30682,-1.30665,-1.30647,-1.30628,-1.30608,-1.30587,-1.30564,-1.30538,-1.30507,-1.30473,-1.30436,-1.30407,-1.30347,-1.30197,-1.29243,-1.27216,-1.25758,-1.2502,-1.24636,-1.24426,-1.24305,-1.24219,-1.24149,-1.24089,-1.24033,-1.23984,-1.23948,-1.23925,-1.23908,-1.23896,-1.23886,-1.23876,-1.23867,-1.23859,-1.23851,-1.23841,-1.23826,-1.238,-1.23759,-1.23705,-1.23657,-1.23626,-1.2361,-1.23603,-1.23599,-1.23597,-1.23595,-1.23594,-1.23593,-1.23592,-1.23591,-1.2359,-1.2359,-1.23589,-1.23589,-1.23588,-1.23588,-1.23587,-1.23587,-1.23586,-1.23586,-1.23604,-1.23577,-1.23421,-1.21857,-1.18572,-1.17691,-1.16324,-1.16313,-1.15877,-1.15293,-1.15625,-1.15613,-1.15454,-1.15449,-1.15336,-1.14841,-1.15158,-1.14467,-1.16344,-1.15407,-1.15628,-1.151,-1.15376,-1.14777,-1.14952,-1.15925,-1.15802,-1.15218,-1.15511,-1.14935,-1.15188,-1.14486,-1.1634,-1.15407,-1.15629,-1.15098,-1.15372,-1.14765,-1.14927,-1.15924,-1.15802,-1.15217,-1.15511,-1.14933,-1.15183,-1.14475,-1.16339,-1.15406,-1.15629,-1.15098,-1.15403,-1.14143,-1.14147,-1.13981,-1.09547,-1.07462,-1.06806,-1.06677,-1.02991,-1.07839,-1.06491,-1.04682,-1.05565,-1.0639,-1.06283,-1.04374,-1.06947,-1.06831,-1.05217,-1.05222,-1.05719,-1.06786,-1.04073,-1.07325,-1.07,-1.04335,-1.05405,-1.06813,-1.05795,-1.03841,-1.08363,-1.06498,-1.03835,-1.06637,-1.05945,-1.06401,-1.03589,-1.08161,-1.06148,-1.05396,-1.05038,-1.06664,-1.06477,-1.04386,-1.06999,-1.07344,-1.04671,-1.04947,-1.06532,-1.06167]
32×26 Array{Float64,2}:
 -0.0782905   -0.00554523    0.0184073   -0.188404    -0.139607    -0.138646      0.0179706     0.121116    0.0610145  -0.128709     0.0489962   -0.0673065    0.0826775   -0.18801    -0.123893     0.0489905  -0.0106341    0.060517    -0.0264772   -0.15108     -0.0377761   -0.283957    -0.0460558  -0.0476899   -0.0823944   -0.000226548
 -0.0591408    0.0462641     0.10926     -0.178938    -0.049345    -0.0146658     0.199195     -0.0487868  -0.191701   -0.0267614   -0.105032    -0.0267119    0.0172786    0.073621   -0.0873416   -0.143921   -0.0174366   -0.0328221    0.00886885   0.0983258   -0.0278584   -0.165385     0.178017   -0.0175292    0.0394361   -0.0690966  
 -0.151549     0.101276     -0.138535    -0.105361     0.0411374   -0.048599      0.0325487    -0.289064    0.115385   -0.1065      -0.66486     -0.16151      0.0804525   -0.0484619   0.0109215    0.121467    0.123847    -0.0673641    0.168256     0.115023    -0.124348     0.072614     0.0435319  -0.0170752    0.0873481   -0.0174779  
 -0.148997     0.109143     -0.122539    -0.092861     0.0424223   -0.0568514     0.0577373    -0.285184    0.112076   -0.302456     0.702105    -0.0443219    0.178838    -0.105183   -0.0072296    0.147644    0.00304894  -0.0656642    0.182922     0.00747998  -0.115361     0.0439263    0.133333    0.195049    -0.00162167  -0.0481748  
 -0.111336    -0.00782674    0.0293772    0.0163223   -0.0460714    0.0316299     0.0464041    -0.0977173  -0.0392289   0.131416     0.0685698   -0.0343277   -0.0386339    0.17467    -0.0946471   -0.0279721   0.00970675  -0.0524519    0.00094003  -0.0171632   -0.0166493    0.0656449    0.0887213  -0.118947     0.0739694    0.173702   
  0.0404866    0.0741081    -0.0266609    0.0855097   -0.0489101   -0.0331804    -0.230167      0.188803    0.146875   -0.0727443    0.090187     0.0994541   -0.0254254   -0.21685     0.0642815    0.0256312   0.0873831    0.0850387   -0.0230894   -0.0736349    0.0283221   -0.0103337   -0.0307122  -0.0454314   -0.066113     0.0862656  
  0.115157    -0.000709481   0.0321644   -0.0647406    0.00827875   0.0692344     0.139613      0.0993     -0.112698   -0.00991391  -0.152055    -0.0838677   -0.00473823   0.0827927   0.182932     0.0175986   0.0193414   -0.171376    -0.0633766    0.0264493   -0.092404    -0.0372077    0.0247487   0.0836457   -0.0178364   -0.00931386 
 -0.0210961    0.0897851    -0.069527     0.132596     0.126341     0.028398      0.0609951    -0.0628234  -0.048739    0.103433     0.0948092   -0.168773     0.0405281    0.143488   -0.0715365   -0.151392    0.132625     0.119412     0.0273481    0.0924189   -0.0668764    0.0858585    0.0648022   0.00944145   0.0074406   -0.177028   
  0.0340611    0.151356     -0.0806344    0.0833452    0.138071     0.0409747     0.0178813     0.0719254  -0.0611039  -0.167349     0.065618     0.0939211   -0.0726618   -0.181267   -0.0193639   -0.042525    0.0716377    0.15691     -0.107425     0.0478766    0.0344284   -0.169691    -0.129946    0.0111945    0.170144     0.0531215  
 -0.0817813   -0.013751      0.00320819   0.0897284    0.0685755   -0.00220451   -0.00413423    0.0667546  -0.108768   -0.0244503    0.145965    -0.0985816   -0.0787752    0.0220212   0.0810812   -0.0171288   0.053683     0.0160927   -0.0528086    0.144639    -0.0405896   -0.0108207   -0.0451801  -0.0103768    0.00448684  -0.0243548  
 -0.0165457    0.155482      0.175066    -0.103146     0.108029    -0.148761      0.0914391     0.0908729  -0.0388246   0.0855206   -0.0431098    0.0227766   -0.0654652   -0.0518255  -0.0304898    0.0726261   0.07336      0.0452922    0.070962    -0.00732662   0.0382051    0.0493685   -0.0633696  -0.27567      0.0200417    0.0436051  
  0.129443    -0.0320225    -0.271646     0.055937    -0.0553654   -0.118346      0.153397     -0.0398378   0.0627909  -0.176554     0.0161647   -0.00586314   0.0720227   -0.0172004   0.0296114   -0.0714957   0.156713    -0.09393      0.125519    -0.00662047  -0.102988     0.0834946   -0.0312202  -0.067776     0.0827845    0.0469808  
  0.00962164  -0.0336657     0.0990053    0.142945     0.0299543   -0.0770966    -0.183408     -0.0800276  -0.130246    0.0274336    0.00714481   0.160867    -0.508767     0.0583704  -0.0580113    0.0301517  -0.0376896    0.00955883   0.0238325   -0.0237201    0.300155    -0.212094    -0.0191541  -0.0954015   -0.0116733   -0.055294   
 -0.0366443    0.0625176     0.0491657   -0.0919702    0.0489552   -0.156655     -0.244312     -0.100163   -0.309965    0.0123816   -0.0625257    0.0704799    0.108163     0.0520553  -0.0326857    0.0675243   0.0833761    0.155241     0.015964    -0.0441134    0.272474    -0.016011    -0.0153387   0.331248    -0.0582658   -0.0873236  
  0.0807592   -0.0227428    -0.0808378    0.193271     0.261492    -0.0692839     0.0229701    -0.0374042  -0.0266416  -0.125743    -0.0418179   -0.0105055    0.135273     0.0968786  -0.219108     0.0622567   0.0142495   -0.20224      0.00385738  -0.111916    -0.04692      0.15241     -0.0445982  -0.135742     0.0487474   -0.0516448  
  0.0488747    0.113231     -0.0365692   -0.0223575   -0.053402     0.0300519     0.000993948  -0.0416393   0.0355039  -0.0117944   -0.0343201    0.0376955   -0.0578273   -0.156447    0.0351714   -0.0381569  -0.00731321   0.0348371   -0.0447284   -0.0366813    0.0329383   -0.0373905   -0.0438895  -0.0166756    0.0163351   -0.0674984  
  0.0939243   -0.108053      0.00403839   0.0140335    0.0697887    0.0110431    -0.14503      -0.136628    0.104795   -0.113066    -0.0316655   -0.066802     0.116529     0.215654   -0.0264276   -0.185178    0.181172     0.0752091   -0.092708     0.0933927    0.0202522   -0.0510894   -0.0370628  -0.129888    -0.00526362   0.0670094  
  0.0677322    0.05878      -0.0186957   -0.00257822   0.32883      0.246259     -0.0845337    -0.163417    1.1157      0.0811165   -0.12878     -0.500731    -0.0484448   -0.0119976   0.168665    -1.54087     0.10665      0.139324    -0.122531     0.123751    -0.0364573   -0.0511925    0.262819   -0.00983676  -0.778165     0.0366831  
 -0.023298    -0.892791      0.0268435   -0.0413137    0.108422    -0.0553898     0.111363     -0.078937   -0.20494    -0.145244     0.0827718    0.0278414   -0.220825     0.0450914   0.0262165    0.060177    0.178967    -0.0389052   -0.0731524   -0.0697085    0.00902842  -0.0130773    0.0410023  -0.0543889   -0.00745289   0.0751422  
 -0.0234151    0.801649      0.0256711   -0.0418416    0.0533629   -0.053701      0.0410067    -0.0786804  -0.203964   -0.193271     0.0462343    0.035262    -0.218031     0.0390259   0.0109007    0.0623236   0.178738    -0.0124563    0.12649     -0.0264507    0.0524492   -0.0129703   -0.158957   -0.067114     0.126098     0.100645   
 -0.0451437   -0.140638      0.00525791   0.243275     0.0343219    0.00709871   -0.119431      0.046716    0.369092    0.0103275    0.0972782   -0.11451     -0.0342978    0.105243    0.015143     0.068538   -0.0861378   -0.0583122   -0.778365     0.0204111   -0.178515    -0.0337263    0.137268    0.123013    -0.152825    -0.0817635  
 -0.0299086   -0.140343      0.00741422  -0.164671    -0.0684934   -0.0109177    -0.0232065     0.053147   -0.248892    0.0344222    0.120076     0.121752    -0.0434131    0.0398355   0.00544382  -0.128897   -0.083585    -0.0701251    0.724934    -0.00304692  -0.173409    -0.0342472   -0.316451    0.107916    -0.103728    -0.0757531  
  0.0603556   -0.061287     -0.0912029    0.0165288    0.0363282   -0.0670352    -0.0138293    -0.104692    0.187305   -0.756903    -0.168817     0.00363458  -0.221479     0.239313   -0.243549    -0.308443   -0.176255    -0.0620837   -0.0853669   -0.138673    -0.223591    -0.101214    -0.0575715   0.252091    -0.0866207   -0.0420695  
 -0.0103698   -0.056698     -0.0960366    0.0410753    0.0940945   -0.00913007   -0.050989     -0.0769355   0.160798    0.890766    -0.155376     0.0407544   -0.15464      0.200622   -0.0836111   -0.303741   -0.108918     0.0846928   -0.0635338   -0.114186     0.151947    -0.107056    -0.0683604   0.133658    -0.126347    -0.0369265  
  0.0471911    0.0963317    -0.0981937   -0.00839096  -0.103953    -0.0133698     0.101158      0.0767462   0.0354072  -0.147629     0.173098    -0.0606989   -0.00207208   0.0444192  -0.145488     0.0250957   0.0347187    0.137979     0.0277777   -0.0300404   -0.0471183    0.0505009    0.0144457  -0.0381682    0.0246749    0.207233   
  0.0361508   -0.108769      0.12346      0.0928306   -0.1375       0.102577      0.0433626    -0.0241749  -0.0629916  -0.130546    -0.187504     0.291053     0.106695     0.144648   -0.0828174   -0.0753024  -0.150086    -0.0900513    0.0604499   -0.0367188   -0.0423057    0.00478329  -0.0885674  -0.00473059  -0.0952151    0.00729553 
  0.105201    -0.109097      0.068693     0.0590979    0.0418077   -0.0219562    -0.024019      0.0255978   0.134931   -0.0357849   -0.0652309    0.0511445   -0.161082     0.0539315  -0.0235038    0.104698   -0.108013    -0.0776044   -0.179566    -0.0628895   -0.0832442    0.00644381  -0.192292   -0.0107747   -0.0559654    0.0597026  
 -0.0530613    0.0197054     0.031305    -0.0127424   -0.0324044    0.000499728  -0.00355697    0.0215339  -0.057561    0.025199    -0.0571682    0.0400057    0.0774368   -0.078726    0.0626881    0.0816165  -0.01458      0.0606086    0.00026221  -0.0138661    0.0608512    0.00406813  -0.0484124   0.0336141    0.0472542   -0.00922719 
 -0.0993249   -0.099127      0.0212104   -0.0756712    0.0822742    0.0219        0.0237396     0.030455   -0.0569971  -0.0621318    0.0636725    0.0099203   -0.0571266    0.0719497  -0.0917684   -0.0440964  -0.0346645    0.110922     0.0223932    0.134131     0.0233078   -0.0644867    0.0719255   0.0290231    0.0170651    0.0290446  
 -0.0448334    0.112383     -0.0982209    0.157638     0.0717235   -0.00917798    0.0422678     0.0301452   0.158603   -0.0115119    0.0553321   -0.130222     0.0391755   -0.0178739   0.0255007    0.14052     0.00455291  -0.0865696    0.077273    -0.201161    -0.0898803    0.00878434  -0.102677   -0.121597     0.146633     0.0640831  
 -0.0887503    0.0957831     0.200911    -0.0853626   -0.00266927  -0.0561091    -0.0855924    -0.0470186  -0.0374996   0.172885    -0.0521801   -0.0762709    0.0442052    0.115569   -0.071545     0.0802513   0.0247944   -0.0594021    0.0298683    0.0770949   -0.176414     0.0484708   -0.0289999   0.021632     0.128177     0.117538   
 -0.0867695   -0.0299063    -0.0706411   -0.0175802    0.0578621    0.00618085    0.0453188     0.143386   -0.173793    0.0918536   -0.0185863    0.0440594   -0.128122     0.330109    0.0634992    0.250141   -0.0494388   -0.0380389   -0.0671075    0.0313193   -0.0491781    0.00660293  -0.0790959  -0.0267661    0.0117398   -0.158773   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 2 5 6 7 8 9 11 18 19 20 21 22 24 26
INFO: iteration 1, average log likelihood -1.040508
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 26 32
INFO: iteration 2, average log likelihood -1.021884
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 25 26
INFO: iteration 3, average log likelihood -1.032691
WARNING: Variances had to be floored 2 5 6 7 8 9 11 18 19 20 21 22 24 26 32
INFO: iteration 4, average log likelihood -1.033510
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 26
INFO: iteration 5, average log likelihood -1.028850
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 25 26 32
INFO: iteration 6, average log likelihood -1.026196
WARNING: Variances had to be floored 2 5 6 7 8 9 11 18 19 20 21 22 24 26
INFO: iteration 7, average log likelihood -1.039212
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 26 32
INFO: iteration 8, average log likelihood -1.023220
WARNING: Variances had to be floored 2 5 6 7 8 9 11 18 19 20 21 22 24 25 26
INFO: iteration 9, average log likelihood -1.032592
WARNING: Variances had to be floored 2 5 6 7 8 9 11 17 19 20 21 22 24 26 32
INFO: iteration 10, average log likelihood -1.027280
INFO: EM with 100000 data points 10 iterations avll -1.027280
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.248174e+05
      1       6.606784e+05      -1.641390e+05 |       32
      2       6.274326e+05      -3.324584e+04 |       32
      3       6.122641e+05      -1.516843e+04 |       32
      4       6.047912e+05      -7.472949e+03 |       32
      5       6.003891e+05      -4.402115e+03 |       32
      6       5.957526e+05      -4.636429e+03 |       32
      7       5.904929e+05      -5.259734e+03 |       32
      8       5.873423e+05      -3.150631e+03 |       32
      9       5.858509e+05      -1.491401e+03 |       32
     10       5.851475e+05      -7.033253e+02 |       32
     11       5.847017e+05      -4.458502e+02 |       32
     12       5.842872e+05      -4.145315e+02 |       32
     13       5.838656e+05      -4.215895e+02 |       32
     14       5.834579e+05      -4.077149e+02 |       32
     15       5.830827e+05      -3.751204e+02 |       32
     16       5.826834e+05      -3.993206e+02 |       32
     17       5.823894e+05      -2.940502e+02 |       32
     18       5.821907e+05      -1.986611e+02 |       32
     19       5.820540e+05      -1.366973e+02 |       32
     20       5.819787e+05      -7.527588e+01 |       31
     21       5.819280e+05      -5.067677e+01 |       31
     22       5.818948e+05      -3.324177e+01 |       32
     23       5.818732e+05      -2.165699e+01 |       31
     24       5.818563e+05      -1.689478e+01 |       32
     25       5.818426e+05      -1.367633e+01 |       31
     26       5.818325e+05      -1.005048e+01 |       30
     27       5.818230e+05      -9.486773e+00 |       30
     28       5.818137e+05      -9.365077e+00 |       29
     29       5.818042e+05      -9.488090e+00 |       30
     30       5.817972e+05      -6.994588e+00 |       29
     31       5.817914e+05      -5.762571e+00 |       25
     32       5.817864e+05      -5.036136e+00 |       26
     33       5.817815e+05      -4.943166e+00 |       23
     34       5.817775e+05      -3.990607e+00 |       23
     35       5.817750e+05      -2.466010e+00 |       19
     36       5.817730e+05      -2.003765e+00 |       18
     37       5.817709e+05      -2.082430e+00 |       22
     38       5.817685e+05      -2.360042e+00 |       26
     39       5.817657e+05      -2.861803e+00 |       23
     40       5.817637e+05      -2.024198e+00 |       17
     41       5.817625e+05      -1.138333e+00 |       15
     42       5.817619e+05      -6.717989e-01 |       11
     43       5.817614e+05      -4.289347e-01 |       12
     44       5.817610e+05      -3.818793e-01 |        8
     45       5.817608e+05      -2.351773e-01 |        7
     46       5.817606e+05      -1.670723e-01 |        2
     47       5.817606e+05      -2.478481e-02 |        3
     48       5.817605e+05      -6.701050e-02 |        6
     49       5.817604e+05      -1.885754e-01 |        7
     50       5.817600e+05      -3.515538e-01 |       10
K-means terminated without convergence after 50 iterations (objv = 581760.0084365751)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.305585
INFO: iteration 2, average log likelihood -1.274963
INFO: iteration 3, average log likelihood -1.244103
INFO: iteration 4, average log likelihood -1.207650
INFO: iteration 5, average log likelihood -1.169615
WARNING: Variances had to be floored 18
INFO: iteration 6, average log likelihood -1.132914
WARNING: Variances had to be floored 3 20
INFO: iteration 7, average log likelihood -1.108534
WARNING: Variances had to be floored 10 12 28
INFO: iteration 8, average log likelihood -1.082685
WARNING: Variances had to be floored 19 25 26
INFO: iteration 9, average log likelihood -1.075580
WARNING: Variances had to be floored 6 18 30
INFO: iteration 10, average log likelihood -1.071250
WARNING: Variances had to be floored 3 5 8 14 20
INFO: iteration 11, average log likelihood -1.071665
WARNING: Variances had to be floored 10 12
INFO: iteration 12, average log likelihood -1.082876
WARNING: Variances had to be floored 4 17 18 28
INFO: iteration 13, average log likelihood -1.063637
WARNING: Variances had to be floored 25 26
INFO: iteration 14, average log likelihood -1.057306
WARNING: Variances had to be floored 3 6 8 12 14 19 20 30
INFO: iteration 15, average log likelihood -1.018727
WARNING: Variances had to be floored 5 10 18
INFO: iteration 16, average log likelihood -1.100551
WARNING: Variances had to be floored 4
INFO: iteration 17, average log likelihood -1.093321
WARNING: Variances had to be floored 25
INFO: iteration 18, average log likelihood -1.052053
WARNING: Variances had to be floored 8 12 14 17 18 20 26 28
INFO: iteration 19, average log likelihood -1.009251
WARNING: Variances had to be floored 3 4 5 10 19
INFO: iteration 20, average log likelihood -1.088933
WARNING: Variances had to be floored 1 6
INFO: iteration 21, average log likelihood -1.095610
WARNING: Variances had to be floored 25 30
INFO: iteration 22, average log likelihood -1.048267
WARNING: Variances had to be floored 8 12 14 18 20 26
INFO: iteration 23, average log likelihood -1.026071
WARNING: Variances had to be floored 5 10 17
INFO: iteration 24, average log likelihood -1.079818
WARNING: Variances had to be floored 4 28
INFO: iteration 25, average log likelihood -1.056342
WARNING: Variances had to be floored 3 12 18 19 25 30
INFO: iteration 26, average log likelihood -1.021701
WARNING: Variances had to be floored 1 8 14 20
INFO: iteration 27, average log likelihood -1.085162
WARNING: Variances had to be floored 5 6 10 26
INFO: iteration 28, average log likelihood -1.065273
WARNING: Variances had to be floored 4 17
INFO: iteration 29, average log likelihood -1.062220
WARNING: Variances had to be floored 12 18 25 28 30
INFO: iteration 30, average log likelihood -1.032136
WARNING: Variances had to be floored 8 14
INFO: iteration 31, average log likelihood -1.073785
WARNING: Variances had to be floored 3 5 10 19 20
INFO: iteration 32, average log likelihood -1.038819
WARNING: Variances had to be floored 4 6 12 18 26
INFO: iteration 33, average log likelihood -1.054187
WARNING: Variances had to be floored 1 17 28 30
INFO: iteration 34, average log likelihood -1.077127
WARNING: Variances had to be floored 8 14 25
INFO: iteration 35, average log likelihood -1.065400
WARNING: Variances had to be floored 5 10 20
INFO: iteration 36, average log likelihood -1.057333
WARNING: Variances had to be floored 4 12 18 19 30
INFO: iteration 37, average log likelihood -1.034692
WARNING: Variances had to be floored 3 6 14 26 28
INFO: iteration 38, average log likelihood -1.067160
WARNING: Variances had to be floored 8 17
INFO: iteration 39, average log likelihood -1.084475
WARNING: Variances had to be floored 5 10 20 25
INFO: iteration 40, average log likelihood -1.047811
WARNING: Variances had to be floored 1 12 18
INFO: iteration 41, average log likelihood -1.049647
WARNING: Variances had to be floored 4 8 14 26 28 30
INFO: iteration 42, average log likelihood -1.048364
WARNING: Variances had to be floored 3
INFO: iteration 43, average log likelihood -1.072858
WARNING: Variances had to be floored 5 17 19 20 25
INFO: iteration 44, average log likelihood -1.038456
WARNING: Variances had to be floored 10 12 18
INFO: iteration 45, average log likelihood -1.050384
WARNING: Variances had to be floored 4 6 8 26 28
INFO: iteration 46, average log likelihood -1.065999
WARNING: Variances had to be floored 1 3 30
INFO: iteration 47, average log likelihood -1.065729
WARNING: Variances had to be floored 12 14 18 20 25
INFO: iteration 48, average log likelihood -1.054172
WARNING: Variances had to be floored 5 10
INFO: iteration 49, average log likelihood -1.078567
WARNING: Variances had to be floored 6 8 17 19 28
INFO: iteration 50, average log likelihood -1.048190
INFO: EM with 100000 data points 50 iterations avll -1.048190
59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.117708    0.0235635    0.0227834     0.110484    -0.0398421    0.0688653    0.0303233  -0.3315       0.0424405   0.125459     0.26975     -0.0361593   -0.0484109    0.17954    -0.0705232   -0.0820622     0.000339691  -0.0214009   -0.0674778    0.00524068  -0.0231112    0.0743002    0.128288    -0.154487     0.0623348    0.22434   
 -0.0883369   0.0934511    0.199088     -0.0858887   -0.00383985  -0.0549745   -0.0857479  -0.0479693   -0.0386924   0.172308    -0.0494638   -0.0766855    0.0446608    0.116518   -0.0714561    0.0803154     0.0251254    -0.0591591    0.0300771    0.0750735   -0.174582     0.0476508   -0.028366     0.0218092    0.128916     0.117006  
  0.0717925   0.00181965   0.0300238    -0.0360407    2.10376e-5   0.0608651    0.128584    0.091283    -0.100742    0.0214398   -0.12744     -0.0711274   -0.0172194    0.145499    0.122534     0.00120532    0.0174401    -0.141088    -0.0484208    0.0235917   -0.0797977   -0.0176304    0.0511064    0.0586236    0.0231051    0.0113231 
 -0.145453   -0.097603     0.000773345  -0.0872673    0.131377    -0.00878989   0.0680619   0.0563076   -0.0279141   0.0990976    0.0748759    0.0253564   -0.0162956   -0.0653503   0.0232528   -0.000521965  -0.004251      0.0123954   -0.0448028    0.125096    -0.0296451   -0.0965911    0.143248    -0.0501314   -0.0454019    0.0247369 
  0.100715    0.00311357  -0.114204      0.163245     0.128575    -0.0375189   -0.0189661   0.0950741   -0.156491   -0.0265368    0.119022    -0.0619937    0.0821392   -0.0097248   0.0291209   -0.0773433     0.117019      0.0265445   -0.053312     0.0883684   -0.0755318   -0.054546    -0.0118915    0.00375273   0.0311255   -0.0911128 
  0.0362309   0.168376     0.157252     -0.0144206   -0.123082    -0.0599832   -0.0285686  -0.0624731    0.0851451   0.10772     -0.14954      0.055871     0.060139    -0.269605    0.114267     0.0300302    -0.0594179     0.100776    -0.02611      0.00281164   0.0795127   -0.107024    -0.00145774   0.0749004    0.0548209   -0.122875  
 -0.0543559  -0.0949427    0.035678     -0.0507872    0.0264441    0.0473949   -0.0230682   0.00649016  -0.0857091  -0.212326     0.0461254   -0.017929    -0.0863047    0.208282   -0.190956    -0.0912262    -0.0571431     0.217511     0.078384     0.12429      0.0684732   -0.0245662    0.00191845   0.0970134    0.0747818    0.0291002 
 -0.0619227   0.0461179    0.111502     -0.163872    -0.0411505   -0.0149588    0.201811   -0.0487439   -0.198776   -0.0289127   -0.114939    -0.0271745    0.0180266    0.0761669  -0.0789494   -0.141222     -0.0167146    -0.039477     0.0085095    0.0980052   -0.0282848   -0.163614     0.186757    -0.0146594    0.0342086   -0.068138  
 -0.230834    0.0299058    0.173018      0.120278    -0.0180839    0.017628    -0.0140858   0.0221819   -0.0430564   0.0140018    0.187791    -0.0812412   -0.237466    -0.0160691   0.0943035    0.0255572    -0.00770717    0.0396409   -0.0449394    0.162951     0.0553647   -0.00290298  -0.103533    -0.0615699   -0.00192491   0.0402381 
 -0.020503    0.117433     0.185218     -0.270711     0.108498    -0.154113     0.0904013   0.0925295   -0.0338318   0.103215    -0.0725416   -0.00369466  -0.11685     -0.0334677   0.00106325   0.102179      0.0643781     0.0378913    0.0526673    0.0141033    0.0113266    0.0854967   -0.0791466   -0.244228     0.0217895    0.0255388 
  0.0828266  -0.0223083   -0.0779157     0.194033     0.257015    -0.0706684    0.03194    -0.0342579   -0.0270548  -0.125797    -0.0425721   -0.00996809   0.1348       0.0943705  -0.216277     0.0609705     0.0145732    -0.203634     0.00142442  -0.111477    -0.0467205    0.148091    -0.0445085   -0.142414     0.0495607   -0.0518586 
 -0.108757   -0.0334982   -0.0661363    -0.0242281    0.0591638    0.00449723   0.0395064   0.144616    -0.168289    0.0938681   -0.00154849   0.0453658   -0.124949     0.323408    0.0577717    0.241271     -0.0447231    -0.0351342   -0.0651774    0.0296853   -0.051466     0.00441794  -0.0792007   -0.0204634    0.00828376  -0.143472  
 -0.0377212   0.122577    -0.100216      0.161887     0.0689153   -0.00703258   0.0421753   0.0245212    0.171866   -0.00999169   0.0611863   -0.136846     0.0392265   -0.0159297   0.0328172    0.145951      0.00633954   -0.0919507    0.0829188   -0.218734    -0.090943     0.00625092  -0.112296    -0.12682      0.154409     0.0611697 
  0.0602027  -0.135021     0.124975      0.102182    -0.238749     0.105064     0.0399442  -0.0444756   -0.0656545  -0.159114    -0.163585     0.589209     0.095042     0.162147   -0.0852703   -0.0982277    -0.209458     -0.230783     0.0514551   -0.0990045   -0.0264644   -0.0148433   -0.0976692   -0.0507894   -0.101339    -0.0229536 
  0.117264   -0.02219     -0.255393      0.0519754   -0.0513755   -0.116829     0.141599   -0.0388795    0.0570684  -0.168732     0.0184626   -0.00337681   0.0629294   -0.0154166   0.0293329   -0.0722512     0.15161      -0.084264     0.123274    -0.00331124  -0.0989416    0.0810894   -0.032446    -0.0745901    0.0755419    0.0434615 
 -0.149503    0.107069    -0.086581      0.0131969   -0.0050665   -0.0112418    0.112446   -0.0292514    0.11419     0.0258467   -0.100493     0.0872474    0.107089    -0.292314    0.0436734   -0.100324     -0.0845007     0.0400215   -0.0163654   -0.0423242    0.0544108    0.0665846   -0.102274    -0.0564553   -0.0249715   -0.127339  
  0.093741   -0.109982     0.00195557    0.0145643    0.068305     0.0103737   -0.145764   -0.137778     0.104393   -0.113134    -0.0318905   -0.0648791    0.115438     0.21383    -0.0261419   -0.186008      0.181927      0.0764256   -0.0927833    0.0951606    0.0201048   -0.0509791   -0.0391275   -0.130112    -0.0143512    0.0668309 
 -0.0361374   0.0732547   -0.06057       0.138792     0.121541     0.019832     0.0562771  -0.0589298   -0.0291309   0.108678     0.0925821   -0.153919     0.0326152    0.148825   -0.0578498   -0.135617      0.115201      0.0991179    0.022829     0.0862671   -0.0742708    0.0737005    0.0447927    0.0103923    0.00328111  -0.156388  
  0.0369165   0.0660672   -0.0278143     0.0859037   -0.0609624   -0.0308441   -0.225863    0.177335     0.145904   -0.0678647    0.0987182    0.0939442   -0.0225322   -0.213177    0.0581292    0.0294849     0.0814693     0.0777066   -0.0202947   -0.0760015    0.0256133   -0.00412767  -0.0323979   -0.0566321   -0.0528274    0.0789763 
  0.0613621   0.149534    -0.0753721     0.104812     0.190013     0.0433163    0.0219743   0.0707197   -0.0637734  -0.197292     0.023102     0.114097    -0.0836211   -0.183245   -0.0204062   -0.0571746     0.0906877     0.147765    -0.106609     0.0385754    0.0307376   -0.199132    -0.158736     0.00215975   0.170555     0.0431104 
 -0.0587598  -0.0918456   -0.0738507     0.0656997   -0.119685     0.0244038   -0.0508626   0.0432558   -0.109677    0.073317    -0.00869893   0.0467969    0.113759     0.0282755  -0.0101741    0.103879      0.0348354     0.1729      -0.0549687   -0.00821088   0.0318626    0.047309    -0.0859402    0.0603681    0.104741    -0.0184524 
  0.116981    0.0621984    0.0419551    -0.0142248   -0.0289053   -0.0105725   -0.154136   -0.0758047   -0.133709   -0.0158923   -0.00138391   0.0527391   -0.21729      0.0137428  -0.00737749   0.0336729     0.0520544     0.0597635   -0.0256212   -0.0340661    0.146077    -0.1327      -0.00281699   0.0758144    0.0157417   -0.0415699 
  0.0285212  -0.0601506   -0.0921711     0.0299893    0.06639     -0.0359181   -0.0338644  -0.0873092    0.172751    0.107894    -0.160376     0.0221074   -0.184758     0.216912   -0.157334    -0.304477     -0.140841      0.0119162   -0.0747743   -0.122781    -0.0286105   -0.103045    -0.0639048    0.188982    -0.108606    -0.0394766 
 -0.117238    0.013529    -0.010821     -0.118148     0.155991     0.0365733    0.0811093   0.0652858   -0.166294   -0.112862    -0.0151526   -0.0134266    0.053277    -0.0179313   0.0962845    0.118305     -0.0205721    -0.136879     0.110409    -0.0147282    0.082958     0.0656606   -0.0528982   -0.0720332   -0.0162276    0.170388  
 -0.0421796  -0.125452     0.00673125    0.0429423   -0.0540693    0.017361    -0.0848209   0.0342081    0.0364642   0.00847739   0.0724609    0.00293639  -0.0140346    0.0523722   0.00967186  -0.0577233    -0.0978635    -0.0743988    0.0330641    0.0111468   -0.164411    -0.0409346   -0.103024     0.136398    -0.129732    -0.0727382 
  0.0324481  -0.0840552    0.115842      0.0693109   -0.0958881    0.103332     0.0527736  -0.0105524   -0.0630376  -0.143437    -0.154673     0.13831      0.0962511    0.164412   -0.10976     -0.0647391    -0.0924891     0.0291318    0.0519602    0.00302179  -0.0400775    0.0606305   -0.0661993   -0.0218364   -0.0916206    0.0359567 
  0.260783    0.0261691    0.0139639     0.00747674   0.0988749   -0.0104379   -0.12306     0.0151867    0.121001    0.0404571   -0.159527     0.0151415   -0.227569     0.0138634  -0.0526311    0.164962     -0.109672     -0.171193    -0.111173    -0.158608    -0.00373508  -0.0844791   -0.249477     0.0927365   -0.0484055    0.0521491 
  0.0482605   0.0857682   -0.0960496    -0.0129222   -0.066381    -0.00888397   0.0934729   0.0747153    0.0371154  -0.145352     0.162198    -0.0545817   -0.00450768   0.0551225  -0.148215     0.020133      0.038839      0.130649     0.0179602   -0.0334417   -0.0515146    0.0382845    0.0104382   -0.0367812    0.0277778    0.203664  
 -0.149979    0.106295    -0.130623     -0.0993622    0.0411339   -0.0527993    0.0459073  -0.287086     0.114217   -0.204583     0.0262357   -0.102123     0.130088    -0.0770278   0.00218022   0.135232      0.0617219    -0.0659317    0.175556     0.0602224   -0.119703     0.0581036    0.0886948    0.0902038    0.0424737   -0.0327008 
 -0.0409186  -0.0149075    0.029053     -0.0418734    0.0526726   -0.041587     0.0673232  -0.0920782   -0.184158   -0.090897     0.0632472    0.0159614   -0.191148     0.0396786  -0.00887002   0.0507819     0.140729     -0.0347056    0.0312508   -0.0378522    0.0189367    0.00145608  -0.020862    -0.0790439    0.0590135    0.115766  
 -0.0784293  -0.00511801   0.0207338    -0.186729    -0.128103    -0.138164     0.0176102   0.119371     0.056264   -0.120762     0.0518739   -0.0675611    0.0807142   -0.183413   -0.122914     0.0436647    -0.0108932     0.0596849   -0.0238707   -0.145994    -0.0381678   -0.278994    -0.0414952   -0.0559529   -0.0819865   -0.00411578
 -0.0959125  -0.269114     0.159181      0.130968    -0.0160116   -0.031565     0.0835952   0.0482593    0.155193   -0.13055      0.0438283    0.113085    -0.084961     0.123675   -0.0317787    0.0153425    -0.117297      0.00916155  -0.268317     0.0416612   -0.192843     0.118085    -0.125368    -0.143162    -0.0737508    0.0767655 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.065509
WARNING: Variances had to be floored 1 3 4 12 18 20 26 30
INFO: iteration 2, average log likelihood -1.009362
WARNING: Variances had to be floored 3 4 5 6 8 10 12 14 18 19 20 25 26 30
INFO: iteration 3, average log likelihood -0.995740
WARNING: Variances had to be floored 1 4 17 18 26 28 30
INFO: iteration 4, average log likelihood -1.034097
WARNING: Variances had to be floored 3 4 12 18 20
INFO: iteration 5, average log likelihood -1.028751
WARNING: Variances had to be floored 1 3 4 5 6 8 10 12 14 18 20 25 26 30
INFO: iteration 6, average log likelihood -0.992418
WARNING: Variances had to be floored 4 12 17 18 19 26 28 30
INFO: iteration 7, average log likelihood -1.028621
WARNING: Variances had to be floored 1 3 5 12 20 25
INFO: iteration 8, average log likelihood -1.030755
WARNING: Variances had to be floored 4 6 8 10 12 14 18 26 30
INFO: iteration 9, average log likelihood -1.004907
WARNING: Variances had to be floored 1 3 4 5 12 17 18 19 20 25 26 28 30
INFO: iteration 10, average log likelihood -1.010595
INFO: EM with 100000 data points 10 iterations avll -1.010595
59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.138793     0.0535379    0.08881      0.0656318    0.0693704    0.00158995   0.0418349    0.0402575   -0.1358       0.0297345    0.0882855   -0.0305506   -0.205429    -0.0180829   -0.116428    -0.169344     0.0102464   -0.0154529    0.0653697     0.0739979   -0.0599062    0.045607    -0.194969     0.00992461   0.0769374   -0.00123391
 -0.101681     0.0473583    0.127444     0.1033       0.150349    -0.110042     0.0474778   -0.191981     0.13521      0.029225    -0.0560087    0.139404    -0.0232324   -0.0602077    0.190495    -0.079106    -0.162993    -0.13088     -0.124996      0.00701823  -0.146165    -0.124842    -0.0856404    0.00913672  -0.158658    -0.105637  
  0.0189421    0.0190264   -0.00410468  -0.137154    -0.0283826    0.0428427    0.0310649    0.136886     0.0715434    0.276868     0.0732044   -0.0993173   -0.125585    -0.105059     0.0176162    0.132121    -0.0262088   -0.0621642    0.0609928    -0.00756186   0.0596091    0.195927     0.0350298   -0.156933    -0.113106     0.123862  
  0.237363     0.241569    -0.0683801    0.243809    -0.0152521    0.0289152    0.104975     0.0885025    0.0411257   -0.00518751  -0.129172    -0.0837032    0.125718    -0.0707491   -0.03726     -0.00511397  -0.203902     0.0147083    0.159613      0.0231902   -0.0860882    0.0402104   -0.0246931   -0.209884    -0.0959704    0.183458  
 -0.165094    -0.118769    -0.173128    -0.00518944   0.00666474  -0.136512    -0.103407    -0.00346006  -0.157005     0.0859149    0.0689843    0.0516729   -0.0727076    0.032242    -0.00437236   0.0956614    0.0363996    0.0271073   -0.0203323    -0.00929692  -0.0284566    0.172233    -0.0830777   -0.0883953   -0.0310802    0.14911   
 -0.0085837    0.00888466  -0.0369972    0.0216254   -0.12318      0.00908409   0.0939166    0.115347    -0.0589466   -0.00812097  -0.0527639   -0.0513368    0.00746206  -0.0348271    0.192507     0.026649     0.0168905    0.00100444  -0.152282     -0.173184    -0.0318963    0.0479906   -0.0334017    0.0755562    0.0501044   -0.0300042 
 -0.115638    -0.106155    -0.110327     0.0282933   -0.0144599   -0.185645    -0.0170949   -0.162104     0.0482186    0.0250876   -0.0280944    0.0144817   -0.0224792    0.0502541    0.105107    -0.117162     0.0257277    0.00623408  -0.0548936     0.0970908   -0.123753    -0.065033    -0.00958819  -0.00688505   0.050843    -0.0755576 
 -0.0758137   -0.109267    -0.0608067   -0.0163939    0.0339376   -0.106349    -0.0665842    0.096164    -0.179197    -0.0690493    0.0245306   -0.160845     0.0143943   -0.00533703  -0.0161398   -0.0509559    0.0137536    0.0362183    0.0665243    -0.120425     0.162988     0.119067     0.177465     0.0813728    0.0757698   -0.0351669 
  0.0746819    0.0725768   -0.0330153   -0.217704     0.0374514   -0.0504137   -0.211495    -0.146585    -0.143368     0.134724     0.0665906    0.176115    -0.0474118   -0.0543251    0.0115267    0.33055      0.0282675   -0.0566817    0.173224      0.0358894    0.0683444    0.00523162  -0.0562337    0.0568231    0.0399728    0.00377669
  0.0342044   -0.101342    -0.0809985    0.138063     0.0185424    0.0224418   -0.0183844    0.0419467   -0.122105    -0.104033     0.0200539    0.0626105   -0.0228267   -0.0142315    0.0478439    0.0553698   -0.0152593   -0.0508792   -0.16368      -0.0716876   -0.061507    -0.186673     0.136237     0.124915    -0.0156035   -0.075239  
 -0.0574318   -0.0972901    0.057757    -0.0509479   -0.104588    -0.173088    -0.0771681    0.105876    -0.111051    -0.122609     0.0468169   -0.050847    -0.360003    -0.00858479   0.0816891   -0.0852753   -0.100024     0.055967    -0.034538      0.208237     0.205925     0.00317082   0.0833126    0.0638142    0.100611     0.0262309 
 -0.0815595   -0.0468355    0.0613748    0.0190841   -0.08297     -0.0564413    0.126543     0.0283395    0.161423     0.123317    -0.248562    -0.0335389    0.0533329   -0.135232     0.0746783   -0.00169519  -0.058082    -0.0131802    0.044717      0.0377441   -0.10135     -0.0916508    0.0100978   -0.0971548    0.0165113   -0.156226  
  0.02966      0.0880004    0.046        0.0987262    0.130111     0.12935      0.0117955   -0.0290552    0.052832    -0.00869252  -0.126555     0.0561367   -0.139476     0.0927389   -0.017828    -0.0621523    0.0694278    0.127538    -0.0511846    -0.113933    -0.158273    -0.102025    -0.0490281   -0.0604428    0.00545717   0.0459777 
  0.0836405   -0.0638692    0.0206042    0.258819     0.0998118    0.0229602    0.0516949    0.0494003   -0.184453     0.0288083   -0.00977183  -0.0123274    0.0246531   -0.109013     0.250065     0.151632     0.112309     0.122012    -0.0028619    -0.0740602   -0.107499     0.151457    -0.150292    -0.0186394   -0.192317    -0.104608  
 -0.00552273  -0.0773092    0.0251241   -0.116068    -0.0372502   -0.0250909   -0.0992809   -0.0659262   -0.0686676   -0.00437395  -0.146685     0.0326899    0.0401003    0.0599432   -0.104704    -0.180132    -0.0210171   -0.206041    -0.191153      0.0739909   -0.00913941   0.0605702   -0.0742251   -0.118101    -0.121567     0.0274701 
 -0.121416    -0.137325    -0.0193519    0.084742     0.214921    -0.0450958   -0.0176098    0.0809963   -0.0886432    0.0724072   -0.0642517    0.0154048   -0.105997    -0.00514934   0.159965    -0.0532474   -0.0506152    0.0425551   -0.0248999    -0.00543135  -0.239878    -0.00610128   0.016202     0.0693585   -0.096863     0.00732523
  0.0447283    0.014201    -0.0912668    0.0136845   -0.00845526  -0.0955823   -0.00109934   0.130634     0.16111      0.104149     0.182483     0.0411085    0.0699721    0.0675479    0.121394     3.48931e-5   0.216867     0.115213     0.073554      0.0201553   -0.0620213    0.00165759  -0.0518409    0.191886     0.0456644   -0.177449  
 -0.224492     0.0257149    0.0506101    0.0637265    0.267286    -0.0563807    0.0266697    0.00529421   0.0576036    0.128059    -0.180174     0.073428    -0.0295496    0.0140228    0.158933     0.123511     0.0685558    0.0165922   -0.139587      0.00620775  -0.0333816   -0.186188     0.259864    -0.062879     0.0183049    0.0319781 
 -0.00180999  -0.0594038   -0.197434    -0.0531779   -0.0155537   -0.114555     0.00474722  -0.0262978    0.159034     0.146903     0.0831286   -0.0934583    0.0461709   -0.255651    -0.0548668   -0.0768543   -0.126023     0.0294156    0.113157      0.0124146   -0.193026     0.0819839   -0.165432     0.0337861    0.053675     0.021374  
 -0.0597038    0.0352379   -0.0159486    0.262057    -0.0622734   -0.053761     0.0427479    0.0175429   -0.0897078   -0.111817     0.205099    -0.0846671    0.099961    -0.105388    -0.0545069    0.0648676   -0.119031    -0.0525312   -0.0294467     0.00684564   0.0564031    0.079203     0.115612     0.00149279  -0.0351672    0.102463  
  0.00189447  -0.00383844   0.0646672   -0.0799695   -0.0742317   -0.0651784   -0.1135      -0.0677238   -0.0934493   -0.0794639   -0.0782076   -0.343855    -0.0988646    0.0146629    0.0796408    0.176061    -0.166219    -0.00653861  -0.110941     -0.0161315   -0.00590671  -0.134541    -0.0144965   -0.0957681   -0.0678607    0.0117875 
 -0.0640105   -0.0310113    0.070593     0.0383409   -0.0565754    0.0881475    0.102805     0.204079     0.0253633    0.120416     0.082878    -0.144879    -0.0808037   -0.111818    -0.0496639   -0.0376479   -0.0837855   -0.0138625    0.0560989    -0.0171726   -0.0396893   -0.090652     0.0782855   -0.0496775   -0.147839     0.17246   
  0.0475036    0.074323    -0.181882    -0.0668457   -0.119072     0.0161773    0.0244788    0.0319792    0.201309     0.126367     0.0214814   -0.0794817   -0.135996     0.00364928   0.0592536   -0.196819     0.0979827    0.081745     0.000122607  -0.226456     0.152689    -0.116778     0.156261    -0.0436115   -0.0481763    0.0414769 
 -0.0702989   -0.121114    -0.134505    -0.109455    -0.222184    -0.0237962    0.0756474   -0.112273    -0.00517054  -0.104938     0.121586    -0.00293375  -0.159621     0.220469     0.03182      0.257093    -0.00394921  -0.130864    -0.0860623     0.0115103    0.00996422  -0.0725969   -0.0684081   -0.00735139  -0.0513684   -0.0977118 
  0.0174893    0.0432096   -0.0613186    0.191941     0.0173321   -0.0851428    0.0057817    0.0566502   -0.127575     0.0384655    0.0637663    0.0926831   -0.132056    -0.0837011   -0.11062      0.0262764    0.0786923   -0.0743013   -0.107612     -0.0747483    0.1068      -0.20646      0.202791     0.0194347   -0.00581455   0.0799175 
  0.0149927    0.149358    -0.189329    -0.0371132   -0.0900247    0.0874725   -0.110288     0.0759472   -0.168847     0.0778676    0.18382      0.0537949    0.0650545    0.0139068   -0.0482162    0.071245     0.065283    -0.0154498    0.00681354   -0.160925    -0.0199954   -0.0368973    0.0273389   -0.0467503    0.0377357    0.0397198 
  0.180779    -0.00471551  -0.0805387    0.25418     -0.0106804   -0.0919368   -0.0709008   -0.220732     0.092023     0.0477103   -0.0747079   -0.0489454   -0.190351    -0.152026     0.112728     0.0843983   -0.0401616   -0.0596706   -0.111441     -0.00815844   0.0387918   -0.0295782   -0.0173919    0.0744943   -0.010135     0.135183  
  0.0560044    0.130345    -0.106139    -0.0236354   -0.0940224    0.0676371   -0.00765127   0.139026    -0.0782265   -0.0875142   -0.148647    -0.207183     0.0657273    0.0857434    0.151468    -0.0559276   -0.0919293   -0.0562194    0.0793389     0.00699326  -0.0496393    0.0187586   -0.0513929   -0.190634     0.267862     0.0487301 
 -0.0320846    0.125451     0.142948     0.0596968    0.0751313   -0.0657075   -0.0182425    0.148497     0.0395318    0.0219107    0.0319192   -0.11223     -0.0923848    0.0929744   -0.0405346   -0.0122749   -0.00715032  -0.12632     -0.180101     -0.035755    -0.0638014   -0.0708812    0.0862469    0.0189621   -0.132189    -0.041115  
  0.011231    -0.0584263   -0.00626351  -0.217817     0.109402     0.0900925   -0.0604889    0.0724017    0.0554753    0.0525507    0.131859     0.17112     -0.125778    -0.0120935   -0.132964    -0.00791711   0.0410404   -0.0816015    0.182216      0.0701955    0.0582906    0.0515238   -0.110395     0.11638     -0.18611     -0.0295303 
 -0.116327     0.0746786    0.114086    -0.17497      0.0361402   -0.0520854   -0.0282048   -0.0650672   -0.132892     0.0791878    0.0667348   -0.0894902   -0.0875902   -0.178132    -0.146281    -0.00115859  -0.0903589   -0.0396048   -0.0044523    -0.139299     0.0018649   -0.0570464   -0.112542    -0.142301     0.0189081   -0.01544   
  0.0329998   -0.0101908   -0.211183     0.168149     0.0909063   -0.170871     0.0081058   -0.0241402   -0.00508474   0.00544007  -0.15578      0.0545279    0.0296227   -0.0378577    0.0855547    0.0103481   -0.0773463   -0.0536389    0.044802     -0.176021     0.0228649    0.0160725    0.0951943   -0.013162    -0.0301443   -0.123702  kind full, method split
0: avll = -1.4319920884867987
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.432011
INFO: iteration 2, average log likelihood -1.431958
INFO: iteration 3, average log likelihood -1.431922
INFO: iteration 4, average log likelihood -1.431881
INFO: iteration 5, average log likelihood -1.431831
INFO: iteration 6, average log likelihood -1.431766
INFO: iteration 7, average log likelihood -1.431677
INFO: iteration 8, average log likelihood -1.431538
INFO: iteration 9, average log likelihood -1.431286
INFO: iteration 10, average log likelihood -1.430787
INFO: iteration 11, average log likelihood -1.429894
INFO: iteration 12, average log likelihood -1.428686
INFO: iteration 13, average log likelihood -1.427601
INFO: iteration 14, average log likelihood -1.426956
INFO: iteration 15, average log likelihood -1.426668
INFO: iteration 16, average log likelihood -1.426552
INFO: iteration 17, average log likelihood -1.426506
INFO: iteration 18, average log likelihood -1.426488
INFO: iteration 19, average log likelihood -1.426480
INFO: iteration 20, average log likelihood -1.426477
INFO: iteration 21, average log likelihood -1.426475
INFO: iteration 22, average log likelihood -1.426475
INFO: iteration 23, average log likelihood -1.426474
INFO: iteration 24, average log likelihood -1.426474
INFO: iteration 25, average log likelihood -1.426474
INFO: iteration 26, average log likelihood -1.426474
INFO: iteration 27, average log likelihood -1.426474
INFO: iteration 28, average log likelihood -1.426473
INFO: iteration 29, average log likelihood -1.426473
INFO: iteration 30, average log likelihood -1.426473
INFO: iteration 31, average log likelihood -1.426473
INFO: iteration 32, average log likelihood -1.426473
INFO: iteration 33, average log likelihood -1.426473
INFO: iteration 34, average log likelihood -1.426473
INFO: iteration 35, average log likelihood -1.426473
INFO: iteration 36, average log likelihood -1.426473
INFO: iteration 37, average log likelihood -1.426473
INFO: iteration 38, average log likelihood -1.426473
INFO: iteration 39, average log likelihood -1.426473
INFO: iteration 40, average log likelihood -1.426473
INFO: iteration 41, average log likelihood -1.426473
INFO: iteration 42, average log likelihood -1.426473
INFO: iteration 43, average log likelihood -1.426473
INFO: iteration 44, average log likelihood -1.426473
INFO: iteration 45, average log likelihood -1.426473
INFO: iteration 46, average log likelihood -1.426473
INFO: iteration 47, average log likelihood -1.426473
INFO: iteration 48, average log likelihood -1.426473
INFO: iteration 49, average log likelihood -1.426473
INFO: iteration 50, average log likelihood -1.426473
INFO: EM with 100000 data points 50 iterations avll -1.426473
952.4 data points per parameter
1: avll = [-1.43201,-1.43196,-1.43192,-1.43188,-1.43183,-1.43177,-1.43168,-1.43154,-1.43129,-1.43079,-1.42989,-1.42869,-1.4276,-1.42696,-1.42667,-1.42655,-1.42651,-1.42649,-1.42648,-1.42648,-1.42648,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.426488
INFO: iteration 2, average log likelihood -1.426435
INFO: iteration 3, average log likelihood -1.426387
INFO: iteration 4, average log likelihood -1.426325
INFO: iteration 5, average log likelihood -1.426243
INFO: iteration 6, average log likelihood -1.426142
INFO: iteration 7, average log likelihood -1.426030
INFO: iteration 8, average log likelihood -1.425921
INFO: iteration 9, average log likelihood -1.425826
INFO: iteration 10, average log likelihood -1.425747
INFO: iteration 11, average log likelihood -1.425683
INFO: iteration 12, average log likelihood -1.425629
INFO: iteration 13, average log likelihood -1.425584
INFO: iteration 14, average log likelihood -1.425547
INFO: iteration 15, average log likelihood -1.425516
INFO: iteration 16, average log likelihood -1.425490
INFO: iteration 17, average log likelihood -1.425469
INFO: iteration 18, average log likelihood -1.425451
INFO: iteration 19, average log likelihood -1.425436
INFO: iteration 20, average log likelihood -1.425422
INFO: iteration 21, average log likelihood -1.425409
INFO: iteration 22, average log likelihood -1.425398
INFO: iteration 23, average log likelihood -1.425387
INFO: iteration 24, average log likelihood -1.425377
INFO: iteration 25, average log likelihood -1.425367
INFO: iteration 26, average log likelihood -1.425359
INFO: iteration 27, average log likelihood -1.425351
INFO: iteration 28, average log likelihood -1.425343
INFO: iteration 29, average log likelihood -1.425336
INFO: iteration 30, average log likelihood -1.425329
INFO: iteration 31, average log likelihood -1.425323
INFO: iteration 32, average log likelihood -1.425317
INFO: iteration 33, average log likelihood -1.425312
INFO: iteration 34, average log likelihood -1.425307
INFO: iteration 35, average log likelihood -1.425302
INFO: iteration 36, average log likelihood -1.425298
INFO: iteration 37, average log likelihood -1.425294
INFO: iteration 38, average log likelihood -1.425290
INFO: iteration 39, average log likelihood -1.425287
INFO: iteration 40, average log likelihood -1.425284
INFO: iteration 41, average log likelihood -1.425281
INFO: iteration 42, average log likelihood -1.425278
INFO: iteration 43, average log likelihood -1.425276
INFO: iteration 44, average log likelihood -1.425273
INFO: iteration 45, average log likelihood -1.425271
INFO: iteration 46, average log likelihood -1.425269
INFO: iteration 47, average log likelihood -1.425267
INFO: iteration 48, average log likelihood -1.425266
INFO: iteration 49, average log likelihood -1.425264
INFO: iteration 50, average log likelihood -1.425263
INFO: EM with 100000 data points 50 iterations avll -1.425263
473.9 data points per parameter
2: avll = [-1.42649,-1.42643,-1.42639,-1.42633,-1.42624,-1.42614,-1.42603,-1.42592,-1.42583,-1.42575,-1.42568,-1.42563,-1.42558,-1.42555,-1.42552,-1.42549,-1.42547,-1.42545,-1.42544,-1.42542,-1.42541,-1.4254,-1.42539,-1.42538,-1.42537,-1.42536,-1.42535,-1.42534,-1.42534,-1.42533,-1.42532,-1.42532,-1.42531,-1.42531,-1.4253,-1.4253,-1.42529,-1.42529,-1.42529,-1.42528,-1.42528,-1.42528,-1.42528,-1.42527,-1.42527,-1.42527,-1.42527,-1.42527,-1.42526,-1.42526]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.425272
INFO: iteration 2, average log likelihood -1.425219
INFO: iteration 3, average log likelihood -1.425175
INFO: iteration 4, average log likelihood -1.425126
INFO: iteration 5, average log likelihood -1.425066
INFO: iteration 6, average log likelihood -1.424994
INFO: iteration 7, average log likelihood -1.424910
INFO: iteration 8, average log likelihood -1.424818
INFO: iteration 9, average log likelihood -1.424723
INFO: iteration 10, average log likelihood -1.424630
INFO: iteration 11, average log likelihood -1.424542
INFO: iteration 12, average log likelihood -1.424464
INFO: iteration 13, average log likelihood -1.424396
INFO: iteration 14, average log likelihood -1.424339
INFO: iteration 15, average log likelihood -1.424292
INFO: iteration 16, average log likelihood -1.424255
INFO: iteration 17, average log likelihood -1.424225
INFO: iteration 18, average log likelihood -1.424202
INFO: iteration 19, average log likelihood -1.424182
INFO: iteration 20, average log likelihood -1.424165
INFO: iteration 21, average log likelihood -1.424150
INFO: iteration 22, average log likelihood -1.424137
INFO: iteration 23, average log likelihood -1.424125
INFO: iteration 24, average log likelihood -1.424115
INFO: iteration 25, average log likelihood -1.424104
INFO: iteration 26, average log likelihood -1.424095
INFO: iteration 27, average log likelihood -1.424085
INFO: iteration 28, average log likelihood -1.424077
INFO: iteration 29, average log likelihood -1.424068
INFO: iteration 30, average log likelihood -1.424060
INFO: iteration 31, average log likelihood -1.424052
INFO: iteration 32, average log likelihood -1.424045
INFO: iteration 33, average log likelihood -1.424037
INFO: iteration 34, average log likelihood -1.424030
INFO: iteration 35, average log likelihood -1.424023
INFO: iteration 36, average log likelihood -1.424016
INFO: iteration 37, average log likelihood -1.424009
INFO: iteration 38, average log likelihood -1.424003
INFO: iteration 39, average log likelihood -1.423996
INFO: iteration 40, average log likelihood -1.423990
INFO: iteration 41, average log likelihood -1.423983
INFO: iteration 42, average log likelihood -1.423977
INFO: iteration 43, average log likelihood -1.423971
INFO: iteration 44, average log likelihood -1.423965
INFO: iteration 45, average log likelihood -1.423959
INFO: iteration 46, average log likelihood -1.423953
INFO: iteration 47, average log likelihood -1.423947
INFO: iteration 48, average log likelihood -1.423941
INFO: iteration 49, average log likelihood -1.423936
INFO: iteration 50, average log likelihood -1.423930
INFO: EM with 100000 data points 50 iterations avll -1.423930
236.4 data points per parameter
3: avll = [-1.42527,-1.42522,-1.42518,-1.42513,-1.42507,-1.42499,-1.42491,-1.42482,-1.42472,-1.42463,-1.42454,-1.42446,-1.4244,-1.42434,-1.42429,-1.42426,-1.42423,-1.4242,-1.42418,-1.42417,-1.42415,-1.42414,-1.42413,-1.42411,-1.4241,-1.42409,-1.42409,-1.42408,-1.42407,-1.42406,-1.42405,-1.42404,-1.42404,-1.42403,-1.42402,-1.42402,-1.42401,-1.424,-1.424,-1.42399,-1.42398,-1.42398,-1.42397,-1.42397,-1.42396,-1.42395,-1.42395,-1.42394,-1.42394,-1.42393]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.423933
INFO: iteration 2, average log likelihood -1.423865
INFO: iteration 3, average log likelihood -1.423803
INFO: iteration 4, average log likelihood -1.423731
INFO: iteration 5, average log likelihood -1.423643
INFO: iteration 6, average log likelihood -1.423537
INFO: iteration 7, average log likelihood -1.423413
INFO: iteration 8, average log likelihood -1.423280
INFO: iteration 9, average log likelihood -1.423146
INFO: iteration 10, average log likelihood -1.423018
INFO: iteration 11, average log likelihood -1.422903
INFO: iteration 12, average log likelihood -1.422800
INFO: iteration 13, average log likelihood -1.422710
INFO: iteration 14, average log likelihood -1.422631
INFO: iteration 15, average log likelihood -1.422561
INFO: iteration 16, average log likelihood -1.422499
INFO: iteration 17, average log likelihood -1.422444
INFO: iteration 18, average log likelihood -1.422395
INFO: iteration 19, average log likelihood -1.422352
INFO: iteration 20, average log likelihood -1.422313
INFO: iteration 21, average log likelihood -1.422278
INFO: iteration 22, average log likelihood -1.422247
INFO: iteration 23, average log likelihood -1.422218
INFO: iteration 24, average log likelihood -1.422193
INFO: iteration 25, average log likelihood -1.422169
INFO: iteration 26, average log likelihood -1.422147
INFO: iteration 27, average log likelihood -1.422126
INFO: iteration 28, average log likelihood -1.422107
INFO: iteration 29, average log likelihood -1.422088
INFO: iteration 30, average log likelihood -1.422071
INFO: iteration 31, average log likelihood -1.422054
INFO: iteration 32, average log likelihood -1.422038
INFO: iteration 33, average log likelihood -1.422023
INFO: iteration 34, average log likelihood -1.422008
INFO: iteration 35, average log likelihood -1.421994
INFO: iteration 36, average log likelihood -1.421981
INFO: iteration 37, average log likelihood -1.421968
INFO: iteration 38, average log likelihood -1.421956
INFO: iteration 39, average log likelihood -1.421944
INFO: iteration 40, average log likelihood -1.421932
INFO: iteration 41, average log likelihood -1.421922
INFO: iteration 42, average log likelihood -1.421911
INFO: iteration 43, average log likelihood -1.421901
INFO: iteration 44, average log likelihood -1.421891
INFO: iteration 45, average log likelihood -1.421882
INFO: iteration 46, average log likelihood -1.421873
INFO: iteration 47, average log likelihood -1.421865
INFO: iteration 48, average log likelihood -1.421857
INFO: iteration 49, average log likelihood -1.421849
INFO: iteration 50, average log likelihood -1.421842
INFO: EM with 100000 data points 50 iterations avll -1.421842
118.1 data points per parameter
4: avll = [-1.42393,-1.42386,-1.4238,-1.42373,-1.42364,-1.42354,-1.42341,-1.42328,-1.42315,-1.42302,-1.4229,-1.4228,-1.42271,-1.42263,-1.42256,-1.4225,-1.42244,-1.4224,-1.42235,-1.42231,-1.42228,-1.42225,-1.42222,-1.42219,-1.42217,-1.42215,-1.42213,-1.42211,-1.42209,-1.42207,-1.42205,-1.42204,-1.42202,-1.42201,-1.42199,-1.42198,-1.42197,-1.42196,-1.42194,-1.42193,-1.42192,-1.42191,-1.4219,-1.42189,-1.42188,-1.42187,-1.42186,-1.42186,-1.42185,-1.42184]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.421843
INFO: iteration 2, average log likelihood -1.421774
INFO: iteration 3, average log likelihood -1.421709
INFO: iteration 4, average log likelihood -1.421631
INFO: iteration 5, average log likelihood -1.421535
INFO: iteration 6, average log likelihood -1.421417
INFO: iteration 7, average log likelihood -1.421280
INFO: iteration 8, average log likelihood -1.421131
INFO: iteration 9, average log likelihood -1.420977
INFO: iteration 10, average log likelihood -1.420829
INFO: iteration 11, average log likelihood -1.420690
INFO: iteration 12, average log likelihood -1.420563
INFO: iteration 13, average log likelihood -1.420449
INFO: iteration 14, average log likelihood -1.420348
INFO: iteration 15, average log likelihood -1.420260
INFO: iteration 16, average log likelihood -1.420182
INFO: iteration 17, average log likelihood -1.420114
INFO: iteration 18, average log likelihood -1.420055
INFO: iteration 19, average log likelihood -1.420002
INFO: iteration 20, average log likelihood -1.419955
INFO: iteration 21, average log likelihood -1.419913
INFO: iteration 22, average log likelihood -1.419875
INFO: iteration 23, average log likelihood -1.419840
INFO: iteration 24, average log likelihood -1.419807
INFO: iteration 25, average log likelihood -1.419777
INFO: iteration 26, average log likelihood -1.419749
INFO: iteration 27, average log likelihood -1.419722
INFO: iteration 28, average log likelihood -1.419697
INFO: iteration 29, average log likelihood -1.419672
INFO: iteration 30, average log likelihood -1.419649
INFO: iteration 31, average log likelihood -1.419626
INFO: iteration 32, average log likelihood -1.419605
INFO: iteration 33, average log likelihood -1.419584
INFO: iteration 34, average log likelihood -1.419563
INFO: iteration 35, average log likelihood -1.419544
INFO: iteration 36, average log likelihood -1.419525
INFO: iteration 37, average log likelihood -1.419507
INFO: iteration 38, average log likelihood -1.419489
INFO: iteration 39, average log likelihood -1.419472
INFO: iteration 40, average log likelihood -1.419456
INFO: iteration 41, average log likelihood -1.419440
INFO: iteration 42, average log likelihood -1.419425
INFO: iteration 43, average log likelihood -1.419411
INFO: iteration 44, average log likelihood -1.419397
INFO: iteration 45, average log likelihood -1.419384
INFO: iteration 46, average log likelihood -1.419371
INFO: iteration 47, average log likelihood -1.419359
INFO: iteration 48, average log likelihood -1.419347
INFO: iteration 49, average log likelihood -1.419336
INFO: iteration 50, average log likelihood -1.419325
INFO: EM with 100000 data points 50 iterations avll -1.419325
59.0 data points per parameter
5: avll = [-1.42184,-1.42177,-1.42171,-1.42163,-1.42154,-1.42142,-1.42128,-1.42113,-1.42098,-1.42083,-1.42069,-1.42056,-1.42045,-1.42035,-1.42026,-1.42018,-1.42011,-1.42005,-1.42,-1.41996,-1.41991,-1.41987,-1.41984,-1.41981,-1.41978,-1.41975,-1.41972,-1.4197,-1.41967,-1.41965,-1.41963,-1.4196,-1.41958,-1.41956,-1.41954,-1.41952,-1.41951,-1.41949,-1.41947,-1.41946,-1.41944,-1.41943,-1.41941,-1.4194,-1.41938,-1.41937,-1.41936,-1.41935,-1.41934,-1.41933]
[-1.43199,-1.43201,-1.43196,-1.43192,-1.43188,-1.43183,-1.43177,-1.43168,-1.43154,-1.43129,-1.43079,-1.42989,-1.42869,-1.4276,-1.42696,-1.42667,-1.42655,-1.42651,-1.42649,-1.42648,-1.42648,-1.42648,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42647,-1.42649,-1.42643,-1.42639,-1.42633,-1.42624,-1.42614,-1.42603,-1.42592,-1.42583,-1.42575,-1.42568,-1.42563,-1.42558,-1.42555,-1.42552,-1.42549,-1.42547,-1.42545,-1.42544,-1.42542,-1.42541,-1.4254,-1.42539,-1.42538,-1.42537,-1.42536,-1.42535,-1.42534,-1.42534,-1.42533,-1.42532,-1.42532,-1.42531,-1.42531,-1.4253,-1.4253,-1.42529,-1.42529,-1.42529,-1.42528,-1.42528,-1.42528,-1.42528,-1.42527,-1.42527,-1.42527,-1.42527,-1.42527,-1.42526,-1.42526,-1.42527,-1.42522,-1.42518,-1.42513,-1.42507,-1.42499,-1.42491,-1.42482,-1.42472,-1.42463,-1.42454,-1.42446,-1.4244,-1.42434,-1.42429,-1.42426,-1.42423,-1.4242,-1.42418,-1.42417,-1.42415,-1.42414,-1.42413,-1.42411,-1.4241,-1.42409,-1.42409,-1.42408,-1.42407,-1.42406,-1.42405,-1.42404,-1.42404,-1.42403,-1.42402,-1.42402,-1.42401,-1.424,-1.424,-1.42399,-1.42398,-1.42398,-1.42397,-1.42397,-1.42396,-1.42395,-1.42395,-1.42394,-1.42394,-1.42393,-1.42393,-1.42386,-1.4238,-1.42373,-1.42364,-1.42354,-1.42341,-1.42328,-1.42315,-1.42302,-1.4229,-1.4228,-1.42271,-1.42263,-1.42256,-1.4225,-1.42244,-1.4224,-1.42235,-1.42231,-1.42228,-1.42225,-1.42222,-1.42219,-1.42217,-1.42215,-1.42213,-1.42211,-1.42209,-1.42207,-1.42205,-1.42204,-1.42202,-1.42201,-1.42199,-1.42198,-1.42197,-1.42196,-1.42194,-1.42193,-1.42192,-1.42191,-1.4219,-1.42189,-1.42188,-1.42187,-1.42186,-1.42186,-1.42185,-1.42184,-1.42184,-1.42177,-1.42171,-1.42163,-1.42154,-1.42142,-1.42128,-1.42113,-1.42098,-1.42083,-1.42069,-1.42056,-1.42045,-1.42035,-1.42026,-1.42018,-1.42011,-1.42005,-1.42,-1.41996,-1.41991,-1.41987,-1.41984,-1.41981,-1.41978,-1.41975,-1.41972,-1.4197,-1.41967,-1.41965,-1.41963,-1.4196,-1.41958,-1.41956,-1.41954,-1.41952,-1.41951,-1.41949,-1.41947,-1.41946,-1.41944,-1.41943,-1.41941,-1.4194,-1.41938,-1.41937,-1.41936,-1.41935,-1.41934,-1.41933]
32×26 Array{Float64,2}:
  0.258342    -0.0435325   -0.127951   -0.312853    -0.503645    -0.0389976  -0.20577    -0.000587356  -0.334282   -0.140324    0.21395      0.34231       0.29162    -0.0508089  -0.185029   -0.0324356   0.318184    0.248192    0.658576    -0.212842   -0.397775     -0.274869   -0.284076   -0.123107    1.06582     0.599366  
 -0.108756    -0.00159949  -0.0299951   0.199402    -0.48788     -0.649339    0.543575    0.0652008    -0.861038   -0.0645617   0.460042     0.399804     -0.405106   -0.0817084   0.0592106  -0.568699    0.466215    0.154984   -0.14343     -0.150225    0.856922      0.388891   -0.471335   -0.54693     0.0756336   0.661297  
 -0.627845    -0.146065    -0.488789    0.272299     0.314945     0.201346    0.103578   -0.799203      0.311333    0.202925    0.0258224   -0.205337     -0.0465024   0.0735531   0.0861628  -0.0968732   0.0463327   0.659527   -0.197913    -0.371353   -0.0197823    -0.0707986   0.628147   -0.114482    0.545905   -0.0543079 
 -0.49601     -0.057586     0.195449    0.0522656    0.259699     0.114279   -0.170161    0.471037      0.107389   -0.146414    0.111634     0.254801     -0.0670501  -0.519188    0.0616351  -0.0404823   0.224538    0.567749    0.346515     0.379206   -0.000619319  -0.0410822   1.00719    -0.481203    0.590095   -0.00195071
  0.0439664    0.581662     0.0703998   0.806655    -0.153785     0.0882193   0.314653   -0.215345     -0.647522   -0.0914524  -0.350241    -0.381027     -0.377169    0.617573   -0.218831   -0.0697168  -0.476202    0.580141   -0.360441    -1.09736    -0.615719      0.0832583   0.154859    0.37489    -0.399765    1.17155   
  0.461965     0.151237     0.692605    0.0591554   -0.243632    -0.0941219  -0.218073    0.249847      0.753204    0.0633736  -0.116933    -0.0993411    -0.44565    -0.0556968  -0.102884    0.264489   -0.152963    0.423141   -0.0489757   -1.41492    -0.338234      0.217558    0.157173   -0.270898   -0.335491    0.523423  
 -0.142939    -0.345166    -0.633936    1.03319     -0.152948     0.133798   -0.0865685   0.339298      0.0230482  -0.015719    0.248957     0.642214     -0.0849481   0.0281474  -0.164076    0.208772    0.148648   -0.610197    0.013293     0.351386   -0.125633     -0.303594    0.744932    0.108677   -0.03353     0.475452  
  0.318515    -0.208763    -0.163565    0.152272    -0.175459    -0.0524138  -0.143165    0.0534453     0.202803   -0.0941532   0.392446     0.465622     -0.91939     0.162975    0.289474    0.0630408  -0.668225   -0.126651   -0.827029     0.54975     0.237014      0.345106    0.342241   -0.0677228  -0.0969858  -0.155035  
 -0.91257     -0.140835    -0.113156    0.142225     0.389689    -0.0392714   0.353588   -0.440601     -0.407074    0.384061   -0.0889433    0.814972      0.291593    0.116779   -0.0850863  -0.211947   -0.158249   -0.358171   -0.136342     0.887787    0.0468093    -0.417789   -0.655798   -0.0679425  -0.359857   -0.645307  
  0.00538473   0.365439    -0.675708    0.0430261    0.621502    -0.681444    0.107781   -0.120502      0.0263907   0.0457654   0.438015    -0.101518      0.298707   -0.0402825   0.0692764  -0.0496952  -0.336652   -0.354567   -0.255185     0.842397    0.27186      -0.275223   -0.154621   -0.0990022  -0.206972   -0.496722  
 -0.0280305    0.264682     0.3788     -0.580299     0.0858389   -0.129271    0.0844393  -0.433818     -0.150575   -0.0479746  -0.368733    -0.500684     -0.165028   -0.212831    0.257135   -0.0259058  -0.186022    0.0263547  -0.174646    -0.602615    0.131325      0.274508   -0.532478    0.0184533  -0.44307    -0.425359  
 -0.0884946   -0.0146647    0.0274277   0.113533     0.242682     0.0172784  -0.100931    0.308146      0.198451    0.202043   -0.0549592   -0.14181       0.124177    0.198577   -0.016408    0.0832413   0.0662247  -0.0428121   0.0353028    0.175394   -0.106363     -0.191882    0.225016   -0.0669642  -0.0388322  -0.0500737 
  0.150513    -0.716651     0.102439   -0.350783    -0.311438     0.627276    0.0048826  -0.136122     -0.0570825   0.025836    0.495003     0.000969458   0.570487   -0.447347   -0.818044   -0.0383468  -0.394236   -0.258884    0.301056     0.0756979  -0.159515     -0.0324288  -0.559817    0.5208      0.236868   -0.0127716 
  0.209751    -0.19365     -0.293717   -0.523196    -0.0834628    0.194872    0.615303   -0.107071     -0.133419    0.0382167  -0.130075    -0.506887      0.209535   -1.07366     0.548178    0.0924149  -0.0692965   0.0417675   0.264228     0.400437   -0.290722     -0.117264    0.102432    0.0523231   0.304303   -0.646433  
  0.57528     -0.68606     -0.407095   -0.770415     0.0618369    0.0625676   0.481877    0.263383      0.0258276   0.347096   -0.170493    -0.194359     -0.319859   -0.332351    0.0398571  -0.35064     0.049856    0.259104   -0.386456    -0.259958    0.814457     -0.311303    0.131099   -0.0981272   0.10208    -0.502949  
  0.399246    -0.649239    -0.627516   -0.0325475   -0.254279    -0.482097    0.281302   -0.344924     -0.119188    0.255213   -0.24082      0.116019     -0.14682    -0.54386     0.31028     0.290045    0.128942   -0.462703   -0.240204    -0.433722    0.568001      0.483826   -0.204965    0.599043    0.178612   -0.248725  
 -0.52915      0.318781     0.127067   -0.184256     0.0776132   -0.268318   -0.20867    -0.0427753    -0.394831    0.149355   -0.498239    -0.421516      0.529568    0.119273    0.064914   -0.0195409   0.182062    0.2995      0.315875    -0.11977    -0.326495     -0.158185   -0.445293   -0.584301    0.255339   -0.198618  
  0.127279     0.246064    -0.178473    0.115766     0.31739     -0.320777   -0.406268    0.285469     -0.502257   -0.197131   -0.0259016   -0.809578      0.516723    0.39372    -0.411718    0.121277    0.19483    -0.131952    0.0660498   -0.150543    0.0380041    -0.137496   -0.250345    0.70547     0.164308    0.093069  
 -0.588161     0.894059     0.552131    0.35068     -0.0563127    0.220254   -0.446089    0.0561143    -0.0162529  -0.238595    0.583506     0.298686     -0.127311    0.309207   -0.222903    0.131218   -0.234464   -0.0839038   0.573914     0.452296   -0.749204      0.0626195  -0.132921   -0.172532   -0.210089    0.516493  
  0.550695     0.203001     0.389619   -0.655531     0.00392424   0.26659    -0.20899     0.54324       0.488287    0.0876821   0.166727     0.274525      0.0293368  -0.167443    0.24763     0.0197479   0.105425   -0.445296    0.625837     0.897298   -0.135731     -0.201543   -0.368582   -0.226762   -0.3361     -0.136095  
 -0.58552      0.0839965   -0.0476165   0.536057     0.250764    -0.696096   -0.164558   -0.0644478     0.364877    0.077125   -0.529375     0.00782687   -0.294625    0.112344    0.238847    0.121297    0.0561303  -0.372171    0.072911    -0.291877    0.713924     -0.0549566   0.248083   -0.414252   -0.582443    0.118719  
  0.174096     0.408629    -0.0961241   0.0975206   -0.037986    -0.305374   -0.27158    -0.172516      0.293935   -0.0616365   0.637661    -0.05937      -0.085013    0.54958    -0.183456   -0.308852    0.194499    0.0198172   0.0667562   -0.233594    0.0884314    -0.0490926  -0.0151584  -0.405998   -0.34786     0.0967314 
  0.070511     0.428191     0.564049    0.2012       0.0457165   -0.469175    0.186293    0.557185     -0.408446    0.0331299  -0.372918    -0.0457686    -0.523905    0.243866    0.195889   -0.275522    0.225207    0.18315    -0.401409     0.195031   -0.0623718    -0.148659    0.224578   -0.464318   -0.114682    0.227896  
 -0.0389811   -0.32198      0.508669    0.424569    -0.179167     0.140778    0.433832   -0.0345934    -0.38071     0.29684    -0.104966     0.36269      -0.673982   -0.146948    0.395871   -0.224299    0.550059    0.134062    0.192493    -0.339358   -0.303775     -0.0858668  -0.250513   -0.328498   -0.111859   -0.0158875 
  0.0354503    0.251252    -0.135423    0.137561     0.197561    -0.0715352   0.0461741  -0.358735     -0.0465144   0.14175     0.540805     0.0831263     0.024299   -0.0983243  -0.228775    0.131676   -0.255544    0.419264    0.13572     -0.0649993  -0.243057     -0.466926   -0.23948     0.243833    0.244999    0.0643545 
  0.0225594   -0.101569     0.0541993   0.469733     0.0281326    0.236918    0.064968    0.102814     -0.135603   -0.0245481  -0.00470413   0.217832     -0.165346   -0.0616885   0.107083    0.0790694  -0.14861    -0.178476   -0.443642     0.265787   -0.0746323     0.0437989   0.198884    0.522986    0.0914889   0.347566  
 -0.0738838    0.0423935   -0.115957   -0.0939385    0.206892    -0.211848   -0.0781046  -0.206588     -0.0612017  -0.0205413  -0.284247    -0.0643507    -0.0312691  -0.0947102   0.102696    0.226767   -0.342018   -0.0117331   0.0411221   -0.0394193   0.180722      0.0945933  -0.0459468  -0.0683644  -0.176942   -0.163889  
  0.0406133   -0.205402    -0.136562   -0.0773041   -0.188923     0.157774    0.0434552   0.214991      0.137437    0.119216    0.0382434   -0.116874     -0.0382244  -0.154833    0.0746957  -0.105119    0.293628   -0.154316    0.00920469  -0.093058   -0.112517      0.0484107   0.110014   -0.0409081   0.104872   -0.0258354 
  0.611634    -0.191926     0.400829   -0.0262338   -0.126923    -0.197763   -0.562923    0.0346075    -0.381635   -0.0282826  -0.324004     0.134334      0.115374    0.256745    0.146466    0.0238945   0.0623642  -0.711321   -0.0740641   -0.258349   -0.0173706     0.405214   -1.14346     0.236754   -0.511067    0.0216276 
 -0.280664    -0.223326    -0.0369517  -0.033617     0.207199     0.683789   -0.198568    0.195064     -0.368808   -0.932435   -0.574085    -0.264065     -0.1034     -0.258386    0.240709   -0.260284    0.294457   -0.340243   -0.235549    -0.313385    0.0603027     0.149961    1.01871     0.17301    -0.734709    0.0040202 
 -0.163602    -0.141309     0.0849778   0.00752804   0.0791715    0.22204    -0.0148326   0.151826      0.682278    0.442767   -0.369803    -0.56664       0.0620849   0.188218    0.0476147   0.489777   -0.292387    0.0658972  -0.291445     0.206786   -0.459399      0.233903    0.50027     0.57983    -0.181574   -0.890916  
  0.143743    -0.125356    -0.464677   -0.175364    -0.384469     0.486922   -0.20205     0.371558      0.749801   -0.150664    0.0725676   -0.128189      0.0890517   0.269199   -0.178972    0.497506   -0.476933   -0.233894   -0.279942    -0.379503   -0.042836      0.339625    0.273014    0.335041   -0.352037    0.413478  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419315
INFO: iteration 2, average log likelihood -1.419304
INFO: iteration 3, average log likelihood -1.419294
INFO: iteration 4, average log likelihood -1.419285
INFO: iteration 5, average log likelihood -1.419275
INFO: iteration 6, average log likelihood -1.419266
INFO: iteration 7, average log likelihood -1.419257
INFO: iteration 8, average log likelihood -1.419249
INFO: iteration 9, average log likelihood -1.419240
INFO: iteration 10, average log likelihood -1.419232
INFO: EM with 100000 data points 10 iterations avll -1.419232
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.014309e+06
      1       7.150413e+05      -2.992680e+05 |       32
      2       7.034928e+05      -1.154850e+04 |       32
      3       6.983685e+05      -5.124351e+03 |       32
      4       6.954989e+05      -2.869542e+03 |       32
      5       6.936545e+05      -1.844450e+03 |       32
      6       6.923565e+05      -1.298018e+03 |       32
      7       6.913763e+05      -9.801953e+02 |       32
      8       6.906239e+05      -7.523562e+02 |       32
      9       6.899597e+05      -6.642054e+02 |       32
     10       6.894030e+05      -5.566885e+02 |       32
     11       6.889534e+05      -4.496267e+02 |       32
     12       6.885916e+05      -3.617966e+02 |       32
     13       6.882660e+05      -3.256187e+02 |       32
     14       6.879628e+05      -3.031359e+02 |       32
     15       6.876961e+05      -2.667284e+02 |       32
     16       6.874756e+05      -2.205275e+02 |       32
     17       6.872918e+05      -1.837771e+02 |       32
     18       6.871407e+05      -1.511331e+02 |       32
     19       6.870123e+05      -1.284077e+02 |       32
     20       6.868988e+05      -1.134291e+02 |       32
     21       6.867955e+05      -1.033526e+02 |       32
     22       6.867020e+05      -9.345850e+01 |       32
     23       6.866183e+05      -8.368118e+01 |       32
     24       6.865362e+05      -8.209091e+01 |       32
     25       6.864599e+05      -7.636487e+01 |       32
     26       6.863893e+05      -7.061038e+01 |       32
     27       6.863238e+05      -6.546840e+01 |       32
     28       6.862646e+05      -5.918695e+01 |       32
     29       6.862092e+05      -5.538002e+01 |       32
     30       6.861533e+05      -5.590729e+01 |       32
     31       6.861040e+05      -4.928361e+01 |       32
     32       6.860570e+05      -4.705324e+01 |       32
     33       6.860061e+05      -5.088085e+01 |       32
     34       6.859521e+05      -5.403661e+01 |       32
     35       6.859013e+05      -5.081480e+01 |       32
     36       6.858486e+05      -5.268148e+01 |       32
     37       6.857902e+05      -5.833725e+01 |       32
     38       6.857341e+05      -5.616349e+01 |       32
     39       6.856803e+05      -5.377024e+01 |       32
     40       6.856286e+05      -5.173450e+01 |       32
     41       6.855777e+05      -5.091790e+01 |       32
     42       6.855357e+05      -4.193485e+01 |       32
     43       6.854933e+05      -4.239340e+01 |       32
     44       6.854489e+05      -4.444166e+01 |       32
     45       6.854046e+05      -4.424627e+01 |       32
     46       6.853656e+05      -3.905994e+01 |       32
     47       6.853315e+05      -3.407912e+01 |       32
     48       6.852979e+05      -3.363814e+01 |       32
     49       6.852683e+05      -2.959167e+01 |       32
     50       6.852395e+05      -2.874985e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 685239.5186415404)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.431128
INFO: iteration 2, average log likelihood -1.426014
INFO: iteration 3, average log likelihood -1.424596
INFO: iteration 4, average log likelihood -1.423540
INFO: iteration 5, average log likelihood -1.422499
INFO: iteration 6, average log likelihood -1.421597
INFO: iteration 7, average log likelihood -1.420974
INFO: iteration 8, average log likelihood -1.420600
INFO: iteration 9, average log likelihood -1.420370
INFO: iteration 10, average log likelihood -1.420216
INFO: iteration 11, average log likelihood -1.420103
INFO: iteration 12, average log likelihood -1.420014
INFO: iteration 13, average log likelihood -1.419940
INFO: iteration 14, average log likelihood -1.419878
INFO: iteration 15, average log likelihood -1.419823
INFO: iteration 16, average log likelihood -1.419775
INFO: iteration 17, average log likelihood -1.419731
INFO: iteration 18, average log likelihood -1.419691
INFO: iteration 19, average log likelihood -1.419654
INFO: iteration 20, average log likelihood -1.419619
INFO: iteration 21, average log likelihood -1.419586
INFO: iteration 22, average log likelihood -1.419555
INFO: iteration 23, average log likelihood -1.419526
INFO: iteration 24, average log likelihood -1.419498
INFO: iteration 25, average log likelihood -1.419471
INFO: iteration 26, average log likelihood -1.419445
INFO: iteration 27, average log likelihood -1.419420
INFO: iteration 28, average log likelihood -1.419396
INFO: iteration 29, average log likelihood -1.419372
INFO: iteration 30, average log likelihood -1.419350
INFO: iteration 31, average log likelihood -1.419328
INFO: iteration 32, average log likelihood -1.419307
INFO: iteration 33, average log likelihood -1.419287
INFO: iteration 34, average log likelihood -1.419267
INFO: iteration 35, average log likelihood -1.419249
INFO: iteration 36, average log likelihood -1.419230
INFO: iteration 37, average log likelihood -1.419213
INFO: iteration 38, average log likelihood -1.419195
INFO: iteration 39, average log likelihood -1.419179
INFO: iteration 40, average log likelihood -1.419163
INFO: iteration 41, average log likelihood -1.419147
INFO: iteration 42, average log likelihood -1.419132
INFO: iteration 43, average log likelihood -1.419117
INFO: iteration 44, average log likelihood -1.419103
INFO: iteration 45, average log likelihood -1.419089
INFO: iteration 46, average log likelihood -1.419075
INFO: iteration 47, average log likelihood -1.419062
INFO: iteration 48, average log likelihood -1.419050
INFO: iteration 49, average log likelihood -1.419037
INFO: iteration 50, average log likelihood -1.419025
INFO: EM with 100000 data points 50 iterations avll -1.419025
59.0 data points per parameter
32×26 Array{Float64,2}:
  0.186803    -0.149724    -0.475496   -0.275828   -0.38559    -0.0375949  -0.584428    0.0849881  -0.499981   -0.832132     0.433295     0.506555    0.352406     0.157198     0.0187861   0.0292474   0.302105   -0.0893625    0.601959    -0.328601    -0.159803    -0.326985   -0.417558     -0.325185    0.731386    0.851091   
 -0.0662508    0.35418      0.194925    0.0426809   0.157558   -0.485291    0.132296    0.404773    0.0715743   0.23209     -0.139939    -0.119574   -0.376167     0.255939     0.299727   -0.182742    0.379644    0.105702    -0.168379     0.129583     0.0498797   -0.105314    0.322498     -0.702135   -0.162171   -0.00955422 
 -0.601356     0.827666     0.298456    0.494333   -0.0514456   0.370059   -0.664366    0.271182    0.219825   -0.0154092    0.658238     0.385825   -0.162289     0.279059    -0.313306    0.194423   -0.242089    0.0231033    0.884496     0.380989    -0.624336    -0.0744492   0.253155     -0.388493   -0.0943313   0.556979   
  0.537494     0.518742     0.544201    0.349016   -0.142316    0.161295    0.278885    0.543185   -0.206662   -0.0806597    0.138956    -0.0408795  -0.140288     0.234866    -0.376825   -0.169575   -0.261688    0.00726955  -0.545315    -0.319321    -0.74276     -0.364887    0.0692854     0.0607043  -0.418262    0.924832   
 -0.507539    -0.19425     -0.245918    0.0408089   0.13517    -0.196178    0.054082   -0.250879    0.0908229   1.01275     -0.40421     -0.143419    0.215489     0.162833    -0.192891    0.049906    0.265243   -0.00649687   0.212666    -0.246107    -0.646861    -0.19786    -0.140707     -0.169866    0.32896    -0.515223   
 -0.362172     0.232103    -0.402857   -0.0434435   0.149978    0.166478    0.106734   -0.345724    0.111568   -0.221792     0.370737    -0.0909203   0.150383    -0.00630299  -0.167356   -0.296039    0.0566171   0.307497     0.0286919    0.0818561   -0.204325    -0.130235    0.439739     -0.170909    0.255615    0.0346032  
  0.216319    -0.164225    -0.294647   -0.151156   -0.543562   -0.312914    0.828629   -0.139143   -0.338269   -0.0319981    0.351741     0.382493   -0.4714      -0.533681     0.401322   -0.475274    0.453585   -0.0974364   -0.266541     0.0355557    0.722052     0.0843291   0.125796     -0.410107    0.271431    0.232698   
  0.171388    -0.47326     -0.138635   -0.0520354  -0.233335    0.46631     0.116493    0.145432    0.213269    0.111682     0.00377594   0.0212844  -0.119531    -0.360697     0.180978    0.0351795   0.0909646  -0.189176    -0.0798205   -0.131204    -0.101671     0.115875    0.144415      0.231976    0.161789    0.0125682  
 -0.395162    -0.277814    -0.540851    0.0357154   0.481083   -0.340611   -0.0669968  -0.427235    0.42469     0.270859    -0.468213     0.0936617   0.200651    -0.462131     0.707995    0.250877   -0.0504184   0.0869296    0.30428      0.318986     0.821353    -0.0285712   0.443329     -0.188064    0.603171   -0.396951   
 -0.119894    -0.340439    -0.124985    0.731382    0.0364831   0.259446    0.0582093   0.158502   -0.143567   -0.0735593    0.0520874    0.435197   -0.144743    -0.0599248   -0.0529599   0.124767   -0.240994   -0.255039    -0.519783     0.790935    -0.00289785  -0.116841    0.579778      0.634048    0.249371    0.233625   
  0.00632747   0.102604    -0.0187543   0.0854711   0.100589   -0.134223   -0.0219666  -0.0363634  -0.102447    0.069123    -0.0320704   -0.0268872  -0.00706555  -0.0251299    0.0415455   0.123529   -0.111799   -0.00433758   0.00727036   0.00482437  -0.0268347   -0.0713076  -0.135336      0.074152   -0.0726821   0.0119546  
  0.177839     0.0874328   -0.123102    0.16076    -0.218403   -0.300952   -0.288924   -0.0987863   0.262706   -0.0820719    0.307248     0.558666   -0.836762     0.143368     0.301196    0.0831266  -0.559271   -0.186003    -0.595124     0.431041     0.0637949    0.472443    0.181124     -0.183364   -0.104655   -0.154895   
  0.233919     0.00143985   0.336236   -0.410344    0.0653779   0.226473   -0.208203    0.577571    0.16098     0.101461     0.128673     0.457756    0.207765    -0.166504     0.0241082  -0.0655325   0.150593   -0.655332     0.512854     1.17324     -0.111523    -0.272717   -0.5012       -0.0807303  -0.308117   -0.313909   
 -0.353179    -0.428982     0.650711   -0.0299159  -0.399208    0.447701    0.145605    0.384955   -0.620723    0.00286666  -0.750062     0.0408429  -0.405641     0.161094     0.614848   -0.458896    0.373589   -0.0429729   -0.225042    -0.366946    -0.19391      0.535233    0.0978533    -0.628636   -0.436033    0.0956451  
  0.0897929    0.370401    -0.0356091  -0.0527586   0.331832   -0.251248   -0.769325    0.274372    0.0588879  -0.0748734    0.0976353   -0.588988    0.684124     0.534289    -0.383045    0.0115046   0.0117153  -0.248071    -0.154388     0.152891    -0.0693093    0.0567015  -0.254219      0.32528     0.0383569  -0.0117926  
 -0.34809     -0.0133673   -0.051809    0.433653    0.103054   -0.48864    -0.170373   -0.187815    0.367414   -0.159872    -0.0581376    0.0324732  -0.139102     0.203411    -0.145307    0.0383216  -0.0634589  -0.390358     0.111224    -0.358389     0.684344    -0.104137   -0.000775541  -0.23454    -0.788262    0.182171   
  0.614992    -0.583919    -0.165553   -0.768992    0.137901   -0.113227    0.369936    0.219619   -0.0505481   0.428135    -0.119845    -0.245607   -0.424505    -0.217991    -0.144202   -0.362937   -0.153695    0.373129    -0.437279    -0.246991     1.00076     -0.231038   -0.0755231     0.103836    0.0342069  -0.425232   
 -0.229071     0.152358    -0.122918    0.641428   -0.0209389   0.0348854   0.196696   -0.532329   -0.0751652  -0.0128831   -0.0736257   -0.229519   -0.368479     0.368697    -0.124711    0.0548672  -0.247852    0.846728    -0.468636    -1.23722     -0.092989     0.115874    0.339795      0.17003     0.0215828   0.623635   
 -0.190793     0.0488121   -0.353507    0.196261    0.436624   -0.195746    0.122302    0.0362045   0.258547    0.139615     0.100451    -0.0770038  -0.198303     0.253008     0.116369    0.192361   -0.365797   -0.356309    -0.561336     0.312879     0.30807     -0.017274    0.246276      0.0417118  -0.648154   -0.317129   
  0.773836    -0.737016    -0.278823   -0.248379   -0.373754   -0.616307    0.0530709  -0.41181    -0.628196    0.0366257   -0.361289    -0.0110753   0.326468    -0.349593     0.299737    0.127416    0.429721   -0.817669    -0.248939    -0.533554     0.28426      0.35643    -0.904965      0.622092   -0.167189   -0.268193   
  0.431244    -0.173887     0.0241344   0.259453   -0.396158   -0.523338    0.0547808   0.634321   -0.191103    0.58252      0.129553    -0.155847   -0.0086515   -0.059266    -0.744126    0.117545    0.247843    0.269431     0.408479    -0.249083     0.105523    -0.142169    0.102832     -0.0791955   0.709379    0.462742   
  0.676601     0.148869     0.305104    0.299308   -0.466053    0.120989   -0.418827   -0.303686   -0.14768    -0.207674     0.39802     -0.116973   -0.746051     0.460114    -0.182853    0.0258511   0.302135   -0.168085     0.023225    -0.5344      -0.384764     0.248703   -0.667071      0.110666   -0.530646   -0.0574025  
  0.250985    -0.344019    -0.197643   -0.187941   -0.614147    0.612473   -0.127409    0.64356     0.769709   -0.108185    -0.109141    -0.179696    0.0202615    0.249855    -0.299521    0.632267   -0.529518    0.00769555  -0.156428    -0.492535    -0.228872     0.411635    0.221672      0.347461   -0.371806    0.241024   
 -0.178179     0.0398269   -0.289454   -0.622316    0.231812    0.241568   -0.313796   -0.256946   -0.273266   -0.603557    -0.514867    -0.471189    0.123386    -0.311894    -0.0160721   0.409702   -0.492916   -0.149675     0.0849035   -0.347264     0.152204     0.41643     0.161669      0.204817   -0.263517   -0.333787   
 -0.401196    -0.274041     0.637958    0.245961    0.288602    0.10034    -0.118053    0.185265   -0.272957   -0.371563     0.0713715    0.264219   -0.129734    -0.475563     0.0774836  -0.287099    0.595011    1.14488      0.55856     -0.0336958   -0.26236     -0.111162    0.361329     -0.251651    0.623144    0.000796379
  0.293437    -0.251969    -0.298746   -0.556601    0.0191453   0.327681    0.681667    0.12497     0.164751    0.183996    -0.121063    -0.734294    0.180428    -0.775554     0.546303    0.282868   -0.0559956   0.21525     -0.0288044    0.456426    -0.406655    -0.111586    0.392659      0.107618    0.115841   -0.967624   
  0.048461    -0.0604667    0.120517   -0.178111   -0.2361      0.126332   -0.0290944   0.029108   -0.191263    0.104246    -0.0648944   -0.100454    0.182396    -0.150493    -0.197472   -0.11976     0.190267    0.126313     0.286487    -0.113687    -0.215752    -0.0845914  -0.117131      0.0295314   0.471387    0.150187   
  0.228653     0.548568     0.914514   -0.561284    0.265315   -0.320234   -0.374504   -0.263168    0.820196    0.0746972   -0.207453    -0.243923   -0.19606     -0.289464     0.670216   -0.0416724  -0.372993    0.305256     0.223335    -1.03348     -0.194012     0.210678   -0.442336     -0.365396   -0.398625   -0.128538   
 -0.246615     0.224498     0.136779    0.390111    0.286358   -0.643708    0.398183   -0.170576   -0.69163     0.315134     0.126041     0.645982   -0.320852     0.0660496    0.0872891  -0.229319    0.186788    0.0161605    0.0361683    0.00834452   0.195078    -0.177655   -0.873631     -0.354679   -0.239568    0.22221    
 -0.479515     0.896376     0.373439    0.319593    0.160872   -0.26942    -0.0852014  -0.111754   -0.863984   -0.378852    -0.454161    -0.633551    0.156377     0.129374     0.510089   -0.0497094   0.126383    0.21214      0.142323     0.196198    -0.266817    -0.193937   -0.209861     -0.0931852   0.0644108  -0.079922   
  0.0849006   -0.319859    -0.395861    0.525528    0.277303    0.181428   -0.215224    0.305654   -0.178877   -0.474392    -0.444973    -0.256932   -0.321291    -0.163542     0.308482   -0.123705    0.772319   -0.55005      0.0928269   -0.624556    -0.0127623   -0.0423646   1.36952       0.15351    -0.721576    0.208983   
 -0.0918392   -0.120379    -0.0628475  -0.337925    0.0155237   0.0637934   0.193815   -0.778199    0.080386    0.109534     0.762744     0.0681393   0.548456    -0.317786    -0.528783   -0.0485523  -0.65524     0.11266      0.143173     0.217531    -0.0968767   -0.197934   -0.846457      0.406655    0.202619   -0.242459   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419013
INFO: iteration 2, average log likelihood -1.419002
INFO: iteration 3, average log likelihood -1.418991
INFO: iteration 4, average log likelihood -1.418980
INFO: iteration 5, average log likelihood -1.418969
INFO: iteration 6, average log likelihood -1.418959
INFO: iteration 7, average log likelihood -1.418949
INFO: iteration 8, average log likelihood -1.418939
INFO: iteration 9, average log likelihood -1.418929
INFO: iteration 10, average log likelihood -1.418920
INFO: EM with 100000 data points 10 iterations avll -1.418920
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
