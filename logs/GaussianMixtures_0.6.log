>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.739
Commit 361161b (2016-09-22 21:53 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (661.34375 MB free)
Uptime: 23863.0 sec
Load Avg:  1.00634765625  1.01806640625  1.04443359375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1383073 s        137 s     174272 s     525596 s         70 s
#2  3500 MHz     695375 s       6344 s      96088 s    1451806 s          2 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-1.7421736558134085e6,[99949.2,50.7935],
[419.442 -14.7439 -98.4557; -129.675 -83.7041 26.1064],

Array{Float64,2}[
[1.00072e5 96.3161 -94.9086; 96.3161 99979.2 584.435; -94.9086 584.435 99028.8],

[346.247 193.505 -62.4961; 193.505 169.463 -33.014; -62.4961 -33.014 67.1542]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.334447e+03
      1       9.539050e+02      -3.805420e+02 |        6
      2       9.405161e+02      -1.338882e+01 |        2
      3       9.377786e+02      -2.737565e+00 |        0
      4       9.377786e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 937.7785660286518)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.071331
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.832893
INFO: iteration 2, lowerbound -3.716929
INFO: iteration 3, lowerbound -3.597054
INFO: iteration 4, lowerbound -3.455985
INFO: iteration 5, lowerbound -3.304582
INFO: iteration 6, lowerbound -3.162249
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -3.037216
INFO: dropping number of Gaussions to 6
INFO: iteration 8, lowerbound -2.936232
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.865776
INFO: iteration 10, lowerbound -2.826870
INFO: dropping number of Gaussions to 4
INFO: iteration 11, lowerbound -2.802117
INFO: dropping number of Gaussions to 3
INFO: iteration 12, lowerbound -2.784206
INFO: iteration 13, lowerbound -2.765734
INFO: iteration 14, lowerbound -2.745189
INFO: iteration 15, lowerbound -2.717362
INFO: iteration 16, lowerbound -2.681481
INFO: iteration 17, lowerbound -2.638025
INFO: iteration 18, lowerbound -2.589081
INFO: iteration 19, lowerbound -2.538111
INFO: iteration 20, lowerbound -2.488975
INFO: iteration 21, lowerbound -2.444520
INFO: iteration 22, lowerbound -2.405641
INFO: iteration 23, lowerbound -2.371604
INFO: iteration 24, lowerbound -2.341954
INFO: iteration 25, lowerbound -2.319112
INFO: iteration 26, lowerbound -2.307990
INFO: dropping number of Gaussions to 2
INFO: iteration 27, lowerbound -2.303051
INFO: iteration 28, lowerbound -2.299262
INFO: iteration 29, lowerbound -2.299257
INFO: iteration 30, lowerbound -2.299255
INFO: iteration 31, lowerbound -2.299254
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Fri 23 Sep 2016 11:07:03 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Fri 23 Sep 2016 11:07:05 AM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Fri 23 Sep 2016 11:07:06 AM UTC: EM with 272 data points 0 iterations avll -2.071331
5.8 data points per parameter
,Fri 23 Sep 2016 11:07:07 AM UTC: GMM converted to Variational GMM
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 1, lowerbound -3.832893
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 2, lowerbound -3.716929
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 3, lowerbound -3.597054
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 4, lowerbound -3.455985
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 5, lowerbound -3.304582
,Fri 23 Sep 2016 11:07:09 AM UTC: iteration 6, lowerbound -3.162249
,Fri 23 Sep 2016 11:07:10 AM UTC: dropping number of Gaussions to 7
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 7, lowerbound -3.037216
,Fri 23 Sep 2016 11:07:10 AM UTC: dropping number of Gaussions to 6
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 8, lowerbound -2.936232
,Fri 23 Sep 2016 11:07:10 AM UTC: dropping number of Gaussions to 5
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 9, lowerbound -2.865776
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 10, lowerbound -2.826870
,Fri 23 Sep 2016 11:07:10 AM UTC: dropping number of Gaussions to 4
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 11, lowerbound -2.802117
,Fri 23 Sep 2016 11:07:10 AM UTC: dropping number of Gaussions to 3
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 12, lowerbound -2.784206
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 13, lowerbound -2.765734
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 14, lowerbound -2.745189
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 15, lowerbound -2.717362
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 16, lowerbound -2.681481
,Fri 23 Sep 2016 11:07:10 AM UTC: iteration 17, lowerbound -2.638025
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 18, lowerbound -2.589081
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 19, lowerbound -2.538111
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 20, lowerbound -2.488975
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 21, lowerbound -2.444520
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 22, lowerbound -2.405641
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 23, lowerbound -2.371604
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 24, lowerbound -2.341954
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 25, lowerbound -2.319112
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 26, lowerbound -2.307990
,Fri 23 Sep 2016 11:07:11 AM UTC: dropping number of Gaussions to 2
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 27, lowerbound -2.303051
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 28, lowerbound -2.299262
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 29, lowerbound -2.299257
,Fri 23 Sep 2016 11:07:11 AM UTC: iteration 30, lowerbound -2.299255
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 31, lowerbound -2.299254
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 32, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 33, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 34, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 35, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 36, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 37, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 38, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 39, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 40, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 41, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 42, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:12 AM UTC: iteration 43, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 44, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 45, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 46, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 47, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 48, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 49, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: iteration 50, lowerbound -2.299253
,Fri 23 Sep 2016 11:07:13 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.045,95.9549]
Î² = [178.045,95.9549]
m = [4.2503 79.2869; 2.00023 53.852]
Î½ = [180.045,97.9549]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.184042 -0.00764405; 0.0 0.00858171],

[0.375876 -0.00895312; 0.0 0.0127487]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9948970326908703
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -0.9948970326908699
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -0.9948970326908699
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0147510463320446
avll from llpg:  -1.0147510463320446
avll direct:     -1.0147510463320446
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.00198244   0.165398     0.0117839    0.0584735    0.067659      0.00957889   0.0483316  -0.074348    -0.0950272    0.0209941   -0.0941453    -0.0368241   0.123232    -0.0111287    -0.13751      -0.00686658   0.0866758   -0.0440477   -0.0204638    0.0161326     0.0278637   -0.0186533    0.0304088    0.0441038    -0.0152707   0.0620286 
  0.108385     0.105364     0.0583259   -0.0226665   -0.0124763    -0.0978175    0.097832    0.0238058   -0.0307798    0.0234549   -0.128706     -0.229752    0.0433077    0.00755379   -0.183534     -0.0777001    0.00164689  -0.0728028    0.037314     0.056233     -0.145385     0.114654     0.0177209   -0.0021811    -0.126565   -0.0693895 
  0.163111     0.00937825   0.270299     0.0267874   -0.166368     -0.0344506    0.124982   -0.105186     0.0720397    0.233906     0.0576812     0.0561129   0.0378075    0.0133547     0.0775357     0.0485425   -0.050137    -0.0344109   -0.0869274    0.0647034    -0.0864059   -0.0201719   -0.110683     0.000354514  -0.193977   -0.00397527
  0.0209701    0.0302329   -0.0727871    0.0749886    0.0879744     0.00728001   0.0710009   0.0224859    0.0707408   -0.0707104    0.0726616    -0.0280993  -0.0787646    0.0517934    -0.150982     -0.0246837   -0.192714    -0.00869657  -0.0177967    0.0666836     0.0308692    0.0155274    0.114293    -0.0704542    -0.0410549   0.0518647 
 -0.0982207   -0.039791     0.0901306    0.069006    -0.0889122    -0.157105     0.0430321   0.114401     0.102997     0.128002     0.0349639    -0.0308972   0.0632789   -0.0553953     0.165529      0.0898038    0.0839321   -0.154654     0.1223       0.107385      0.0990986    0.0877496   -0.0569044    0.0363307    -0.0883635  -0.077755  
 -0.0198441    0.0295498   -0.0935412   -0.0646223    0.000936687   0.14788     -0.172072   -0.0931296    0.03925     -0.0389583   -0.10866      -0.0895928  -0.0678053   -0.087725      0.0933636     0.0601232    0.0465786   -0.0851223    0.0881429   -0.0227437    -0.0606182    0.107545    -0.214694    -0.0205746     0.0217628   0.0429655 
 -0.0395997   -0.261644     0.0421539    0.037311    -0.00231459   -0.0801873   -0.079776   -0.0386682   -0.061986    -0.0288192    0.0927345    -0.037461    0.00988261   0.0296116     0.000420877   0.111279    -0.0140308   -0.158913     0.018926    -0.00506714   -0.089278     0.163361     0.0492831    0.137548      0.0412329   0.00462057
  0.117231    -0.128242    -0.071501    -0.130249    -0.0187473    -0.193894    -0.103759   -0.00588274  -0.0958906    0.0770413   -0.0566681    -0.0835231  -0.0736635   -0.231461     -0.0655615    -0.123517     0.0055282    0.0691896    0.0641261    0.102679     -0.124936     0.114749    -0.168724    -0.140662      0.044131   -0.0322917 
  0.165062     0.108418     0.180979     0.0979529   -0.115678      0.116304     0.154      -0.0215258    0.0918452   -0.0893085   -0.151822     -0.0533715   0.148416     0.0842433     0.0113368     0.0258268   -0.125261     0.0448953   -0.0990976   -0.16344       0.0169557   -0.0215572   -0.105616     0.0418923     0.212063    0.0257168 
  0.0587617    0.039774     0.0685815   -0.0521216    0.224682     -0.0501054   -0.0867169   0.131083     0.00576401   0.0949442    0.0258496     0.0953752  -0.0830702   -0.0981035     0.0222644    -0.0848193   -0.0666469   -0.104002     0.0364256   -0.179957      0.0542548    0.0987694    0.114211    -0.00449786   -0.0875601   0.0741344 
 -0.041763    -0.0848103    0.12226     -0.13012     -0.0794322     0.0357499   -0.065324    0.0944603    0.124535    -0.14567      0.0392221    -0.107474    0.152284    -0.0355786    -0.0185646     0.131106     0.334679     0.0121238   -0.0652693    0.0273488    -0.080909    -0.238739     0.00024223   0.000372757   0.0362197   0.0923929 
  0.0620596    0.0824704    0.0300394   -0.0191324   -0.201848      0.0135678   -0.0404045  -0.0329284   -0.022178     0.00287005   0.0863444     0.0278211  -0.096948     0.0214103     0.0669074     0.146725    -0.0015858    0.0521154    0.180375     0.122199     -0.11199      0.00603244  -0.0365293   -0.0116129    -0.0482716   0.179542  
 -0.221683    -0.0382544    0.0598401   -0.0127207    0.024114     -0.0289162   -0.0453784   0.118813    -0.151908    -0.0923335   -0.173854     -0.181961   -0.0182095   -0.114419      0.158005     -0.098115    -0.0587767    0.0193104    0.0368907    0.000358408  -0.0454866   -0.0451452    0.0980782    0.017561      0.0540866  -0.144192  
  0.01527     -0.161142     0.0569129   -0.0726319   -0.0491609    -0.0694901    0.0891032   0.201296     0.218683    -0.0732031   -0.0144093     0.0343696   0.0126556    0.0533611    -0.181961      0.0511424    0.293959    -0.00290815  -0.116206     0.185028     -0.127971    -0.113393     0.0258521   -0.0507532    -0.111637    0.0658939 
  0.0675279    0.0192974    0.0412275    0.0385108   -0.209365      0.13792     -0.0495904   0.0704892   -0.0117731    0.0882207    0.0324289     0.205348    0.0493338   -0.0223779    -0.106201     -0.0499647    0.0512435    0.0504686    0.0550768   -0.0802126     0.0234161    0.0243251   -0.108043    -0.0121054     0.0121657   0.0803074 
 -0.0275507    0.0124099    0.0718502    0.22614     -0.154459      0.00601706  -0.0681876  -0.0704861   -0.00932826   0.056065    -0.0892255    -0.0906904  -0.0468287    0.054228      0.126842      0.0398015    0.030687    -0.0425308   -0.120891     0.122233      0.00764532  -0.0646403   -0.169799     0.0668211    -0.148298   -0.16406   
  0.0586512   -0.190009    -0.127619    -0.0730778    0.128966      0.00354229  -0.0723883  -0.0486989   -0.0215111   -0.134051    -0.0233391    -0.102483   -0.110211    -0.101802      0.189827     -0.158179     0.0810703    0.108229     0.00196032  -0.051744     -0.0426472   -0.0256511   -0.0601174    0.0600645    -0.14846     0.00448892
  0.163574    -0.0678626    0.00602978  -0.081764     0.140187      0.0555327   -0.0110168  -0.093712     0.047702    -0.0351168    0.245234      0.110265    0.0325263   -0.103169     -0.0316114    -0.0614384   -0.00578501   0.0219383    0.0923104   -0.122697     -0.00562942   0.0797672    0.00433394   0.231172     -0.0978751   0.0513738 
 -0.00895607  -0.101001    -0.145074     0.0210089    0.0204123     0.0192615    0.102672   -0.00271099   0.0544615   -0.026678     0.118716      0.301023   -0.032706     0.233609      0.0149296     0.200667    -0.156625     0.0160055    0.167871     0.171067     -0.038272    -0.0373201   -0.103833    -0.0958757    -0.0325614   0.0735807 
 -0.00766341   0.0420083   -0.164068     0.124456     0.0548262    -0.237494     0.0869523  -0.0428206   -0.13859     -0.014902     0.000804775   0.080093    0.134141     0.0929958    -0.0779854     0.0434638    0.0725689    0.0680589   -0.0432738    0.0112402    -0.0712729    0.0551087    0.0874046   -0.104531      0.13468    -0.0944197 
 -0.00782272   0.0838204   -0.0866449    0.0749332   -0.116677     -0.309508    -0.0918172  -0.128261     0.0242061   -0.0382941   -0.0388128    -0.0490644   0.0321842   -0.136625      0.0128149     0.0324716   -0.0394394    0.0532229    0.0113007    0.213611      0.096258     0.0879085   -0.128502    -0.0975627    -0.0119977  -0.235593  
  0.156431    -0.23483      0.210327     0.155547    -0.108807      0.0176618    0.0170736   0.190006     0.109583     0.118054    -0.00241993    0.09112    -0.0639503   -0.0437024     0.0730061    -0.0673032   -0.0459717   -0.0248608    0.0220187   -0.105745      0.0529629   -0.051579     0.216173    -0.0703998     0.0215022  -0.114006  
  0.14422     -0.146909    -0.135414     0.00762568   0.0333794    -0.0105355   -0.110094    0.0400701   -0.0325626    0.107147     0.105527     -0.160936    0.126108    -0.131999     -0.100758      0.145023    -0.0185998   -0.0750489   -0.0460782   -0.0695566     0.0852242   -0.113436     0.0468439   -0.122377     -0.0976406  -0.0881314 
 -0.113733     0.0191669   -0.0956183    0.0481623   -0.0215494    -0.0695295   -0.0459211   0.0171355    0.0162808    0.0825903   -0.0618099    -0.0684737   0.168057     0.00734762    0.100801      0.0722781   -0.0233083    0.00233101  -0.218964     0.029018      0.0677201    0.0878625    0.0056302    0.104148     -0.0695458   0.034131  
 -0.0330513   -0.138016     0.189832     0.128421     0.112978     -0.0540576    0.0812448   0.00106334   0.0464182   -0.0921492   -0.00299519    0.14504    -0.0819852   -0.0623046    -0.0825        0.0778308   -0.0381699   -0.0513725    0.21797      0.0955538     0.0396999   -0.0871508   -0.0599659   -0.131106     -0.126182   -0.0266527 
 -0.0284622    0.164915     0.112709    -0.0151617    0.0280836     0.0465554    0.157429    0.126311     0.0667286    0.0958846   -0.133611     -0.0315533   0.0143677    0.0961789     0.0671436     0.0557703   -0.0911268   -0.112578    -0.0617074   -0.0662724    -0.0121209    0.124688     0.0433337    0.185512      0.0722476  -0.0272316 
 -0.116813     0.113115    -0.0150936   -0.0759243    0.0531036    -0.175151    -0.052111    0.0303785    0.0261225   -0.0545343   -0.075812     -0.11226     0.0135355   -0.000311994  -0.100027     -0.211148     0.0462152   -0.233888     0.0285758   -0.154214     -0.213417     0.0549346    0.00542986   0.0763533     0.0416638  -0.0223365 
 -0.0820256    0.0287366    0.12075     -0.143515     0.167933     -0.0237258   -0.0765379   0.211289     0.0859822   -0.158696     0.00158457   -0.0813697   0.063055     0.102395      0.114124      0.113882     0.0542406   -0.115515    -0.0214291    0.0105667     0.00614315   0.0137764    0.140626    -0.206786     -0.0480015   0.151535  
 -0.0364942    0.0154444   -0.0440313    0.00677048   0.0612967    -0.0179664    0.07302    -0.168317    -0.0969524    0.118054    -0.0645644     0.0346036  -0.118318    -0.175022     -0.148337      0.172386     0.100464     0.133907     0.0451915    0.0335572    -0.123236    -0.0881817    0.139078     0.000372285   0.0548958   0.0174912 
  0.00647421   0.145605     0.0246575    0.134968     0.158219      0.038671     0.0729637   0.10865      0.0125194    0.0138507   -0.142255     -0.106854    0.0495534    0.151498      0.0766937    -0.0740223   -0.224067    -0.127139     0.137145     0.0134384     0.175033    -0.122404     0.128266     0.0288376    -0.0139987  -0.0801494 
  0.020605    -0.0280217   -0.0780947    0.114905     0.142944      0.113538     0.0278519  -0.0551603   -0.110892     0.11344     -0.140029      0.257916   -0.00768932   0.130767     -0.11926      -0.0819075    0.103985     0.0530327   -0.0602203   -0.00639994    0.0485403    0.165642     0.136316    -0.00862264    0.149683    0.104128  
  0.0563629   -0.00830873   0.148476    -0.0620519    0.158586     -0.145367     0.135654   -0.0966248    0.105212    -0.239887     0.0906738    -0.0694936   0.0991729   -0.0130144     0.0431782     0.071727    -0.145469    -0.184473    -0.0797817   -0.0443437    -0.135218     0.0653181    0.0399487    0.0468482    -0.116233    0.0163921 kind diag, method split
0: avll = -1.3952538359043385
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.395344
INFO: iteration 2, average log likelihood -1.395268
INFO: iteration 3, average log likelihood -1.394960
INFO: iteration 4, average log likelihood -1.391638
INFO: iteration 5, average log likelihood -1.377645
INFO: iteration 6, average log likelihood -1.367167
INFO: iteration 7, average log likelihood -1.365270
INFO: iteration 8, average log likelihood -1.364646
INFO: iteration 9, average log likelihood -1.364257
INFO: iteration 10, average log likelihood -1.363963
INFO: iteration 11, average log likelihood -1.363750
INFO: iteration 12, average log likelihood -1.363608
INFO: iteration 13, average log likelihood -1.363518
INFO: iteration 14, average log likelihood -1.363461
INFO: iteration 15, average log likelihood -1.363425
INFO: iteration 16, average log likelihood -1.363401
INFO: iteration 17, average log likelihood -1.363384
INFO: iteration 18, average log likelihood -1.363373
INFO: iteration 19, average log likelihood -1.363364
INFO: iteration 20, average log likelihood -1.363358
INFO: iteration 21, average log likelihood -1.363354
INFO: iteration 22, average log likelihood -1.363350
INFO: iteration 23, average log likelihood -1.363347
INFO: iteration 24, average log likelihood -1.363345
INFO: iteration 25, average log likelihood -1.363343
INFO: iteration 26, average log likelihood -1.363341
INFO: iteration 27, average log likelihood -1.363339
INFO: iteration 28, average log likelihood -1.363336
INFO: iteration 29, average log likelihood -1.363334
INFO: iteration 30, average log likelihood -1.363332
INFO: iteration 31, average log likelihood -1.363329
INFO: iteration 32, average log likelihood -1.363327
INFO: iteration 33, average log likelihood -1.363324
INFO: iteration 34, average log likelihood -1.363321
INFO: iteration 35, average log likelihood -1.363317
INFO: iteration 36, average log likelihood -1.363314
INFO: iteration 37, average log likelihood -1.363310
INFO: iteration 38, average log likelihood -1.363306
INFO: iteration 39, average log likelihood -1.363301
INFO: iteration 40, average log likelihood -1.363296
INFO: iteration 41, average log likelihood -1.363291
INFO: iteration 42, average log likelihood -1.363286
INFO: iteration 43, average log likelihood -1.363280
INFO: iteration 44, average log likelihood -1.363274
INFO: iteration 45, average log likelihood -1.363267
INFO: iteration 46, average log likelihood -1.363260
INFO: iteration 47, average log likelihood -1.363252
INFO: iteration 48, average log likelihood -1.363243
INFO: iteration 49, average log likelihood -1.363233
INFO: iteration 50, average log likelihood -1.363222
INFO: EM with 100000 data points 50 iterations avll -1.363222
952.4 data points per parameter
1: avll = [-1.39534,-1.39527,-1.39496,-1.39164,-1.37765,-1.36717,-1.36527,-1.36465,-1.36426,-1.36396,-1.36375,-1.36361,-1.36352,-1.36346,-1.36343,-1.3634,-1.36338,-1.36337,-1.36336,-1.36336,-1.36335,-1.36335,-1.36335,-1.36334,-1.36334,-1.36334,-1.36334,-1.36334,-1.36333,-1.36333,-1.36333,-1.36333,-1.36332,-1.36332,-1.36332,-1.36331,-1.36331,-1.36331,-1.3633,-1.3633,-1.36329,-1.36329,-1.36328,-1.36327,-1.36327,-1.36326,-1.36325,-1.36324,-1.36323,-1.36322]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.363334
INFO: iteration 2, average log likelihood -1.363218
INFO: iteration 3, average log likelihood -1.362971
INFO: iteration 4, average log likelihood -1.360953
INFO: iteration 5, average log likelihood -1.351833
INFO: iteration 6, average log likelihood -1.339372
INFO: iteration 7, average log likelihood -1.333405
INFO: iteration 8, average log likelihood -1.330048
INFO: iteration 9, average log likelihood -1.327163
INFO: iteration 10, average log likelihood -1.324810
INFO: iteration 11, average log likelihood -1.323120
INFO: iteration 12, average log likelihood -1.322017
INFO: iteration 13, average log likelihood -1.321306
INFO: iteration 14, average log likelihood -1.320848
INFO: iteration 15, average log likelihood -1.320554
INFO: iteration 16, average log likelihood -1.320362
INFO: iteration 17, average log likelihood -1.320233
INFO: iteration 18, average log likelihood -1.320143
INFO: iteration 19, average log likelihood -1.320077
INFO: iteration 20, average log likelihood -1.320026
INFO: iteration 21, average log likelihood -1.319984
INFO: iteration 22, average log likelihood -1.319947
INFO: iteration 23, average log likelihood -1.319912
INFO: iteration 24, average log likelihood -1.319876
INFO: iteration 25, average log likelihood -1.319839
INFO: iteration 26, average log likelihood -1.319798
INFO: iteration 27, average log likelihood -1.319753
INFO: iteration 28, average log likelihood -1.319703
INFO: iteration 29, average log likelihood -1.319647
INFO: iteration 30, average log likelihood -1.319581
INFO: iteration 31, average log likelihood -1.319500
INFO: iteration 32, average log likelihood -1.319396
INFO: iteration 33, average log likelihood -1.319261
INFO: iteration 34, average log likelihood -1.319092
INFO: iteration 35, average log likelihood -1.318892
INFO: iteration 36, average log likelihood -1.318679
INFO: iteration 37, average log likelihood -1.318474
INFO: iteration 38, average log likelihood -1.318300
INFO: iteration 39, average log likelihood -1.318164
INFO: iteration 40, average log likelihood -1.318060
INFO: iteration 41, average log likelihood -1.317977
INFO: iteration 42, average log likelihood -1.317907
INFO: iteration 43, average log likelihood -1.317842
INFO: iteration 44, average log likelihood -1.317779
INFO: iteration 45, average log likelihood -1.317717
INFO: iteration 46, average log likelihood -1.317660
INFO: iteration 47, average log likelihood -1.317607
INFO: iteration 48, average log likelihood -1.317558
INFO: iteration 49, average log likelihood -1.317515
INFO: iteration 50, average log likelihood -1.317480
INFO: EM with 100000 data points 50 iterations avll -1.317480
473.9 data points per parameter
2: avll = [-1.36333,-1.36322,-1.36297,-1.36095,-1.35183,-1.33937,-1.3334,-1.33005,-1.32716,-1.32481,-1.32312,-1.32202,-1.32131,-1.32085,-1.32055,-1.32036,-1.32023,-1.32014,-1.32008,-1.32003,-1.31998,-1.31995,-1.31991,-1.31988,-1.31984,-1.3198,-1.31975,-1.3197,-1.31965,-1.31958,-1.3195,-1.3194,-1.31926,-1.31909,-1.31889,-1.31868,-1.31847,-1.3183,-1.31816,-1.31806,-1.31798,-1.31791,-1.31784,-1.31778,-1.31772,-1.31766,-1.31761,-1.31756,-1.31752,-1.31748]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.317604
INFO: iteration 2, average log likelihood -1.317436
INFO: iteration 3, average log likelihood -1.316976
INFO: iteration 4, average log likelihood -1.312297
INFO: iteration 5, average log likelihood -1.294795
INFO: iteration 6, average log likelihood -1.279077
INFO: iteration 7, average log likelihood -1.272545
INFO: iteration 8, average log likelihood -1.269115
INFO: iteration 9, average log likelihood -1.267000
INFO: iteration 10, average log likelihood -1.265702
INFO: iteration 11, average log likelihood -1.264920
INFO: iteration 12, average log likelihood -1.264401
INFO: iteration 13, average log likelihood -1.264004
INFO: iteration 14, average log likelihood -1.263675
INFO: iteration 15, average log likelihood -1.263388
INFO: iteration 16, average log likelihood -1.263097
INFO: iteration 17, average log likelihood -1.262734
INFO: iteration 18, average log likelihood -1.262215
INFO: iteration 19, average log likelihood -1.261385
INFO: iteration 20, average log likelihood -1.260056
INFO: iteration 21, average log likelihood -1.258220
INFO: iteration 22, average log likelihood -1.256818
INFO: iteration 23, average log likelihood -1.256442
INFO: iteration 24, average log likelihood -1.256307
INFO: iteration 25, average log likelihood -1.256212
INFO: iteration 26, average log likelihood -1.256125
INFO: iteration 27, average log likelihood -1.256037
INFO: iteration 28, average log likelihood -1.255947
INFO: iteration 29, average log likelihood -1.255856
INFO: iteration 30, average log likelihood -1.255773
INFO: iteration 31, average log likelihood -1.255703
INFO: iteration 32, average log likelihood -1.255647
INFO: iteration 33, average log likelihood -1.255605
INFO: iteration 34, average log likelihood -1.255573
INFO: iteration 35, average log likelihood -1.255548
INFO: iteration 36, average log likelihood -1.255526
INFO: iteration 37, average log likelihood -1.255506
INFO: iteration 38, average log likelihood -1.255487
INFO: iteration 39, average log likelihood -1.255468
INFO: iteration 40, average log likelihood -1.255447
INFO: iteration 41, average log likelihood -1.255424
INFO: iteration 42, average log likelihood -1.255396
INFO: iteration 43, average log likelihood -1.255361
INFO: iteration 44, average log likelihood -1.255317
INFO: iteration 45, average log likelihood -1.255265
INFO: iteration 46, average log likelihood -1.255202
INFO: iteration 47, average log likelihood -1.255131
INFO: iteration 48, average log likelihood -1.255055
INFO: iteration 49, average log likelihood -1.254980
INFO: iteration 50, average log likelihood -1.254916
INFO: EM with 100000 data points 50 iterations avll -1.254916
236.4 data points per parameter
3: avll = [-1.3176,-1.31744,-1.31698,-1.3123,-1.2948,-1.27908,-1.27255,-1.26911,-1.267,-1.2657,-1.26492,-1.2644,-1.264,-1.26368,-1.26339,-1.2631,-1.26273,-1.26221,-1.26138,-1.26006,-1.25822,-1.25682,-1.25644,-1.25631,-1.25621,-1.25613,-1.25604,-1.25595,-1.25586,-1.25577,-1.2557,-1.25565,-1.25561,-1.25557,-1.25555,-1.25553,-1.25551,-1.25549,-1.25547,-1.25545,-1.25542,-1.2554,-1.25536,-1.25532,-1.25526,-1.2552,-1.25513,-1.25506,-1.25498,-1.25492]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.255061
INFO: iteration 2, average log likelihood -1.254758
INFO: iteration 3, average log likelihood -1.253370
INFO: iteration 4, average log likelihood -1.242177
INFO: iteration 5, average log likelihood -1.217524
INFO: iteration 6, average log likelihood -1.203080
INFO: iteration 7, average log likelihood -1.197480
INFO: iteration 8, average log likelihood -1.194775
INFO: iteration 9, average log likelihood -1.193327
INFO: iteration 10, average log likelihood -1.191953
INFO: iteration 11, average log likelihood -1.190741
INFO: iteration 12, average log likelihood -1.189924
INFO: iteration 13, average log likelihood -1.189341
INFO: iteration 14, average log likelihood -1.188704
INFO: iteration 15, average log likelihood -1.187877
INFO: iteration 16, average log likelihood -1.186786
INFO: iteration 17, average log likelihood -1.185453
INFO: iteration 18, average log likelihood -1.184161
INFO: iteration 19, average log likelihood -1.182781
WARNING: Variances had to be floored 14
INFO: iteration 20, average log likelihood -1.180901
INFO: iteration 21, average log likelihood -1.189995
INFO: iteration 22, average log likelihood -1.186412
INFO: iteration 23, average log likelihood -1.185153
INFO: iteration 24, average log likelihood -1.184583
INFO: iteration 25, average log likelihood -1.184086
INFO: iteration 26, average log likelihood -1.183647
INFO: iteration 27, average log likelihood -1.183285
INFO: iteration 28, average log likelihood -1.183020
INFO: iteration 29, average log likelihood -1.182865
INFO: iteration 30, average log likelihood -1.182777
INFO: iteration 31, average log likelihood -1.182716
INFO: iteration 32, average log likelihood -1.182668
INFO: iteration 33, average log likelihood -1.182630
INFO: iteration 34, average log likelihood -1.182600
INFO: iteration 35, average log likelihood -1.182577
INFO: iteration 36, average log likelihood -1.182560
INFO: iteration 37, average log likelihood -1.182548
INFO: iteration 38, average log likelihood -1.182538
INFO: iteration 39, average log likelihood -1.182529
INFO: iteration 40, average log likelihood -1.182522
INFO: iteration 41, average log likelihood -1.182516
INFO: iteration 42, average log likelihood -1.182510
INFO: iteration 43, average log likelihood -1.182504
INFO: iteration 44, average log likelihood -1.182498
INFO: iteration 45, average log likelihood -1.182493
INFO: iteration 46, average log likelihood -1.182487
INFO: iteration 47, average log likelihood -1.182481
INFO: iteration 48, average log likelihood -1.182475
INFO: iteration 49, average log likelihood -1.182469
INFO: iteration 50, average log likelihood -1.182463
INFO: EM with 100000 data points 50 iterations avll -1.182463
118.1 data points per parameter
4: avll = [-1.25506,-1.25476,-1.25337,-1.24218,-1.21752,-1.20308,-1.19748,-1.19478,-1.19333,-1.19195,-1.19074,-1.18992,-1.18934,-1.1887,-1.18788,-1.18679,-1.18545,-1.18416,-1.18278,-1.1809,-1.19,-1.18641,-1.18515,-1.18458,-1.18409,-1.18365,-1.18328,-1.18302,-1.18287,-1.18278,-1.18272,-1.18267,-1.18263,-1.1826,-1.18258,-1.18256,-1.18255,-1.18254,-1.18253,-1.18252,-1.18252,-1.18251,-1.1825,-1.1825,-1.18249,-1.18249,-1.18248,-1.18248,-1.18247,-1.18246]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.182710
INFO: iteration 2, average log likelihood -1.182350
INFO: iteration 3, average log likelihood -1.180149
INFO: iteration 4, average log likelihood -1.154862
WARNING: Variances had to be floored 14
INFO: iteration 5, average log likelihood -1.097788
WARNING: Variances had to be floored 8 21 26
INFO: iteration 6, average log likelihood -1.074706
WARNING: Variances had to be floored 14
INFO: iteration 7, average log likelihood -1.090651
INFO: iteration 8, average log likelihood -1.074595
WARNING: Variances had to be floored 14 21 26
INFO: iteration 9, average log likelihood -1.059237
WARNING: Variances had to be floored 8 29
INFO: iteration 10, average log likelihood -1.075073
WARNING: Variances had to be floored 14
INFO: iteration 11, average log likelihood -1.078421
WARNING: Variances had to be floored 21 26
INFO: iteration 12, average log likelihood -1.064983
WARNING: Variances had to be floored 8 14
INFO: iteration 13, average log likelihood -1.073993
WARNING: Variances had to be floored 29
INFO: iteration 14, average log likelihood -1.070905
WARNING: Variances had to be floored 14 21 26
INFO: iteration 15, average log likelihood -1.065284
WARNING: Variances had to be floored 8
INFO: iteration 16, average log likelihood -1.081029
WARNING: Variances had to be floored 14
INFO: iteration 17, average log likelihood -1.068581
WARNING: Variances had to be floored 21 26 29
INFO: iteration 18, average log likelihood -1.057952
WARNING: Variances had to be floored 8 14
INFO: iteration 19, average log likelihood -1.082187
INFO: iteration 20, average log likelihood -1.075452
WARNING: Variances had to be floored 14 21 26
INFO: iteration 21, average log likelihood -1.055571
WARNING: Variances had to be floored 8 29
INFO: iteration 22, average log likelihood -1.075120
WARNING: Variances had to be floored 14
INFO: iteration 23, average log likelihood -1.076660
WARNING: Variances had to be floored 21 26
INFO: iteration 24, average log likelihood -1.063041
WARNING: Variances had to be floored 8 14
INFO: iteration 25, average log likelihood -1.073251
WARNING: Variances had to be floored 29
INFO: iteration 26, average log likelihood -1.069710
WARNING: Variances had to be floored 14 21 26
INFO: iteration 27, average log likelihood -1.064300
WARNING: Variances had to be floored 8
INFO: iteration 28, average log likelihood -1.080705
WARNING: Variances had to be floored 14
INFO: iteration 29, average log likelihood -1.067730
WARNING: Variances had to be floored 21 26 29
INFO: iteration 30, average log likelihood -1.057285
WARNING: Variances had to be floored 8 14
INFO: iteration 31, average log likelihood -1.082095
INFO: iteration 32, average log likelihood -1.075015
WARNING: Variances had to be floored 14 21 26
INFO: iteration 33, average log likelihood -1.055205
WARNING: Variances had to be floored 8 29
INFO: iteration 34, average log likelihood -1.075044
WARNING: Variances had to be floored 14
INFO: iteration 35, average log likelihood -1.076504
WARNING: Variances had to be floored 21 26
INFO: iteration 36, average log likelihood -1.062905
WARNING: Variances had to be floored 8 14
INFO: iteration 37, average log likelihood -1.073215
WARNING: Variances had to be floored 29
INFO: iteration 38, average log likelihood -1.069634
WARNING: Variances had to be floored 14 21 26
INFO: iteration 39, average log likelihood -1.064257
WARNING: Variances had to be floored 8
INFO: iteration 40, average log likelihood -1.080699
WARNING: Variances had to be floored 14
INFO: iteration 41, average log likelihood -1.067705
WARNING: Variances had to be floored 21 26 29
INFO: iteration 42, average log likelihood -1.057267
WARNING: Variances had to be floored 8 14
INFO: iteration 43, average log likelihood -1.082093
INFO: iteration 44, average log likelihood -1.075007
WARNING: Variances had to be floored 14 21 26
INFO: iteration 45, average log likelihood -1.055199
WARNING: Variances had to be floored 8 29
INFO: iteration 46, average log likelihood -1.075042
WARNING: Variances had to be floored 14
INFO: iteration 47, average log likelihood -1.076501
WARNING: Variances had to be floored 21 26
INFO: iteration 48, average log likelihood -1.062902
WARNING: Variances had to be floored 8 14
INFO: iteration 49, average log likelihood -1.073213
WARNING: Variances had to be floored 29
INFO: iteration 50, average log likelihood -1.069632
INFO: EM with 100000 data points 50 iterations avll -1.069632
59.0 data points per parameter
5: avll = [-1.18271,-1.18235,-1.18015,-1.15486,-1.09779,-1.07471,-1.09065,-1.0746,-1.05924,-1.07507,-1.07842,-1.06498,-1.07399,-1.0709,-1.06528,-1.08103,-1.06858,-1.05795,-1.08219,-1.07545,-1.05557,-1.07512,-1.07666,-1.06304,-1.07325,-1.06971,-1.0643,-1.08071,-1.06773,-1.05729,-1.0821,-1.07502,-1.05521,-1.07504,-1.0765,-1.0629,-1.07321,-1.06963,-1.06426,-1.0807,-1.0677,-1.05727,-1.08209,-1.07501,-1.0552,-1.07504,-1.0765,-1.0629,-1.07321,-1.06963]
[-1.39525,-1.39534,-1.39527,-1.39496,-1.39164,-1.37765,-1.36717,-1.36527,-1.36465,-1.36426,-1.36396,-1.36375,-1.36361,-1.36352,-1.36346,-1.36343,-1.3634,-1.36338,-1.36337,-1.36336,-1.36336,-1.36335,-1.36335,-1.36335,-1.36334,-1.36334,-1.36334,-1.36334,-1.36334,-1.36333,-1.36333,-1.36333,-1.36333,-1.36332,-1.36332,-1.36332,-1.36331,-1.36331,-1.36331,-1.3633,-1.3633,-1.36329,-1.36329,-1.36328,-1.36327,-1.36327,-1.36326,-1.36325,-1.36324,-1.36323,-1.36322,-1.36333,-1.36322,-1.36297,-1.36095,-1.35183,-1.33937,-1.3334,-1.33005,-1.32716,-1.32481,-1.32312,-1.32202,-1.32131,-1.32085,-1.32055,-1.32036,-1.32023,-1.32014,-1.32008,-1.32003,-1.31998,-1.31995,-1.31991,-1.31988,-1.31984,-1.3198,-1.31975,-1.3197,-1.31965,-1.31958,-1.3195,-1.3194,-1.31926,-1.31909,-1.31889,-1.31868,-1.31847,-1.3183,-1.31816,-1.31806,-1.31798,-1.31791,-1.31784,-1.31778,-1.31772,-1.31766,-1.31761,-1.31756,-1.31752,-1.31748,-1.3176,-1.31744,-1.31698,-1.3123,-1.2948,-1.27908,-1.27255,-1.26911,-1.267,-1.2657,-1.26492,-1.2644,-1.264,-1.26368,-1.26339,-1.2631,-1.26273,-1.26221,-1.26138,-1.26006,-1.25822,-1.25682,-1.25644,-1.25631,-1.25621,-1.25613,-1.25604,-1.25595,-1.25586,-1.25577,-1.2557,-1.25565,-1.25561,-1.25557,-1.25555,-1.25553,-1.25551,-1.25549,-1.25547,-1.25545,-1.25542,-1.2554,-1.25536,-1.25532,-1.25526,-1.2552,-1.25513,-1.25506,-1.25498,-1.25492,-1.25506,-1.25476,-1.25337,-1.24218,-1.21752,-1.20308,-1.19748,-1.19478,-1.19333,-1.19195,-1.19074,-1.18992,-1.18934,-1.1887,-1.18788,-1.18679,-1.18545,-1.18416,-1.18278,-1.1809,-1.19,-1.18641,-1.18515,-1.18458,-1.18409,-1.18365,-1.18328,-1.18302,-1.18287,-1.18278,-1.18272,-1.18267,-1.18263,-1.1826,-1.18258,-1.18256,-1.18255,-1.18254,-1.18253,-1.18252,-1.18252,-1.18251,-1.1825,-1.1825,-1.18249,-1.18249,-1.18248,-1.18248,-1.18247,-1.18246,-1.18271,-1.18235,-1.18015,-1.15486,-1.09779,-1.07471,-1.09065,-1.0746,-1.05924,-1.07507,-1.07842,-1.06498,-1.07399,-1.0709,-1.06528,-1.08103,-1.06858,-1.05795,-1.08219,-1.07545,-1.05557,-1.07512,-1.07666,-1.06304,-1.07325,-1.06971,-1.0643,-1.08071,-1.06773,-1.05729,-1.0821,-1.07502,-1.05521,-1.07504,-1.0765,-1.0629,-1.07321,-1.06963,-1.06426,-1.0807,-1.0677,-1.05727,-1.08209,-1.07501,-1.0552,-1.07504,-1.0765,-1.0629,-1.07321,-1.06963]
32Ã—26 Array{Float64,2}:
 -0.120836   -0.403964     0.237626    -0.44519     -0.0182426   -0.0735991    0.127953     0.198404     0.229055    -0.11024     0.0535286    0.108836      0.11253      0.118414    -0.190563     0.197688    0.353968     -0.148897    -0.0479567    0.179865    -1.99524     -0.0298915     0.0198447   -0.0572978    -0.0798292    0.0854176 
  0.0415352   0.395392    -0.185425    -0.311412    -0.072299    -0.065498     0.0596604    0.195865     0.209178    -0.0298183  -0.0711217    0.0162314    -0.0470453    0.0468912   -0.185349    -0.146121    0.149042     -0.0585836   -0.0661214    0.128482    -0.0912146   -0.175967      0.0363456   -0.0581747    -0.147507     0.0460632 
  0.127791   -0.367145     0.0548086    0.475075    -0.0829857   -0.0677874    0.0599018    0.208265     0.21889     -0.055425   -0.0155064    0.117427      0.0110054   -0.00883975  -0.180176     0.152039    0.410001      0.0970132   -0.128603     0.248106    -0.466125     0.000129113   0.0242257    0.00817782   -0.129101     0.0777771 
  0.0671076  -0.266126     0.146748    -0.129367    -0.0327152   -0.0712176    0.12241      0.203961     0.231497    -0.0869945   0.0341914    0.0505106     0.076929     0.0893663   -0.183494     0.0190212   0.302508      0.072816    -0.186821     0.139338     1.55723     -0.159708      0.0224033   -0.108745     -0.116133     0.0178756 
 -0.0238915  -0.0118835    0.100925     0.129439     0.135978    -0.0113674    0.0728967    0.0552622    0.0328401   -0.0329764  -0.0623304    0.0410559    -0.0261803    0.0337697   -0.0148888    0.0175724  -0.139318     -0.0659975    0.18693      0.0538641    0.110857    -0.108333      0.0153935   -0.0639271    -0.0649058   -0.0515746 
  0.0327848  -0.00539321   0.146448    -0.0431753    0.140599    -0.119759     0.13021     -0.0889129    0.103101    -0.244903    0.0910916   -0.072543      0.102227    -0.0173925    0.027569     0.0731014  -0.142976     -0.181093    -0.0763811   -0.0303836   -0.135307     0.0667288     0.031836     0.0593349    -0.105838     0.0144315 
 -0.112416   -0.0407001    0.0621776    0.0846668   -0.0877576   -0.151357     0.0333618    0.0845784    0.0636641    0.107329    0.0319303   -0.0220002     0.0638127   -0.0437639    0.159784     0.0935559   0.0870158    -0.158146     0.108978     0.113323     0.125319     0.0889168    -0.0494332    0.0309643    -0.101707    -0.0831524 
  0.114333   -0.0155778    0.270191     0.0470305   -0.169745    -0.02765      0.0970954   -0.0937584    0.0611004    0.231397    0.0571123    0.0382203     0.00455514   0.0226192    0.0907877    0.0252425  -0.0403129    -0.0389248   -0.102273     0.0603746   -0.073354    -0.0143084    -0.097144    -0.000425808  -0.135192    -0.0075074 
  0.166083   -0.0804599   -0.145714     0.0177194    0.0500494   -0.22029     -0.11414      0.0379948   -0.0326832    0.0717631   0.173545    -0.18382       0.117487    -0.0993213   -0.167806     0.244188    0.0419728    -0.0589423   -0.0521399   -0.23092      0.0759109   -0.0863147     0.0905073   -0.101832     -0.0963225   -0.063671  
  0.135068   -0.249254    -0.127123    -0.00440111   0.0719329    0.288036    -0.0980055    0.0446736   -0.0370631    0.170404    0.0213419   -0.127175      0.165959    -0.161284    -0.052228     0.0825292  -0.040722     -0.0673645   -0.0471629    0.108378     0.126403    -0.12141       0.0425394   -0.146073     -0.0775986   -0.0811195 
 -0.141595   -0.00445817   0.0812301   -0.0235074    0.0321896   -0.0120922    0.0264228    0.118374    -0.0426195   -0.0126694  -0.15541     -0.12281      -0.00199527  -0.0187431    0.141013    -0.0365527  -0.0590968    -0.0275907    0.00718372  -0.0318219   -0.0313818    0.0265528     0.0734626    0.11931       0.053342    -0.101175  
 -0.0072581   0.0574074   -0.0884601    0.0711819   -0.0988296   -0.323037    -0.128014    -0.129527     0.0110506   -0.0381039  -0.0425803   -0.0619605     0.00670786  -0.180773     0.0562873    0.0315169  -0.0378893     0.0967776    0.0148047    0.218063     0.083723     0.0807683    -0.12457     -0.0921759    -0.0245769   -0.239719  
  0.0817744  -0.211704    -0.127852    -0.0769614    0.146277    -0.00297488  -0.0782145   -0.0524777    0.0118319   -0.131679   -0.00724568  -0.139088     -0.0975871   -0.0958214    0.191587    -0.184133    0.083076      0.0786012    0.00273909  -0.0664316   -0.0676553   -0.0461161    -0.0899279    0.0727165    -0.151502     0.0149834 
  0.0768047   0.0671426    0.0168903   -0.0193692   -0.160607     0.0107442   -0.0304695   -0.0314027   -0.0314606    0.0111008   0.0775164    0.000253864  -0.0433782   -0.00909966   0.0818032    0.136429   -0.000583449   0.0701092    0.157555     0.142476    -0.111129     0.0208181     0.0142629    0.0224735    -0.0403142    0.172386  
 -0.0617354   0.0917556    0.0234745   -0.0225663    0.0802222   -0.0153823   -0.0243639    0.0653723    0.00542227  -0.0559238  -0.0586998   -0.0586275     0.128609     0.034251     0.0164907    0.0542122  -0.00680601   -0.0687146   -0.0743248    0.0214498    0.031885     0.0340878     0.0785471   -0.0408344    -0.0419433    0.0970522 
  0.0904722  -0.0971471    0.137548     0.0572384    0.0451003   -0.0118671   -0.0218478    0.167536     0.0581311    0.102047    0.0110356    0.0923913    -0.0616676   -0.05963      0.076928    -0.0592648  -0.0540814    -0.0797436    0.0235793   -0.147093     0.0718685    0.0179472     0.159455    -0.0271895    -0.0226178   -0.00994377
  0.0183496  -0.00883035  -0.0713837    0.118731     0.138897     0.125077     0.0257202   -0.0548593   -0.119326     0.115002   -0.21108      0.255507      0.0139223    0.120927    -0.104754    -0.0820019   0.0963254     0.0527448   -0.0585208   -0.0562365    0.0425291    0.165915      0.13831     -0.027007      0.143899     0.102473  
 -0.0477405   0.00587129   0.0738818    0.227517    -0.135772     0.0609716   -0.0660312   -0.0713562   -0.0402229    0.0604967  -0.0526208   -0.0989222    -0.050752     0.0729787    0.168629     0.0435228   0.0409851    -0.0449857   -0.123755     0.118485     0.019339    -0.0413563    -0.181554     0.100567     -0.131179    -0.157944  
 -0.0347624  -0.0782757   -0.138777     0.0421437    0.041808     0.0179594    0.0981542   -0.00884839   0.0544394   -0.0110522   0.110272     0.301009     -0.0334483    0.238225    -0.00823137   0.197941   -0.169334      0.0249095    0.151974     0.170789    -0.0432275   -0.0132113    -0.0906958   -0.0767955    -0.0373458    0.0781062 
  0.0789599   0.0368672    0.0358505    0.0240709   -0.203991     0.136861    -0.0289584    0.073976    -0.00659577   0.0760146   0.0212795    0.205498      0.0894557    0.00700289  -0.0513168   -0.0420567   0.0642819     0.0466753    0.0508788   -0.0482822    0.0235633    0.0397307    -0.0964487   -0.0103826    -0.00160355   0.0827432 
 -0.0346562  -0.25933     -0.00355874   0.0319948   -0.00805144  -0.0509815   -0.0806049   -0.035947    -0.0780047   -0.0328543   0.107752    -0.0494984     0.00908522   0.0330499    0.00120765   0.151798   -0.0234893    -0.151529     0.0162321   -0.00544716  -0.0931834    0.181715      0.0543365    0.155019      0.0463512    0.0212877 
  0.0018872   0.075068    -0.17167      0.114882    -0.0322991   -0.248673     0.085559    -0.0435037   -0.136252    -0.0106417   0.00360463   0.0836815     0.138587     0.112053    -0.0721413    0.0336794   0.0564146     0.0672339   -0.062869     0.0176516   -0.0731207    0.0543901     0.129845    -0.0633087     0.139563    -0.0849321 
  0.205409   -0.0876691   -0.0340372   -0.0564956    0.244752    -1.04736     -0.0161634   -0.0967662    0.0327186    0.0234732   0.270826     0.103871      0.0356157   -0.132171    -0.0468406   -0.0441722  -0.00580103    0.031194     0.118145    -0.130921     0.0778775    0.0808185     0.00327265   0.231325     -0.107764     0.0391222 
  0.120793   -0.036104    -0.0233923   -0.173804     0.118587     1.1883      -0.00536675  -0.092111     0.104687    -0.10457     0.247709     0.115213      0.0284713   -0.0573924   -0.0493147   -0.0854169  -0.00586319    0.0530587    0.105746    -0.137446    -0.0517127    0.0814628     0.00985713   0.25667      -0.0936654    0.0608149 
  0.109375    0.112094     0.0681218   -0.0417634   -0.00388891  -0.0944974    0.0997687    0.0227585   -0.0455413    0.0277924  -0.15331     -0.258162      0.0589879   -0.0247779   -0.195967    -0.073108    0.000649144  -0.0675491    0.0420778    0.0437793   -0.14506      0.126338      0.0278075   -0.000460336  -0.124752    -0.0735048 
  0.119258   -0.13773     -0.0533618   -0.126349     0.0116081   -0.180146    -0.102581     0.00111237  -0.0963492    0.101295   -0.0844876   -0.0743933    -0.0350868   -0.21516     -0.00467192  -0.119276   -0.0219783     0.0642988    0.0476577    0.0529865   -0.122557     0.10491      -0.156339    -0.137575      0.0479107   -0.0316927 
  0.0226146   0.0351466   -0.0821365    0.0790243    0.0651869    0.0158185    0.0650756    0.0227855    0.0698021   -0.0625011   0.05167     -0.0724333    -0.0775658    0.0519081   -0.149257    -0.0199478  -0.179651     -0.0227082   -0.0329076    0.0283474    0.0319367    0.0110977     0.110636    -0.0162347    -0.0355265    0.0473158 
 -0.0446968  -0.0900603    0.132259    -0.129433    -0.0890757    0.0357299   -0.0846259    0.0948381    0.136561    -0.148278    0.0522171   -0.132306      0.151067    -0.0335755   -0.0103141    0.130785    0.331647      0.00978039  -0.0876165    0.0462114   -0.0857401   -0.23832      -0.00810201  -0.000484329   0.0296651    0.0890434 
 -0.116189    0.108388    -0.0116751   -0.0756242    0.0324367   -0.172607    -0.0830474    0.0249072   -0.011732    -0.101563   -0.10682     -0.108046      0.0110989   -0.00318035  -0.0905162   -0.205195    0.0489405    -0.205087     0.0356099   -0.17391     -0.205908     0.0469908     0.00577189   0.0848944     0.0502638   -0.0205087 
 -0.0197034   0.0221649   -0.051493    -0.0177177    0.0286955    0.0628889   -0.0576131   -0.11168     -0.0244462    0.0378805  -0.0831892   -0.0350813    -0.0862179   -0.122176    -0.0148338    0.107731    0.0720487     0.00904416   0.0558763   -0.00371379  -0.064438     0.00506819   -0.0327467   -0.0201269     0.0323832    0.0374896 
  0.16081     0.0865552    0.264236     0.127819    -0.115731     0.134888     0.180917    -0.0592693    0.0252713   -0.0684611  -0.146132    -0.0188859     0.295493    -0.509535     0.0129252    0.0638613  -0.108752      0.0777553   -0.134125    -0.202393     0.00839707   0.00111398   -0.0101303   -0.0178933     0.261047    -0.021206  
  0.165573    0.139563     0.0838037    0.0608386   -0.114042     0.10084      0.145937     0.0342556    0.0854654   -0.10715    -0.14168     -0.047724      0.0414079    0.564015     0.0108491    0.0264191  -0.135849      0.0151328   -0.0463347   -0.164741     0.0173799   -0.0855039    -0.209835     0.0310159     0.123419     0.0726476 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 14 21 26
INFO: iteration 1, average log likelihood -1.064256
WARNING: Variances had to be floored 8 14 21 26
INFO: iteration 2, average log likelihood -1.056306
WARNING: Variances had to be floored 14 21 26
INFO: iteration 3, average log likelihood -1.055359
WARNING: Variances had to be floored 8 14 21 26 29
INFO: iteration 4, average log likelihood -1.050639
WARNING: Variances had to be floored 14 21 26
INFO: iteration 5, average log likelihood -1.064216
WARNING: Variances had to be floored 8 14 21 26
INFO: iteration 6, average log likelihood -1.056240
WARNING: Variances had to be floored 14 21 26
INFO: iteration 7, average log likelihood -1.055327
WARNING: Variances had to be floored 8 14 21 26 29
INFO: iteration 8, average log likelihood -1.050617
WARNING: Variances had to be floored 14 21 26
INFO: iteration 9, average log likelihood -1.064216
WARNING: Variances had to be floored 8 14 21 26
INFO: iteration 10, average log likelihood -1.056238
INFO: EM with 100000 data points 10 iterations avll -1.056238
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.850245e+05
      1       6.674429e+05      -2.175816e+05 |       32
      2       6.363014e+05      -3.114150e+04 |       32
      3       6.219548e+05      -1.434666e+04 |       32
      4       6.138398e+05      -8.114992e+03 |       32
      5       6.079281e+05      -5.911642e+03 |       32
      6       6.039869e+05      -3.941266e+03 |       32
      7       6.014034e+05      -2.583497e+03 |       32
      8       5.994636e+05      -1.939740e+03 |       32
      9       5.979163e+05      -1.547337e+03 |       32
     10       5.967935e+05      -1.122817e+03 |       32
     11       5.961546e+05      -6.389068e+02 |       32
     12       5.957752e+05      -3.793422e+02 |       32
     13       5.954708e+05      -3.044110e+02 |       32
     14       5.951904e+05      -2.804358e+02 |       32
     15       5.948796e+05      -3.108172e+02 |       32
     16       5.946225e+05      -2.570160e+02 |       32
     17       5.944677e+05      -1.548123e+02 |       32
     18       5.943818e+05      -8.594153e+01 |       32
     19       5.943351e+05      -4.663824e+01 |       31
     20       5.943092e+05      -2.592264e+01 |       32
     21       5.942953e+05      -1.392689e+01 |       29
     22       5.942855e+05      -9.830645e+00 |       31
     23       5.942777e+05      -7.726105e+00 |       29
     24       5.942736e+05      -4.094103e+00 |       27
     25       5.942701e+05      -3.516703e+00 |       30
     26       5.942674e+05      -2.678362e+00 |       22
     27       5.942660e+05      -1.474570e+00 |       24
     28       5.942638e+05      -2.140279e+00 |       22
     29       5.942618e+05      -2.004016e+00 |       22
     30       5.942599e+05      -1.882020e+00 |       23
     31       5.942579e+05      -2.053921e+00 |       20
     32       5.942564e+05      -1.537851e+00 |       17
     33       5.942552e+05      -1.127827e+00 |       16
     34       5.942543e+05      -8.916628e-01 |       16
     35       5.942530e+05      -1.300455e+00 |       21
     36       5.942519e+05      -1.136367e+00 |       16
     37       5.942509e+05      -9.881512e-01 |       14
     38       5.942502e+05      -7.578613e-01 |       14
     39       5.942495e+05      -6.206671e-01 |       12
     40       5.942491e+05      -4.751562e-01 |       10
     41       5.942485e+05      -5.556192e-01 |        7
     42       5.942479e+05      -6.282285e-01 |       10
     43       5.942473e+05      -5.997855e-01 |       10
     44       5.942466e+05      -6.803984e-01 |        8
     45       5.942460e+05      -6.376340e-01 |       12
     46       5.942439e+05      -2.054238e+00 |       16
     47       5.942414e+05      -2.485998e+00 |       15
     48       5.942388e+05      -2.600377e+00 |       17
     49       5.942357e+05      -3.155823e+00 |       21
     50       5.942311e+05      -4.577597e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 594231.0803788372)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.321780
INFO: iteration 2, average log likelihood -1.292146
INFO: iteration 3, average log likelihood -1.261551
INFO: iteration 4, average log likelihood -1.231415
INFO: iteration 5, average log likelihood -1.193938
INFO: iteration 6, average log likelihood -1.146536
WARNING: Variances had to be floored 1 6 32
INFO: iteration 7, average log likelihood -1.093919
WARNING: Variances had to be floored 2 27 30
INFO: iteration 8, average log likelihood -1.085586
INFO: iteration 9, average log likelihood -1.090536
WARNING: Variances had to be floored 3
INFO: iteration 10, average log likelihood -1.058976
WARNING: Variances had to be floored 1 6
INFO: iteration 11, average log likelihood -1.050671
WARNING: Variances had to be floored 32
INFO: iteration 12, average log likelihood -1.068209
WARNING: Variances had to be floored 30
INFO: iteration 13, average log likelihood -1.054183
WARNING: Variances had to be floored 5 6
INFO: iteration 14, average log likelihood -1.037997
WARNING: Variances had to be floored 1 3
INFO: iteration 15, average log likelihood -1.052767
WARNING: Variances had to be floored 32
INFO: iteration 16, average log likelihood -1.058595
WARNING: Variances had to be floored 6 30
INFO: iteration 17, average log likelihood -1.042922
WARNING: Variances had to be floored 1 5
INFO: iteration 18, average log likelihood -1.050611
WARNING: Variances had to be floored 3
INFO: iteration 19, average log likelihood -1.055663
WARNING: Variances had to be floored 6 32
INFO: iteration 20, average log likelihood -1.043580
WARNING: Variances had to be floored 30
INFO: iteration 21, average log likelihood -1.053965
WARNING: Variances had to be floored 1 5
INFO: iteration 22, average log likelihood -1.035792
WARNING: Variances had to be floored 3 6
INFO: iteration 23, average log likelihood -1.050616
WARNING: Variances had to be floored 32
INFO: iteration 24, average log likelihood -1.059381
WARNING: Variances had to be floored 30
INFO: iteration 25, average log likelihood -1.049360
WARNING: Variances had to be floored 1 5 6
INFO: iteration 26, average log likelihood -1.036930
INFO: iteration 27, average log likelihood -1.068945
WARNING: Variances had to be floored 3 32
INFO: iteration 28, average log likelihood -1.039609
WARNING: Variances had to be floored 6 30
INFO: iteration 29, average log likelihood -1.043163
WARNING: Variances had to be floored 1 5
INFO: iteration 30, average log likelihood -1.050990
INFO: iteration 31, average log likelihood -1.056239
WARNING: Variances had to be floored 3 6 32
INFO: iteration 32, average log likelihood -1.029893
WARNING: Variances had to be floored 30
INFO: iteration 33, average log likelihood -1.058009
WARNING: Variances had to be floored 1 5
INFO: iteration 34, average log likelihood -1.047615
WARNING: Variances had to be floored 6
INFO: iteration 35, average log likelihood -1.059449
WARNING: Variances had to be floored 32
INFO: iteration 36, average log likelihood -1.050330
WARNING: Variances had to be floored 1 3 30
INFO: iteration 37, average log likelihood -1.034245
WARNING: Variances had to be floored 5 6
INFO: iteration 38, average log likelihood -1.055860
INFO: iteration 39, average log likelihood -1.067063
WARNING: Variances had to be floored 1 32
INFO: iteration 40, average log likelihood -1.034896
WARNING: Variances had to be floored 3 6 30
INFO: iteration 41, average log likelihood -1.042495
WARNING: Variances had to be floored 5
INFO: iteration 42, average log likelihood -1.065695
WARNING: Variances had to be floored 32
INFO: iteration 43, average log likelihood -1.057603
WARNING: Variances had to be floored 1 6
INFO: iteration 44, average log likelihood -1.042242
INFO: iteration 45, average log likelihood -1.053344
WARNING: Variances had to be floored 3 5 30 32
INFO: iteration 46, average log likelihood -1.026253
WARNING: Variances had to be floored 6
INFO: iteration 47, average log likelihood -1.064770
WARNING: Variances had to be floored 1
INFO: iteration 48, average log likelihood -1.055653
WARNING: Variances had to be floored 32
INFO: iteration 49, average log likelihood -1.040838
WARNING: Variances had to be floored 3 5 6 30
INFO: iteration 50, average log likelihood -1.031036
INFO: EM with 100000 data points 50 iterations avll -1.031036
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.118811     -0.123461    -0.0441165   -0.127316    -3.26439e-5  -0.179849    -0.0948649    0.00263721   -0.0928096    0.0974446   -0.0858871   -0.0819065   -0.0439806   -0.218191    -0.0225177    -0.119251   -0.0199457    0.0618415    0.0587029    0.0632121   -0.125897     0.110709    -0.157749    -0.137062     0.0387387    -0.032598  
 -0.0558807     0.140545     0.00792974  -0.00750534   0.0358508   -0.062254    -0.0154203   -0.029325     -0.0563693   -0.0507209   -0.106376    -0.0666993    0.0628764   -0.0053818   -0.115006     -0.0949265   0.0646552   -0.158154     0.00454519  -0.0730572   -0.0890238    0.0229167    0.0428413    0.0523844    0.0104702     0.0387091 
 -0.0192492     0.144961     0.00653476   0.128195     0.155728     0.0415552    0.065798     0.117596      0.00558748   0.0146356   -0.139669    -0.104471     0.0596638    0.150072     0.0780881    -0.0726803  -0.214358    -0.127872     0.148067     0.0148279    0.175095    -0.126484     0.132173     0.0296093   -0.0036565    -0.081415  
  0.0389742    -0.0110553    0.146869    -0.0482415    0.139412    -0.1261       0.127897    -0.0957066     0.103659    -0.2609       0.0908531   -0.0782935    0.102709    -0.0211961    0.0272505     0.072849   -0.142962    -0.183671    -0.0751968   -0.0269067   -0.137199     0.0628625    0.0344566    0.0530479   -0.110252      0.0141936 
  0.126103     -0.0144247    0.266684     0.0359146   -0.170763    -0.0291303    0.101005    -0.107965      0.0640649    0.237437     0.0584882    0.0451396    0.0125694    0.0175134    0.08587       0.0203035  -0.0470535   -0.02944     -0.104676     0.0627111   -0.0712943   -0.0197693   -0.100757    -0.00785443  -0.136611     -0.00362246
 -0.0318552    -0.266231    -0.00567925   0.0327395   -0.0149671   -0.0553421   -0.0806457   -0.0362892    -0.0776728   -0.029202     0.112948    -0.0444892    0.0092289    0.0297739   -0.000571954   0.154299   -0.0256004   -0.151865     0.0169262   -0.00474278  -0.0990272    0.181574     0.05217      0.155445     0.0465489     0.0246095 
 -0.106452     -0.0406212    0.0778368    0.0852262   -0.0885938   -0.14923      0.0353059    0.0774992     0.0669819    0.112576     0.0329538   -0.0226869    0.0550866   -0.0423542    0.159487      0.089676    0.0861644   -0.154342     0.106284     0.112286     0.116297     0.0880086   -0.0551963    0.0300599   -0.0993699    -0.0821547 
  0.0400997     0.0442623    0.0732672   -0.0533697    0.232597    -0.0364675   -0.0761691    0.169949      0.00252729   0.153531     0.0265803    0.089535    -0.0836804   -0.0906186    0.012888     -0.0865484  -0.0735011   -0.101552     0.0353176   -0.180578     0.0499002    0.101291     0.113197     0.00833805  -0.0755228     0.0693043 
 -0.107086      0.0242879   -0.115718     0.0506496   -0.0253493   -0.0723293   -0.0433438    0.0120663    -0.0315728    0.0820759   -0.0575801   -0.0783042    0.187782    -0.00250475   0.0915878     0.070448   -0.0653145   -0.0169485   -0.214523     0.0181111    0.076706     0.0946231    0.0103515    0.112999    -0.0402644     0.0432183 
  0.120525     -0.343066    -0.122536     0.0153551   -0.0343662    0.219567    -0.228385     0.0391126    -0.00720811   0.251872     0.0105675   -0.10742      0.108499     0.134431    -0.131865     -0.0768658   0.225468    -0.0498642   -0.00865831  -0.0514362   -0.191245    -0.0690921    0.155279    -0.0607034   -0.0771211    -0.102964  
 -0.0450851    -0.0901947    0.130825    -0.129315    -0.0899308    0.0352519   -0.0872425    0.0946901     0.134873    -0.147173     0.0512195   -0.132664     0.151752    -0.0338244   -0.0096951     0.13184     0.331631     0.0100685   -0.0863913    0.0465662   -0.0863171   -0.238563    -0.00892294  -0.00111853   0.0297173     0.0887516 
  0.0369203    -0.115022     0.0394418   -0.0984585   -0.0543071   -0.069121     0.089272     0.201605      0.220969    -0.0662063   -0.00632073   0.0679977    0.0287955    0.057115    -0.185199      0.0343967   0.29129     -0.00469739  -0.109057     0.171067    -0.130189    -0.100374     0.0266562   -0.0543075   -0.121077      0.0537377 
 -0.000448935   0.0728123   -0.173944     0.113504    -0.0278137   -0.248601     0.0847345   -0.0436541    -0.140101    -0.0107951    0.00355007   0.0814117    0.138727     0.114415    -0.072855      0.0331357   0.0566648    0.0681601   -0.0642105    0.0186949   -0.0742043    0.0539761    0.132728    -0.0595564    0.139202     -0.0889607 
 -0.0313823    -0.0826856   -0.141819     0.0405937    0.0386908    0.0191891    0.0972817   -0.00867235    0.0557933   -0.0117943    0.112503     0.301284    -0.0331289    0.239741    -0.0110162     0.198403   -0.168303     0.0267238    0.151848     0.172162    -0.0404581   -0.012688    -0.0910251   -0.0777648   -0.0388439     0.0785234 
  0.163115      0.113779     0.172719     0.0910781   -0.114768     0.117091     0.163509    -0.0105606     0.0551399   -0.0878907   -0.143796    -0.0334641    0.163556     0.0442074    0.0120014     0.0444388  -0.12245      0.0453577   -0.0893057   -0.182742     0.0116943   -0.0446743   -0.112599     0.00868253   0.19138       0.0282047 
 -0.00725755    0.0640186   -0.0845556    0.0679713   -0.100947    -0.323501    -0.130016    -0.130386      0.0148265   -0.0383783   -0.0390578   -0.0590729    0.00957974  -0.176272     0.0616898     0.0353567  -0.0389947    0.0979325    0.0172787    0.219762     0.0836686    0.0802991   -0.125592    -0.093057    -0.0248651    -0.232883  
  0.0783995    -0.172269    -0.120858    -0.0709412    0.125732    -0.0117056   -0.0772899   -0.0487713     0.00918852  -0.119734    -0.00112992  -0.121796    -0.0983682   -0.0889835    0.1867       -0.159526    0.0802758    0.0704983    0.0225403   -0.0693927   -0.0792215   -0.0415415   -0.071546     0.0653325   -0.138206      0.033816  
  0.0164058     0.149718    -0.0401763    1.25849      0.0692335    0.129686     0.0255797   -0.0631961    -0.0978465    0.116391    -0.342122     0.303742    -0.0151763    0.127044    -0.0928595    -0.0800796   0.155608     0.0510653   -0.0763048   -0.00762529   0.0226259    0.165524     0.14133     -0.0349818    0.136126      0.100997  
  0.154571     -0.154671    -0.137493     0.00493157   0.0704527    0.0129695   -0.105628     0.0410426    -0.0364808    0.108401     0.109769    -0.161515     0.140464    -0.143119    -0.119818      0.179929   -0.00911195  -0.065041    -0.0471863   -0.0793649    0.118338    -0.106185     0.0614853   -0.130936    -0.0909257    -0.075761  
 -0.0494237    -0.00185311   0.0731962    0.235335    -0.152397     0.0619508   -0.0651165   -0.0840218    -0.0431492    0.0605559   -0.0463832   -0.100666    -0.0591988    0.0723771    0.167798      0.0425044   0.0482328   -0.0422802   -0.125084     0.121451     0.00954635  -0.0349204   -0.203027     0.0965344   -0.135548     -0.160686  
  0.156953     -0.233867     0.209235     0.158839    -0.106171     0.0199062    0.022206     0.18809       0.115945     0.0411281    0.00104483   0.104591    -0.055277    -0.0424262    0.106866     -0.0623137  -0.0212546   -0.0569218    0.0482092   -0.122038     0.0830435   -0.0574047    0.214425    -0.0695391    0.029128     -0.0993343 
  0.0359441     0.0492086    0.00988601   0.00625709   0.0457042   -0.0474388    0.0664993   -0.095989     -0.0744355    0.0735542   -0.110119    -0.110415    -0.0346426   -0.102968    -0.168564      0.062242    0.0592259    0.0350332    0.0358674    0.0332894   -0.123841    -0.00336357   0.101185    -0.0141322   -0.0294202    -0.0340389 
  0.163534     -0.0621217   -0.0289108   -0.114489     0.182519     0.0724465   -0.010735    -0.0940829     0.0696532   -0.0419148    0.261825     0.109511     0.0320905   -0.0961412   -0.0481769    -0.0638927  -0.00561637   0.0424449    0.116276    -0.134546     0.0121262    0.0816171    0.00685834   0.245373    -0.101489      0.0497017 
 -0.214302     -0.117761     0.0617584   -0.0161225    0.0407267   -0.0348504   -0.0777146    0.114765     -0.119711    -0.0970749   -0.164001    -0.17993     -0.0219827   -0.106648     0.187202     -0.102593   -0.0328663    0.0264487    0.0713368   -5.71636e-5  -0.0422724   -0.0447796    0.104491     0.0367284    0.0404548    -0.15155   
  0.0285017     0.0344981   -0.0813439    0.0718065    0.0665891    0.0131376    0.0686507    0.0210998     0.067015    -0.0720129    0.0654087   -0.0806865   -0.0795227    0.0487653   -0.167828     -0.026448   -0.179059    -0.0173508   -0.0257152    0.0317049    0.0270578    0.00609781   0.114725    -0.0235942   -0.0397957     0.0473114 
  0.0807038     0.0328474    0.0368481    0.0264342   -0.20743      0.140814    -0.0321441    0.0731569    -0.00987221   0.0766316    0.0233161    0.206036     0.090177     0.00474029  -0.0619138    -0.0437769   0.068272     0.0497578    0.0545235   -0.0467239    0.0233719    0.0409034   -0.0964764   -0.0114953    0.000226653   0.0831852 
 -0.0276044    -0.143708     0.200005     0.136392     0.110917    -0.0527733    0.0822708   -0.000482873   0.0476229   -0.0800954   -0.00251589   0.170227    -0.0832273   -0.063336    -0.0823369     0.113231   -0.0556797   -0.0213975    0.216026     0.0917142    0.0561096   -0.106857    -0.0709503   -0.128474    -0.118548     -0.0281729 
 -0.0815833     0.0321156    0.121147    -0.144952     0.143073    -0.0284783   -0.077159     0.237982      0.113494    -0.18313      0.00176077  -0.0621028    0.0717098    0.0936133    0.117765      0.101187   -0.061838    -0.0779024   -0.0432386    0.0162241    0.0250292    0.0349282    0.143477    -0.20973     -0.0586829     0.157459  
 -0.0179612     0.0191447   -0.0831537   -0.0791467   -0.0154842    0.137226    -0.177898    -0.0624968     0.0364771   -0.0375667   -0.0866856   -0.0931654   -0.0968654   -0.0875861    0.0850622     0.0566328   0.0563655   -0.0759022    0.0930354   -0.0182678   -0.055204     0.0933451   -0.218728    -0.0292469    0.0174561     0.0630709 
 -0.0308994     0.158072     0.108987    -0.0231458    0.0352851    0.0253757    0.158737     0.124386      0.0648503    0.0950617   -0.134253    -0.0329303    0.0203974    0.0922386    0.0664296     0.0563327  -0.0972053   -0.111315    -0.0688813   -0.0908699   -0.0168401    0.129317     0.0357572    0.20414      0.0715061    -0.0153792 
  0.0200856    -0.137215    -0.0970287   -0.798933     0.194932     0.12158      0.0256699   -0.0477977    -0.136187     0.113908    -0.105979     0.21611      0.0373681    0.115779    -0.116341     -0.0835443   0.0473891    0.0542093   -0.0439076   -0.0954248    0.057961     0.166301     0.13585     -0.020613     0.15065       0.103481  
  0.112063      0.0804323    0.0317633   -0.00916428  -0.180411     0.00219226  -0.00042388  -0.0284413    -0.022329     0.00885726   0.0738178    0.00227005  -0.0426231   -0.0124706    0.0793889     0.120588   -0.0014917    0.0939756    0.211838     0.178791    -0.151924     0.0204058   -0.00161899   0.00874555  -0.0539378     0.16052   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.072838
WARNING: Variances had to be floored 1
INFO: iteration 2, average log likelihood -1.048958
WARNING: Variances had to be floored 1 6 32
INFO: iteration 3, average log likelihood -1.030548
WARNING: Variances had to be floored 1 5
INFO: iteration 4, average log likelihood -1.038112
WARNING: Variances had to be floored 1 3 30
INFO: iteration 5, average log likelihood -1.033092
WARNING: Variances had to be floored 1 6 10 32
INFO: iteration 6, average log likelihood -1.043358
WARNING: Variances had to be floored 1
INFO: iteration 7, average log likelihood -1.052656
WARNING: Variances had to be floored 1 3 5
INFO: iteration 8, average log likelihood -1.024237
WARNING: Variances had to be floored 1 6 30 32
INFO: iteration 9, average log likelihood -1.038848
WARNING: Variances had to be floored 1
INFO: iteration 10, average log likelihood -1.060641
INFO: EM with 100000 data points 10 iterations avll -1.060641
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.156766     -0.0558659    0.0678886   -0.0787489   -0.123361     0.0646161    0.0899929  -0.0348005   -0.140675      0.1111      -0.0309568     0.14378     -0.00650161    0.115318   -0.0143295    0.0180843    0.10946      0.0212698    0.0242787    -0.154877    -0.139721     0.142875     0.0207517     0.119032     0.107442    -0.0550989  
 -0.0201121    -0.0122704    0.0404872    0.11978      0.0652925   -0.150163    -0.10724     0.0591239    0.0046695     0.0320169    0.0338005     0.0962753    0.138943     -0.0713187  -0.0533948    0.0743029    0.0438321    0.0697043    0.145054     -0.0820367    0.0503147   -0.124228     0.143087     -0.127682    -0.154609     0.0829848  
 -0.17595      -0.133131    -0.0895077   -0.0454374   -0.129571    -0.0496664   -0.0741484   0.108703    -0.00759609   -0.0997047   -0.150935     -0.100473     0.0163472    -0.0378603  -0.20435      0.0550132   -0.127875     0.0657991   -0.0425772    -0.0608685    0.128231     0.0780865    0.0296452     0.192936     0.0590611    0.000205634
 -0.123705     -0.00979096  -0.110433     0.0901777   -0.0283758    0.0150588   -0.125791   -0.101362     0.0298946    -0.0208302    0.0148909     0.105445     0.0852293     0.0272525  -0.177979    -0.082091     0.0647512   -0.0982488    0.0221995     0.0561243    0.0415785   -0.104005     0.00774181    0.0881618    0.0264713   -0.247279   
  0.097301     -0.0429118   -0.0314626    0.0990508   -0.090148     0.00242893   0.0490039   0.0935178   -0.0352519    -0.0792321   -0.064246     -0.00413693   0.0310735    -0.0350026   0.00656672   0.0136709    0.0407347    0.00972301   0.0387202    -0.0036508    0.0357216   -0.356141    -0.0790659     0.0215801    0.103749     0.13708    
  0.18861      -0.0824799    0.124956    -0.00736169   0.111894    -0.175838     0.138141    0.187835     0.129903     -0.158259     0.139598      0.109508     0.128182      0.150848    0.00787739  -0.0886796   -0.00226893  -0.01116     -0.0506871    -0.04839     -0.0903953   -0.0422398   -0.0847217    -0.0734002   -0.027728     0.0360357  
 -0.120583     -0.125982     0.175217    -0.135735    -0.104826     0.107654    -0.134964   -0.112695    -0.134408     -0.219863    -0.105772     -0.0559932    0.028852     -0.10822     0.0172988    0.150155    -0.0783355    0.0908508    0.0101012     0.145956    -0.013837     0.175772     0.00445698    0.231194    -0.168572     0.152744   
  0.0562832     0.0607145    0.185327    -0.0386728    0.0770968    0.0133414   -0.0620119   0.0150037   -0.123326     -0.0035825   -0.0244239     0.0450955   -0.0710329     0.130738   -0.106962     0.0378053   -0.227136     0.222573    -0.045739     -0.052123    -0.00552189   0.0127081    0.0294729     0.0113091    0.0145796   -0.10846    
  0.136631      0.0425123    0.0270728    0.292129     0.185783    -0.122922     0.0853865   0.101925    -0.0965277    -0.117576     0.134905      0.00814399   0.126565      0.0559533   0.159907    -0.0910124    0.129712     0.0239273    0.0564563    -0.0381138    0.174411     0.107588     0.155032     -0.192274     0.00157429   0.0303468  
 -0.130195     -0.0144358   -0.133359     0.0939954   -0.0726869    0.00311791  -0.0441543  -0.0275869    0.154081     -0.0935425    0.00246242    0.0351709   -0.0445517     0.136574   -0.0816479   -0.177674    -0.178976    -0.0554563    0.0960359    -0.0110756    0.0222538    0.0555831    0.000662585   0.044663     0.129199    -0.0928673  
 -0.0574986    -0.0082742   -0.042763    -0.0295599    0.092577    -0.158468     0.0321852  -0.00807838   0.168102     -0.0339293    0.0238697    -0.0747392    0.0267835     0.0837841  -0.0233021    0.111564    -0.0373783   -0.123127    -0.0229427     0.00440314  -0.119555     0.129432     0.0936323     0.0926909   -0.0173375   -0.137293   
 -0.0851469     0.0818915    0.0544368    0.00641129  -0.157269     0.0995862   -0.0770893   0.177655    -0.0987843     0.0865285   -0.10978       0.304626     0.0064527     0.0606549  -0.131861     0.148942    -0.222114    -0.194102     0.164237      0.115574    -0.108826     0.0962606   -0.0308436     0.285133     0.0764555    0.0959858  
 -0.283713      0.0150989    5.06242e-5   0.0465225   -0.00969872  -0.00214341   0.0485462   0.0203352    0.0521878    -0.151208     0.10105       0.0448947    0.0160218    -0.013353    0.156873    -0.129102     0.0870299   -0.10056      0.118816     -0.0642491   -0.116707    -0.00340283  -0.125284     -0.149357    -0.0567497   -0.0410647  
  0.0352592    -0.0857339   -0.0712442   -0.0862363   -0.129994    -0.02365      0.0791556  -0.0570783   -0.0850462     0.117998     0.0308591    -0.0318738    0.192447      0.122723    0.0854405    0.0632548    0.295584    -0.0699793   -0.0540049     0.0487911    0.16658     -0.0528575   -0.113211      0.275632    -0.0811421    0.0658414  
 -0.113427     -0.184179     0.032363     0.0722297    0.0202687   -0.0558227   -0.0680188  -0.0157756    0.143094     -0.0166911   -0.0129818    -0.048266    -0.0434959    -0.134661   -0.139069     0.0787582    0.0463461   -0.106763    -0.0703045     0.033215     0.0212848   -0.0826426   -0.0468099    -0.175937    -0.167198     0.0694767  
  0.0553149     0.0767169   -0.00983604  -0.0653861    0.0145055    0.0738401    0.0844797  -0.0226623    0.0645264    -0.107461    -0.170425     -0.0589157   -0.328475     -0.0894694  -0.0675871    0.117125    -0.034686     0.0441836    0.10677       0.0522773    0.0741179    0.0495095    0.150868      0.00928005  -0.0975876   -0.00945768 
  0.117949     -0.212971    -0.104423    -0.193241     0.0850835   -0.152299     0.0116415  -0.0367757   -0.145639     -0.0516221   -0.0814676    -0.0810518    0.000801617   0.0729823  -0.0118923   -0.0148322   -0.0801975    0.0671348    0.0978542    -0.17139      0.124778     0.105596     0.049659     -0.0627936   -0.0526612   -0.0328985  
 -0.0231763     0.0610401   -0.0875584   -0.136276    -0.0966044   -0.0846809    0.0726021   0.060861    -0.0345851     0.149106    -0.0765715     0.0898222    0.0782938    -0.103061   -0.316238    -0.033345    -0.0727114   -0.180291     0.0378653    -0.0233284    0.254313     0.222852     0.0395507    -0.010963     0.211946    -0.0910253  
  0.0881684    -0.0254688    0.018164    -0.112062     0.0699093   -0.021057    -0.194994   -0.0598104    0.00821048   -0.00964657   0.0384539     0.0350849    0.114488     -0.104154   -0.0989992   -0.0412756   -0.112887     0.124059    -0.0971711    -0.172939    -0.0224192   -0.0578498    0.134842      0.0591938    0.123975    -0.0525487  
 -0.0134003     0.259291     0.118466    -0.237941     0.0287025    0.0329995    0.0122935   0.0128695    0.0679313    -0.0446143   -0.0152721    -0.012151    -0.0218013     0.0971696  -0.0256177   -0.0146637   -0.0799826    0.0817874    0.00367001   -0.0314228    0.0746623    0.146705    -0.026853     -0.134365     0.0554504   -0.165502   
 -0.0904313     0.0133854   -0.0563133    0.072961     0.0459008    0.0615656   -0.170546   -0.0379775    0.229637      0.223932     0.158809     -0.109752    -0.0655156    -0.111864    0.0664645    0.111165     0.151729    -0.0719557    0.0215238     0.0738292   -0.0529682    0.0880776    0.152918     -0.140536     0.0271341   -0.155205   
 -0.128509     -0.109707    -0.15918     -0.0877227    0.115932     0.0563207    0.0484091   0.0936301    0.0700622    -0.0812032   -0.0762307     0.181843    -0.0268104    -0.0763068  -0.00541989   0.00232119  -0.184597     0.0474871   -0.0294007    -0.0689565    0.0925393   -0.064599    -0.119918     -0.0681132   -0.143004    -0.0657472  
 -0.194166      0.0886691   -0.0475691   -0.104365    -0.076337    -0.0851946    0.0898647  -0.0717047   -0.108363      0.129259    -0.0687346    -0.0720274   -0.0868741    -0.130542   -0.0337199    0.0845533   -0.0213625    0.0840339    0.000715588  -0.0457357    0.0163831    0.114866     0.0881034    -0.0197535   -0.109645     0.118664   
  0.0179491    -0.141644    -0.0723225   -0.0251704    0.112446     0.0470457    0.01338    -0.145715    -0.155727     -0.109488     0.304475      0.0176507   -0.0581158     0.0539444   0.0282054    0.0308147   -0.0764155   -0.121751    -0.111976      0.124854     0.0513503    0.154224     0.0948931    -0.121763     0.0776429    0.0160758  
 -0.0547295    -0.0549204    0.054985     0.115042     0.0905029    0.0292494    0.114896   -0.0600057    0.000283724   0.0372377   -0.17333       0.0809852   -0.0207882    -0.0371481   0.0213491   -0.0763673    0.191831     0.0867053   -0.015806      0.0613499   -0.0825532    0.083388     0.0495786     0.0555347   -0.0646402    0.0363189  
 -0.0836913     0.120988     0.0399084   -0.0830464    0.0329899    0.0195812    0.0729856   0.00880851   0.0853892     0.0602775   -0.000610722   0.109166     0.0625467    -0.0371934  -0.0513219    0.205377    -0.0127666   -0.0470111   -0.0466627    -0.0579936    0.0137249   -0.0745862   -0.103424     -0.00512345   0.0859982    0.0599234  
 -0.000493145  -0.0234505    0.0689439    0.0186779    0.0466723    0.121        0.0996239   0.0449603   -0.113788     -0.00164576   0.0316577    -0.234128    -0.0343072    -0.111144    0.0101595   -0.10299     -0.0532909    0.0198426   -0.0334023    -0.144283     0.148275    -0.113764    -0.120422      0.0941008   -0.180047     0.099634   
  0.0261419     0.123271    -0.0107741    0.0872847    0.107092    -0.234629     0.0601603   0.0864028   -0.0193394    -0.0442767   -0.046187      0.10105     -0.0200744     0.110673    0.0191171    0.0759493    0.0347385   -0.086219    -0.0298774     0.113866     0.0565199    0.109377    -0.17646       0.103181    -0.0167758   -0.0430287  
  0.00452723   -0.0531503   -0.0248769    0.107686     0.128604     0.188367     0.0996097   0.0315179    0.0758045    -0.0481477    0.0213117     0.11827      0.0115705     0.167505    0.0272372   -0.0377458   -0.123602     0.00440196  -0.021721     -0.331306    -0.0867794    0.0250623    0.0436115    -0.0886751   -0.213229    -0.0817717  
  0.154144     -0.114125     0.131692     0.0970715   -0.00699126   0.0417381    0.0720042  -0.105917     0.0525958    -0.125539     0.0344812     0.00284061   0.132637      0.0286389   0.097982     0.0987464   -0.0210653   -0.0207792   -0.0265557    -0.0198265    0.152973    -0.174041     0.0182409     0.176838    -0.0184796   -0.0372339  
 -0.160414      0.206815     0.087695    -0.0902893    0.142133    -0.0700632   -0.0666887   0.0511987    0.0117156    -0.060604     0.0100791    -0.0936622   -0.201455      0.0922719  -0.226347     0.0336662    0.0765804    0.0697311   -0.182345      0.0853907   -0.0107513    0.149786    -0.0601917    -0.148974     0.0537267    0.113554   
 -0.144312      0.143519     0.032501    -0.0128623    0.0691306   -0.0587918    0.213133    0.145939    -0.0861182    -0.012402     0.0957712     0.100244     0.188657      0.0213607   0.0189118   -0.00980087  -0.0824746    0.0819966    0.0142474     0.10072     -0.182032    -0.127002     0.0565077    -0.0240083    0.0223677   -0.00387165 kind full, method split
0: avll = -1.4340681119714664
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.434088
INFO: iteration 2, average log likelihood -1.434035
INFO: iteration 3, average log likelihood -1.433999
INFO: iteration 4, average log likelihood -1.433957
INFO: iteration 5, average log likelihood -1.433903
INFO: iteration 6, average log likelihood -1.433829
INFO: iteration 7, average log likelihood -1.433715
INFO: iteration 8, average log likelihood -1.433513
INFO: iteration 9, average log likelihood -1.433115
INFO: iteration 10, average log likelihood -1.432356
INFO: iteration 11, average log likelihood -1.431188
INFO: iteration 12, average log likelihood -1.429967
INFO: iteration 13, average log likelihood -1.429156
INFO: iteration 14, average log likelihood -1.428779
INFO: iteration 15, average log likelihood -1.428630
INFO: iteration 16, average log likelihood -1.428571
INFO: iteration 17, average log likelihood -1.428548
INFO: iteration 18, average log likelihood -1.428538
INFO: iteration 19, average log likelihood -1.428533
INFO: iteration 20, average log likelihood -1.428531
INFO: iteration 21, average log likelihood -1.428530
INFO: iteration 22, average log likelihood -1.428529
INFO: iteration 23, average log likelihood -1.428529
INFO: iteration 24, average log likelihood -1.428528
INFO: iteration 25, average log likelihood -1.428528
INFO: iteration 26, average log likelihood -1.428527
INFO: iteration 27, average log likelihood -1.428527
INFO: iteration 28, average log likelihood -1.428527
INFO: iteration 29, average log likelihood -1.428527
INFO: iteration 30, average log likelihood -1.428527
INFO: iteration 31, average log likelihood -1.428526
INFO: iteration 32, average log likelihood -1.428526
INFO: iteration 33, average log likelihood -1.428526
INFO: iteration 34, average log likelihood -1.428526
INFO: iteration 35, average log likelihood -1.428526
INFO: iteration 36, average log likelihood -1.428526
INFO: iteration 37, average log likelihood -1.428526
INFO: iteration 38, average log likelihood -1.428526
INFO: iteration 39, average log likelihood -1.428526
INFO: iteration 40, average log likelihood -1.428525
INFO: iteration 41, average log likelihood -1.428525
INFO: iteration 42, average log likelihood -1.428525
INFO: iteration 43, average log likelihood -1.428525
INFO: iteration 44, average log likelihood -1.428525
INFO: iteration 45, average log likelihood -1.428525
INFO: iteration 46, average log likelihood -1.428525
INFO: iteration 47, average log likelihood -1.428525
INFO: iteration 48, average log likelihood -1.428525
INFO: iteration 49, average log likelihood -1.428525
INFO: iteration 50, average log likelihood -1.428525
INFO: EM with 100000 data points 50 iterations avll -1.428525
952.4 data points per parameter
1: avll = [-1.43409,-1.43404,-1.434,-1.43396,-1.4339,-1.43383,-1.43371,-1.43351,-1.43311,-1.43236,-1.43119,-1.42997,-1.42916,-1.42878,-1.42863,-1.42857,-1.42855,-1.42854,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.428541
INFO: iteration 2, average log likelihood -1.428484
INFO: iteration 3, average log likelihood -1.428436
INFO: iteration 4, average log likelihood -1.428376
INFO: iteration 5, average log likelihood -1.428297
INFO: iteration 6, average log likelihood -1.428193
INFO: iteration 7, average log likelihood -1.428066
INFO: iteration 8, average log likelihood -1.427921
INFO: iteration 9, average log likelihood -1.427775
INFO: iteration 10, average log likelihood -1.427644
INFO: iteration 11, average log likelihood -1.427539
INFO: iteration 12, average log likelihood -1.427462
INFO: iteration 13, average log likelihood -1.427409
INFO: iteration 14, average log likelihood -1.427373
INFO: iteration 15, average log likelihood -1.427348
INFO: iteration 16, average log likelihood -1.427329
INFO: iteration 17, average log likelihood -1.427314
INFO: iteration 18, average log likelihood -1.427302
INFO: iteration 19, average log likelihood -1.427292
INFO: iteration 20, average log likelihood -1.427284
INFO: iteration 21, average log likelihood -1.427277
INFO: iteration 22, average log likelihood -1.427271
INFO: iteration 23, average log likelihood -1.427266
INFO: iteration 24, average log likelihood -1.427261
INFO: iteration 25, average log likelihood -1.427257
INFO: iteration 26, average log likelihood -1.427254
INFO: iteration 27, average log likelihood -1.427251
INFO: iteration 28, average log likelihood -1.427248
INFO: iteration 29, average log likelihood -1.427246
INFO: iteration 30, average log likelihood -1.427244
INFO: iteration 31, average log likelihood -1.427242
INFO: iteration 32, average log likelihood -1.427240
INFO: iteration 33, average log likelihood -1.427239
INFO: iteration 34, average log likelihood -1.427237
INFO: iteration 35, average log likelihood -1.427236
INFO: iteration 36, average log likelihood -1.427235
INFO: iteration 37, average log likelihood -1.427234
INFO: iteration 38, average log likelihood -1.427233
INFO: iteration 39, average log likelihood -1.427233
INFO: iteration 40, average log likelihood -1.427232
INFO: iteration 41, average log likelihood -1.427231
INFO: iteration 42, average log likelihood -1.427230
INFO: iteration 43, average log likelihood -1.427230
INFO: iteration 44, average log likelihood -1.427229
INFO: iteration 45, average log likelihood -1.427229
INFO: iteration 46, average log likelihood -1.427228
INFO: iteration 47, average log likelihood -1.427228
INFO: iteration 48, average log likelihood -1.427228
INFO: iteration 49, average log likelihood -1.427227
INFO: iteration 50, average log likelihood -1.427227
INFO: EM with 100000 data points 50 iterations avll -1.427227
473.9 data points per parameter
2: avll = [-1.42854,-1.42848,-1.42844,-1.42838,-1.4283,-1.42819,-1.42807,-1.42792,-1.42778,-1.42764,-1.42754,-1.42746,-1.42741,-1.42737,-1.42735,-1.42733,-1.42731,-1.4273,-1.42729,-1.42728,-1.42728,-1.42727,-1.42727,-1.42726,-1.42726,-1.42725,-1.42725,-1.42725,-1.42725,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.427240
INFO: iteration 2, average log likelihood -1.427192
INFO: iteration 3, average log likelihood -1.427155
INFO: iteration 4, average log likelihood -1.427115
INFO: iteration 5, average log likelihood -1.427068
INFO: iteration 6, average log likelihood -1.427014
INFO: iteration 7, average log likelihood -1.426951
INFO: iteration 8, average log likelihood -1.426882
INFO: iteration 9, average log likelihood -1.426810
INFO: iteration 10, average log likelihood -1.426736
INFO: iteration 11, average log likelihood -1.426664
INFO: iteration 12, average log likelihood -1.426595
INFO: iteration 13, average log likelihood -1.426530
INFO: iteration 14, average log likelihood -1.426466
INFO: iteration 15, average log likelihood -1.426404
INFO: iteration 16, average log likelihood -1.426344
INFO: iteration 17, average log likelihood -1.426283
INFO: iteration 18, average log likelihood -1.426223
INFO: iteration 19, average log likelihood -1.426164
INFO: iteration 20, average log likelihood -1.426107
INFO: iteration 21, average log likelihood -1.426055
INFO: iteration 22, average log likelihood -1.426007
INFO: iteration 23, average log likelihood -1.425965
INFO: iteration 24, average log likelihood -1.425928
INFO: iteration 25, average log likelihood -1.425896
INFO: iteration 26, average log likelihood -1.425869
INFO: iteration 27, average log likelihood -1.425845
INFO: iteration 28, average log likelihood -1.425824
INFO: iteration 29, average log likelihood -1.425805
INFO: iteration 30, average log likelihood -1.425788
INFO: iteration 31, average log likelihood -1.425772
INFO: iteration 32, average log likelihood -1.425758
INFO: iteration 33, average log likelihood -1.425744
INFO: iteration 34, average log likelihood -1.425731
INFO: iteration 35, average log likelihood -1.425718
INFO: iteration 36, average log likelihood -1.425706
INFO: iteration 37, average log likelihood -1.425694
INFO: iteration 38, average log likelihood -1.425682
INFO: iteration 39, average log likelihood -1.425670
INFO: iteration 40, average log likelihood -1.425659
INFO: iteration 41, average log likelihood -1.425647
INFO: iteration 42, average log likelihood -1.425635
INFO: iteration 43, average log likelihood -1.425623
INFO: iteration 44, average log likelihood -1.425611
INFO: iteration 45, average log likelihood -1.425599
INFO: iteration 46, average log likelihood -1.425586
INFO: iteration 47, average log likelihood -1.425574
INFO: iteration 48, average log likelihood -1.425561
INFO: iteration 49, average log likelihood -1.425548
INFO: iteration 50, average log likelihood -1.425535
INFO: EM with 100000 data points 50 iterations avll -1.425535
236.4 data points per parameter
3: avll = [-1.42724,-1.42719,-1.42716,-1.42712,-1.42707,-1.42701,-1.42695,-1.42688,-1.42681,-1.42674,-1.42666,-1.4266,-1.42653,-1.42647,-1.4264,-1.42634,-1.42628,-1.42622,-1.42616,-1.42611,-1.42605,-1.42601,-1.42596,-1.42593,-1.4259,-1.42587,-1.42584,-1.42582,-1.4258,-1.42579,-1.42577,-1.42576,-1.42574,-1.42573,-1.42572,-1.42571,-1.42569,-1.42568,-1.42567,-1.42566,-1.42565,-1.42563,-1.42562,-1.42561,-1.4256,-1.42559,-1.42557,-1.42556,-1.42555,-1.42554]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.425531
INFO: iteration 2, average log likelihood -1.425463
INFO: iteration 3, average log likelihood -1.425403
INFO: iteration 4, average log likelihood -1.425336
INFO: iteration 5, average log likelihood -1.425258
INFO: iteration 6, average log likelihood -1.425165
INFO: iteration 7, average log likelihood -1.425058
INFO: iteration 8, average log likelihood -1.424940
INFO: iteration 9, average log likelihood -1.424817
INFO: iteration 10, average log likelihood -1.424694
INFO: iteration 11, average log likelihood -1.424575
INFO: iteration 12, average log likelihood -1.424465
INFO: iteration 13, average log likelihood -1.424365
INFO: iteration 14, average log likelihood -1.424274
INFO: iteration 15, average log likelihood -1.424192
INFO: iteration 16, average log likelihood -1.424120
INFO: iteration 17, average log likelihood -1.424056
INFO: iteration 18, average log likelihood -1.424000
INFO: iteration 19, average log likelihood -1.423950
INFO: iteration 20, average log likelihood -1.423906
INFO: iteration 21, average log likelihood -1.423867
INFO: iteration 22, average log likelihood -1.423831
INFO: iteration 23, average log likelihood -1.423797
INFO: iteration 24, average log likelihood -1.423766
INFO: iteration 25, average log likelihood -1.423737
INFO: iteration 26, average log likelihood -1.423708
INFO: iteration 27, average log likelihood -1.423681
INFO: iteration 28, average log likelihood -1.423656
INFO: iteration 29, average log likelihood -1.423631
INFO: iteration 30, average log likelihood -1.423607
INFO: iteration 31, average log likelihood -1.423584
INFO: iteration 32, average log likelihood -1.423561
INFO: iteration 33, average log likelihood -1.423540
INFO: iteration 34, average log likelihood -1.423520
INFO: iteration 35, average log likelihood -1.423500
INFO: iteration 36, average log likelihood -1.423482
INFO: iteration 37, average log likelihood -1.423464
INFO: iteration 38, average log likelihood -1.423447
INFO: iteration 39, average log likelihood -1.423431
INFO: iteration 40, average log likelihood -1.423416
INFO: iteration 41, average log likelihood -1.423402
INFO: iteration 42, average log likelihood -1.423388
INFO: iteration 43, average log likelihood -1.423375
INFO: iteration 44, average log likelihood -1.423363
INFO: iteration 45, average log likelihood -1.423352
INFO: iteration 46, average log likelihood -1.423341
INFO: iteration 47, average log likelihood -1.423330
INFO: iteration 48, average log likelihood -1.423320
INFO: iteration 49, average log likelihood -1.423310
INFO: iteration 50, average log likelihood -1.423301
INFO: EM with 100000 data points 50 iterations avll -1.423301
118.1 data points per parameter
4: avll = [-1.42553,-1.42546,-1.4254,-1.42534,-1.42526,-1.42516,-1.42506,-1.42494,-1.42482,-1.42469,-1.42458,-1.42447,-1.42436,-1.42427,-1.42419,-1.42412,-1.42406,-1.424,-1.42395,-1.42391,-1.42387,-1.42383,-1.4238,-1.42377,-1.42374,-1.42371,-1.42368,-1.42366,-1.42363,-1.42361,-1.42358,-1.42356,-1.42354,-1.42352,-1.4235,-1.42348,-1.42346,-1.42345,-1.42343,-1.42342,-1.4234,-1.42339,-1.42338,-1.42336,-1.42335,-1.42334,-1.42333,-1.42332,-1.42331,-1.4233]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.423302
INFO: iteration 2, average log likelihood -1.423230
INFO: iteration 3, average log likelihood -1.423162
INFO: iteration 4, average log likelihood -1.423082
INFO: iteration 5, average log likelihood -1.422982
INFO: iteration 6, average log likelihood -1.422856
INFO: iteration 7, average log likelihood -1.422704
INFO: iteration 8, average log likelihood -1.422531
INFO: iteration 9, average log likelihood -1.422347
INFO: iteration 10, average log likelihood -1.422166
INFO: iteration 11, average log likelihood -1.421997
INFO: iteration 12, average log likelihood -1.421846
INFO: iteration 13, average log likelihood -1.421717
INFO: iteration 14, average log likelihood -1.421606
INFO: iteration 15, average log likelihood -1.421513
INFO: iteration 16, average log likelihood -1.421434
INFO: iteration 17, average log likelihood -1.421367
INFO: iteration 18, average log likelihood -1.421309
INFO: iteration 19, average log likelihood -1.421259
INFO: iteration 20, average log likelihood -1.421214
INFO: iteration 21, average log likelihood -1.421175
INFO: iteration 22, average log likelihood -1.421139
INFO: iteration 23, average log likelihood -1.421107
INFO: iteration 24, average log likelihood -1.421078
INFO: iteration 25, average log likelihood -1.421050
INFO: iteration 26, average log likelihood -1.421025
INFO: iteration 27, average log likelihood -1.421001
INFO: iteration 28, average log likelihood -1.420979
INFO: iteration 29, average log likelihood -1.420957
INFO: iteration 30, average log likelihood -1.420937
INFO: iteration 31, average log likelihood -1.420918
INFO: iteration 32, average log likelihood -1.420900
INFO: iteration 33, average log likelihood -1.420883
INFO: iteration 34, average log likelihood -1.420866
INFO: iteration 35, average log likelihood -1.420851
INFO: iteration 36, average log likelihood -1.420835
INFO: iteration 37, average log likelihood -1.420821
INFO: iteration 38, average log likelihood -1.420807
INFO: iteration 39, average log likelihood -1.420794
INFO: iteration 40, average log likelihood -1.420781
INFO: iteration 41, average log likelihood -1.420769
INFO: iteration 42, average log likelihood -1.420758
INFO: iteration 43, average log likelihood -1.420746
INFO: iteration 44, average log likelihood -1.420735
INFO: iteration 45, average log likelihood -1.420725
INFO: iteration 46, average log likelihood -1.420715
INFO: iteration 47, average log likelihood -1.420705
INFO: iteration 48, average log likelihood -1.420695
INFO: iteration 49, average log likelihood -1.420685
INFO: iteration 50, average log likelihood -1.420676
INFO: EM with 100000 data points 50 iterations avll -1.420676
59.0 data points per parameter
5: avll = [-1.4233,-1.42323,-1.42316,-1.42308,-1.42298,-1.42286,-1.4227,-1.42253,-1.42235,-1.42217,-1.422,-1.42185,-1.42172,-1.42161,-1.42151,-1.42143,-1.42137,-1.42131,-1.42126,-1.42121,-1.42117,-1.42114,-1.42111,-1.42108,-1.42105,-1.42102,-1.421,-1.42098,-1.42096,-1.42094,-1.42092,-1.4209,-1.42088,-1.42087,-1.42085,-1.42084,-1.42082,-1.42081,-1.42079,-1.42078,-1.42077,-1.42076,-1.42075,-1.42074,-1.42072,-1.42071,-1.4207,-1.42069,-1.42069,-1.42068]
[-1.43407,-1.43409,-1.43404,-1.434,-1.43396,-1.4339,-1.43383,-1.43371,-1.43351,-1.43311,-1.43236,-1.43119,-1.42997,-1.42916,-1.42878,-1.42863,-1.42857,-1.42855,-1.42854,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42853,-1.42854,-1.42848,-1.42844,-1.42838,-1.4283,-1.42819,-1.42807,-1.42792,-1.42778,-1.42764,-1.42754,-1.42746,-1.42741,-1.42737,-1.42735,-1.42733,-1.42731,-1.4273,-1.42729,-1.42728,-1.42728,-1.42727,-1.42727,-1.42726,-1.42726,-1.42725,-1.42725,-1.42725,-1.42725,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42724,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42723,-1.42724,-1.42719,-1.42716,-1.42712,-1.42707,-1.42701,-1.42695,-1.42688,-1.42681,-1.42674,-1.42666,-1.4266,-1.42653,-1.42647,-1.4264,-1.42634,-1.42628,-1.42622,-1.42616,-1.42611,-1.42605,-1.42601,-1.42596,-1.42593,-1.4259,-1.42587,-1.42584,-1.42582,-1.4258,-1.42579,-1.42577,-1.42576,-1.42574,-1.42573,-1.42572,-1.42571,-1.42569,-1.42568,-1.42567,-1.42566,-1.42565,-1.42563,-1.42562,-1.42561,-1.4256,-1.42559,-1.42557,-1.42556,-1.42555,-1.42554,-1.42553,-1.42546,-1.4254,-1.42534,-1.42526,-1.42516,-1.42506,-1.42494,-1.42482,-1.42469,-1.42458,-1.42447,-1.42436,-1.42427,-1.42419,-1.42412,-1.42406,-1.424,-1.42395,-1.42391,-1.42387,-1.42383,-1.4238,-1.42377,-1.42374,-1.42371,-1.42368,-1.42366,-1.42363,-1.42361,-1.42358,-1.42356,-1.42354,-1.42352,-1.4235,-1.42348,-1.42346,-1.42345,-1.42343,-1.42342,-1.4234,-1.42339,-1.42338,-1.42336,-1.42335,-1.42334,-1.42333,-1.42332,-1.42331,-1.4233,-1.4233,-1.42323,-1.42316,-1.42308,-1.42298,-1.42286,-1.4227,-1.42253,-1.42235,-1.42217,-1.422,-1.42185,-1.42172,-1.42161,-1.42151,-1.42143,-1.42137,-1.42131,-1.42126,-1.42121,-1.42117,-1.42114,-1.42111,-1.42108,-1.42105,-1.42102,-1.421,-1.42098,-1.42096,-1.42094,-1.42092,-1.4209,-1.42088,-1.42087,-1.42085,-1.42084,-1.42082,-1.42081,-1.42079,-1.42078,-1.42077,-1.42076,-1.42075,-1.42074,-1.42072,-1.42071,-1.4207,-1.42069,-1.42069,-1.42068]
32Ã—26 Array{Float64,2}:
 -0.524333   -0.0746039    0.199201   -0.471684   -0.514251   -0.319488     0.378059   -0.386084     0.11665    -0.173687    0.128317    -0.312783    -0.149683   -0.312916    0.274696   -0.537631     0.11813     0.170186    -0.320806     -0.688768    0.134673    0.592939    0.0595872   -0.544477    0.00518298  -0.377457  
 -0.215043   -0.147669    -0.108396   -0.0125521   0.520295    0.0581595    0.0751917  -0.199572    -0.396221   -0.490736    0.609805    -0.636739     0.408824   -0.217951    0.338639   -0.681151    -0.27698     0.277616    -0.435012     -0.309807   -0.59952    -0.239       0.00547005  -0.559332   -0.185409    -0.21925   
 -0.811285   -0.0237617   -0.208182    0.577762    0.212859   -0.0206933   -0.467279   -0.157316     0.109205    0.275326   -0.30384      0.311422     0.580043    0.0429923   0.317993   -0.126618    -0.196762   -0.00591761  -0.165994     -0.363803   -0.563123   -0.188388   -0.0420388   -0.135547   -0.0213925    0.336991  
  0.35195     0.271694    -0.182502    0.328638    0.460825   -0.11002     -0.606952   -0.335157     0.197827    0.31767    -0.271112     0.328229    -0.297047   -0.319824    0.219083   -0.244011    -0.391953    0.0263486   -0.162718     -0.494803   -0.266274   -0.376604    0.435736    -0.0414937   0.051052    -0.39084   
  0.303339    0.468646     0.266682    0.139593    0.0994758  -0.336712    -0.174109   -0.595017     0.118864   -0.0940722   0.225827    -0.084864    -0.276552    0.184095    0.493542    0.119727     0.138631    0.0808986   -0.0784323     0.358388    0.12837    -0.587141    0.130681     0.253673   -0.484007     0.0677625 
  0.0740304   0.261861    -0.329415    0.0719176   0.0316303  -0.442006     0.0333913  -0.171204     0.196556   -0.147638   -0.257506     0.245371    -0.574247   -0.166524    0.130445   -0.057648     0.0775384   0.0689234   -0.0200617     0.276748    0.396911    0.484658   -0.44625     -0.0242063  -0.818357     0.196579  
 -0.0759026  -0.272738     0.218849    0.0556541  -0.220567    0.754652     0.237169   -0.128245     0.523554   -0.216337    0.616093     0.00394417  -0.398617   -0.0958652   0.154897   -0.233033     0.126611   -0.354098     0.257061      0.0761344  -0.250202    0.291739   -0.689519     0.388548    0.0900687    0.0962646 
  0.461743   -0.00947298  -0.0725828  -0.0859446  -0.160248    0.00712147   0.217468   -0.0613425    0.34772    -0.775421    0.173601    -0.167319    -0.543677   -0.51441    -0.225672   -0.0877485    0.318133   -0.209348     0.337486      0.378087    0.31786    -0.0108226   0.391699     0.0225181   0.293685    -0.438365  
  0.205049   -0.34526      0.318828   -0.373631    0.181146    0.526625    -0.32205    -0.276831    -0.506563    0.0960833   0.126212     0.176429    -0.219922   -0.967024   -0.683481    0.27679      0.081704   -0.717622    -0.273129     -0.828318   -0.12142    -0.0295669  -0.165063     0.0527923   0.177493     0.272755  
 -0.335142   -0.288187     0.161488   -0.613141   -0.638691    0.249725     0.0221674  -0.296465    -0.570819    0.0650818  -0.0794342   -0.25032      1.14893    -0.0547357  -0.0227195   0.397881    -0.0757951  -0.159806    -0.229272     -0.839315    0.0216544  -0.24244     0.0524831    0.22083     0.432918     0.176029  
  0.0115647  -0.0663892    0.424512   -0.373124   -0.453163   -0.0498313    0.252855    0.269968    -0.587584   -0.541213    0.203855    -0.240239     0.402855    0.266429   -0.226245   -0.0509791    0.17111    -0.150444    -0.117586      0.491222    0.183418    0.315214   -0.532462    -0.285608   -0.147358     0.240929  
  0.0945052  -0.630657     0.463615   -0.182419   -0.378245    0.412682    -0.071372    0.199848    -0.0625968   0.65588     0.00114906  -0.0518236    0.45472     0.464779   -0.189368    0.768347     0.197059   -7.19066e-5   0.372198      0.191016    0.0642863   0.282081   -0.185107    -0.0346937  -0.347978     0.0702466 
  0.0148588   0.0453783    0.1103      0.0449485   0.0753489   0.0517025   -0.0136317   0.00804571  -0.0763968   0.0102509   0.0441496    0.145882     0.038741   -0.0435843   0.0271094  -0.0675694    0.0379072  -0.233017    -0.294602     -0.0519597  -0.0395387   0.0739308  -0.119908    -0.214998   -0.0103606   -0.00934224
 -0.0476061  -0.0485441   -0.273061   -0.108764    0.114093    0.0171466   -0.0394648  -0.0967911    0.115719   -0.0337671  -0.0858007   -0.00116835   0.0428052   0.120933   -0.108031    0.193787    -0.062776    0.220105     0.311416     -0.0331141  -0.0827389  -0.0912315   0.15613      0.215979   -0.0360825    0.0215017 
 -0.0281016  -0.198951     0.151446    0.291982    0.0187795  -0.27634      0.140305    0.366252     0.0664112   0.0826173  -0.256496    -0.0244918   -0.0872057   0.107366    0.0031733   0.00252953  -0.856445   -0.107645     0.108881      0.25974     0.434043    0.302182    0.0822047    0.121096    0.231357    -0.406023  
 -0.187397    0.158168     0.244693    0.0894123  -0.129792   -0.319169     0.306382    0.527258     0.17386     0.0581031   0.299802    -0.140424    -0.0439611  -0.0274987  -0.200211    0.0600928    0.682412    0.34003     -0.0136524     0.0604873   0.533293    0.0312901   0.156914     0.357214    0.224179     0.110258  
 -0.049268   -0.0428049    0.244849   -0.547294   -0.644533   -0.0164833    0.508632    0.261486    -0.319499   -0.340633    0.111292    -0.554028     0.20754     0.157562   -0.261331    0.0656746    0.471198    0.117815    -0.081877      0.163847    0.225458    0.19197    -0.187184    -0.0806405  -0.111285     0.121005  
  0.0523351   0.303433    -0.330456    0.191774    0.364102    0.0302084   -0.235667   -0.288661     0.121058    0.187592   -0.247734     0.674982    -0.0463641   0.146       0.360793    0.0683779   -0.230608   -0.214106     0.000783852  -0.0525493   0.0205177  -0.182261   -0.0507555    0.261027   -0.22922      0.304004  
 -0.163102   -0.135365     0.319754    0.549      -0.117389    0.132621     0.146291   -0.222215     0.709336   -0.379519    0.219981    -0.453394    -0.472153   -0.754968    0.0816915  -0.684626     0.268932    0.00573359  -0.313075     -0.0788954  -0.0809486  -0.0950285   0.111622    -0.0258464   0.208665    -0.461814  
 -0.199989   -0.0844334    0.492042   -0.128635   -0.206644    0.056351    -0.535757   -0.143535    -0.0340909  -0.410589    0.0786956   -0.805966    -0.302093   -0.437176    0.393185    0.0310454   -0.744035    0.0246374    0.977163     -0.280924   -0.126466    0.227875    0.123857    -0.05734    -0.143842    -0.276363  
  0.182853    0.328046     0.326944    0.179364    0.317025   -0.0600014    0.379189    0.679817    -0.626309    0.41609    -0.0151775    0.102137     0.356253    0.852336   -0.603591    0.0824947   -0.0278377  -0.149302    -0.574365      0.593253    0.218782   -0.392483   -0.0835308    0.268417    0.32166      0.0357222 
 -0.801291    0.317074    -0.180804    0.353124    0.0590871   0.135697    -0.0210414   0.159117    -0.706056    0.522027    0.112645    -0.27958      0.330405    0.521358   -0.407421    0.00453228  -0.475936   -0.0664424    0.844331      0.178458   -0.468438   -0.484876   -0.249028     0.281665    0.666372    -0.304745  
  0.367608    0.202194     0.654577   -0.212035   -0.113012    0.0695288    0.160632    1.17945     -0.681413    0.950368    0.0597419    0.309585    -0.156148   -0.0733484  -0.228049   -0.227107    -0.286516   -0.194991    -0.759114     -0.837316    0.125737    0.779518   -0.336373     0.0495451  -0.0796678   -0.335141  
 -0.180473   -0.613291    -0.116125   -0.347155   -0.319327    0.180882     0.280077    0.95368      0.238735   -0.197788   -0.54504      0.264656     0.122318   -0.116513   -0.37772    -0.498392    -0.51408    -0.119565    -0.0373667    -0.553979   -0.0573192   0.5773      0.100566    -0.115698    1.1306      -0.183059  
  0.1212      0.147648    -0.0286364  -0.157713   -0.41951     0.419106    -0.229508    0.241821     0.333422    0.264089   -1.06892      0.235791     0.0842632   0.713179   -0.0613795   0.297342     0.116264   -0.192753    -0.28068       0.218849   -0.0281365   0.261868   -0.213454     0.279673   -0.182515     0.717002  
  0.118837   -0.24558     -0.0863414   0.359045    0.591388    0.201278    -0.412685    0.478267     0.285988    0.221964   -0.774104     0.211095    -0.108186   -0.118055   -0.45021     0.619331    -0.25892    -0.488969     0.370885      0.221622    0.367532   -0.0631406   0.403042     0.225273    0.247877     0.558922  
  0.238007   -0.177438     0.362896    0.576592    0.536124   -0.430184    -0.0698736  -0.069162    -0.201179   -0.181276    1.28256      0.756752     0.146828   -0.158286   -0.278058    0.255293    -0.0105423  -0.174976    -0.214107      0.22401    -0.0236542   0.168223    0.187439    -0.683949    0.19194     -0.59592   
  0.728711   -0.285365    -0.421747   -0.0747834   0.376034    0.111304     0.40404    -0.289909    -0.108922   -0.120197    0.303756     0.927773    -0.188661    0.227852    0.0580919  -0.113081    -0.117814   -0.785008    -0.0352477     0.256081    0.0875124  -0.269141   -0.347908    -0.289562   -0.0275401   -0.208399  
 -0.318579    0.452836     0.0650047  -0.459116    0.0130575  -0.341543    -0.302102    0.0272845   -0.616321   -0.0234267  -0.47372     -0.660301     0.237291   -0.129291   -0.345743    0.397057     0.156172    0.674796    -0.0933485    -0.311219    0.0707723  -0.0469575   0.679535     0.0556154  -0.262046     0.101318  
 -0.139769    0.0716544   -0.877009   -0.322443    0.304022   -0.197238     0.434157   -0.0750791    0.0613602   0.147487    0.103896     0.28136     -0.0747114   0.0343361  -0.2865      0.240607     0.16162     0.746122     0.286989     -0.58007    -0.148165   -0.211268    0.333307     0.360178   -0.146081    -0.0598966 
 -0.054592    0.0606081   -0.672096    0.241969    0.197339   -0.172508    -0.200347   -0.411181     0.625792   -0.615122   -0.534542    -0.229646     0.0274369   0.890665    0.194196   -0.0385534    0.165596    0.834705     0.805475      0.793389   -0.0837411  -0.413149    0.378498    -0.74064    -0.308736    -0.508541  
 -0.671217    0.356252     0.0397514   0.678611    0.0294032  -0.382313    -0.103095    0.508529     0.483919    0.0217934   0.237622    -0.0613152    0.321858    0.589152    0.724077   -0.498165    -0.239956    0.612958     0.211405      0.680598   -0.236233    0.318957    0.0439853    0.217313   -0.146235     0.113894  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.420667
INFO: iteration 2, average log likelihood -1.420658
INFO: iteration 3, average log likelihood -1.420649
INFO: iteration 4, average log likelihood -1.420640
INFO: iteration 5, average log likelihood -1.420632
INFO: iteration 6, average log likelihood -1.420623
INFO: iteration 7, average log likelihood -1.420615
INFO: iteration 8, average log likelihood -1.420607
INFO: iteration 9, average log likelihood -1.420598
INFO: iteration 10, average log likelihood -1.420590
INFO: EM with 100000 data points 10 iterations avll -1.420590
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.693631e+05
      1       7.241226e+05      -2.452404e+05 |       32
      2       7.087274e+05      -1.539523e+04 |       32
      3       7.030809e+05      -5.646562e+03 |       32
      4       7.002653e+05      -2.815542e+03 |       32
      5       6.985474e+05      -1.717912e+03 |       32
      6       6.971960e+05      -1.351422e+03 |       32
      7       6.962036e+05      -9.923919e+02 |       32
      8       6.954209e+05      -7.826921e+02 |       32
      9       6.947707e+05      -6.502061e+02 |       32
     10       6.941994e+05      -5.712708e+02 |       32
     11       6.936952e+05      -5.042520e+02 |       32
     12       6.932584e+05      -4.367513e+02 |       32
     13       6.929051e+05      -3.533633e+02 |       32
     14       6.925798e+05      -3.252064e+02 |       32
     15       6.923046e+05      -2.752353e+02 |       32
     16       6.920562e+05      -2.484216e+02 |       32
     17       6.918316e+05      -2.245671e+02 |       32
     18       6.916373e+05      -1.943279e+02 |       32
     19       6.914738e+05      -1.635070e+02 |       32
     20       6.913137e+05      -1.600702e+02 |       32
     21       6.911621e+05      -1.516257e+02 |       32
     22       6.910236e+05      -1.384874e+02 |       32
     23       6.909017e+05      -1.218594e+02 |       32
     24       6.907924e+05      -1.093819e+02 |       32
     25       6.906894e+05      -1.029450e+02 |       32
     26       6.905878e+05      -1.016160e+02 |       32
     27       6.904876e+05      -1.002460e+02 |       32
     28       6.904001e+05      -8.748229e+01 |       32
     29       6.903265e+05      -7.352614e+01 |       32
     30       6.902581e+05      -6.848141e+01 |       32
     31       6.901838e+05      -7.429143e+01 |       32
     32       6.901054e+05      -7.840739e+01 |       32
     33       6.900265e+05      -7.887838e+01 |       32
     34       6.899423e+05      -8.417991e+01 |       32
     35       6.898590e+05      -8.328636e+01 |       32
     36       6.897789e+05      -8.015731e+01 |       32
     37       6.896950e+05      -8.389747e+01 |       32
     38       6.896175e+05      -7.742842e+01 |       32
     39       6.895518e+05      -6.573764e+01 |       32
     40       6.894956e+05      -5.623956e+01 |       32
     41       6.894353e+05      -6.023807e+01 |       32
     42       6.893773e+05      -5.805097e+01 |       32
     43       6.893193e+05      -5.801517e+01 |       32
     44       6.892569e+05      -6.239108e+01 |       32
     45       6.891993e+05      -5.759933e+01 |       32
     46       6.891411e+05      -5.818881e+01 |       32
     47       6.890843e+05      -5.676435e+01 |       32
     48       6.890281e+05      -5.619283e+01 |       32
     49       6.889844e+05      -4.375470e+01 |       32
     50       6.889488e+05      -3.560949e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 688948.7552226677)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.432646
INFO: iteration 2, average log likelihood -1.427659
INFO: iteration 3, average log likelihood -1.426304
INFO: iteration 4, average log likelihood -1.425258
INFO: iteration 5, average log likelihood -1.424112
INFO: iteration 6, average log likelihood -1.423049
INFO: iteration 7, average log likelihood -1.422337
INFO: iteration 8, average log likelihood -1.421959
INFO: iteration 9, average log likelihood -1.421757
INFO: iteration 10, average log likelihood -1.421629
INFO: iteration 11, average log likelihood -1.421535
INFO: iteration 12, average log likelihood -1.421458
INFO: iteration 13, average log likelihood -1.421392
INFO: iteration 14, average log likelihood -1.421333
INFO: iteration 15, average log likelihood -1.421280
INFO: iteration 16, average log likelihood -1.421231
INFO: iteration 17, average log likelihood -1.421186
INFO: iteration 18, average log likelihood -1.421144
INFO: iteration 19, average log likelihood -1.421104
INFO: iteration 20, average log likelihood -1.421067
INFO: iteration 21, average log likelihood -1.421033
INFO: iteration 22, average log likelihood -1.421000
INFO: iteration 23, average log likelihood -1.420969
INFO: iteration 24, average log likelihood -1.420940
INFO: iteration 25, average log likelihood -1.420912
INFO: iteration 26, average log likelihood -1.420886
INFO: iteration 27, average log likelihood -1.420862
INFO: iteration 28, average log likelihood -1.420838
INFO: iteration 29, average log likelihood -1.420816
INFO: iteration 30, average log likelihood -1.420795
INFO: iteration 31, average log likelihood -1.420776
INFO: iteration 32, average log likelihood -1.420757
INFO: iteration 33, average log likelihood -1.420739
INFO: iteration 34, average log likelihood -1.420722
INFO: iteration 35, average log likelihood -1.420706
INFO: iteration 36, average log likelihood -1.420690
INFO: iteration 37, average log likelihood -1.420676
INFO: iteration 38, average log likelihood -1.420661
INFO: iteration 39, average log likelihood -1.420648
INFO: iteration 40, average log likelihood -1.420635
INFO: iteration 41, average log likelihood -1.420623
INFO: iteration 42, average log likelihood -1.420611
INFO: iteration 43, average log likelihood -1.420599
INFO: iteration 44, average log likelihood -1.420588
INFO: iteration 45, average log likelihood -1.420577
INFO: iteration 46, average log likelihood -1.420567
INFO: iteration 47, average log likelihood -1.420557
INFO: iteration 48, average log likelihood -1.420547
INFO: iteration 49, average log likelihood -1.420538
INFO: iteration 50, average log likelihood -1.420529
INFO: EM with 100000 data points 50 iterations avll -1.420529
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.72583     0.528836    0.341904      0.480831    0.165786    -0.351621    -0.562496   -0.518048     0.182846     -0.169857     0.23229     0.167325   -0.394717   -0.169524     0.565608     0.0266933  -0.0993882   -0.27284    -0.177596    0.377902   -0.0723729   -0.403523     0.203866    0.0726997  -0.281818    -0.174657 
 -0.53137    -0.279875    0.112929     -0.226122   -0.552736    -0.216147     0.229414    0.347486     0.422768     -0.371127    -0.403268   -0.315951   -0.233704   -0.5817      -0.0283876   -0.815418   -0.251167     0.0711261  -0.409333   -0.627668    0.136242     0.678083     0.04214    -0.299106    0.454866    -0.135783 
  0.657114   -0.198388    0.637268      0.253492   -0.307162     0.0332677    0.157634    1.06838     -0.120566      0.30855      0.0895426   0.545014    0.258154    0.380869    -0.421938     0.0238709  -0.1664      -0.171598   -0.167322    0.490311    0.349975     0.538507    -0.34116    -0.0992705   0.0750654   -0.262374 
  0.188993   -0.356137   -0.0235785     0.169958    0.282291     0.35572     -0.797988    0.135362    -0.0731705     0.358096    -0.253282    0.564783   -0.0855873  -0.447673    -0.254019    -0.0916542  -0.396072    -0.375524    0.142881   -1.01654    -0.450448    -0.252248     0.254649   -0.100759    0.356101    -0.132701 
 -0.0460982   0.325712    0.117625     -0.346377   -0.284174    -0.807406     0.397732   -0.112226    -0.491001     -0.505654     0.854931   -0.309442   -0.100239   -0.45751     -0.0237583   -0.643602    0.11635      0.622963    0.100531   -0.130089    0.367376    -0.414446     0.224602    0.0262774   0.00399346  -0.654897 
 -0.054535   -0.305023    0.751516     -0.214      -0.127433    -0.269108    -0.259912    0.102083    -0.278825      0.092993     0.210014   -0.804792    0.019976   -0.0538779    0.142583     0.0967744  -0.245507     0.241255    0.135755   -0.0367614   0.177741     0.0714159    0.283852   -0.144487   -0.337703    -0.226171 
 -0.580141   -0.0903529   0.291264     -0.465452   -0.542564     0.51534      0.136223   -0.0916989   -0.702527     -0.0612131    0.150239   -0.791068    0.0089912  -0.298465    -0.606681     0.574881    0.151823     0.289588    0.295059   -0.623815   -0.323564     0.0738792   -0.0564493   0.236227   -0.0115075   -0.345042 
 -0.478898   -0.387933   -0.0877614    -0.370067    0.0641664   -0.0235044    0.874718    0.670282    -0.347165     -0.145969    -0.0394129  -0.185108    0.667717    0.549838    -0.395183    -0.0232855  -0.0778669    0.217348    0.140884    0.11052     0.244984     0.149999    -0.10647    -0.0243717   0.555663     0.100923 
  0.107985   -0.197547    0.757562     -0.193651    0.309275     0.399542    -0.129396    0.326931    -0.740079     -0.286639     0.674816   -0.609224    0.120022    0.36053     -0.264716    -0.503104   -0.157626    -0.943006   -0.670056    0.429291    0.0954446   -0.305954    -0.449337   -0.0485695  -0.106072     0.617636 
 -0.389023   -0.114354   -0.311088     -0.0874662   0.289509     0.453893    -0.72261    -0.658886    -0.354546     -0.73972     -0.269393   -0.564387   -0.0352908  -0.427092    -0.0776172    0.163376   -0.52279     -0.192602    0.247746    0.167169   -0.415152     0.165465    -0.253226   -0.425292   -0.369146     0.451866 
 -0.168295    0.523302    0.0844409    -0.427337   -0.190771    -0.376053    -0.0952782   0.28846     -0.620843      0.143932    -0.588448   -0.410454    0.554815    0.118395    -0.350939     0.394683    0.444456     0.619552   -0.39605    -0.290301    0.120936     0.095963     0.609832   -0.155475   -0.105034     0.260651 
 -0.156928   -0.747978    0.430203     -0.0787911  -0.298482     0.537765    -0.322815    0.251419     0.460634      0.635835    -0.460623    0.0581999   0.471573    0.41333     -0.240882     1.0933      0.19916     -0.427615    0.457398    0.107887    0.0759131    0.235919     0.111623    0.0907101   0.00263853   0.49701  
 -1.31286     0.232331   -0.021089      0.778173    0.0286329   -0.130271    -0.33019     0.210345    -0.000166992   0.502454     0.149098   -0.174171    0.520467    0.496152     0.382349    -0.374939   -0.534607     0.310923    0.554421    0.271679   -0.666558     0.0349651   -0.24301     0.322693    0.102386     0.0581307
  0.264539    0.303195   -0.15818      -0.144719   -0.363022    -0.00556879  -0.108961    0.176877    -0.00783787   -0.0455973   -0.655511   -0.628609    0.0532695   0.906717     0.492259    -0.171078    0.105568     0.627239    0.314337    0.615721    0.00399309   0.0926408   -0.201898    0.137897   -0.581317     0.420103 
 -0.133427   -0.268285    0.379199     -0.470417   -0.217742     0.44367      0.144122    0.0111696   -0.456531      0.192236     0.278344    0.0261556   0.148137   -0.560994    -0.318642     0.170065   -0.029337    -0.55111    -0.407109   -0.781757    0.011257     0.223514    -0.306578    0.229857    0.317809     0.21419  
  0.0808696   0.27018    -0.000485584   0.0362155  -0.167987    -0.238167     0.217877   -0.112458     0.374741     -0.0926784    0.0928822  -0.0906566  -0.55559     0.0218176   -0.198523     0.296332    0.616145     0.33115     0.154366    0.383097    0.613923     0.0320459   -0.246288    0.460374   -0.452614     0.22057  
 -0.0562208  -0.0374379   0.347681     -0.650407   -1.26149     -0.167942     0.301666   -0.251112    -0.395717     -0.250483    -0.0570976  -0.218469    0.471845    0.195342     0.250311     0.0586604   0.314804    -0.208254   -0.173405   -0.0812411  -0.0103069    0.440352    -0.558766   -0.397139   -0.286516     0.170813 
 -0.115098   -0.0269116  -0.222307     -0.0415894   0.0277776   -0.125342    -0.0144121   0.0764956    0.296578      0.0322151   -0.155229   -0.0353395   0.0435307  -0.0448635   -0.0348299    0.0270962  -0.0994907    0.343844    0.196958   -0.281271   -0.049962    -0.0445803    0.375768    0.235606    0.134966    -0.0684562
  0.773489    0.0519931  -0.216944     -0.640548    0.294788    -0.0621332    0.158558   -0.102801    -0.260921     -0.165133    -0.111579    0.312414   -0.500925   -0.298788    -0.506276     0.26016     0.480621    -0.354603   -0.247316   -0.195327    0.412383    -0.0766495    0.25733    -0.248613   -0.185339     0.0630421
  0.173676   -0.0863145  -0.365904      0.394556    0.250836     0.0597194    0.243682   -0.135143     0.560558      0.211335    -0.0177183   1.18821    -0.429807    0.0827059    0.389954    -0.408102   -0.247755    -0.664099    0.136633    0.36067     0.330285     0.0710923   -0.458315   -0.0212905  -0.156429     0.192448 
 -0.0327596   0.190218   -0.2093        0.262096    0.402919    -0.0819016   -0.245585    0.425704     0.0251352     0.247437    -1.14034    -0.0247315  -0.0865928   0.0850923   -0.117321     0.353605   -0.697402    -0.252388    0.113945    0.296977    0.604744    -0.194518     0.488037    0.498477    0.326901     0.253053 
 -0.0403242  -0.0718893  -0.022521      0.16725    -0.115032    -0.189332     0.271754    0.0519173    0.228502     -0.3193       0.102661    0.040018   -0.497591   -0.27354     -0.060315    -0.201178   -0.300948    -0.331124    0.15075     0.125091    0.234161     0.424743    -0.135237   -0.0638343   0.216134    -0.373279 
  0.0349354   0.141349   -0.346988      0.34952     0.485699     0.00651212  -0.0220522  -0.0625371   -0.481359      0.410613     0.322319    0.389903    0.468028    0.43537     -0.395595     0.698121   -0.122457     0.219165    0.152049    0.174894   -0.146841    -0.461205     0.111629    0.204167   -0.103197    -0.0166928
  0.870094   -0.217194   -0.597434     -0.68898     0.161127     0.252985     0.153741    0.198713     0.0928953    -0.166471     0.03625     0.494845   -0.19652     0.40182     -0.22633      0.499242   -0.0106507    0.0271587   0.83693     0.308693   -0.326437     0.105076     0.172768    0.302883    0.178405    -0.613244 
 -0.884746    0.748097    0.452072      0.840032   -0.106532     0.310947    -0.211342    0.622611     0.320109      0.126683     0.48857    -0.387855   -0.0633731  -0.363939     0.042479    -0.0554589   0.62266      0.197742   -0.256686    0.425522   -0.136457    -0.0586222    0.171386    0.288247    0.997398     0.0283378
 -0.34515     0.321091   -0.211948     -0.158595   -0.13437      0.298215    -0.436888   -0.288556     0.340728      0.0186944   -0.440153    0.6335      0.276888    0.38441      0.196802     0.288172    0.247858    -0.211171   -0.4394     -0.273034   -0.412697    -0.175463    -0.520704    0.598634   -0.384196     0.846582 
 -0.0174584   0.0217446   0.100857      0.0169373  -0.00913091   0.108089    -0.0220797   0.00172283  -0.0270683     0.0143908   -0.0351194   0.0939669   0.113838    0.172471     0.00733759   0.0568065   0.0418386   -0.105224   -0.0763042   0.175379    0.0143163    0.0472095   -0.204657    0.0102379  -0.113942     0.14981  
  0.180236    0.0500681  -0.0287996     0.186266    0.397933    -0.109266     0.144953   -0.0951004   -0.104003     -0.0300332    0.363056    0.441209   -0.0103664  -0.110647    -0.130717     0.0934971  -0.0793912   -0.161988   -0.0560624  -0.0265746   0.105909     0.00513322   0.0739702  -0.136677    0.0144654   -0.179291 
 -0.325263    0.119523   -0.675601     -0.0661676   0.399196    -0.276623     0.0875042  -0.53259      0.277462      0.0437138   -0.0704602  -0.131504   -0.243931   -0.275117     0.177123    -0.0297798   0.00688526   0.727146    0.111198   -0.786758   -0.356669    -0.333751     0.404118    0.335443   -0.311345     0.0647515
 -0.127221    0.0334411  -0.130069      0.205151    0.431789    -0.134704    -0.0256928  -0.261522    -0.269598     -0.00184968   0.233332    0.193379    0.296747   -0.00486791   0.220426    -0.462044   -0.0571583   -0.0459223  -0.543769   -0.316417   -0.338793    -0.00604227  -0.115664   -0.592482   -0.0934879   -0.335302 
 -0.32388     0.221384   -0.384339      0.329471    0.270965    -0.440152     0.0497895  -0.337936     0.684692     -0.580894    -0.0943335  -0.0234703   0.0507427   0.525804     0.394169    -0.234301    0.041564     0.709125    0.466041    0.719378    0.101079    -0.14904      0.525962   -0.46816    -0.328437    -0.370121 
  0.254305   -0.574463    0.299432      0.0814459  -0.151624     0.848089     0.433225   -0.328729     0.833678     -0.581425     0.532389   -0.493169   -0.346453   -0.193704     0.213443    -0.42645     0.566582    -0.191473    0.077933    0.299009   -0.137011    -0.200494    -0.055914   -0.0488174   0.275488    -0.392686 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.420520
INFO: iteration 2, average log likelihood -1.420511
INFO: iteration 3, average log likelihood -1.420503
INFO: iteration 4, average log likelihood -1.420494
INFO: iteration 5, average log likelihood -1.420486
INFO: iteration 6, average log likelihood -1.420478
INFO: iteration 7, average log likelihood -1.420471
INFO: iteration 8, average log likelihood -1.420463
INFO: iteration 9, average log likelihood -1.420456
INFO: iteration 10, average log likelihood -1.420448
INFO: EM with 100000 data points 10 iterations avll -1.420448
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
