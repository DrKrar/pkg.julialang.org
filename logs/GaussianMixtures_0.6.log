>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.782
Commit ed517a6 (2016-09-25 21:49 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (667.2265625 MB free)
Uptime: 23556.0 sec
Load Avg:  1.02294921875  1.0146484375  1.029296875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1389910 s       4209 s     138004 s     504396 s         49 s
#2  3500 MHz     624500 s       2224 s      83175 s    1527964 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-7.57696714502549e6,[98989.0,1011.0],
[2248.4 1017.74 -912.542; -2391.63 -594.502 908.845],

Array{Float64,2}[
[94526.3 -1657.17 1167.13; -1657.17 98736.0 121.563; 1167.13 121.563 98712.8],

[6102.64 1046.95 -1708.6; 1046.95 1477.36 -561.883; -1708.6 -561.883 1726.57]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.019947e+03
      1       9.123281e+02      -1.076186e+02 |        6
      2       8.962258e+02      -1.610225e+01 |        0
      3       8.962258e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 896.2258223439549)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.082867
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.868388
INFO: iteration 2, lowerbound -3.744325
INFO: iteration 3, lowerbound -3.582724
INFO: iteration 4, lowerbound -3.356979
INFO: iteration 5, lowerbound -3.082671
INFO: iteration 6, lowerbound -2.807947
INFO: iteration 7, lowerbound -2.592835
INFO: dropping number of Gaussions to 7
INFO: iteration 8, lowerbound -2.461566
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.377048
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.329205
INFO: iteration 11, lowerbound -2.315527
INFO: dropping number of Gaussions to 2
INFO: iteration 12, lowerbound -2.306605
INFO: iteration 13, lowerbound -2.299268
INFO: iteration 14, lowerbound -2.299260
INFO: iteration 15, lowerbound -2.299256
INFO: iteration 16, lowerbound -2.299254
INFO: iteration 17, lowerbound -2.299254
INFO: iteration 18, lowerbound -2.299253
INFO: iteration 19, lowerbound -2.299253
INFO: iteration 20, lowerbound -2.299253
INFO: iteration 21, lowerbound -2.299253
INFO: iteration 22, lowerbound -2.299253
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Mon 26 Sep 2016 11:02:27 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Mon 26 Sep 2016 11:02:30 AM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Mon 26 Sep 2016 11:02:31 AM UTC: EM with 272 data points 0 iterations avll -2.082867
5.8 data points per parameter
,Mon 26 Sep 2016 11:02:32 AM UTC: GMM converted to Variational GMM
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 1, lowerbound -3.868388
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 2, lowerbound -3.744325
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 3, lowerbound -3.582724
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 4, lowerbound -3.356979
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 5, lowerbound -3.082671
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 6, lowerbound -2.807947
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 7, lowerbound -2.592835
,Mon 26 Sep 2016 11:02:34 AM UTC: dropping number of Gaussions to 7
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 8, lowerbound -2.461566
,Mon 26 Sep 2016 11:02:34 AM UTC: dropping number of Gaussions to 5
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 9, lowerbound -2.377048
,Mon 26 Sep 2016 11:02:34 AM UTC: dropping number of Gaussions to 4
,Mon 26 Sep 2016 11:02:34 AM UTC: iteration 10, lowerbound -2.329205
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 11, lowerbound -2.315527
,Mon 26 Sep 2016 11:02:35 AM UTC: dropping number of Gaussions to 2
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 12, lowerbound -2.306605
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 13, lowerbound -2.299268
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 14, lowerbound -2.299260
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 15, lowerbound -2.299256
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 16, lowerbound -2.299254
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 17, lowerbound -2.299254
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 18, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 19, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 20, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 21, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:35 AM UTC: iteration 22, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 23, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 24, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 25, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 26, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 27, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 28, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 29, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 30, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 31, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 32, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 33, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 34, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 35, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 36, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 37, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:36 AM UTC: iteration 38, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 39, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 40, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 41, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 42, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 43, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 44, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 45, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 46, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 47, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 48, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 49, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: iteration 50, lowerbound -2.299253
,Mon 26 Sep 2016 11:02:37 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.9549,178.045]
Î² = [95.9549,178.045]
m = [2.00023 53.852; 4.2503 79.2869]
Î½ = [97.9549,180.045]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.375876 -0.00895312; 0.0 0.0127487],

[0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0267837028062405
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -1.026783702806241
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -1.026783702806241
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9562608735233309
avll from llpg:  -0.9562608735233309
avll direct:     -0.9562608735233309
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0500098     0.0179665    0.0552136   -0.0542889    0.0127687   0.197657     0.0667813    -0.21741     0.0496074   -0.13099     -0.122604     0.0183413    0.0960592   -0.038144     0.00386964  -0.140119    -0.170155     0.0124604   -0.10173     -0.228383     0.0276846   -0.0600914     0.0383933    0.0442048    0.161784    -0.0232585 
  0.0444998    -0.0305359   -0.0494684    0.0011961    0.109594   -0.12966      0.0612588     0.109751   -0.120393    -0.0733631    0.245403     0.100594    -0.0735415    0.0281224    0.112828     0.0923317    0.111874     0.107903    -0.0318221    0.118503     0.0290849    0.0774331    -0.15082      0.154335    -0.133185    -0.0493514 
 -0.0588265    -0.101674     0.0533633   -0.0894635   -0.174638    0.0884066   -0.179888      0.0990745  -0.0719061   -0.0178342   -0.0229757    0.154691    -0.020392     0.0196646    0.054008    -0.0153049    0.0650067    0.0768541   -0.104944     0.124229    -0.132991     0.0262145    -0.0506632    0.0356199    0.163674    -0.104694  
  0.100916      0.0324637   -0.10399     -0.128336     0.111783   -0.160154     0.0314901     0.0730694  -0.00965638   0.11494     -0.0361086   -0.0405958    0.0294464    0.126994    -0.0117094    0.0300876   -0.0875147   -0.173777    -0.0453596   -0.197696    -0.0659923    0.0511599     0.0300186   -0.243935    -0.0538444    0.0160421 
 -0.0387768    -0.00331698   0.0357473   -0.0414736    0.0543737   0.0385358    0.119636     -0.11095     0.132116    -0.0448477   -0.0177407   -0.0337195    0.147202     0.0245992    0.0741469    0.0171285   -0.148443     0.059808    -0.215273    -0.011873    -0.0100821    0.0718457    -0.135041     0.0526161   -0.0941824    0.117146  
 -0.250424     -0.10542     -0.143415    -0.126256    -0.152026    0.209646    -0.0415428    -0.0722666  -0.113186    -0.0144406   -0.109847    -0.00486754  -0.0157825    0.0284794   -0.0289716    0.0362781    0.139074     0.018924     0.0257656   -0.079348    -0.159737     0.230687     -0.0605835   -0.0845268    0.00816305  -0.00496314
 -0.0312092     0.118592    -0.0391029   -0.0299578   -0.0266492  -0.176484     0.0145561     0.11556     0.102398    -0.134131    -0.0127228   -0.0420195    0.153393    -0.017538    -0.031424    -0.0441256    0.0287494   -0.111828     0.00466841   0.161128     0.032501    -0.0423558     0.148129    -0.145023     0.0535235    0.0447818 
 -0.0603221    -0.00721643  -0.0889398   -0.160263     0.0242991   3.40549e-5  -0.00874789   -0.0863828  -0.0374767    0.0226991   -0.0691748    0.00958233  -0.0610259   -0.181189     0.00738901  -0.0398466    0.0340745   -0.0633663   -0.0198885    0.136416    -0.0558063    0.000175763   0.0716644   -0.0499504    0.0805685    0.0612269 
  0.190767      0.117673    -0.0374589    0.148723     0.0722698   0.00863613  -0.0637262    -0.0372823  -0.0343253   -0.00815554  -0.0185065    0.119522     0.0576749   -0.0267659   -0.210661     0.08036      0.0606299    0.0683136    0.0898809    0.15549     -0.00605186  -0.153944     -0.160973     0.130055     0.112794     0.0230791 
 -0.0592289     0.112776     0.0845129    0.110549     0.0575381   0.0586912   -0.224287     -0.0146674  -0.0747459   -0.138312     0.0798203    0.139503     0.0721698   -0.0403275    0.123132     0.177408     0.0995723    0.00442528   0.0291346    0.0249155   -0.0400438   -0.0850368     0.0049051    0.117525     0.00433296   0.035452  
 -0.000597682   0.14019     -0.10086     -0.0568735   -0.0480485   0.100614    -0.0635544    -0.0320219  -0.00905166   0.0473456    0.101253    -0.189606    -0.104677     0.031128    -0.0287963    0.0330837   -0.024642     0.0411539   -0.00073952   0.0612543   -0.0204877   -0.0342242    -0.121443     0.13461     -0.0365822   -0.157236  
 -0.0902666     0.0972414    0.108386     0.132891     0.0629726  -0.0668713   -0.0398857     0.0626219   0.101255     0.126273    -0.0750936    0.010097    -0.0644422   -0.0533373    0.0505751   -0.0482256    0.098677    -0.152102    -0.0880664    0.14702     -0.0449387   -0.171994      0.00520038  -0.210831     0.0489876   -0.075808  
 -0.146233      0.0312867   -0.0261296   -0.0491355   -0.017362    0.0741762    0.0169584     0.0421108  -0.0237789    0.057384    -0.0390092    0.0420714    0.0275432   -0.00191806   0.0859928   -0.102167    -0.101557    -0.123634    -0.0216254    0.126682     0.0200103   -0.0159771     0.108978    -0.137161     0.00526266   0.150745  
  0.125281     -0.0600151   -0.205323     0.0541324    0.128157   -0.0663637   -0.0511877     0.140435    0.149434     0.194072    -0.0310012   -0.117047    -0.0304949   -0.111312    -0.0266127    0.168098    -0.0823951   -0.0588016   -0.031603     0.101131     0.0456212   -0.142015      0.0410347    0.147063     0.0238573    0.0543339 
 -0.202855      0.0617519    0.110495    -0.0903974    0.0776202   0.181565     0.00808769   -0.0537374   0.0704723    0.246514    -0.0905611    0.0289498   -0.0345632    0.13109      0.161038    -0.0284077   -0.102827    -0.187818     0.00116774  -0.172899    -0.0297867   -0.0388974     0.0146792   -0.223041     0.164161     0.126214  
 -0.00160912   -0.0134135    0.0235306    0.0696204    0.107468    0.0134474    0.1355        0.147675    0.0228652    0.123006    -0.058803    -0.0259504    0.00521158  -0.0756163   -0.00740059   0.107675    -0.0487958   -0.0459877   -0.0608566    0.15035     -0.13956      0.0331168     0.0920628   -0.049795    -0.0605888   -0.109358  
 -0.0596876    -0.100401    -0.0958884    0.0201868   -0.0606636   0.026964    -0.0604714     0.0570484   0.0444613    0.118187     0.00469055  -0.198855    -0.0734997   -0.138142    -0.00299571   0.0391038    0.105859     0.136925     0.105158    -0.0438529   -0.251585    -0.0463898     0.104825    -0.0334314   -0.0424852    0.0163325 
  0.0114671     0.0462982   -0.0133216   -0.121117     0.0304744   0.237098    -0.0570185    -0.0275863   0.0100163    0.0441155    0.0485737   -0.0588356   -0.0582379    0.0968957   -0.0651679    0.0660116    0.080623     0.00845973  -0.141996    -0.109684    -0.0779255   -0.202992     -0.205        0.0805232    0.102436     0.0620669 
  0.216562      0.0759554   -0.0711899   -0.0392066    0.0159876   0.149609    -0.173499      0.243454    0.150809     0.153067     0.0312273   -0.143845     0.094848     0.0253956   -0.118281     0.107072     0.0115661   -0.0344196   -0.0471699    0.0243855    0.0337694    0.0491874    -0.0557403   -0.115245     0.184639    -0.0509325 
 -0.131664     -0.168182    -0.160004     0.0742731   -0.172964    0.0980104    0.215007     -0.0187216   0.140506     0.0873944    0.117882     0.155828     0.0312068   -0.178668    -0.197987    -0.152395     0.0922666   -0.0621105    0.133951     0.0776884   -0.00721213  -0.00117596    0.00734239   0.111063    -0.109731    -0.0754382 
  0.0725764    -0.0847007    0.0606413   -0.163903     0.0840174   0.0961027    0.0154583     0.123323    0.0119242    0.0571846   -0.0480188   -0.00474373   0.118106    -0.0115707   -0.0497183    0.027546    -0.0525074   -0.19555      0.219085    -0.130603     0.00890955  -0.0808224     0.0870931    0.0150137   -0.154944    -0.100198  
  0.111442     -0.016848     0.0107113    0.0886082   -0.161155   -0.0214159   -0.000254999  -0.108537   -0.0440421    0.0137347    0.21351     -0.188344    -0.030987    -0.0656461   -0.0296072   -0.00973528  -0.00596119  -0.0534461    0.187079     0.0333231   -0.00861178  -0.0312753    -0.0711336   -0.100704    -0.0824603    0.0968656 
  0.113347      0.132672     0.0938329   -0.0456608   -0.0543353   0.00378419   0.0854847    -0.126719    0.0364134    0.320663     0.16624      0.0484009   -0.0425892   -0.124368    -0.086719     0.0672281    0.0863526    0.0121539    0.139653     0.117609     0.0282034   -0.110662      0.00771792  -0.141452    -0.0326144    0.0670289 
 -0.17179       0.0605571    0.00928818  -0.0703696   -0.010275    0.131618     0.0712183     0.201129   -0.164582     0.0163124    0.120499     0.129648    -0.0867001    0.228912    -0.0186351    0.138722     0.137288     0.0282034    0.0557945   -0.0331802   -0.0614736    0.0200047    -0.0689456    0.0897507   -0.15872      0.0627605 
  0.214347     -0.0960058   -0.0841614   -0.0520103    0.0576935  -0.0924874    0.0733044     0.0262537   0.126032     0.00857679   0.0976919    0.076599    -0.172147    -0.0345101    0.130875    -0.110962    -0.183715    -0.129985    -0.0449894   -0.0263528   -0.00805585  -0.0828619     0.0327329    0.0797452   -0.0450135    0.0223518 
  0.0766141    -0.0363188    0.202174     0.00192919   0.150716   -0.134657     0.0509044     0.103318   -0.112757     0.0525253   -0.0515453   -0.0749603    0.0149222    0.140127    -0.086065     0.0740247    0.175775    -0.113509     0.0709414    0.0842349   -0.0193117   -0.100232     -0.110467    -0.0641522    0.073238     0.0647187 
 -0.0107594     0.249324     0.101564     0.0702842   -0.152091    0.1601      -0.0374934     0.0486681   0.04436     -0.00193103   0.0678211   -0.106581     0.0371023   -0.15863     -0.113208    -0.0428336   -0.0237718   -0.0462639    0.225502     0.0264201    0.0833031    0.0563557    -0.0688511   -0.0950051   -0.0409107    0.23555   
  0.0943333     0.0590975   -0.0574417    0.068209     0.181176   -0.023507    -0.0950394     0.0347879  -0.056385     0.0112194   -0.0641811   -0.0509771   -0.0721324    0.107754     0.166878    -0.147308    -0.0425119   -0.0574693   -0.131048     0.0809513   -0.131203    -0.0309918    -0.128828    -0.0281356   -0.0239014    0.0468218 
 -0.106216     -0.0489905    0.010583    -0.0217201   -0.020013    0.0712084    0.0658632     0.016817    0.232604    -0.0748813    0.0616978   -0.0327807   -0.0935995   -0.00773612  -0.0470988    0.17523      0.157225     0.0594734   -0.0317302    0.155563    -0.0705335    0.0458663    -0.00654399   0.0456514    0.0337662   -0.102083  
 -0.0768149    -0.0171348    0.112353     0.1119      -0.0702302   0.0975404    0.0328934    -0.0689702   0.150377    -0.0590786   -0.0390685   -0.0439028    0.164766    -0.117812     0.00746746   0.0143239    0.00065569  -0.102112    -0.0181891    0.00703411   0.112542    -0.00236996    0.00602712  -0.00422596  -0.132561     0.0622036 
 -0.0341485    -0.019258     0.114395    -0.0350798    0.0806402  -0.038247    -0.128626     -0.0976699   0.199869    -0.127695     0.128997    -0.0321421   -0.126219     0.0367166    0.131833     0.0046058    0.117878    -0.0053      -0.07815      0.0584764   -0.0557157   -0.193297     -0.0569845    0.0353524   -0.0750556    0.1607    
  0.0996231    -0.0433508   -0.085904    -0.111618    -0.0478378  -0.0145749    0.186353      0.0170667  -0.0296986   -0.14145      0.0389887   -0.0682964   -0.0591818    0.00286066  -0.011336     0.0241355   -0.0628541   -0.273092    -0.0134482    0.0243172    0.0208777   -0.00625926   -0.117396     0.187466     0.0333491   -0.0807865 kind diag, method split
0: avll = -1.4195498711849786
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.419648
INFO: iteration 2, average log likelihood -1.419550
INFO: iteration 3, average log likelihood -1.419031
INFO: iteration 4, average log likelihood -1.413759
INFO: iteration 5, average log likelihood -1.399145
INFO: iteration 6, average log likelihood -1.392181
INFO: iteration 7, average log likelihood -1.390120
INFO: iteration 8, average log likelihood -1.388370
INFO: iteration 9, average log likelihood -1.387237
INFO: iteration 10, average log likelihood -1.386703
INFO: iteration 11, average log likelihood -1.386461
INFO: iteration 12, average log likelihood -1.386344
INFO: iteration 13, average log likelihood -1.386280
INFO: iteration 14, average log likelihood -1.386242
INFO: iteration 15, average log likelihood -1.386217
INFO: iteration 16, average log likelihood -1.386200
INFO: iteration 17, average log likelihood -1.386188
INFO: iteration 18, average log likelihood -1.386178
INFO: iteration 19, average log likelihood -1.386171
INFO: iteration 20, average log likelihood -1.386165
INFO: iteration 21, average log likelihood -1.386159
INFO: iteration 22, average log likelihood -1.386155
INFO: iteration 23, average log likelihood -1.386151
INFO: iteration 24, average log likelihood -1.386147
INFO: iteration 25, average log likelihood -1.386144
INFO: iteration 26, average log likelihood -1.386142
INFO: iteration 27, average log likelihood -1.386139
INFO: iteration 28, average log likelihood -1.386137
INFO: iteration 29, average log likelihood -1.386135
INFO: iteration 30, average log likelihood -1.386133
INFO: iteration 31, average log likelihood -1.386131
INFO: iteration 32, average log likelihood -1.386130
INFO: iteration 33, average log likelihood -1.386129
INFO: iteration 34, average log likelihood -1.386127
INFO: iteration 35, average log likelihood -1.386126
INFO: iteration 36, average log likelihood -1.386125
INFO: iteration 37, average log likelihood -1.386124
INFO: iteration 38, average log likelihood -1.386123
INFO: iteration 39, average log likelihood -1.386122
INFO: iteration 40, average log likelihood -1.386121
INFO: iteration 41, average log likelihood -1.386120
INFO: iteration 42, average log likelihood -1.386119
INFO: iteration 43, average log likelihood -1.386119
INFO: iteration 44, average log likelihood -1.386118
INFO: iteration 45, average log likelihood -1.386117
INFO: iteration 46, average log likelihood -1.386117
INFO: iteration 47, average log likelihood -1.386116
INFO: iteration 48, average log likelihood -1.386116
INFO: iteration 49, average log likelihood -1.386115
INFO: iteration 50, average log likelihood -1.386115
INFO: EM with 100000 data points 50 iterations avll -1.386115
952.4 data points per parameter
1: avll = [-1.41965,-1.41955,-1.41903,-1.41376,-1.39915,-1.39218,-1.39012,-1.38837,-1.38724,-1.3867,-1.38646,-1.38634,-1.38628,-1.38624,-1.38622,-1.3862,-1.38619,-1.38618,-1.38617,-1.38616,-1.38616,-1.38615,-1.38615,-1.38615,-1.38614,-1.38614,-1.38614,-1.38614,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38611]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.386265
INFO: iteration 2, average log likelihood -1.386142
INFO: iteration 3, average log likelihood -1.385849
INFO: iteration 4, average log likelihood -1.382455
INFO: iteration 5, average log likelihood -1.367530
INFO: iteration 6, average log likelihood -1.353891
INFO: iteration 7, average log likelihood -1.348465
INFO: iteration 8, average log likelihood -1.345268
INFO: iteration 9, average log likelihood -1.342879
INFO: iteration 10, average log likelihood -1.341136
INFO: iteration 11, average log likelihood -1.340069
INFO: iteration 12, average log likelihood -1.339473
INFO: iteration 13, average log likelihood -1.339120
INFO: iteration 14, average log likelihood -1.338887
INFO: iteration 15, average log likelihood -1.338714
INFO: iteration 16, average log likelihood -1.338575
INFO: iteration 17, average log likelihood -1.338452
INFO: iteration 18, average log likelihood -1.338337
INFO: iteration 19, average log likelihood -1.338230
INFO: iteration 20, average log likelihood -1.338132
INFO: iteration 21, average log likelihood -1.338045
INFO: iteration 22, average log likelihood -1.337967
INFO: iteration 23, average log likelihood -1.337895
INFO: iteration 24, average log likelihood -1.337827
INFO: iteration 25, average log likelihood -1.337763
INFO: iteration 26, average log likelihood -1.337699
INFO: iteration 27, average log likelihood -1.337631
INFO: iteration 28, average log likelihood -1.337544
INFO: iteration 29, average log likelihood -1.337426
INFO: iteration 30, average log likelihood -1.337290
INFO: iteration 31, average log likelihood -1.337173
INFO: iteration 32, average log likelihood -1.337085
INFO: iteration 33, average log likelihood -1.337021
INFO: iteration 34, average log likelihood -1.336977
INFO: iteration 35, average log likelihood -1.336948
INFO: iteration 36, average log likelihood -1.336927
INFO: iteration 37, average log likelihood -1.336912
INFO: iteration 38, average log likelihood -1.336901
INFO: iteration 39, average log likelihood -1.336893
INFO: iteration 40, average log likelihood -1.336885
INFO: iteration 41, average log likelihood -1.336879
INFO: iteration 42, average log likelihood -1.336874
INFO: iteration 43, average log likelihood -1.336868
INFO: iteration 44, average log likelihood -1.336863
INFO: iteration 45, average log likelihood -1.336858
INFO: iteration 46, average log likelihood -1.336853
INFO: iteration 47, average log likelihood -1.336847
INFO: iteration 48, average log likelihood -1.336841
INFO: iteration 49, average log likelihood -1.336834
INFO: iteration 50, average log likelihood -1.336826
INFO: EM with 100000 data points 50 iterations avll -1.336826
473.9 data points per parameter
2: avll = [-1.38626,-1.38614,-1.38585,-1.38246,-1.36753,-1.35389,-1.34846,-1.34527,-1.34288,-1.34114,-1.34007,-1.33947,-1.33912,-1.33889,-1.33871,-1.33857,-1.33845,-1.33834,-1.33823,-1.33813,-1.33805,-1.33797,-1.33789,-1.33783,-1.33776,-1.3377,-1.33763,-1.33754,-1.33743,-1.33729,-1.33717,-1.33708,-1.33702,-1.33698,-1.33695,-1.33693,-1.33691,-1.3369,-1.33689,-1.33689,-1.33688,-1.33687,-1.33687,-1.33686,-1.33686,-1.33685,-1.33685,-1.33684,-1.33683,-1.33683]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.337032
INFO: iteration 2, average log likelihood -1.336845
INFO: iteration 3, average log likelihood -1.336326
INFO: iteration 4, average log likelihood -1.331256
INFO: iteration 5, average log likelihood -1.313988
INFO: iteration 6, average log likelihood -1.297741
INFO: iteration 7, average log likelihood -1.290482
INFO: iteration 8, average log likelihood -1.286906
INFO: iteration 9, average log likelihood -1.283916
INFO: iteration 10, average log likelihood -1.280954
INFO: iteration 11, average log likelihood -1.279138
INFO: iteration 12, average log likelihood -1.278247
INFO: iteration 13, average log likelihood -1.277698
INFO: iteration 14, average log likelihood -1.277337
INFO: iteration 15, average log likelihood -1.277076
INFO: iteration 16, average log likelihood -1.276872
INFO: iteration 17, average log likelihood -1.276701
INFO: iteration 18, average log likelihood -1.276555
INFO: iteration 19, average log likelihood -1.276429
INFO: iteration 20, average log likelihood -1.276321
INFO: iteration 21, average log likelihood -1.276231
INFO: iteration 22, average log likelihood -1.276157
INFO: iteration 23, average log likelihood -1.276100
INFO: iteration 24, average log likelihood -1.276059
INFO: iteration 25, average log likelihood -1.276029
INFO: iteration 26, average log likelihood -1.276008
INFO: iteration 27, average log likelihood -1.275991
INFO: iteration 28, average log likelihood -1.275978
INFO: iteration 29, average log likelihood -1.275967
INFO: iteration 30, average log likelihood -1.275957
INFO: iteration 31, average log likelihood -1.275948
INFO: iteration 32, average log likelihood -1.275940
INFO: iteration 33, average log likelihood -1.275932
INFO: iteration 34, average log likelihood -1.275924
INFO: iteration 35, average log likelihood -1.275916
INFO: iteration 36, average log likelihood -1.275908
INFO: iteration 37, average log likelihood -1.275900
INFO: iteration 38, average log likelihood -1.275891
INFO: iteration 39, average log likelihood -1.275881
INFO: iteration 40, average log likelihood -1.275870
INFO: iteration 41, average log likelihood -1.275859
INFO: iteration 42, average log likelihood -1.275845
INFO: iteration 43, average log likelihood -1.275829
INFO: iteration 44, average log likelihood -1.275811
INFO: iteration 45, average log likelihood -1.275790
INFO: iteration 46, average log likelihood -1.275764
INFO: iteration 47, average log likelihood -1.275732
INFO: iteration 48, average log likelihood -1.275693
INFO: iteration 49, average log likelihood -1.275643
INFO: iteration 50, average log likelihood -1.275577
INFO: EM with 100000 data points 50 iterations avll -1.275577
236.4 data points per parameter
3: avll = [-1.33703,-1.33684,-1.33633,-1.33126,-1.31399,-1.29774,-1.29048,-1.28691,-1.28392,-1.28095,-1.27914,-1.27825,-1.2777,-1.27734,-1.27708,-1.27687,-1.2767,-1.27655,-1.27643,-1.27632,-1.27623,-1.27616,-1.2761,-1.27606,-1.27603,-1.27601,-1.27599,-1.27598,-1.27597,-1.27596,-1.27595,-1.27594,-1.27593,-1.27592,-1.27592,-1.27591,-1.2759,-1.27589,-1.27588,-1.27587,-1.27586,-1.27584,-1.27583,-1.27581,-1.27579,-1.27576,-1.27573,-1.27569,-1.27564,-1.27558]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.275762
INFO: iteration 2, average log likelihood -1.275302
INFO: iteration 3, average log likelihood -1.274040
INFO: iteration 4, average log likelihood -1.264649
INFO: iteration 5, average log likelihood -1.236717
INFO: iteration 6, average log likelihood -1.214039
INFO: iteration 7, average log likelihood -1.204287
INFO: iteration 8, average log likelihood -1.197325
INFO: iteration 9, average log likelihood -1.191416
WARNING: Variances had to be floored 1 12
INFO: iteration 10, average log likelihood -1.187271
INFO: iteration 11, average log likelihood -1.208184
INFO: iteration 12, average log likelihood -1.194744
INFO: iteration 13, average log likelihood -1.189574
INFO: iteration 14, average log likelihood -1.186248
WARNING: Variances had to be floored 16
INFO: iteration 15, average log likelihood -1.183324
WARNING: Variances had to be floored 12
INFO: iteration 16, average log likelihood -1.191023
INFO: iteration 17, average log likelihood -1.198014
INFO: iteration 18, average log likelihood -1.190700
INFO: iteration 19, average log likelihood -1.187490
INFO: iteration 20, average log likelihood -1.184982
WARNING: Variances had to be floored 12
INFO: iteration 21, average log likelihood -1.182974
INFO: iteration 22, average log likelihood -1.192583
INFO: iteration 23, average log likelihood -1.184854
INFO: iteration 24, average log likelihood -1.180644
INFO: iteration 25, average log likelihood -1.177513
WARNING: Variances had to be floored 12
INFO: iteration 26, average log likelihood -1.176252
INFO: iteration 27, average log likelihood -1.187004
INFO: iteration 28, average log likelihood -1.180381
INFO: iteration 29, average log likelihood -1.177523
INFO: iteration 30, average log likelihood -1.176038
WARNING: Variances had to be floored 12
INFO: iteration 31, average log likelihood -1.175704
INFO: iteration 32, average log likelihood -1.186735
INFO: iteration 33, average log likelihood -1.180163
INFO: iteration 34, average log likelihood -1.177346
INFO: iteration 35, average log likelihood -1.175848
WARNING: Variances had to be floored 12
INFO: iteration 36, average log likelihood -1.175469
INFO: iteration 37, average log likelihood -1.186473
INFO: iteration 38, average log likelihood -1.179845
INFO: iteration 39, average log likelihood -1.177046
INFO: iteration 40, average log likelihood -1.175593
WARNING: Variances had to be floored 12
INFO: iteration 41, average log likelihood -1.175268
INFO: iteration 42, average log likelihood -1.186323
INFO: iteration 43, average log likelihood -1.179726
INFO: iteration 44, average log likelihood -1.176976
INFO: iteration 45, average log likelihood -1.175557
WARNING: Variances had to be floored 12
INFO: iteration 46, average log likelihood -1.175250
INFO: iteration 47, average log likelihood -1.186313
INFO: iteration 48, average log likelihood -1.179718
INFO: iteration 49, average log likelihood -1.176973
INFO: iteration 50, average log likelihood -1.175556
INFO: EM with 100000 data points 50 iterations avll -1.175556
118.1 data points per parameter
4: avll = [-1.27576,-1.2753,-1.27404,-1.26465,-1.23672,-1.21404,-1.20429,-1.19732,-1.19142,-1.18727,-1.20818,-1.19474,-1.18957,-1.18625,-1.18332,-1.19102,-1.19801,-1.1907,-1.18749,-1.18498,-1.18297,-1.19258,-1.18485,-1.18064,-1.17751,-1.17625,-1.187,-1.18038,-1.17752,-1.17604,-1.1757,-1.18674,-1.18016,-1.17735,-1.17585,-1.17547,-1.18647,-1.17984,-1.17705,-1.17559,-1.17527,-1.18632,-1.17973,-1.17698,-1.17556,-1.17525,-1.18631,-1.17972,-1.17697,-1.17556]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 23 24
INFO: iteration 1, average log likelihood -1.175577
WARNING: Variances had to be floored 23 24
INFO: iteration 2, average log likelihood -1.175148
WARNING: Variances had to be floored 23 24
INFO: iteration 3, average log likelihood -1.172266
WARNING: Variances had to be floored 23 24 25
INFO: iteration 4, average log likelihood -1.139768
WARNING: Variances had to be floored 1 2 5 23 24 25 26 29
INFO: iteration 5, average log likelihood -1.078235
WARNING: Variances had to be floored 4 10 23 24 25
INFO: iteration 6, average log likelihood -1.080959
WARNING: Variances had to be floored 5 23 24 25 26 29
INFO: iteration 7, average log likelihood -1.071242
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 8, average log likelihood -1.061855
WARNING: Variances had to be floored 4 5 10 11 23 24 25 26 29 31
INFO: iteration 9, average log likelihood -1.048461
WARNING: Variances had to be floored 23 24 25
INFO: iteration 10, average log likelihood -1.093128
WARNING: Variances had to be floored 1 2 5 23 24 25 26 29
INFO: iteration 11, average log likelihood -1.049498
WARNING: Variances had to be floored 4 23 24 25
INFO: iteration 12, average log likelihood -1.068749
WARNING: Variances had to be floored 5 10 23 24 25 26 29 31
INFO: iteration 13, average log likelihood -1.050808
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 14, average log likelihood -1.069103
WARNING: Variances had to be floored 4 5 11 23 24 25 26 29
INFO: iteration 15, average log likelihood -1.048881
WARNING: Variances had to be floored 1 23 24 25 31
INFO: iteration 16, average log likelihood -1.072310
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29
INFO: iteration 17, average log likelihood -1.049034
WARNING: Variances had to be floored 10 23 24 25
INFO: iteration 18, average log likelihood -1.069343
WARNING: Variances had to be floored 1 4 5 23 24 25 26 29
INFO: iteration 19, average log likelihood -1.048663
WARNING: Variances had to be floored 1 2 11 23 24 25 31
INFO: iteration 20, average log likelihood -1.059597
WARNING: Variances had to be floored 4 5 23 24 25 26 29
INFO: iteration 21, average log likelihood -1.058721
WARNING: Variances had to be floored 1 10 23 24 25
INFO: iteration 22, average log likelihood -1.068792
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29
INFO: iteration 23, average log likelihood -1.047177
WARNING: Variances had to be floored 23 24 25
INFO: iteration 24, average log likelihood -1.069605
WARNING: Variances had to be floored 1 4 5 11 23 24 25 26 29 31
INFO: iteration 25, average log likelihood -1.039563
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 26, average log likelihood -1.074318
WARNING: Variances had to be floored 4 5 10 23 24 25 26 29
INFO: iteration 27, average log likelihood -1.046172
WARNING: Variances had to be floored 1 23 24 25
INFO: iteration 28, average log likelihood -1.074439
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29
INFO: iteration 29, average log likelihood -1.041938
WARNING: Variances had to be floored 23 24 25
INFO: iteration 30, average log likelihood -1.066995
WARNING: Variances had to be floored 1 4 5 10 11 23 24 25 26 29 32
INFO: iteration 31, average log likelihood -1.035232
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 32, average log likelihood -1.082335
WARNING: Variances had to be floored 4 5 23 24 25 26 29
INFO: iteration 33, average log likelihood -1.052968
WARNING: Variances had to be floored 1 23 24 25
INFO: iteration 34, average log likelihood -1.068202
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29
INFO: iteration 35, average log likelihood -1.037701
WARNING: Variances had to be floored 10 11 23 24 25 32
INFO: iteration 36, average log likelihood -1.059597
WARNING: Variances had to be floored 1 4 5 23 24 25 26 29
INFO: iteration 37, average log likelihood -1.063210
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 38, average log likelihood -1.067873
WARNING: Variances had to be floored 4 5 23 24 25 26 29 32
INFO: iteration 39, average log likelihood -1.044533
WARNING: Variances had to be floored 1 10 23 24 25 31
INFO: iteration 40, average log likelihood -1.073253
WARNING: Variances had to be floored 1 2 4 5 11 23 24 25 26 29
INFO: iteration 41, average log likelihood -1.052101
WARNING: Variances had to be floored 23 24 25 32
INFO: iteration 42, average log likelihood -1.072410
WARNING: Variances had to be floored 1 4 5 23 24 25 26 29 31
INFO: iteration 43, average log likelihood -1.053258
WARNING: Variances had to be floored 1 2 10 23 24 25
INFO: iteration 44, average log likelihood -1.067795
WARNING: Variances had to be floored 4 5 23 24 25 26 29 32
INFO: iteration 45, average log likelihood -1.048375
WARNING: Variances had to be floored 1 23 24 25 31
INFO: iteration 46, average log likelihood -1.075290
WARNING: Variances had to be floored 1 2 4 5 11 23 24 25 26 29
INFO: iteration 47, average log likelihood -1.044738
WARNING: Variances had to be floored 10 23 24 25 32
INFO: iteration 48, average log likelihood -1.069208
WARNING: Variances had to be floored 1 4 5 23 24 25 26 29 31
INFO: iteration 49, average log likelihood -1.059036
WARNING: Variances had to be floored 1 2 23 24 25
INFO: iteration 50, average log likelihood -1.070273
INFO: EM with 100000 data points 50 iterations avll -1.070273
59.0 data points per parameter
5: avll = [-1.17558,-1.17515,-1.17227,-1.13977,-1.07823,-1.08096,-1.07124,-1.06186,-1.04846,-1.09313,-1.0495,-1.06875,-1.05081,-1.0691,-1.04888,-1.07231,-1.04903,-1.06934,-1.04866,-1.0596,-1.05872,-1.06879,-1.04718,-1.0696,-1.03956,-1.07432,-1.04617,-1.07444,-1.04194,-1.067,-1.03523,-1.08233,-1.05297,-1.0682,-1.0377,-1.0596,-1.06321,-1.06787,-1.04453,-1.07325,-1.0521,-1.07241,-1.05326,-1.06779,-1.04837,-1.07529,-1.04474,-1.06921,-1.05904,-1.07027]
[-1.41955,-1.41965,-1.41955,-1.41903,-1.41376,-1.39915,-1.39218,-1.39012,-1.38837,-1.38724,-1.3867,-1.38646,-1.38634,-1.38628,-1.38624,-1.38622,-1.3862,-1.38619,-1.38618,-1.38617,-1.38616,-1.38616,-1.38615,-1.38615,-1.38615,-1.38614,-1.38614,-1.38614,-1.38614,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38613,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38612,-1.38611,-1.38626,-1.38614,-1.38585,-1.38246,-1.36753,-1.35389,-1.34846,-1.34527,-1.34288,-1.34114,-1.34007,-1.33947,-1.33912,-1.33889,-1.33871,-1.33857,-1.33845,-1.33834,-1.33823,-1.33813,-1.33805,-1.33797,-1.33789,-1.33783,-1.33776,-1.3377,-1.33763,-1.33754,-1.33743,-1.33729,-1.33717,-1.33708,-1.33702,-1.33698,-1.33695,-1.33693,-1.33691,-1.3369,-1.33689,-1.33689,-1.33688,-1.33687,-1.33687,-1.33686,-1.33686,-1.33685,-1.33685,-1.33684,-1.33683,-1.33683,-1.33703,-1.33684,-1.33633,-1.33126,-1.31399,-1.29774,-1.29048,-1.28691,-1.28392,-1.28095,-1.27914,-1.27825,-1.2777,-1.27734,-1.27708,-1.27687,-1.2767,-1.27655,-1.27643,-1.27632,-1.27623,-1.27616,-1.2761,-1.27606,-1.27603,-1.27601,-1.27599,-1.27598,-1.27597,-1.27596,-1.27595,-1.27594,-1.27593,-1.27592,-1.27592,-1.27591,-1.2759,-1.27589,-1.27588,-1.27587,-1.27586,-1.27584,-1.27583,-1.27581,-1.27579,-1.27576,-1.27573,-1.27569,-1.27564,-1.27558,-1.27576,-1.2753,-1.27404,-1.26465,-1.23672,-1.21404,-1.20429,-1.19732,-1.19142,-1.18727,-1.20818,-1.19474,-1.18957,-1.18625,-1.18332,-1.19102,-1.19801,-1.1907,-1.18749,-1.18498,-1.18297,-1.19258,-1.18485,-1.18064,-1.17751,-1.17625,-1.187,-1.18038,-1.17752,-1.17604,-1.1757,-1.18674,-1.18016,-1.17735,-1.17585,-1.17547,-1.18647,-1.17984,-1.17705,-1.17559,-1.17527,-1.18632,-1.17973,-1.17698,-1.17556,-1.17525,-1.18631,-1.17972,-1.17697,-1.17556,-1.17558,-1.17515,-1.17227,-1.13977,-1.07823,-1.08096,-1.07124,-1.06186,-1.04846,-1.09313,-1.0495,-1.06875,-1.05081,-1.0691,-1.04888,-1.07231,-1.04903,-1.06934,-1.04866,-1.0596,-1.05872,-1.06879,-1.04718,-1.0696,-1.03956,-1.07432,-1.04617,-1.07444,-1.04194,-1.067,-1.03523,-1.08233,-1.05297,-1.0682,-1.0377,-1.0596,-1.06321,-1.06787,-1.04453,-1.07325,-1.0521,-1.07241,-1.05326,-1.06779,-1.04837,-1.07529,-1.04474,-1.06921,-1.05904,-1.07027]
32Ã—26 Array{Float64,2}:
  0.0400126   0.00954938  -0.0492799    -0.0217332    0.107684     -0.106474    0.0580845    0.0952147   -0.113605   -0.0582025     0.229455     0.112975    -0.0986431     0.0228913    0.0703842    0.0964374    0.0738633    0.0891267   -0.0307247    0.120187     0.0257767    0.0765471   -0.150592      0.162064   -0.13339      -0.05527  
  0.0757697  -0.0328658    0.209754      0.0141201    0.148924     -0.0906424   0.050984     0.110527    -0.132187    0.0567346    -0.0686987   -0.080573     0.0189911     0.151345    -0.0842303    0.0734678    0.187417    -0.126862     0.0689309    0.0771403    0.011571    -0.103906    -0.113395     -0.0565266   0.0959118     0.057206 
 -0.148763    0.0342497   -0.0197527    -0.0526507   -0.0280317     0.06839    -0.00812894   0.0384677   -0.014528    0.0535334    -0.045507     0.0413843    0.00643968   -0.00951949   0.0635873   -0.102905    -0.0861755   -0.110526    -0.05435      0.130794     0.00227889  -0.0122564    0.110274     -0.125606    0.000516789   0.160344 
  0.252556   -0.0941945   -0.0831923    -0.0305332    0.0868299    -0.110724    0.102744     0.0302967    0.118083    0.000891817   0.121518     0.066363    -0.178155     -0.0391386    0.12461     -0.109472    -0.173369    -0.115       -0.0392493   -0.0275198   -0.00442318  -0.0869353    0.0175039     0.0766368  -0.0491395     0.0281066
  0.119401   -0.0795133   -0.196053      0.0511435    0.108272     -0.0549638  -0.059356     0.11633      0.162415    0.195175     -0.0311024   -0.115408    -0.0197249    -0.112605    -0.0275698    0.161869    -0.0724642   -0.0556973   -0.0332185    0.109958     0.0273963   -0.139756     0.022639      0.150076    0.0375405     0.0519819
 -0.0603334  -0.101633     0.0536508    -0.0831844   -0.215775      0.0842267  -0.183377     0.110979    -0.0789887  -0.0112407    -0.0254039    0.170479    -0.0411792     0.0204173    0.0466902   -0.0237614    0.0758085    0.0773853   -0.105647     0.123183    -0.109539     0.0374487   -0.0434377     0.0357346   0.204587     -0.0828803
 -0.0893697   0.123122     0.101684      0.138654     0.063006     -0.0691975  -0.0516518    0.0663696    0.0965712   0.137852     -0.0853896    0.0065817   -0.0636533    -0.0668632    0.0671494   -0.0469177    0.110277    -0.148644    -0.0867983    0.14552     -0.0437735   -0.203602    -0.000939851  -0.204801    0.0314478    -0.127552 
 -0.0224295  -0.0377325    0.0950881    -0.0411809    0.0965369    -0.040436   -0.11772     -0.0940912    0.197752   -0.165012      0.150303    -0.0266023   -0.118452      0.04124      0.129909    -0.0049567    0.119424     0.0121169   -0.0776746    0.0603154   -0.0953266   -0.197295    -0.0608545     0.0395408  -0.0701781     0.172046 
 -0.0149624   0.119504    -0.0324255    -0.0261496   -0.0940545    -0.191813    0.0173615    0.114531     0.0947084  -0.147482     -0.0228672   -0.00705184   0.153234     -0.0169905   -0.0292561   -0.0687103    0.0257524   -0.104959    -0.00151294   0.181349     0.0430848   -0.0660821    0.143343     -0.115748    0.0768774     0.0406686
 -0.0552872  -0.00156683   0.000943493  -0.00186204   0.0984505     0.0445817   0.1219       0.134836    -0.0148508   0.0928789    -0.0269763    0.0103436   -0.00254796   -0.0202003   -0.00727483   0.118032    -0.0223636   -0.0303715   -0.0422422    0.109189    -0.128526    -0.00326476   0.0257103    -0.0230208  -0.0774001    -0.0894351
 -0.093383    0.133808     0.095544      0.0503192    0.034632      0.0775807  -0.224277    -0.00743625  -0.0613328  -0.108285      0.0742188    0.103049     0.0608095    -0.116751     0.106356     0.169074     0.101659     0.00379376   0.00700808  -0.0207746   -0.0231817   -0.10164     -0.0587627     0.0922211   0.0119477     0.0397113
  0.0895583   0.0330226   -0.0370816    -0.0098212    0.107564      0.0716709  -0.0994227    0.0156592   -0.0313119   0.0438987    -0.0178928   -0.0551716   -0.073698      0.103864     0.0574433   -0.0417033    0.00056663  -0.0383224   -0.14134     -0.0110063   -0.107404    -0.113721    -0.156074      0.0156511   0.0477635     0.0373443
  0.112937    0.0232667    0.0097539     0.100788    -0.194062      0.212931    0.164564    -0.301187     0.237658    0.0629922     0.0242707   -0.176364    -0.0966067    -0.292498    -0.117032    -0.141103    -0.0101938    0.0871431    0.137395    -2.12226     -0.124434    -0.0340228   -0.0612678    -0.315817   -0.108234      0.100798 
  0.101389   -0.0278345   -0.0238656     0.082457    -0.185259      0.0299831  -0.207321    -0.0362322    0.0584197  -0.0272174     0.00171486  -0.203675    -0.00350901   -0.0929924    0.328387    -0.0749816   -0.0365238    0.0874301    0.195789     1.20026      0.0593766   -0.0416212   -0.326658      0.0444491  -0.0808868     0.0835699
  0.112849   -0.0151337    0.0199506     0.0681506   -0.182332     -0.2157     -0.0323301    0.114099    -0.138235    0.0518587     0.432952    -0.194297    -0.000890614   0.0396596   -0.0152791    0.120459     0.0148298   -0.211759     0.286243    -1.76546      0.0644628   -0.0278723    0.246417      0.0679293  -0.0728309     0.0909409
  0.118614   -0.042656     0.030126      0.0712759   -0.100996      0.113407    0.0772066   -0.151036    -0.188569    0.0310462     0.320496    -0.171378    -0.043174      0.00959412  -0.427144     0.0707392    0.0508363   -0.141478     0.165817     2.9937      -0.101325    -0.0280582   -0.0169038    -0.230363   -0.0721405     0.11023  
  0.0690955  -0.0752809    0.0600634    -0.170621     0.0628286     0.0968463   0.0351488    0.0959993   -0.0021412   0.0441939    -0.0503904   -0.00135115   0.0959358    -0.0102916   -0.0814111    0.0448967   -0.0573158   -0.193145     0.231274    -0.137696     0.00651945  -0.0820002    0.100715      0.01869    -0.1586       -0.0504885
  0.114822   -0.0920318   -0.0914187    -0.129007    -0.000456266  -0.0258729   0.186182     0.0286697   -0.0294892  -0.136755      0.0384121   -0.00780955  -0.0429593     0.00739534  -0.0130632    0.0531591   -0.0703829   -0.270645    -0.0376047    0.00376629   0.0189612   -0.0100072   -0.107466      0.191837    0.0274931    -0.0764982
  0.016166    0.0607574   -0.0352759    -0.0300116   -0.0138039     0.147081   -0.0112261   -0.121149     0.0202899  -0.0458612     0.0182961   -0.085687    -3.98912e-5    0.0130193    0.0163181   -0.0372832   -0.0860088    0.0321605   -0.0339024   -0.0726811   -0.0061654   -0.0472836   -0.0547384     0.0871423   0.0522561    -0.111452 
 -0.204919   -0.0558408   -0.0697964    -0.101121    -0.0973321     0.179766    0.00541072   0.0114709   -0.121662    0.0148963    -0.0394645    0.0445584   -0.0357002     0.0930872   -0.00478076   0.0691112    0.141972     0.0192848    0.0390052   -0.0829992   -0.116946     0.14288     -0.0291312    -0.0227016  -0.0296633     0.0293544
 -0.139738   -0.145426    -0.0531396    -0.0230525   -0.186345      0.139425    0.247983     0.0140598    0.195909    0.038788      0.118456     0.175812     0.01739      -0.18486     -0.205195    -0.076554     0.0702266   -0.0679539    0.0453159    0.0725821   -0.663469     0.00215213  -0.054861      0.207998   -0.109624     -0.0939769
 -0.114451   -0.147786    -0.250544      0.112259    -0.196606      0.0621275   0.185058    -0.0269704    0.0633528   0.149742      0.11798      0.103439     0.0279473    -0.143143    -0.169143    -0.273982     0.118273    -0.0599586    0.269967     0.0990519    0.718733     0.00522236  -0.00357692    0.0234638  -0.107185     -0.0185831
 -0.150918   -0.0450791    0.0137299    -0.0344045   -0.0320757     0.0562587   0.0451751   -0.0609138    0.326235   -0.0498374     0.0964415   -0.0328082   -0.042605     -0.152053    -0.0475608    0.172794    -0.230929     0.0655281    0.059622     0.199524    -0.218486     0.137763    -0.024368      0.0307575   0.201084     -0.198036 
 -0.025505   -0.0446663    0.00907899   -0.00746765   0.0382783     0.0821158   0.0824365    0.0811273    0.130927   -0.110858      0.0308563   -0.0316908   -0.171313      0.11787     -0.0611271    0.167183     0.505543     0.053561    -0.0765489    0.122171     0.0457759   -0.0549033    0.0138473     0.129637   -0.214182     -0.0715792
 -0.0573452  -0.0931938   -0.0926206     0.0252607   -0.0593134     0.0339121  -0.0501721    0.0478103    0.0313144   0.112594     -0.0255205   -0.195676    -0.107541     -0.135804     0.010767     0.0348951    0.138598     0.143813     0.128816    -0.0199803   -0.249072    -0.0494912    0.110548     -0.0247582  -0.0493219     0.0123867
  0.272618    0.0753961   -0.0678252    -0.0246786    0.00799941    0.144047   -0.18566      0.248924     0.143547    0.15232       0.0302197   -0.0952088    0.1369        0.0209307   -0.106243     0.103524     0.00434737  -0.0326878   -0.0320638    0.0115484    0.0442347    0.048629    -0.0401808    -0.132128    0.187233     -0.0486589
 -0.0755385  -0.0509494    0.0024671    -0.0195455   -0.0196155     0.0426041   0.011397    -0.0799692    0.0599199  -0.0177162    -0.0572912    0.0143838    0.0558816    -0.142389    -0.00485272  -0.0129154    0.0255742   -0.0698878    8.77201e-5   0.0615219    0.0286341   -0.00590275   0.0340603    -0.0351153  -0.00934192    0.0612935
  0.105267    0.135487     0.0607402    -0.0503675   -0.056257     -0.0511859   0.0856333   -0.113144     0.0404739   0.326333      0.166712     0.0536443   -0.0424119    -0.12527     -0.0960029    0.0638321    0.0851025    0.0604573    0.125847     0.104645     0.0300172   -0.103211     0.0248922    -0.139532   -0.0378546     0.0635605
 -0.0481855  -0.00124615   0.0434207    -0.0281743    0.0574228     0.0343222   0.112708    -0.126301     0.125018   -0.0703195     0.0324624   -0.0397589    0.117039      0.0318482    0.0722488    0.00702924  -0.133363     0.0529036   -0.236945    -0.0377292    0.0177868    0.0995012   -0.134437      0.0386161  -0.0785603     0.127591 
  0.199504    0.10208      0.0243554     0.150606     0.0767769     0.0123677  -0.0706442   -0.0358012   -0.0536016  -0.00936383   -0.0158564    0.111418     0.0846769    -0.0542367   -0.21046      0.0668524    0.103445     0.114545    -0.0219478    0.163464    -0.00934317  -0.181528    -0.159461      0.130385    0.11623       0.0295789
 -0.0287189   0.0298464    0.00018457   -0.112924     0.129291      0.0226052   0.0302739    0.025923     0.0342219   0.162851     -0.0599974   -0.0225097    0.0138448     0.151923     0.0659034    0.00119953  -0.11082     -0.175298    -0.0350651   -0.188617    -0.0659749   -0.00667218   0.0237137    -0.234416    0.038173      0.0645075
 -0.0175726   0.21811      0.0845635     0.0377595   -0.146167      0.158768   -0.0553055    0.0566173   -0.0241834  -0.0346244     0.0763086   -0.103008     0.0180228    -0.173837    -0.110299    -0.043892    -0.0127724   -0.0365926    0.23465      0.0220798    0.0823349    0.0932559   -0.0669829    -0.099219   -0.0542382     0.228435 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 4 5 23 24 25 26 29 32
INFO: iteration 1, average log likelihood -1.041937
WARNING: Variances had to be floored 1 4 5 10 11 23 24 25 26 29 32
INFO: iteration 2, average log likelihood -1.035550
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29 32
INFO: iteration 3, average log likelihood -1.034946
WARNING: Variances had to be floored 4 5 10 11 23 24 25 26 29 32
INFO: iteration 4, average log likelihood -1.036809
WARNING: Variances had to be floored 1 4 5 23 24 25 26 29 32
INFO: iteration 5, average log likelihood -1.038494
WARNING: Variances had to be floored 1 2 4 5 10 11 23 24 25 26 29 32
INFO: iteration 6, average log likelihood -1.030506
WARNING: Variances had to be floored 4 5 23 24 25 26 29 32
INFO: iteration 7, average log likelihood -1.041095
WARNING: Variances had to be floored 1 4 5 10 11 23 24 25 26 29 32
INFO: iteration 8, average log likelihood -1.034023
WARNING: Variances had to be floored 1 2 4 5 23 24 25 26 29 32
INFO: iteration 9, average log likelihood -1.034967
WARNING: Variances had to be floored 4 5 10 11 23 24 25 26 29 32
INFO: iteration 10, average log likelihood -1.036592
INFO: EM with 100000 data points 10 iterations avll -1.036592
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.276457e+05
      1       6.871202e+05      -1.405254e+05 |       32
      2       6.529922e+05      -3.412810e+04 |       32
      3       6.381802e+05      -1.481196e+04 |       32
      4       6.292415e+05      -8.938700e+03 |       32
      5       6.238816e+05      -5.359850e+03 |       32
      6       6.203923e+05      -3.489371e+03 |       32
      7       6.188091e+05      -1.583217e+03 |       32
      8       6.178998e+05      -9.092303e+02 |       32
      9       6.166993e+05      -1.200557e+03 |       32
     10       6.144372e+05      -2.262037e+03 |       32
     11       6.123002e+05      -2.137013e+03 |       32
     12       6.111913e+05      -1.108921e+03 |       32
     13       6.102560e+05      -9.352755e+02 |       32
     14       6.095093e+05      -7.466836e+02 |       32
     15       6.090832e+05      -4.261232e+02 |       32
     16       6.088888e+05      -1.944270e+02 |       32
     17       6.087917e+05      -9.704215e+01 |       32
     18       6.087359e+05      -5.586767e+01 |       31
     19       6.087064e+05      -2.949486e+01 |       30
     20       6.086911e+05      -1.525469e+01 |       29
     21       6.086806e+05      -1.048294e+01 |       27
     22       6.086716e+05      -8.996808e+00 |       27
     23       6.086653e+05      -6.387219e+00 |       28
     24       6.086607e+05      -4.568680e+00 |       25
     25       6.086577e+05      -2.972919e+00 |       20
     26       6.086548e+05      -2.877889e+00 |       24
     27       6.086518e+05      -2.997876e+00 |       18
     28       6.086503e+05      -1.573648e+00 |       16
     29       6.086493e+05      -9.365340e-01 |       14
     30       6.086486e+05      -7.256846e-01 |       18
     31       6.086479e+05      -7.150538e-01 |       12
     32       6.086472e+05      -6.427741e-01 |       11
     33       6.086468e+05      -4.909206e-01 |       13
     34       6.086464e+05      -3.092675e-01 |        5
     35       6.086463e+05      -1.484303e-01 |        7
     36       6.086460e+05      -2.633923e-01 |        9
     37       6.086456e+05      -4.145574e-01 |       13
     38       6.086452e+05      -4.378548e-01 |        8
     39       6.086450e+05      -1.904491e-01 |        8
     40       6.086448e+05      -1.547744e-01 |        5
     41       6.086448e+05      -7.640523e-02 |        4
     42       6.086447e+05      -6.221129e-02 |        3
     43       6.086446e+05      -6.184920e-02 |        2
     44       6.086446e+05      -1.383528e-02 |        2
     45       6.086446e+05      -1.384821e-02 |        0
     46       6.086446e+05       0.000000e+00 |        0
K-means converged with 46 iterations (objv = 608644.6111092565)
INFO: K-means with 32000 data points using 46 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.325328
INFO: iteration 2, average log likelihood -1.295776
INFO: iteration 3, average log likelihood -1.262881
INFO: iteration 4, average log likelihood -1.224446
INFO: iteration 5, average log likelihood -1.180629
WARNING: Variances had to be floored 12
INFO: iteration 6, average log likelihood -1.124726
WARNING: Variances had to be floored 2 6 11 26 30
INFO: iteration 7, average log likelihood -1.073823
WARNING: Variances had to be floored 19 28 32
INFO: iteration 8, average log likelihood -1.103314
WARNING: Variances had to be floored 18 21
INFO: iteration 9, average log likelihood -1.093073
WARNING: Variances had to be floored 12 30
INFO: iteration 10, average log likelihood -1.066135
WARNING: Variances had to be floored 2 6 11
INFO: iteration 11, average log likelihood -1.056622
WARNING: Variances had to be floored 4 7 19 26 32
INFO: iteration 12, average log likelihood -1.064037
WARNING: Variances had to be floored 3 15 18 30
INFO: iteration 13, average log likelihood -1.057666
WARNING: Variances had to be floored 12 26 28
INFO: iteration 14, average log likelihood -1.076594
WARNING: Variances had to be floored 2 6 11 32
INFO: iteration 15, average log likelihood -1.069679
WARNING: Variances had to be floored 19
INFO: iteration 16, average log likelihood -1.082576
WARNING: Variances had to be floored 7 15 18 26 30
INFO: iteration 17, average log likelihood -1.038867
WARNING: Variances had to be floored 4 11 12 32
INFO: iteration 18, average log likelihood -1.060743
WARNING: Variances had to be floored 2 6 28
INFO: iteration 19, average log likelihood -1.085192
WARNING: Variances had to be floored 19
INFO: iteration 20, average log likelihood -1.087671
WARNING: Variances had to be floored 18 30
INFO: iteration 21, average log likelihood -1.045851
WARNING: Variances had to be floored 6 7 11 12 15 26 32
INFO: iteration 22, average log likelihood -1.041657
WARNING: Variances had to be floored 2 4
INFO: iteration 23, average log likelihood -1.092766
WARNING: Variances had to be floored 19 26 28
INFO: iteration 24, average log likelihood -1.070375
WARNING: Variances had to be floored 3 12 18 21 30
INFO: iteration 25, average log likelihood -1.045919
WARNING: Variances had to be floored 6 11 32
INFO: iteration 26, average log likelihood -1.075721
INFO: iteration 27, average log likelihood -1.084409
WARNING: Variances had to be floored 2 4 7 19
INFO: iteration 28, average log likelihood -1.030353
WARNING: Variances had to be floored 3 6 12 18 26 28 30
INFO: iteration 29, average log likelihood -1.042428
WARNING: Variances had to be floored 11 32
INFO: iteration 30, average log likelihood -1.097591
WARNING: Variances had to be floored 15
INFO: iteration 31, average log likelihood -1.080342
WARNING: Variances had to be floored 19
INFO: iteration 32, average log likelihood -1.035822
WARNING: Variances had to be floored 2 4 6 7 12 18 21 30
INFO: iteration 33, average log likelihood -1.003210
WARNING: Variances had to be floored 3 11
INFO: iteration 34, average log likelihood -1.104194
WARNING: Variances had to be floored 28 32
INFO: iteration 35, average log likelihood -1.089757
WARNING: Variances had to be floored 19
INFO: iteration 36, average log likelihood -1.073492
WARNING: Variances had to be floored 2 3 6 7 12 15 18 30
INFO: iteration 37, average log likelihood -1.017372
WARNING: Variances had to be floored 4 11 32
INFO: iteration 38, average log likelihood -1.098724
WARNING: Variances had to be floored 28
INFO: iteration 39, average log likelihood -1.099025
WARNING: Variances had to be floored 19 21
INFO: iteration 40, average log likelihood -1.052447
WARNING: Variances had to be floored 2 3 6 11 12 15 18 30 32
INFO: iteration 41, average log likelihood -1.010147
WARNING: Variances had to be floored 7
INFO: iteration 42, average log likelihood -1.111841
WARNING: Variances had to be floored 4 28
INFO: iteration 43, average log likelihood -1.070981
WARNING: Variances had to be floored 19 21 32
INFO: iteration 44, average log likelihood -1.044455
WARNING: Variances had to be floored 2 3 6 11 12 15 18 30
INFO: iteration 45, average log likelihood -1.021445
INFO: iteration 46, average log likelihood -1.105896
WARNING: Variances had to be floored 7 28 32
INFO: iteration 47, average log likelihood -1.058417
WARNING: Variances had to be floored 4 19 21
INFO: iteration 48, average log likelihood -1.042776
WARNING: Variances had to be floored 2 3 6 11 12 15 18 30
INFO: iteration 49, average log likelihood -1.023819
WARNING: Variances had to be floored 32
INFO: iteration 50, average log likelihood -1.108372
INFO: EM with 100000 data points 50 iterations avll -1.108372
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0315139    0.0503466   -0.0072151   -0.134255     0.0223205    0.209435    -0.089603    -0.0102615   -0.000265887   0.0253008    0.0722528  -0.0566899    -0.0592485     0.0925856   -0.0696555     0.0883198    0.070936    -0.000940629  -0.150705    -0.142715    -0.0507708   -0.195118    -0.180299     0.0554857   0.108413      0.0613794  
  0.0850189   -0.0211409    0.178121     0.00962854   0.100897    -0.130511     0.0252907    0.128619    -0.165917      0.0518656   -0.177124   -0.0788094    -0.000130745   0.202349    -0.0869621     0.0700916    0.190235    -0.130268      0.0454518    0.0829664    0.00868088  -0.156424    -0.106701    -0.0406847   0.214059      0.0281974  
  0.404326     0.0835611   -0.0857643   -0.04999      0.00735289   0.178344    -0.143719     0.268395     0.127625      0.180065     0.0290339  -0.118191      0.17933       0.0250906   -0.117668      0.0868377   -0.0100649   -0.014713     -0.0617783    0.00789292   0.0183486    0.0521786   -0.0567273   -0.0979267   0.181055     -0.0625349  
  0.301576    -0.076767    -0.0928289   -0.0258077    0.0887861   -0.128072     0.0923216    0.0331033    0.115614      0.0244408    0.139726    0.0501023    -0.133654     -0.0351445    0.0942538    -0.0722715   -0.139135    -0.116171     -0.0429357    0.00579633  -0.026473    -0.0860828    0.0126155    0.0434387  -0.0453585     0.000589743
 -0.0199044   -0.0343168    0.102446    -0.043918     0.0934408   -0.0440945   -0.106901    -0.0910051    0.195036     -0.157372     0.145142   -0.0318328    -0.108742      0.0341313    0.121311      0.00285762   0.112216     0.0111541    -0.0778267    0.0611092   -0.0971521   -0.198673    -0.0586699    0.0366789  -0.0711701     0.153399   
  0.00137336   0.247972     0.074524     0.0628234   -0.0984496    0.189032    -0.0616076    0.0721254   -0.0478204    -0.0172598    0.106173   -0.130882      0.0119277    -0.216979    -0.0928276    -0.0138392   -0.00120921  -0.0344888     0.365537     0.0427675    0.0709393    0.111495    -0.0769777   -0.0957165  -0.0606929     0.199734   
 -0.165065     0.054272     0.117914    -0.0877871    0.0999158    0.181068     0.0270476   -0.0341133    0.0670277     0.214641    -0.0580821   0.0189503    -0.0203973     0.124457     0.116205     -0.0139737   -0.0986189   -0.167689     -0.00754551  -0.140443    -0.0433274   -0.0493696   -0.0106912   -0.201644    0.14921       0.109644   
 -0.0539425   -0.0145221   -0.0802556   -0.135675     0.0113771    0.00117404   3.5921e-5   -0.0772795   -0.0324191     0.0154293   -0.0682443   0.0175507    -0.0210073    -0.163339    -0.00559483   -0.0522784    0.0312251   -0.0570388     0.0230219    0.132012    -0.034377    -0.00654501   0.0644412   -0.0637089   0.0652011     0.0596063  
  0.115311     0.0576779   -0.076661     0.0725844    0.151956    -0.0603511   -0.109839     0.0308587   -0.0672802     0.0265912   -0.0746474  -0.0508947    -0.0530568     0.112741     0.167236     -0.131571    -0.0431363   -0.0570262    -0.140477     0.0818545   -0.129724    -0.0263912   -0.127708    -0.0199602  -0.00288207    0.0184831  
  0.105797     0.135236     0.0609427   -0.0508197   -0.0560119   -0.0501294    0.0857232   -0.111891     0.0412865     0.327199     0.16676     0.0546169    -0.0428108    -0.124798    -0.096189      0.0642238    0.0849785    0.0621806     0.126123     0.103881     0.0304459   -0.103022     0.0251432   -0.139159   -0.0371775     0.0628522  
 -0.0401896   -0.0597641    0.0781988    0.096254    -0.0490321    0.111303    -0.00722311  -0.047131     0.275219     -0.0227111   -0.0419389   0.129629      0.215614     -0.0822124   -0.0153241     0.0387022   -0.0165469   -0.137208     -0.0333196   -0.0315862    0.0541133    0.00169007  -0.0124842   -0.0554297  -0.104011      0.0414764  
 -0.024742    -0.0786541   -0.0978445    0.00727942  -0.0496561    0.0684271   -0.0752745    0.0913429    0.0438963     0.113038    -0.0329207  -0.416748     -0.122014     -0.112577    -0.0124765     0.0506401    0.132197     0.13177       0.104395    -0.0756771   -0.144127    -0.027283     0.08679     -0.0656539  -0.00615436    0.0140941  
 -0.146797     0.0301783   -0.0238116   -0.0480346   -0.0278828    0.0661631   -0.0083428    0.0388384   -0.0122197     0.0524412   -0.0429811   0.0419117     0.000333288  -0.0114952    0.0632223    -0.102604    -0.0896956   -0.112387     -0.0538377    0.127791     0.0023063   -0.01308      0.109562    -0.119804    0.000953666   0.157904   
  0.111166     0.00575491  -0.0528978    0.0956867   -0.120539    -0.0527787   -0.111325     0.279747     0.242404      0.214466     0.0917813  -0.248215      0.131713     -0.169818    -0.520545      0.25247     -0.0483758   -0.0296361     0.146174    -0.414118    -0.217821     0.0219268    0.52387      0.181489   -0.0678683     0.048786   
 -0.0249034    0.129497    -0.101947    -0.0552271   -0.0353155    0.110613    -0.0455926   -0.0452358   -0.0187232     0.0360237    0.248262   -0.208139     -0.143792      0.107338    -0.000778473   0.035909    -0.0248899    0.0596793    -0.00884208   0.0656206   -0.0410545   -0.0180926   -0.112332     0.166538   -0.0383424    -0.236618   
  0.200063     0.10276      0.0249389    0.150603     0.0764553    0.0138967   -0.069435    -0.0369647   -0.0534176    -0.00945912  -0.0156792   0.110419      0.0866166    -0.0543816   -0.21033       0.0684354    0.103702     0.115161     -0.0203541    0.163155    -0.00952627  -0.18114     -0.1591       0.130228    0.116209      0.0292675  
  0.116631    -0.0941262   -0.0915821   -0.128674    -0.0030683   -0.027881     0.186033     0.0284272   -0.0282778    -0.137428     0.0385825  -0.00224377   -0.0408532     0.00655195  -0.0129437     0.0551437   -0.0688717   -0.269686     -0.0370213    0.00356691   0.019072    -0.0096979   -0.10705      0.190921    0.02972      -0.0772346  
  0.0841701    0.0296843   -0.071701    -0.140234     0.100802    -0.147354     0.0358102    0.116113    -0.129676      0.102594    -0.0850571  -0.0717919     0.0344702     0.194941    -0.039909      0.0172113   -0.0931298   -0.199398     -0.1293      -0.150905    -0.0600823    0.0712154   -0.00786946  -0.172558   -0.0959339     0.0360865  
 -0.035351    -0.00637173   0.0287782   -0.0322246    0.0465146    0.0340706    0.084125    -0.11137      0.122164     -0.0544824    0.0345434  -0.0547419     0.122527      0.0226643    0.0563845     0.0113485   -0.127368     0.0565693    -0.181195    -0.0362724    0.00125171   0.0886226   -0.12003      0.0201065  -0.0764948     0.112145   
 -0.0880438    0.122678     0.102823     0.133734     0.0630788   -0.0714241   -0.0514137    0.0650003    0.0998703     0.138094    -0.0848703   0.00758662   -0.0635441    -0.064684     0.0664755    -0.0460507    0.108843    -0.152115     -0.0865882    0.146793    -0.0436876   -0.205281    -0.00242743  -0.203234    0.0344289    -0.129994   
 -0.116756    -0.0273154    0.00650798   0.0359531    0.135726     0.049496     0.11209      0.165157     0.0160396     0.0953264   -0.185745   -0.0246955    -0.00579897   -0.0626482    0.00910309    0.088637    -0.046992    -0.019955     -0.054316     0.139733    -0.114301     0.0473859    0.0328047   -0.0284372  -0.0669115    -0.121542   
  0.0370745   -0.0347278    0.0386873   -0.0448116    0.0270507    0.200143     0.039697    -0.20697      0.0493876    -0.129211    -0.127305    0.000776282   0.0915709    -0.068698     0.0391949    -0.113985    -0.157969     0.0188195    -0.0674837   -0.210104     0.025081    -0.0649751    0.0231844    0.0475048   0.156704     -0.033786   
 -0.0150064    0.119124    -0.033457    -0.025184    -0.0939942   -0.193786     0.0177049    0.11432      0.0949074    -0.146325    -0.0218989  -0.0103253     0.152668     -0.017362    -0.0297641    -0.064724     0.0260928   -0.102834     -0.00203753   0.181376     0.0419364   -0.0648088    0.144343    -0.116746    0.0782094     0.0409584  
  0.0692016   -0.0740338    0.0598574   -0.170377     0.0606788    0.0976579    0.0329539    0.0955693   -0.00282482    0.0444516   -0.0506287  -0.00191695    0.0950581    -0.0104232   -0.0819735     0.0451576   -0.055763    -0.19362       0.230286    -0.137923     0.0065826   -0.0791031    0.100587     0.0178858  -0.159061     -0.0503948  
  0.0351852   -0.0889354   -0.0724068   -0.0131267   -0.0442066    0.00534568  -0.11586      0.114045     0.0445543     0.0979943   -0.0286731   0.024126     -0.0249648    -0.0512334    0.00407376    0.0759301   -0.00383909   0.00860693   -0.0686378    0.115581    -0.0387954   -0.0523678   -0.0110799    0.0904032   0.124596     -0.0127898  
 -0.170847     0.0672801    0.00371335  -0.0154609   -0.00834383   0.131417     0.0704089    0.205796    -0.166405      0.0135331    0.124227    0.127689     -0.0866812     0.212611    -0.0145821     0.121229     0.16723      0.0276145     0.0550309   -0.0311164   -0.0594018    0.0028257   -0.0355906    0.103447   -0.159677      0.0556698  
 -0.233879    -0.118997    -0.140899    -0.130433    -0.133256     0.211432    -0.039164    -0.0631839   -0.110892      0.00979526  -0.103877   -0.0192674    -0.00928169    0.0197258   -0.0197971     0.0768086    0.155097     0.0368465     0.0505633   -0.0781504   -0.180837     0.234671    -0.0476864   -0.0903781   0.00821566   -0.0192715  
 -0.0879      -0.0447595    0.0110779   -0.0216067    0.00127975   0.0688265    0.0632065    0.00819952   0.22889      -0.0786675    0.0656034  -0.0324555    -0.104935     -0.0236206   -0.0546364     0.170103     0.129144     0.0596511    -0.00590514   0.161566    -0.0891363    0.0424479   -0.00546928   0.0797278  -0.00113458   -0.13728    
 -0.126653    -0.146538    -0.146394     0.0394278   -0.191094     0.101972     0.217905    -0.00565237   0.133004      0.0917599    0.118395    0.141382      0.0241596    -0.164246    -0.190037     -0.168059     0.0939147   -0.064149      0.15185      0.084298    -0.00326187   0.00331745  -0.0270304    0.118983   -0.108685     -0.0582609  
  0.0523657    0.0121856   -0.0426666   -0.0108154    0.0775277   -0.114109     0.0337603    0.0995596   -0.112866     -0.0179153    0.253236    0.129907     -0.105334      0.0258875    0.0378159     0.0867753    0.0827603    0.0872683    -0.026941     0.118889    -0.00246748   0.0557122   -0.103569     0.0934779  -0.136467     -0.0393793  
  0.109869    -0.0172235    0.0077114    0.0788993   -0.166452     0.0366251   -0.00824065  -0.110771    -0.0163941     0.0185527    0.188137   -0.18484      -0.0395245    -0.0817167    0.000910604  -0.0248148    0.00520444  -0.0312881     0.198001     0.0810767   -0.0102984   -0.0372056   -0.0910795   -0.115874   -0.0834521     0.0963159  
 -0.0910747    0.129226     0.11844      0.099484     0.0563416    0.0555408   -0.251991    -0.00936214  -0.0748026    -0.122292     0.0710017   0.13299       0.0702942    -0.171683     0.121998      0.184585     0.102255     0.00099625    0.033649     0.0256456   -0.0287965   -0.100961    -0.0283226    0.0918823  -0.00521151    0.0377236  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 28
INFO: iteration 1, average log likelihood -1.078093
WARNING: Variances had to be floored 4 6 7 19 21 28 30
INFO: iteration 2, average log likelihood -1.010937
WARNING: Variances had to be floored 2 3 11 12 15 18 19 28 32
INFO: iteration 3, average log likelihood -1.001324
WARNING: Variances had to be floored 4 6 7 21 28 30
INFO: iteration 4, average log likelihood -1.047991
WARNING: Variances had to be floored 12 19 28
INFO: iteration 5, average log likelihood -1.030466
WARNING: Variances had to be floored 2 3 4 6 7 11 15 18 21 28 30 32
INFO: iteration 6, average log likelihood -0.981425
WARNING: Variances had to be floored 12 19 28
INFO: iteration 7, average log likelihood -1.065999
WARNING: Variances had to be floored 4 6 7 21 28 30
INFO: iteration 8, average log likelihood -1.016921
WARNING: Variances had to be floored 2 3 11 12 14 15 18 19 28 32
INFO: iteration 9, average log likelihood -1.000190
WARNING: Variances had to be floored 4 6 7 21 28 30
INFO: iteration 10, average log likelihood -1.047979
INFO: EM with 100000 data points 10 iterations avll -1.047979
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0415988   -0.118344    -0.0407338    0.00400933   0.164448   -0.101424    -0.00617332   0.0504467    0.0128616   -0.0973362   -0.0133106    0.139532     0.116885    -0.127245    -0.0268504   -0.0869901   -0.0231011     0.0539962    0.00711242   0.0611123     0.0600229    0.03848     -0.15099      0.0641121   -0.109251     0.0405182 
  0.0357425    0.0489175    0.0574735   -0.137416     0.171519    0.170856    -0.0767329    0.101117    -0.140006     0.0526101   -0.142468     0.117045     0.174273    -0.0241425    0.305454    -0.233954    -0.00384565    0.071304     0.0645117    0.0435043    -0.0331924   -0.0259402   -0.0257928   -0.114435    -0.119631    -0.135669  
  0.185454     0.101567     0.0440127    0.0329193   -0.127497   -0.268725    -0.0629019    0.00154534   0.161653     0.0196358   -0.00440987  -0.0021132   -0.00424298  -0.0529356   -0.0186059   -0.103615    -0.309546      0.0568971    0.217631    -0.0995238    -0.00966651  -0.0329476   -0.0269765    0.011938     0.192714     0.0839839 
  0.0813564    0.0527989    0.0187571   -0.104352     0.126562   -0.054919    -0.133569    -0.0366588    0.142474     0.0653547   -0.0783059   -0.0220134    0.142848    -0.0104185   -0.137727     0.0175224    0.0460602    -0.174045    -0.0377811   -0.126678      0.0341544    0.00738189   0.169148    -0.0354599    0.0367748    0.17012   
 -0.168499     0.0346886    0.0448222    0.0763765    0.0721388  -0.129552     0.0174365   -0.156451    -0.0158539   -0.0579853   -0.138102    -0.0273177    0.0405591    0.0699987    0.0362597   -0.108563    -0.153692     -0.140863    -0.00915088  -0.0102433    -0.0670595   -0.00436973   0.0917661   -0.00327647  -0.00079763   0.128218  
  0.0323614    0.095547    -0.0320242   -0.0427629   -0.0792468  -0.0141244   -0.0555752   -0.217302    -0.0144537    0.0787632    0.148104    -0.104253    -0.0476387   -0.0258953    0.0172897    0.00326699   0.0538135    -0.0420212   -0.0649091    0.135712     -0.066116    -0.0120296   -0.013248     0.0990836    0.00723304   0.0709817 
  0.0144992    0.0697283   -0.143266    -0.137365     0.279501    0.0929794   -0.170687    -0.0646818   -0.103668    -0.145792     0.104144     0.00610828  -0.0413499    0.138515    -0.0792284    0.053477     0.23193      -0.0649774   -0.0486437    0.0940301    -0.0199585    0.0988479   -0.0900686   -0.100534     0.0959127    0.097094  
  0.0591899   -0.0144167   -0.0190966   -0.0729192    0.0941311  -0.0575003   -0.0667635   -0.0541695    0.123541    -0.0192399    0.152361    -0.0604776    0.00350799  -0.0973181    0.0928186    0.111464    -0.228645      0.176514    -0.0680571    0.0790684     0.0364765    0.0490462    0.0914342    0.209624     0.147881     0.0301614 
 -0.0164879   -0.047843     0.0266106    0.0203114   -0.0857552  -0.184503     0.12992      0.0107273    0.0698315    0.0601706   -0.0312877   -0.0747754    0.0216402   -0.0659307   -0.0887682    0.116881    -0.0358982     0.065342     0.0138221   -0.12261      -0.131497    -0.11883      0.0054313   -0.00796142  -0.111994     0.0395826 
 -0.0935957   -0.059794    -0.0592472    0.0758164   -0.0567008   0.0601257   -0.0717272   -0.0797876    0.100843    -0.0999545    0.0113284    0.0786805   -0.0345163   -0.0297635    0.14258      0.03519      0.0564162     0.0333846    0.0832185    0.0641089     0.166813    -0.258645    -0.10328      0.0355346   -0.0726579    0.0144233 
 -0.146596    -0.00362192  -0.120072    -0.0173296    0.228612   -0.0986945    0.0302564   -0.00423657  -0.0484539   -0.0509769   -0.205564     0.223661    -0.0309725    0.125923     0.0760836    0.0371429   -0.0741994     0.0724096   -0.0141825    0.0099593    -0.0666248    0.0350485    0.0247472    0.144144    -0.0233832    0.0459134 
  0.038103     0.0356191    0.21137      0.0245066   -0.106618   -0.0233203   -0.117585    -0.0964219    0.189304     0.0814492   -0.244135    -0.141498    -0.225187    -0.13456      0.133808    -0.102641    -0.119995      0.0850923    0.187111     0.0302663    -0.202573    -0.130148     0.010014    -0.206452    -0.186083    -0.0996616 
 -0.014466     0.00984059   0.138274     0.0807665    0.140003    0.0157098    0.0349928   -0.0722958    0.14146      0.0621443   -0.112632    -0.133307     0.176566     0.130477    -0.0274845   -0.0232954    0.099735      0.00219377  -0.0034073    0.095123     -0.0434975    0.0163827   -0.0380972    0.0597885   -0.242981    -0.169359  
  0.11746      0.0239912   -0.139081    -0.0928205   -0.0392469  -0.0322171   -0.0512971   -0.11836      0.165599     0.118363     0.0699694    0.018246    -0.070632    -0.0232427    0.189905    -0.0425973   -0.0536126    -0.0327631   -0.215613    -0.0161234     0.0523423   -0.0974382    0.0422651   -0.00687838  -0.0871967    0.0374024 
 -0.159972    -0.117043     0.114155    -0.0755657    0.0110606   0.0908417   -0.00113321  -0.0144807    0.0104208   -0.0935243   -0.0265301   -0.0698579    0.172823    -0.0609041   -0.0147569   -0.117729     0.0755889     0.00033042  -0.0607189   -0.00234689    0.0245978    0.0151957    0.00847      0.178661     0.0993197    0.0183813 
  0.236934     0.0281542   -0.136896    -0.115545    -0.0712283   0.0473325   -0.0662892    0.030138     0.122127    -0.0685034   -0.0482092    0.0624622   -0.115231     0.227539    -0.117168     0.041875    -0.0645804    -0.0878916   -0.165866     0.132056     -0.0755704   -0.146696    -0.0528145    0.00883541   0.127469     0.0852543 
  0.0437604    0.0710387    0.171129    -0.0614103   -0.0180738   0.0365484    0.0291434   -0.0783442   -0.0301103   -0.127182    -0.169587     0.00725502  -0.102587     0.0232554    0.0870029   -0.0381726   -0.0670713    -0.0803249    0.0615126   -0.00601099    0.0809914   -0.102107    -0.118598     0.262405     0.0134451    0.00328614
 -0.0358639    0.135098     0.0455556   -0.0276465    0.0748141   0.113504     0.236033     0.0670876   -0.0121781    0.0754417    0.0534773    0.0730964    0.150989     0.054434     0.131151     0.0252834    0.123501      0.155045    -0.129053    -0.0445922     0.00546615   0.123263    -0.0110541    0.196777     0.0654953    0.0426816 
  0.0175191   -0.0261847    0.0125106    0.0247992   -0.062857    0.259713     0.00804142   0.0495414    0.0258615    0.126102     0.216124    -0.0737087    0.17645      0.143611     0.00538551   0.00493334  -0.0982213    -0.122309     0.0651629    0.0685862     0.0128036    0.073059     0.143081    -0.0613293   -0.218697     0.0653038 
 -0.00750049   0.0415533    0.0178041    0.0228843   -0.0114933  -0.00465193  -0.0808684   -0.0047008   -0.0344085    0.255623    -0.0880927   -0.0540323   -0.0330291   -0.084738    -0.061034    -0.0557922   -0.121592      0.0339103   -0.0268901    0.115429      0.0550376   -0.129665     0.128151    -0.138498     0.167896    -0.0209841 
  0.100342    -0.0296312   -0.00483785   0.17452     -0.0253952   0.0535788    0.0518757   -0.203287     0.0161051    0.115448     0.0400739    0.0137654   -0.0859874    0.0304003   -0.0681973   -0.0309874   -0.0616286     0.0219868    0.00415862  -0.0486733     0.0393306   -0.122544    -0.156591     0.0138377   -0.130352     0.167482  
  0.181819    -0.128459     0.0824424    0.0152469   -0.0637417  -0.110698     0.0285827   -0.144026    -0.157961    -0.0713558   -0.0671853   -0.0770621   -0.0315643   -0.0617754    0.0353772    0.209846    -0.0179184     0.0820209   -0.0314412    0.0812864    -0.0564279   -0.0941588   -0.152086     0.0695907    0.0426128   -0.0431822 
 -0.0132023   -0.0639143    0.0116474   -0.0875047   -0.0162305  -0.0895883    0.158758     0.132236     0.00837364  -0.0420409   -0.0893925    0.1529      -0.0985901   -0.00614795  -0.0264569   -0.0850661    0.206055     -0.0652107    0.0829219    0.187099      0.0420201   -0.0785708   -0.0245124    0.194327     0.0372873    0.128398  
  0.023894    -0.0866453    0.0188215    0.128453     0.185993   -0.0184584    0.21821     -0.0727535   -0.0124882    0.0619261    0.150334    -0.241597    -0.0939381    0.110206     0.130086     0.104542     0.0330883     0.0120305    0.173029    -0.0613429     0.0973558    0.180429    -0.172049    -0.0907828   -0.059429     0.287492  
  0.127367     0.0596727   -0.0958271   -0.0689099    0.0634419  -0.11194      0.0693425    0.160499     0.0620771    0.0438492    0.0663507   -0.208019    -0.0214498    0.0912482   -0.0771008   -0.0381688    0.183513     -0.0910832    0.158241     0.0833066    -0.065447    -0.0399495    0.24793     -0.07998      0.04665     -0.0896306 
  0.0767764    0.0032968   -0.0280357    0.171367    -0.0362265   0.0827559   -0.117372    -0.205687     0.102245     0.165489    -0.0316383    0.0165231   -0.0121206    0.062352    -0.00801827   0.040924    -0.0658675     0.116917    -0.17771      0.0350463     0.0510301    0.0728694   -0.00503276   0.0126888   -0.00464404   0.0375274 
  0.0764492   -0.176929     0.131663    -0.0788244    0.0685706  -0.0550003   -0.0176767   -0.0326472    0.00151145  -0.0450637   -0.0933886    0.172781    -0.0221134   -0.215803    -0.138151    -0.14503     -0.132421     -0.00167187   0.113207     0.077797      0.14334     -0.0860308   -0.0154519   -0.033004     0.0644708    0.0999466 
 -0.0537311    0.0175911    0.0199409   -0.0284755    0.0191483  -0.0496918   -0.118107     0.100238     0.00440155   0.0133072   -0.0208742    0.17297     -0.0460875   -0.0124768    0.10017     -0.350668    -0.00507411   -0.00577091  -0.262782     0.0215679    -0.00742503  -0.00809371   0.157901    -0.0741844    0.057677    -0.0396153 
 -0.00525128  -0.00897374  -0.16633      0.0426719   -0.0397862   0.110944    -0.0241061   -0.00926064  -0.0747177   -0.0487466   -0.0624381   -0.0739997    0.0539587   -0.0231314    0.00836409  -0.0898998    0.0622654     0.0396124   -0.0299401    0.0627718    -0.0342202   -0.09523     -0.0164422   -0.0546918    0.0764325   -0.12244   
 -0.0325509    0.0242206    0.0546322   -0.176973    -0.0498996  -0.0541182   -0.111193    -0.0432425   -0.0166931   -0.00257182   0.00971724   0.118625    -0.215202    -0.0581017   -0.0831764   -0.108625    -0.0540039    -0.0197782   -0.0124501    0.0843956    -0.0418794   -0.159153    -0.0385966   -0.057144    -0.0296385   -0.086636  
 -0.0068739    0.0753393   -0.00154626   0.0742602    0.0165913  -0.11499      0.0167547    0.201568     0.124599     0.0292071   -0.0083255    0.114385    -0.117407    -0.100381     0.0683449    0.0118358    0.0257507     0.0962786    0.0447759    0.0786315    -0.105957     0.207522     0.0799528    0.138845    -0.00898491  -0.0178889 
  0.119488    -0.00857727  -0.109062     0.0184663   -0.0835378  -0.0713802   -0.0157811    0.156554    -0.11649     -0.152669     0.0633969    0.00024123  -0.0403016    0.0327986    0.121375    -0.056794    -0.000529532  -0.125534    -0.0358676    0.000543153   0.0231628    0.0487981   -0.0379254   -0.0849861    0.0247434    0.00941181kind full, method split
0: avll = -1.4145706829442197
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414589
INFO: iteration 2, average log likelihood -1.414527
INFO: iteration 3, average log likelihood -1.414481
INFO: iteration 4, average log likelihood -1.414427
INFO: iteration 5, average log likelihood -1.414360
INFO: iteration 6, average log likelihood -1.414273
INFO: iteration 7, average log likelihood -1.414152
INFO: iteration 8, average log likelihood -1.413959
INFO: iteration 9, average log likelihood -1.413615
INFO: iteration 10, average log likelihood -1.412996
INFO: iteration 11, average log likelihood -1.412050
INFO: iteration 12, average log likelihood -1.410992
INFO: iteration 13, average log likelihood -1.410195
INFO: iteration 14, average log likelihood -1.409768
INFO: iteration 15, average log likelihood -1.409580
INFO: iteration 16, average log likelihood -1.409503
INFO: iteration 17, average log likelihood -1.409471
INFO: iteration 18, average log likelihood -1.409457
INFO: iteration 19, average log likelihood -1.409451
INFO: iteration 20, average log likelihood -1.409448
INFO: iteration 21, average log likelihood -1.409447
INFO: iteration 22, average log likelihood -1.409446
INFO: iteration 23, average log likelihood -1.409445
INFO: iteration 24, average log likelihood -1.409444
INFO: iteration 25, average log likelihood -1.409444
INFO: iteration 26, average log likelihood -1.409443
INFO: iteration 27, average log likelihood -1.409443
INFO: iteration 28, average log likelihood -1.409443
INFO: iteration 29, average log likelihood -1.409442
INFO: iteration 30, average log likelihood -1.409442
INFO: iteration 31, average log likelihood -1.409442
INFO: iteration 32, average log likelihood -1.409442
INFO: iteration 33, average log likelihood -1.409441
INFO: iteration 34, average log likelihood -1.409441
INFO: iteration 35, average log likelihood -1.409441
INFO: iteration 36, average log likelihood -1.409441
INFO: iteration 37, average log likelihood -1.409441
INFO: iteration 38, average log likelihood -1.409441
INFO: iteration 39, average log likelihood -1.409441
INFO: iteration 40, average log likelihood -1.409441
INFO: iteration 41, average log likelihood -1.409440
INFO: iteration 42, average log likelihood -1.409440
INFO: iteration 43, average log likelihood -1.409440
INFO: iteration 44, average log likelihood -1.409440
INFO: iteration 45, average log likelihood -1.409440
INFO: iteration 46, average log likelihood -1.409440
INFO: iteration 47, average log likelihood -1.409440
INFO: iteration 48, average log likelihood -1.409440
INFO: iteration 49, average log likelihood -1.409440
INFO: iteration 50, average log likelihood -1.409440
INFO: EM with 100000 data points 50 iterations avll -1.409440
952.4 data points per parameter
1: avll = [-1.41459,-1.41453,-1.41448,-1.41443,-1.41436,-1.41427,-1.41415,-1.41396,-1.41361,-1.413,-1.41205,-1.41099,-1.41019,-1.40977,-1.40958,-1.4095,-1.40947,-1.40946,-1.40945,-1.40945,-1.40945,-1.40945,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409455
INFO: iteration 2, average log likelihood -1.409399
INFO: iteration 3, average log likelihood -1.409355
INFO: iteration 4, average log likelihood -1.409304
INFO: iteration 5, average log likelihood -1.409242
INFO: iteration 6, average log likelihood -1.409169
INFO: iteration 7, average log likelihood -1.409090
INFO: iteration 8, average log likelihood -1.409013
INFO: iteration 9, average log likelihood -1.408943
INFO: iteration 10, average log likelihood -1.408885
INFO: iteration 11, average log likelihood -1.408839
INFO: iteration 12, average log likelihood -1.408803
INFO: iteration 13, average log likelihood -1.408774
INFO: iteration 14, average log likelihood -1.408751
INFO: iteration 15, average log likelihood -1.408732
INFO: iteration 16, average log likelihood -1.408717
INFO: iteration 17, average log likelihood -1.408704
INFO: iteration 18, average log likelihood -1.408694
INFO: iteration 19, average log likelihood -1.408685
INFO: iteration 20, average log likelihood -1.408677
INFO: iteration 21, average log likelihood -1.408671
INFO: iteration 22, average log likelihood -1.408664
INFO: iteration 23, average log likelihood -1.408659
INFO: iteration 24, average log likelihood -1.408653
INFO: iteration 25, average log likelihood -1.408648
INFO: iteration 26, average log likelihood -1.408643
INFO: iteration 27, average log likelihood -1.408638
INFO: iteration 28, average log likelihood -1.408634
INFO: iteration 29, average log likelihood -1.408629
INFO: iteration 30, average log likelihood -1.408625
INFO: iteration 31, average log likelihood -1.408620
INFO: iteration 32, average log likelihood -1.408616
INFO: iteration 33, average log likelihood -1.408612
INFO: iteration 34, average log likelihood -1.408608
INFO: iteration 35, average log likelihood -1.408604
INFO: iteration 36, average log likelihood -1.408600
INFO: iteration 37, average log likelihood -1.408597
INFO: iteration 38, average log likelihood -1.408593
INFO: iteration 39, average log likelihood -1.408589
INFO: iteration 40, average log likelihood -1.408586
INFO: iteration 41, average log likelihood -1.408583
INFO: iteration 42, average log likelihood -1.408579
INFO: iteration 43, average log likelihood -1.408576
INFO: iteration 44, average log likelihood -1.408573
INFO: iteration 45, average log likelihood -1.408569
INFO: iteration 46, average log likelihood -1.408566
INFO: iteration 47, average log likelihood -1.408563
INFO: iteration 48, average log likelihood -1.408560
INFO: iteration 49, average log likelihood -1.408557
INFO: iteration 50, average log likelihood -1.408554
INFO: EM with 100000 data points 50 iterations avll -1.408554
473.9 data points per parameter
2: avll = [-1.40945,-1.4094,-1.40936,-1.4093,-1.40924,-1.40917,-1.40909,-1.40901,-1.40894,-1.40889,-1.40884,-1.4088,-1.40877,-1.40875,-1.40873,-1.40872,-1.4087,-1.40869,-1.40869,-1.40868,-1.40867,-1.40866,-1.40866,-1.40865,-1.40865,-1.40864,-1.40864,-1.40863,-1.40863,-1.40862,-1.40862,-1.40862,-1.40861,-1.40861,-1.4086,-1.4086,-1.4086,-1.40859,-1.40859,-1.40859,-1.40858,-1.40858,-1.40858,-1.40857,-1.40857,-1.40857,-1.40856,-1.40856,-1.40856,-1.40855]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.408564
INFO: iteration 2, average log likelihood -1.408505
INFO: iteration 3, average log likelihood -1.408457
INFO: iteration 4, average log likelihood -1.408403
INFO: iteration 5, average log likelihood -1.408340
INFO: iteration 6, average log likelihood -1.408267
INFO: iteration 7, average log likelihood -1.408187
INFO: iteration 8, average log likelihood -1.408104
INFO: iteration 9, average log likelihood -1.408022
INFO: iteration 10, average log likelihood -1.407943
INFO: iteration 11, average log likelihood -1.407870
INFO: iteration 12, average log likelihood -1.407802
INFO: iteration 13, average log likelihood -1.407740
INFO: iteration 14, average log likelihood -1.407686
INFO: iteration 15, average log likelihood -1.407640
INFO: iteration 16, average log likelihood -1.407601
INFO: iteration 17, average log likelihood -1.407567
INFO: iteration 18, average log likelihood -1.407539
INFO: iteration 19, average log likelihood -1.407515
INFO: iteration 20, average log likelihood -1.407493
INFO: iteration 21, average log likelihood -1.407473
INFO: iteration 22, average log likelihood -1.407455
INFO: iteration 23, average log likelihood -1.407438
INFO: iteration 24, average log likelihood -1.407422
INFO: iteration 25, average log likelihood -1.407406
INFO: iteration 26, average log likelihood -1.407391
INFO: iteration 27, average log likelihood -1.407377
INFO: iteration 28, average log likelihood -1.407364
INFO: iteration 29, average log likelihood -1.407351
INFO: iteration 30, average log likelihood -1.407339
INFO: iteration 31, average log likelihood -1.407327
INFO: iteration 32, average log likelihood -1.407316
INFO: iteration 33, average log likelihood -1.407305
INFO: iteration 34, average log likelihood -1.407295
INFO: iteration 35, average log likelihood -1.407285
INFO: iteration 36, average log likelihood -1.407275
INFO: iteration 37, average log likelihood -1.407266
INFO: iteration 38, average log likelihood -1.407257
INFO: iteration 39, average log likelihood -1.407248
INFO: iteration 40, average log likelihood -1.407239
INFO: iteration 41, average log likelihood -1.407230
INFO: iteration 42, average log likelihood -1.407222
INFO: iteration 43, average log likelihood -1.407214
INFO: iteration 44, average log likelihood -1.407205
INFO: iteration 45, average log likelihood -1.407197
INFO: iteration 46, average log likelihood -1.407189
INFO: iteration 47, average log likelihood -1.407181
INFO: iteration 48, average log likelihood -1.407173
INFO: iteration 49, average log likelihood -1.407165
INFO: iteration 50, average log likelihood -1.407157
INFO: EM with 100000 data points 50 iterations avll -1.407157
236.4 data points per parameter
3: avll = [-1.40856,-1.40851,-1.40846,-1.4084,-1.40834,-1.40827,-1.40819,-1.4081,-1.40802,-1.40794,-1.40787,-1.4078,-1.40774,-1.40769,-1.40764,-1.4076,-1.40757,-1.40754,-1.40751,-1.40749,-1.40747,-1.40746,-1.40744,-1.40742,-1.40741,-1.40739,-1.40738,-1.40736,-1.40735,-1.40734,-1.40733,-1.40732,-1.4073,-1.40729,-1.40728,-1.40728,-1.40727,-1.40726,-1.40725,-1.40724,-1.40723,-1.40722,-1.40721,-1.40721,-1.4072,-1.40719,-1.40718,-1.40717,-1.40716,-1.40716]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407157
INFO: iteration 2, average log likelihood -1.407107
INFO: iteration 3, average log likelihood -1.407063
INFO: iteration 4, average log likelihood -1.407014
INFO: iteration 5, average log likelihood -1.406958
INFO: iteration 6, average log likelihood -1.406891
INFO: iteration 7, average log likelihood -1.406813
INFO: iteration 8, average log likelihood -1.406723
INFO: iteration 9, average log likelihood -1.406625
INFO: iteration 10, average log likelihood -1.406522
INFO: iteration 11, average log likelihood -1.406421
INFO: iteration 12, average log likelihood -1.406324
INFO: iteration 13, average log likelihood -1.406234
INFO: iteration 14, average log likelihood -1.406153
INFO: iteration 15, average log likelihood -1.406082
INFO: iteration 16, average log likelihood -1.406019
INFO: iteration 17, average log likelihood -1.405964
INFO: iteration 18, average log likelihood -1.405915
INFO: iteration 19, average log likelihood -1.405872
INFO: iteration 20, average log likelihood -1.405833
INFO: iteration 21, average log likelihood -1.405798
INFO: iteration 22, average log likelihood -1.405767
INFO: iteration 23, average log likelihood -1.405738
INFO: iteration 24, average log likelihood -1.405711
INFO: iteration 25, average log likelihood -1.405686
INFO: iteration 26, average log likelihood -1.405663
INFO: iteration 27, average log likelihood -1.405642
INFO: iteration 28, average log likelihood -1.405622
INFO: iteration 29, average log likelihood -1.405603
INFO: iteration 30, average log likelihood -1.405585
INFO: iteration 31, average log likelihood -1.405568
INFO: iteration 32, average log likelihood -1.405552
INFO: iteration 33, average log likelihood -1.405537
INFO: iteration 34, average log likelihood -1.405523
INFO: iteration 35, average log likelihood -1.405509
INFO: iteration 36, average log likelihood -1.405496
INFO: iteration 37, average log likelihood -1.405483
INFO: iteration 38, average log likelihood -1.405471
INFO: iteration 39, average log likelihood -1.405459
INFO: iteration 40, average log likelihood -1.405448
INFO: iteration 41, average log likelihood -1.405437
INFO: iteration 42, average log likelihood -1.405426
INFO: iteration 43, average log likelihood -1.405416
INFO: iteration 44, average log likelihood -1.405406
INFO: iteration 45, average log likelihood -1.405396
INFO: iteration 46, average log likelihood -1.405386
INFO: iteration 47, average log likelihood -1.405377
INFO: iteration 48, average log likelihood -1.405368
INFO: iteration 49, average log likelihood -1.405359
INFO: iteration 50, average log likelihood -1.405350
INFO: EM with 100000 data points 50 iterations avll -1.405350
118.1 data points per parameter
4: avll = [-1.40716,-1.40711,-1.40706,-1.40701,-1.40696,-1.40689,-1.40681,-1.40672,-1.40662,-1.40652,-1.40642,-1.40632,-1.40623,-1.40615,-1.40608,-1.40602,-1.40596,-1.40591,-1.40587,-1.40583,-1.4058,-1.40577,-1.40574,-1.40571,-1.40569,-1.40566,-1.40564,-1.40562,-1.4056,-1.40559,-1.40557,-1.40555,-1.40554,-1.40552,-1.40551,-1.4055,-1.40548,-1.40547,-1.40546,-1.40545,-1.40544,-1.40543,-1.40542,-1.40541,-1.4054,-1.40539,-1.40538,-1.40537,-1.40536,-1.40535]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.405350
INFO: iteration 2, average log likelihood -1.405292
INFO: iteration 3, average log likelihood -1.405240
INFO: iteration 4, average log likelihood -1.405181
INFO: iteration 5, average log likelihood -1.405111
INFO: iteration 6, average log likelihood -1.405026
INFO: iteration 7, average log likelihood -1.404925
INFO: iteration 8, average log likelihood -1.404809
INFO: iteration 9, average log likelihood -1.404681
INFO: iteration 10, average log likelihood -1.404546
INFO: iteration 11, average log likelihood -1.404409
INFO: iteration 12, average log likelihood -1.404277
INFO: iteration 13, average log likelihood -1.404153
INFO: iteration 14, average log likelihood -1.404040
INFO: iteration 15, average log likelihood -1.403938
INFO: iteration 16, average log likelihood -1.403849
INFO: iteration 17, average log likelihood -1.403770
INFO: iteration 18, average log likelihood -1.403701
INFO: iteration 19, average log likelihood -1.403640
INFO: iteration 20, average log likelihood -1.403585
INFO: iteration 21, average log likelihood -1.403537
INFO: iteration 22, average log likelihood -1.403493
INFO: iteration 23, average log likelihood -1.403453
INFO: iteration 24, average log likelihood -1.403417
INFO: iteration 25, average log likelihood -1.403384
INFO: iteration 26, average log likelihood -1.403353
INFO: iteration 27, average log likelihood -1.403324
INFO: iteration 28, average log likelihood -1.403298
INFO: iteration 29, average log likelihood -1.403273
INFO: iteration 30, average log likelihood -1.403249
INFO: iteration 31, average log likelihood -1.403226
INFO: iteration 32, average log likelihood -1.403205
INFO: iteration 33, average log likelihood -1.403184
INFO: iteration 34, average log likelihood -1.403164
INFO: iteration 35, average log likelihood -1.403145
INFO: iteration 36, average log likelihood -1.403126
INFO: iteration 37, average log likelihood -1.403108
INFO: iteration 38, average log likelihood -1.403090
INFO: iteration 39, average log likelihood -1.403072
INFO: iteration 40, average log likelihood -1.403055
INFO: iteration 41, average log likelihood -1.403039
INFO: iteration 42, average log likelihood -1.403022
INFO: iteration 43, average log likelihood -1.403006
INFO: iteration 44, average log likelihood -1.402990
INFO: iteration 45, average log likelihood -1.402975
INFO: iteration 46, average log likelihood -1.402960
INFO: iteration 47, average log likelihood -1.402945
INFO: iteration 48, average log likelihood -1.402930
INFO: iteration 49, average log likelihood -1.402916
INFO: iteration 50, average log likelihood -1.402902
INFO: EM with 100000 data points 50 iterations avll -1.402902
59.0 data points per parameter
5: avll = [-1.40535,-1.40529,-1.40524,-1.40518,-1.40511,-1.40503,-1.40493,-1.40481,-1.40468,-1.40455,-1.40441,-1.40428,-1.40415,-1.40404,-1.40394,-1.40385,-1.40377,-1.4037,-1.40364,-1.40359,-1.40354,-1.40349,-1.40345,-1.40342,-1.40338,-1.40335,-1.40332,-1.4033,-1.40327,-1.40325,-1.40323,-1.4032,-1.40318,-1.40316,-1.40314,-1.40313,-1.40311,-1.40309,-1.40307,-1.40306,-1.40304,-1.40302,-1.40301,-1.40299,-1.40297,-1.40296,-1.40294,-1.40293,-1.40292,-1.4029]
[-1.41457,-1.41459,-1.41453,-1.41448,-1.41443,-1.41436,-1.41427,-1.41415,-1.41396,-1.41361,-1.413,-1.41205,-1.41099,-1.41019,-1.40977,-1.40958,-1.4095,-1.40947,-1.40946,-1.40945,-1.40945,-1.40945,-1.40945,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40944,-1.40945,-1.4094,-1.40936,-1.4093,-1.40924,-1.40917,-1.40909,-1.40901,-1.40894,-1.40889,-1.40884,-1.4088,-1.40877,-1.40875,-1.40873,-1.40872,-1.4087,-1.40869,-1.40869,-1.40868,-1.40867,-1.40866,-1.40866,-1.40865,-1.40865,-1.40864,-1.40864,-1.40863,-1.40863,-1.40862,-1.40862,-1.40862,-1.40861,-1.40861,-1.4086,-1.4086,-1.4086,-1.40859,-1.40859,-1.40859,-1.40858,-1.40858,-1.40858,-1.40857,-1.40857,-1.40857,-1.40856,-1.40856,-1.40856,-1.40855,-1.40856,-1.40851,-1.40846,-1.4084,-1.40834,-1.40827,-1.40819,-1.4081,-1.40802,-1.40794,-1.40787,-1.4078,-1.40774,-1.40769,-1.40764,-1.4076,-1.40757,-1.40754,-1.40751,-1.40749,-1.40747,-1.40746,-1.40744,-1.40742,-1.40741,-1.40739,-1.40738,-1.40736,-1.40735,-1.40734,-1.40733,-1.40732,-1.4073,-1.40729,-1.40728,-1.40728,-1.40727,-1.40726,-1.40725,-1.40724,-1.40723,-1.40722,-1.40721,-1.40721,-1.4072,-1.40719,-1.40718,-1.40717,-1.40716,-1.40716,-1.40716,-1.40711,-1.40706,-1.40701,-1.40696,-1.40689,-1.40681,-1.40672,-1.40662,-1.40652,-1.40642,-1.40632,-1.40623,-1.40615,-1.40608,-1.40602,-1.40596,-1.40591,-1.40587,-1.40583,-1.4058,-1.40577,-1.40574,-1.40571,-1.40569,-1.40566,-1.40564,-1.40562,-1.4056,-1.40559,-1.40557,-1.40555,-1.40554,-1.40552,-1.40551,-1.4055,-1.40548,-1.40547,-1.40546,-1.40545,-1.40544,-1.40543,-1.40542,-1.40541,-1.4054,-1.40539,-1.40538,-1.40537,-1.40536,-1.40535,-1.40535,-1.40529,-1.40524,-1.40518,-1.40511,-1.40503,-1.40493,-1.40481,-1.40468,-1.40455,-1.40441,-1.40428,-1.40415,-1.40404,-1.40394,-1.40385,-1.40377,-1.4037,-1.40364,-1.40359,-1.40354,-1.40349,-1.40345,-1.40342,-1.40338,-1.40335,-1.40332,-1.4033,-1.40327,-1.40325,-1.40323,-1.4032,-1.40318,-1.40316,-1.40314,-1.40313,-1.40311,-1.40309,-1.40307,-1.40306,-1.40304,-1.40302,-1.40301,-1.40299,-1.40297,-1.40296,-1.40294,-1.40293,-1.40292,-1.4029]
32Ã—26 Array{Float64,2}:
 -0.0326622  -0.427307    -0.0608098    -0.00416863   -0.0358876  -0.455863    0.200753     0.0373315   -0.455847   -0.216974   -0.300795    -0.426066     0.114104     -0.210526   -0.846549    -0.174084   -0.304237   -0.0303688   -0.341551     0.46982      0.0723279  -0.251013      0.577961    0.0602256   -0.325302   -0.296851  
 -0.106161   -0.263732     0.125372      0.11272      -0.292772   -0.18538     0.555119     0.451059    -0.281212    0.0315816   0.0300901    0.218622    -0.132685      0.0484613  -0.358184     0.0495505  -0.547293    0.197333     0.543206     0.390876    -0.36221     0.343086      0.506907    0.00340156  -0.278656   -0.282781  
 -0.810533    0.173496    -0.0786342     0.556721     -0.359518   -0.558519   -0.0144798    0.139429    -0.0789716   0.241118    0.612212    -0.327457     0.000453232  -0.192916    0.218649    -0.0675513  -0.28385     0.631202     0.0726945    0.317957     0.40342     0.326847      0.124695    0.287971     0.0960466  -0.303084  
 -0.0260571   0.171963    -0.000159083   0.308657      0.19106     0.0576964  -0.374143     0.60246     -0.176188    0.343115   -0.00189777   0.0302647    0.21778       0.0479666   0.210191     0.83108    -0.0622838   0.792311     0.279079     0.299857    -0.245875    0.693344      0.236059   -0.0383225    0.390209    0.337257  
  0.550366    0.25362      0.211256     -0.00100808    0.084392   -0.356426    0.0574522    0.347763    -0.608076   -0.0334509  -0.191373    -0.0274268   -0.53648      -0.260586    0.145057     0.764725   -0.103883   -0.530712    -0.898976    -0.438226    -0.144385   -0.000434488   0.314308   -0.229805    -0.0477612  -0.330742  
  0.126363   -0.198432    -0.461512     -0.620075     -0.172159   -0.690844    0.235039     0.538898     0.340901    0.551791   -0.344979    -0.738159    -0.232792     -0.213182    0.584223     0.220753    0.0497784   0.0261601   -0.304003    -0.217075     0.468911    0.11395       0.227078   -0.316407     0.0431115  -0.562982  
  0.116608   -0.488692    -0.143993     -0.32539       0.0622687   0.314223   -0.276072    -0.248619     0.417234    0.0264239   0.341317    -0.165008     0.506565      0.181844    0.212875     0.385864    0.0144907  -0.900276     0.324587    -0.0310766   -0.122676    0.113676      0.434815   -0.213527    -0.601369    0.0590715 
 -0.34551     0.412084     0.178319     -0.16764       0.019853   -0.0870137  -0.231038     0.668804     0.181723    0.47781     0.211151     0.149989     0.449906     -0.175784    0.0730732   -0.0132819   0.353381   -0.381952    -0.00625832   0.266194     0.115429   -0.85259       0.681786   -0.142205    -0.228769   -0.0659664 
  0.387824   -0.474988    -0.17156       0.603151      0.80712    -0.0268296   0.0193601   -0.111386    -0.258578   -0.3374      1.01188      0.40718     -0.167121      0.133033   -0.0561458    0.457832   -0.626391   -1.07214     -0.232426     0.628773    -0.616434   -0.277622     -0.205835    0.596911     0.246225    0.360769  
  0.868709   -0.0617286   -0.429702     -0.214936      0.47907    -0.384183    0.272958     0.147788     0.882136    0.0423254   0.256792     0.053979     0.0112965     0.48426     0.241424    -0.0584671  -0.27071    -0.238975    -0.467519    -0.0215875   -0.500882   -0.102663     -0.127961    0.043193     0.58155     0.0862223 
 -0.142062    0.765243     0.421466      0.504538      0.403413    0.650611   -0.311414    -0.232321    -0.811854   -0.208946    0.0550806    0.610745     0.581798      0.534393   -0.443384     0.59506     0.0141157   0.678722    -0.681766     0.192602    -0.339628    0.0887897    -0.129487    0.0683584    0.0874205  -0.484472  
  0.337571   -0.085333     0.638062     -0.171674      0.417999    0.154516   -0.200423    -0.11491      0.149701    0.0495519   0.00935889   0.0261262    0.300186      0.593279    0.263749     0.674881    0.470044   -0.0631224   -0.27431     -0.699821    -0.52763     0.202727     -0.57094     0.193204     0.0405309   0.345439  
  0.149136   -0.756272     0.28429       0.198875      0.195462   -0.497105   -0.462931    -0.375487     0.209792   -0.104009   -0.781912     0.836815    -0.189862      0.0383552   0.257666    -0.457004   -0.0813935   0.214506     0.0329218    0.0867389    0.593964    0.204068     -0.193162    0.514978    -0.190244    0.246448  
  0.42558     0.500375    -0.0177677     0.281604     -0.177804   -0.713478    0.398519     0.361578    -0.121562   -0.160537   -0.356988     0.824448    -0.654316      0.153796   -0.149745    -1.08762    -0.430288    0.0950915    0.0393738    0.0617184    0.376891   -0.447505     -0.378871    0.416124    -0.117461    0.115455  
 -0.144745    0.0859262    0.300463      0.000180773   0.323221    0.197234    0.0413048   -0.349611    -0.269796   -0.62271     0.217565    -0.0263299   -0.326343     -0.0605188  -0.199541    -0.81819     0.0284022  -0.232189    -0.0875227   -0.326493    -0.401526   -0.370258     -0.169523   -0.182829     0.125925    0.542436  
  0.0433916   0.0962951   -0.18977      -0.174222     -0.0870611   0.182486    0.00373685  -0.335796     0.432871    0.168316   -0.0526564    0.0274868    0.184312      0.0777061   0.112807    -0.150444    0.198058   -0.0578563    0.353576     0.162345     0.22564    -0.131753     -0.237413    0.0931823    0.0522536   0.0480669 
 -0.0348354  -0.371088    -0.20318       0.175102     -0.03654    -0.305444   -0.306423     0.239548     0.495782   -0.305615   -0.0323918   -0.390935     0.35752      -0.0484009   0.0166653    0.113335    0.0531759   0.50983     -0.349211    -0.00432968  -0.0822675   0.268426     -0.0125715  -0.0404154   -0.242125    0.183106  
 -0.11263     0.478559    -0.0823852    -0.13263       0.33895    -0.285487   -0.0100499    0.148564    -0.262961    0.172225    0.257039    -0.533631     0.00255903   -0.0292753   0.0875737    0.217096   -0.0544343   0.0185604   -0.405299     0.124374     0.152643    0.0444716     0.122535   -0.136646     0.115155   -0.175775  
  0.0104462  -0.241421     0.174824     -0.0859192     0.149206   -0.326186    0.0365505   -0.0413016   -0.0251712   0.0101712  -0.19902      0.301371     0.0895682     0.160682    0.120598     0.0949778  -0.162784   -0.25814     -0.101504    -0.0844257   -0.0169382  -0.0846978     0.156569    0.0188749   -0.103417   -0.109619  
  0.0547707   0.0476003   -0.0337421    -0.00352802   -0.0570346   0.211951   -0.00444267  -0.0532404    0.0880394  -0.0169992   0.0758675    0.00515192  -0.06349      -0.0546243  -0.0337077   -0.124974    0.081723    0.0606896    0.130952     0.0950925   -0.0777469  -0.0467197    -0.0899011   0.136247     0.0180406   0.0725078 
  0.150225    0.0622408   -0.388346      0.561928     -0.0864165  -0.605298    0.354871     0.00107139   0.0925236   0.591657   -0.0407501    0.457229     0.135804     -0.553171    0.629531     0.0992156   0.128438   -0.346273     0.0365934    0.179396     0.18918    -0.0828887     0.0585129  -0.403136     0.0216961   0.762311  
  0.156619    0.154177    -0.663381      0.351799      0.0526389   0.456192   -0.0350558   -0.294862     0.0179809  -0.184751    0.598539     0.170117     0.121905     -0.0762491   0.273076    -0.23394     0.027663   -0.0860238    0.0390207    0.331278     0.321294    0.235661     -0.0738473  -0.718701     0.118299    0.1753    
 -0.026362    0.746192     0.0936964     0.171087      0.439084   -0.126509    0.899113    -0.0378163   -0.732614    0.542071    0.262147     0.0574395    0.228428     -0.0708696  -0.11012     -0.0430074  -0.209368   -0.26902      0.0702102   -0.444446    -0.200739    0.0007244    -0.258789    0.456003     0.305059    0.254909  
  0.138007    0.453442     0.115309     -0.250648      0.342642   -0.28464     0.357503     0.268656     0.135459    0.0542888   0.0428482   -0.0663516   -0.328366     -0.516937    0.303036    -0.161356   -0.302869    0.257569     0.0855493    0.294138     0.161697    0.424049     -0.0694824   0.432618     0.273315    0.565293  
 -1.11226    -0.445243     0.363869     -0.529104      0.0754423   0.0644001  -0.0350924   -0.539772     0.104787   -0.129712   -0.190563    -0.197209     0.302427      0.0219027   0.161811    -0.376198    0.134094    0.178938     0.204804    -0.141402     0.471568   -0.309652      0.358754   -0.400237    -0.1411     -0.254581  
  0.0468343  -0.282879    -0.189566     -0.344151     -0.0611818  -0.111871    0.518943    -0.853941     0.500932   -0.283951    0.0487038    0.0134714   -0.139906     -0.283676   -0.101289    -0.774583    0.394454   -0.43076      0.0822343    0.09485      0.467798   -0.413311     -0.354686    0.162637     0.0215947  -0.333468  
  0.705072    0.00134112   0.290563     -0.711349      0.130928    0.486671   -0.163996     0.0218469   -0.0876034  -0.540842   -0.642056    -0.0280261   -0.484717     -0.142113   -0.246243    -0.278823   -0.080444   -0.277268    -0.339586    -0.107753    -0.393419   -0.518008     -0.0290193  -0.130975    -0.0754638  -0.00422629
 -0.108422    0.2504       0.497278     -0.327999     -0.102535    0.300677   -0.0151746   -0.0916009   -0.12132     0.31372    -0.592829    -0.166031    -0.427765     -0.138056    0.25226     -0.331652    0.430088    0.257882     0.0812159   -0.404154     0.186857   -0.418183     -0.363576    0.0117655    0.082225    0.0322345 
  0.0654526   0.192004    -0.0778977     0.715991     -0.380263    0.579827   -0.688524    -0.0439708   -0.413131    0.25543    -0.0499096    0.0556297    0.0151089    -0.0877957  -0.249968     0.0230429   0.0408212   0.179949    -0.343185     0.148772    -0.150025   -0.178014     -0.0763402  -0.0682496   -0.0408755   0.19981   
  0.0172668  -0.355719    -0.0172918     0.306832     -1.02674     0.449966   -0.281538    -0.0792971    0.101089    0.293858   -0.535773     0.34121      0.230735      0.0915127  -0.00214111  -0.131669    0.0959229  -0.00597657   0.258079    -0.0875287    0.0936855  -0.622295     -0.293211    0.275705    -0.409131   -0.332042  
 -0.0135198  -0.111292    -0.0478608    -0.476754      0.083667    0.28788    -0.305345    -0.275153     0.409853   -0.570812    0.126397    -0.897064    -0.464842      0.489151   -0.492841    -0.116759    0.0075742   0.527328     0.295511     0.087604    -0.203016    0.4477       -0.172582    0.200996    -0.143443   -0.368919  
 -0.0135886  -0.061322    -0.0283618     0.252344     -0.170755    0.336547   -0.190888    -0.418981     0.114498   -0.101308    0.0479256    0.666802    -0.248051      0.464272   -0.169458    -0.0380904  -0.143774    0.159325     0.618631    -0.154744    -0.221631    0.333576     -0.425785    0.277238     0.460678    0.197218  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402888
INFO: iteration 2, average log likelihood -1.402875
INFO: iteration 3, average log likelihood -1.402862
INFO: iteration 4, average log likelihood -1.402849
INFO: iteration 5, average log likelihood -1.402837
INFO: iteration 6, average log likelihood -1.402825
INFO: iteration 7, average log likelihood -1.402814
INFO: iteration 8, average log likelihood -1.402802
INFO: iteration 9, average log likelihood -1.402791
INFO: iteration 10, average log likelihood -1.402781
INFO: EM with 100000 data points 10 iterations avll -1.402781
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.025499e+05
      1       6.915968e+05      -2.109531e+05 |       32
      2       6.791357e+05      -1.246117e+04 |       32
      3       6.745150e+05      -4.620697e+03 |       32
      4       6.720616e+05      -2.453416e+03 |       32
      5       6.706003e+05      -1.461222e+03 |       32
      6       6.695753e+05      -1.025060e+03 |       32
      7       6.687729e+05      -8.024011e+02 |       32
      8       6.681274e+05      -6.454975e+02 |       32
      9       6.675852e+05      -5.421945e+02 |       32
     10       6.671288e+05      -4.563933e+02 |       32
     11       6.667733e+05      -3.554621e+02 |       32
     12       6.664632e+05      -3.101179e+02 |       32
     13       6.661553e+05      -3.079592e+02 |       32
     14       6.658860e+05      -2.692518e+02 |       32
     15       6.656783e+05      -2.077130e+02 |       32
     16       6.655060e+05      -1.722725e+02 |       32
     17       6.653442e+05      -1.618562e+02 |       32
     18       6.651991e+05      -1.450781e+02 |       32
     19       6.650589e+05      -1.402133e+02 |       32
     20       6.649260e+05      -1.328751e+02 |       32
     21       6.647922e+05      -1.338009e+02 |       32
     22       6.646754e+05      -1.168330e+02 |       32
     23       6.645800e+05      -9.535930e+01 |       32
     24       6.644944e+05      -8.556292e+01 |       32
     25       6.644130e+05      -8.146582e+01 |       32
     26       6.643401e+05      -7.285220e+01 |       32
     27       6.642643e+05      -7.585522e+01 |       32
     28       6.642005e+05      -6.379150e+01 |       32
     29       6.641379e+05      -6.252702e+01 |       32
     30       6.640731e+05      -6.485428e+01 |       32
     31       6.640181e+05      -5.501777e+01 |       32
     32       6.639593e+05      -5.876144e+01 |       32
     33       6.639024e+05      -5.691986e+01 |       32
     34       6.638407e+05      -6.171324e+01 |       32
     35       6.637788e+05      -6.192913e+01 |       32
     36       6.637179e+05      -6.087773e+01 |       32
     37       6.636546e+05      -6.326203e+01 |       32
     38       6.636016e+05      -5.302236e+01 |       32
     39       6.635485e+05      -5.307692e+01 |       32
     40       6.634946e+05      -5.393321e+01 |       32
     41       6.634377e+05      -5.693015e+01 |       32
     42       6.633841e+05      -5.352557e+01 |       32
     43       6.633446e+05      -3.955816e+01 |       32
     44       6.633037e+05      -4.088752e+01 |       32
     45       6.632657e+05      -3.794695e+01 |       32
     46       6.632257e+05      -3.999415e+01 |       32
     47       6.631865e+05      -3.927366e+01 |       32
     48       6.631505e+05      -3.600977e+01 |       32
     49       6.631143e+05      -3.619894e+01 |       32
     50       6.630800e+05      -3.422895e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 663080.0266506725)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414612
INFO: iteration 2, average log likelihood -1.409406
INFO: iteration 3, average log likelihood -1.407889
INFO: iteration 4, average log likelihood -1.406706
INFO: iteration 5, average log likelihood -1.405569
INFO: iteration 6, average log likelihood -1.404700
INFO: iteration 7, average log likelihood -1.404198
INFO: iteration 8, average log likelihood -1.403937
INFO: iteration 9, average log likelihood -1.403786
INFO: iteration 10, average log likelihood -1.403683
INFO: iteration 11, average log likelihood -1.403603
INFO: iteration 12, average log likelihood -1.403536
INFO: iteration 13, average log likelihood -1.403479
INFO: iteration 14, average log likelihood -1.403428
INFO: iteration 15, average log likelihood -1.403382
INFO: iteration 16, average log likelihood -1.403341
INFO: iteration 17, average log likelihood -1.403303
INFO: iteration 18, average log likelihood -1.403267
INFO: iteration 19, average log likelihood -1.403235
INFO: iteration 20, average log likelihood -1.403204
INFO: iteration 21, average log likelihood -1.403176
INFO: iteration 22, average log likelihood -1.403149
INFO: iteration 23, average log likelihood -1.403124
INFO: iteration 24, average log likelihood -1.403101
INFO: iteration 25, average log likelihood -1.403079
INFO: iteration 26, average log likelihood -1.403059
INFO: iteration 27, average log likelihood -1.403040
INFO: iteration 28, average log likelihood -1.403022
INFO: iteration 29, average log likelihood -1.403004
INFO: iteration 30, average log likelihood -1.402988
INFO: iteration 31, average log likelihood -1.402973
INFO: iteration 32, average log likelihood -1.402958
INFO: iteration 33, average log likelihood -1.402944
INFO: iteration 34, average log likelihood -1.402930
INFO: iteration 35, average log likelihood -1.402917
INFO: iteration 36, average log likelihood -1.402904
INFO: iteration 37, average log likelihood -1.402891
INFO: iteration 38, average log likelihood -1.402879
INFO: iteration 39, average log likelihood -1.402867
INFO: iteration 40, average log likelihood -1.402856
INFO: iteration 41, average log likelihood -1.402844
INFO: iteration 42, average log likelihood -1.402833
INFO: iteration 43, average log likelihood -1.402822
INFO: iteration 44, average log likelihood -1.402811
INFO: iteration 45, average log likelihood -1.402800
INFO: iteration 46, average log likelihood -1.402790
INFO: iteration 47, average log likelihood -1.402779
INFO: iteration 48, average log likelihood -1.402769
INFO: iteration 49, average log likelihood -1.402758
INFO: iteration 50, average log likelihood -1.402748
INFO: EM with 100000 data points 50 iterations avll -1.402748
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0581253   -0.100387   -0.0511771     0.0622014   -0.343373    -0.116858   -0.0688325   0.0986874  -0.0807503    0.197537   -0.252609    -0.0268954   0.0770024  -0.136754    -0.144343     0.025952   -0.0613086    0.0530907   -0.00726674   0.220115      0.283512   -0.216093     0.110017     0.107494    -0.132836     -0.178278 
 -0.03673     -0.842447    0.193374      0.150225     0.370987    -0.285747    0.239594    0.0262158  -0.287571    -0.554086   -0.0174401   -0.406189    0.406862    0.0347417   -0.626007    -0.236249   -0.161568    -0.0711672   -0.127565     0.0431956    -0.142929   -0.236051     0.809033    -0.29978     -0.403109     -0.112758 
  0.368276     0.169607   -0.000754044  -0.220405     0.0972028    0.113162   -0.0571984   0.109884    0.265948     0.0775977  -0.00374522   0.225441   -0.655543   -0.0196497    0.563341     0.273855   -0.54323      0.262506     0.296109    -0.153434     -0.0280621   0.652282    -0.793411     0.193381     0.690782      0.19328  
  0.199573     0.0127461   0.124485     -0.129483     0.186082     0.0345717   0.079455   -0.165346    0.0691339    0.030239   -0.0233025    0.155482   -0.0331466   0.315165    -0.132024     0.0580508   0.00577312  -0.161916    -0.12635     -0.136778     -0.301729   -0.183928    -0.194269     0.150061     0.163238     -0.125816 
  0.720511     0.0751077   0.250463     -0.405841     0.101584    -0.316668    0.229225    0.230105   -0.208542    -0.193164   -0.297322     0.0380169  -0.852272   -0.0616052    0.341198     0.366241   -0.0225492   -0.691632    -0.669039    -0.54866      -0.205162   -0.0732752    0.500187    -0.488159     0.0256934    -0.394431 
 -0.00737488  -0.0496356  -0.107067     -0.060341    -0.0685742    0.0529537  -0.0531943   0.0173188   0.165937    -0.0920997   0.109918    -0.185125    0.0565051  -0.0735529    0.0500757   -0.0737861   0.0958397    0.0867347    0.0316421    0.0622528     0.0769852   0.120397     0.00916751  -0.0324846   -0.115402      0.110038 
  0.176849     0.188092   -0.199202      0.33938      0.1366      -0.284599    0.177476    0.108998   -0.0704325    0.257079    0.288264     0.389918    0.115083   -0.19417      0.661802     0.252591    0.0762803   -0.400115     0.0522105    0.000548983   0.106508    0.0173819    0.0715872   -0.27066     -0.00367385    0.486556 
  0.0974315   -0.537821   -0.386792      0.296115    -0.273538    -0.0533422  -0.593377    0.629316    0.71329     -0.237494    0.273423    -0.756764    0.12696     0.219902     0.00258681   0.055958    0.114672     0.621101    -0.587023     0.338354     -0.173774    0.017114     0.0449131   -0.111783     0.0484204    -0.263724 
  0.182964    -0.518714    0.119525      0.432169    -0.895487     0.430739   -0.0197908   0.108351    0.228318     0.110831   -0.243797     0.948082    0.197126    0.295554     0.13024     -0.202452    0.0750153    0.0123038    0.555891    -0.211194     -0.353285   -0.150492    -0.010611     0.215168    -0.118656      0.0241815
 -0.143321     0.400504   -0.183939     -0.499927     0.753541    -0.386278    0.246013   -0.214003   -0.212544    -0.074507    0.290505    -1.05389    -0.236824   -0.214304    -0.325059     0.107093    0.0417805    0.11475     -0.290021     0.247339      0.0296179   0.505295    -0.169017     0.0817631   -0.0369582    -0.0245915
 -0.290404    -0.024614   -0.048426      0.0864304   -0.425402    -0.522143    0.877378    0.28901    -0.163049     0.198579    0.293362    -0.208673   -0.129423    0.0171827   -0.347355     0.024771   -0.4204       0.281658     0.40287      0.42747      -0.0767763   0.360831     0.452757     0.0327513   -0.0625241    -0.610226 
 -0.347078     0.0513371  -0.311197      0.599416    -0.754358     0.185929   -0.409066   -0.323784   -0.585137     0.386348    0.135208     0.0492778  -0.062625   -0.0930161   -0.122068    -0.0283953  -0.136586     0.00827309  -0.0841115    0.330734      0.439308   -0.0303196    0.0273217    0.0596046   -0.00695622   -0.306955 
  0.343237    -0.0206657   0.40284      -0.0484042   -0.279915     0.441971   -0.565784    0.123116   -0.552453    -0.750461   -0.187702    -0.292728   -0.53984     0.29204     -1.091       -0.120539   -0.318526     0.236923     0.0620711   -0.0464688    -0.605741   -0.111549     0.00569992   0.261768    -0.104707      0.045456 
  0.116138    -0.239271   -0.0746884    -0.506291     0.192629     0.704361   -0.335827   -0.197726    0.462621     0.0532198   0.368045    -0.404441    0.425165    0.448314     0.243017     0.442824    0.426451    -0.507245     0.31267     -0.0873852    -0.220407    0.0810452    0.0230403   -0.18503     -0.0760801    -0.138273 
 -0.0110281    0.419731    0.198367      0.051479     0.579274     0.227328    0.0738335  -0.481301   -0.00131001  -0.288349    0.345202     0.274834   -0.0634265   0.143225     0.0485921   -0.579666    0.087685    -0.112325     0.171086    -0.207672     -0.322508   -0.177703    -0.366072    -0.00268506   0.374592      0.724984 
  0.450115     0.762639   -0.132522      0.319621     0.391544    -0.182175    0.483385    0.579273   -0.702337     0.527295   -0.0954547   -0.0598707   0.162577   -0.0616919   -0.132531     0.501651   -0.241038     0.0833327   -0.530395    -0.446067     -0.509195   -0.122126    -0.230387     0.480585     0.376177      0.107123 
 -0.0967224   -0.536158   -0.00736407   -0.363113     0.0279036    0.0178867   0.0129898  -0.62127     0.852806    -0.702919   -0.284673     0.0368473  -0.412679    0.35351     -0.435411    -0.553562    0.225954     0.305253     0.655093     0.2489        0.182439    0.109996    -0.352698     0.0699854    0.0320707    -0.295054 
  0.215792     0.131618   -0.486566      0.484881     0.211149     0.301864   -0.0717256  -0.901982    0.279625    -0.242171    0.424568     0.567592    0.14918    -0.285642    -0.183429    -0.436874    0.340658    -0.325347     0.278905     0.289422      0.35136    -0.171784    -0.0269514   -0.358029     0.230771     -0.022773 
 -0.494159    -0.612073    0.163305     -0.506916    -0.267807     0.154642   -0.673141   -0.373053    0.287881     0.0507397  -0.686794    -0.0611477   0.254601   -0.0648987    0.215604    -0.150979   -0.0852166    0.0653554   -0.0358877   -0.11489       0.431186   -0.37602      0.447969    -0.343907    -0.76673      -0.32846  
 -0.269954     0.264918    0.287675     -0.361253    -0.0776152   -0.0884331  -0.0450511   0.619523   -0.116322     0.46715    -0.0818539    0.0175453   0.326943   -0.219457    -0.0348727    0.226381    0.167595    -0.376308     0.0551099    0.119796      0.0519724  -0.533275     0.776013     0.0935389   -0.417793      0.102063 
 -0.622589    -0.06008     1.08492      -0.312634     0.170388    -0.0798629  -0.0279286   0.0289987  -0.326131     0.211928   -0.398508    -0.174932   -0.34347     0.00234414   0.390155    -0.339606    0.423952     0.451635     0.0847699   -0.634735      0.259177   -0.262719    -0.058482     0.0162659    0.425359      0.0261631
 -0.266363     0.291121    0.0646471    -0.14979      0.415748    -0.332063    0.0128566   0.0547067  -0.052311    -0.0519382   0.237109    -0.312536    0.278167   -0.0145493    0.266249    -0.0844052  -0.0329506   -0.089342    -0.506288     0.119406      0.314285   -0.37389      0.194225    -0.341112     0.110037     -0.432025 
  0.0239164   -0.229037    0.197571      0.0604694    0.190791    -0.284028   -0.545008   -0.400612    0.498765    -0.0538886  -0.427508    -0.0891409   0.0776128   0.28812      0.25933      0.0637672   0.385608     0.135988    -0.469307    -0.752624     -0.0053673   0.213823    -0.640703     0.392163    -0.270321      0.393458 
  0.415848     0.336653    0.0514793     0.209168     0.0338539   -0.805918    0.409298    0.329959   -0.151478    -0.0667674  -0.318001     0.660766   -0.575243   -0.0814798   -0.0700593   -0.96221    -0.368265     0.0918029   -0.092377     0.207324      0.422019   -0.295589    -0.189751     0.402587    -0.00372033    0.301507 
  0.454113    -0.409109   -0.429698      0.0873034    0.344933    -0.146703   -0.0789139  -0.181515    0.244836    -0.294566    0.457438     0.415236    0.17227     0.323788     0.00873571   0.229505   -0.802728    -0.856872    -0.145848     0.377173     -0.392445    0.154107     0.0392091    0.141503    -0.111112      0.182377 
 -0.0434477   -0.243494   -0.379402     -0.229556     0.0644945   -0.834517    0.419685   -0.0432427   0.809823     0.674685   -0.0234712   -0.0605391   0.229766   -0.225007     0.743489    -0.0945318   0.17877     -0.348105     0.0137471    0.113865      0.410976   -0.00809407   0.0958746   -0.172386     0.0162501     0.148791 
 -0.136842     0.349537    0.636831      0.605556     0.289884     0.57277    -0.428668   -0.363517   -0.669405    -0.0341005   0.0474209    0.755626    0.388555    0.692822    -0.337255     0.600065    0.153104     0.461158    -0.329255    -0.0161907    -0.374261    0.338186    -0.347935     0.153437     0.00234557   -0.218406 
  0.00348406  -0.263788   -0.0634072    -0.499967    -0.320735     0.277583    0.719995   -0.42977     0.0383273   -0.242773   -0.145832    -0.282952   -0.347395   -0.438974    -0.0889631   -0.900097    0.0960455   -0.504011    -0.166916    -0.20558       0.213327   -0.547573    -0.316313     0.112356    -0.232659     -0.137585 
 -0.216551     0.729012   -0.375041      0.00819188  -0.648715     0.400947   -0.118749   -0.0917829   0.303023     0.291815   -0.219638    -0.204731   -0.0527019  -0.0409714    0.268382    -0.306648    0.397761     0.881373     0.709985    -0.0186316     0.408173   -0.158498    -0.516581     0.0881778   -0.0766527     0.156113 
  0.466568     0.244069    0.119658     -0.0914087    0.00615361   0.588795   -0.414347    0.122257   -0.133754     0.0358305  -0.505829     0.0431256  -0.142255   -0.53604     -0.0068069   -0.176052    0.180667    -0.108763    -0.418622     0.134329     -0.268328   -0.654954    -0.307236    -0.173232    -0.0900815     0.294989 
 -0.116127    -0.0556958   0.143251     -0.017918     0.132648    -0.14846     0.191941    0.0681994  -0.181689     0.0662719  -0.313996     0.127232   -0.161667   -0.115182    -0.141554    -0.0460806  -0.418368     0.282699     0.247309     0.184185     -0.120123    0.266304     0.127097     0.335396     0.000850402   0.14949  
 -0.120111     0.269455   -0.155234      0.423796     0.182542    -0.110096   -0.291477    0.447159   -0.141702     0.14612     0.255622     0.0466779   0.31673    -0.0923164    0.306177     0.554638   -0.185459     0.754299     0.0608411    0.390276     -0.067129    0.711416     0.421881    -0.132113     0.191409      0.40321  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402738
INFO: iteration 2, average log likelihood -1.402728
INFO: iteration 3, average log likelihood -1.402719
INFO: iteration 4, average log likelihood -1.402709
INFO: iteration 5, average log likelihood -1.402699
INFO: iteration 6, average log likelihood -1.402690
INFO: iteration 7, average log likelihood -1.402681
INFO: iteration 8, average log likelihood -1.402671
INFO: iteration 9, average log likelihood -1.402662
INFO: iteration 10, average log likelihood -1.402653
INFO: EM with 100000 data points 10 iterations avll -1.402653
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
