>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.787
Commit c71f205 (2016-09-26 16:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (675.5078125 MB free)
Uptime: 23377.0 sec
Load Avg:  1.13037109375  1.04833984375  1.04541015625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1358102 s       7792 s     159630 s     508238 s         56 s
#2  3499 MHz     622055 s        406 s      87382 s    1481877 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-3.583232302955672e6,[98484.1,1515.94],
[-1941.51 2306.05 -2135.71; 2000.29 -2157.7 2308.18],

Array{Float64,2}[
[95230.9 2579.26 -2687.05; 2579.26 95607.5 3122.7; -2687.05 3122.7 95851.9],

[3775.63 -2433.76 2483.17; -2433.76 4197.13 -2792.06; 2483.17 -2792.06 4602.93]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.534380e+03
      1       1.656623e+03      -8.777573e+02 |        7
      2       1.345245e+03      -3.113778e+02 |        5
      3       1.288526e+03      -5.671960e+01 |        2
      4       1.268687e+03      -1.983825e+01 |        2
      5       1.248290e+03      -2.039733e+01 |        2
      6       1.247448e+03      -8.415946e-01 |        0
      7       1.247448e+03       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 1247.4484135174189)
INFO: K-means with 272 data points using 7 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.087964
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.882288
INFO: iteration 2, lowerbound -3.791550
INFO: iteration 3, lowerbound -3.679008
INFO: iteration 4, lowerbound -3.509120
INFO: iteration 5, lowerbound -3.276531
INFO: iteration 6, lowerbound -3.004170
INFO: iteration 7, lowerbound -2.747880
INFO: dropping number of Gaussions to 7
INFO: iteration 8, lowerbound -2.550493
INFO: dropping number of Gaussions to 6
INFO: iteration 9, lowerbound -2.430624
INFO: dropping number of Gaussions to 5
INFO: iteration 10, lowerbound -2.362452
INFO: dropping number of Gaussions to 4
INFO: iteration 11, lowerbound -2.326911
INFO: dropping number of Gaussions to 3
INFO: iteration 12, lowerbound -2.311160
INFO: dropping number of Gaussions to 2
INFO: iteration 13, lowerbound -2.302975
INFO: iteration 14, lowerbound -2.299265
INFO: iteration 15, lowerbound -2.299258
INFO: iteration 16, lowerbound -2.299255
INFO: iteration 17, lowerbound -2.299254
INFO: iteration 18, lowerbound -2.299254
INFO: iteration 19, lowerbound -2.299253
INFO: iteration 20, lowerbound -2.299253
INFO: iteration 21, lowerbound -2.299253
INFO: iteration 22, lowerbound -2.299253
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Tue 27 Sep 2016 10:59:20 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Tue 27 Sep 2016 10:59:22 AM UTC: K-means with 272 data points using 7 iterations
11.3 data points per parameter
,Tue 27 Sep 2016 10:59:24 AM UTC: EM with 272 data points 0 iterations avll -2.087964
5.8 data points per parameter
,Tue 27 Sep 2016 10:59:24 AM UTC: GMM converted to Variational GMM
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 1, lowerbound -3.882288
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 2, lowerbound -3.791550
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 3, lowerbound -3.679008
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 4, lowerbound -3.509120
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 5, lowerbound -3.276531
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 6, lowerbound -3.004170
,Tue 27 Sep 2016 10:59:27 AM UTC: iteration 7, lowerbound -2.747880
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 7
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 8, lowerbound -2.550493
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 6
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 9, lowerbound -2.430624
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 5
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 10, lowerbound -2.362452
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 4
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 11, lowerbound -2.326911
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 3
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 12, lowerbound -2.311160
,Tue 27 Sep 2016 10:59:28 AM UTC: dropping number of Gaussions to 2
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 13, lowerbound -2.302975
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 14, lowerbound -2.299265
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 15, lowerbound -2.299258
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 16, lowerbound -2.299255
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 17, lowerbound -2.299254
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 18, lowerbound -2.299254
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 19, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:28 AM UTC: iteration 20, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 21, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 22, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 23, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 24, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 25, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 26, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 27, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 28, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 29, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 30, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 31, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 32, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 33, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 34, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:29 AM UTC: iteration 35, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 36, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 37, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 38, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 39, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 40, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 41, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 42, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 43, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 44, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 45, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 46, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 47, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 48, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 49, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: iteration 50, lowerbound -2.299253
,Tue 27 Sep 2016 10:59:30 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.9549,178.045]
Î² = [95.9549,178.045]
m = [2.00023 53.852; 4.2503 79.2869]
Î½ = [97.9549,180.045]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.375876 -0.00895312; 0.0 0.0127487],

[0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9831339752641519
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -0.9831339752641517
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -0.9831339752641518
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9708867823427115
avll from llpg:  -0.9708867823427116
avll direct:     -0.9708867823427116
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.120822     0.094639     -0.0314736   0.0825911   0.00890014   -0.0603355   -0.12861     -0.0582097    0.0578566    0.0235654     0.0120762   -0.146497     -0.203518     0.0486262   -0.165493    -0.0368442   0.0112203    0.0361201    0.0694366    0.00880366    0.0252596    -0.0309046   -0.105966    -0.0923825     0.106236    -0.0651931 
 -0.00110214   0.084688      0.0532046   0.109019    0.119574     -0.0290582    0.0226923    0.0628915   -0.176939    -0.1475       -0.0062397   -0.133211      0.0142372    0.306299    -0.00552232  -0.0863293  -0.100121    -0.0274548   -0.0489046    0.115552      0.0388471    -0.193018     0.0559785   -0.110085     -0.15216     -0.0586247 
 -0.00357339  -0.0395456     0.115158   -0.0167093  -0.0453397    -0.0736905    0.147215     0.170625     0.0195343   -0.184861     -0.138785    -0.182375      0.0447169   -0.116315     0.0842929   -0.211408    0.089715    -0.0711175    0.0478167    0.171635      0.00882838   -0.0471641    0.0262197   -0.0798203     0.0265693    0.0119269 
 -0.0930805   -0.000535322   0.145089    0.04795     0.075642     -0.0195213    0.152169     0.0245328    0.0759146   -0.153319      0.135197     0.0484444    -0.0826996    0.0310014    0.00787172   0.0917419  -0.148344     0.11823     -0.115788     0.0922754     0.0479096     0.0299082    0.0324732    0.0849366     0.0682391   -0.118398  
  0.0740734   -0.0819183    -0.0541792  -0.141794    0.0302266    -0.00976308   0.183772     0.177199    -0.00487442  -0.0793619    -0.290383    -0.0753676     0.0429301   -0.211865    -0.146416    -0.0286131   0.00102604  -0.0546036    0.148539    -0.055446      0.11194      -0.11518      0.151709     0.00506492   -0.0285083   -0.0812465 
  0.0424867   -0.0214554     0.0277243  -0.0742583   0.076081      0.103315     0.11201     -0.0260493   -0.0584791   -0.111343      0.0139871   -0.0135222    -0.121756    -0.0898021   -0.218903     0.0646411   0.00210379   0.0514091   -0.0118086    0.121694     -0.0782727     0.14105      0.0704365    0.0144692     0.125171    -0.00907391
 -0.127713    -0.066763      0.169026    0.017207   -0.04353      -0.0168207   -0.0315846    0.0692391    0.0324176   -0.0523827     0.0901079    0.0362867     0.0727659   -0.056739    -0.00765859  -0.0970064  -0.0182148    0.0209639    0.160155    -0.0498431     0.0773095     0.0803816   -0.0713783   -0.0387608    -0.0357041    0.0668722 
 -0.141367     0.116309      0.0764431  -0.0528107   0.0587268    -0.0500541    0.0596644   -0.0661821   -0.0830895    0.0967652     0.0943335    0.161383      0.0112436    0.0311566   -0.00912932  -0.203839   -0.0984034   -0.0411272    0.127299     0.0326102     0.0768147    -0.0578118    0.00712434  -0.152232      0.0450008   -0.0308201 
  0.0980812    0.0698441    -0.0767222   0.0655732  -0.107041     -0.0592727   -0.0609613   -0.0983483   -0.174808    -0.0734662    -0.0561448    0.114169     -0.166852     6.66786e-5   0.0462754    0.0269265   0.101001     0.193854     0.300639    -0.0849563    -0.0728236     0.0350367    0.0873948    0.00406332   -0.0532485    0.117101  
 -0.011246    -0.0744345    -0.0898302  -0.126169    0.0766473    -0.0101576   -0.00512363   0.129692     0.00235636  -0.0938585     0.160733    -0.122325     -0.0879058   -0.0920547    0.0749976   -0.0257592  -0.018723    -0.0547611   -0.0136461   -0.100403      0.158468      0.115817     0.0467829    0.0621819    -0.1846      -0.0180702 
  0.0905545    0.0375373     0.059672    0.067393   -0.073253      0.0112547    0.124249    -0.069314     0.183095    -0.0509037    -0.0750021    0.076485     -0.0849733    0.0527874    0.211314    -0.0414393   0.109915    -0.0604375    0.189956     0.0609565     0.0819492     0.0711361   -0.0207406    0.00899839    0.140552    -0.1148    
 -0.0942058    0.0414615    -0.0202897   0.049838   -0.0555472     0.216226    -0.00879577   0.0636218   -0.00259647   0.16874       0.0488674   -0.117778      0.0900887   -0.078374    -0.0691882   -0.0195575   0.0656081    0.0394012    0.0703396    0.0738059    -0.0920761     0.074668    -0.00196844   0.03065       0.0531796    0.0139869 
 -0.169953    -0.027749      0.252679    0.146526   -0.195224     -0.00901116  -0.117091     0.0901543    0.136043     0.00194809   -0.0200263   -0.00262985    0.0107724    0.0798836    0.134597     0.0616939   0.0190328    0.248671     0.00669285  -0.169646      0.0036779     0.0144163   -0.0331405    0.0949468    -0.14212      0.109865  
  0.0540773    0.264382     -0.121213    0.0751022  -0.00493958    0.0251458    0.00204286   0.149886     0.00158074   0.221132     -0.126259     0.0613739    -0.211097     0.0222947    0.0761905   -0.058405   -0.0849916    0.14648      0.0769453   -0.00402659   -0.164837     -0.11124     -0.134289    -0.205739      0.1291      -0.155829  
  0.0075026   -0.126539      0.0342554  -0.121688    0.190898     -0.240265     0.079305     0.212811    -0.0542659   -0.0694371     0.0809231   -0.259275     -0.192713    -0.0503715    0.00222591   0.191841   -0.0247115   -0.0629708    0.0161541   -0.0741662     0.0233438     0.0372153    0.0623185    0.0968664    -0.00878034   0.0265685 
  0.0838919    0.189739      0.0522385   0.0788314   0.0795045     0.111209    -0.0512163    0.00122347  -0.079909    -0.000241518   0.0529925   -0.137682     -0.0325901    0.118757     0.0797195    0.145087    0.00904252  -0.100194     0.0620996    0.0756703     0.0115043    -0.16645     -0.160913    -0.0657788    -0.0561021    0.17788   
 -0.00533104   0.167826     -0.0855911  -0.0263675   0.0120481     0.195735     0.0585174   -0.0729007   -0.0107604    0.117569     -0.00295085  -0.0662418     0.0501068    0.0828548    0.0579178    0.0336181   0.1968      -0.0629367   -0.196498     0.0245373     0.126174      0.00700801   0.0254145    0.0148796     0.0857101   -0.0253069 
 -0.0264809   -0.273719     -0.212048   -0.0507946  -0.039577     -0.121598    -0.0669318   -0.112874     0.0424894   -0.0563371     0.0159349    0.0323215    -0.00495169   0.0789134   -0.00262447  -0.0494616  -0.0440081   -0.0928038   -0.0921173   -0.222522     -0.190625      0.273761    -0.0592487   -0.0315832    -0.019128    -0.0691461 
 -0.0125826    0.0342636    -0.0229005   0.0319419  -0.103203      0.189945    -0.0225172    0.00677691  -0.0349992    0.00475628    0.0463188   -0.006421      0.137025     0.0259768    0.15012      0.0578318   0.138809    -0.0240162    0.0495507    0.121289     -0.000668117  -0.0286728   -0.0286343   -0.170402     -0.117081     0.0325544 
 -0.0677331   -0.0709364    -0.131268    0.179501    0.00945163   -0.0056808    0.00880395   0.0551018    0.0505898    0.0415121    -0.0762067    0.137626     -0.0530882   -0.179932     0.00113836   0.0660337   0.0637748    0.0466222    0.0101372    0.0471599     0.09292       0.00867189  -0.231139     0.226045     -0.0726361    0.193591  
  0.0670477    0.0834597    -0.0086829   0.119396    0.0936659    -0.0232441    0.00915219   0.0771121   -0.0183904    0.0029077     0.00261974  -0.0439141     0.0875254   -0.122556     0.120205     0.168152    0.0278703   -0.0803579    0.0329051   -0.119158      0.127194      0.17899     -0.056856     0.000472262   0.0397124    0.0605855 
 -0.0713579   -0.0239643    -0.117335   -0.0103829   0.041424     -0.00924604  -0.064962     0.197989    -0.0701423    0.034039     -0.0411315   -0.0142791     0.0123096   -0.0586798   -0.0746772    0.0914555  -0.100128     0.0547581    0.0329849   -0.138175     -0.0399578     0.0117545   -0.0312871    0.155368      0.0778495   -0.080039  
  0.0783784    0.221822     -0.0554956  -0.0694114   0.172954     -0.114222    -0.221122     0.0221357   -0.0535644    0.0922071    -0.0514943   -0.0927078     0.150404     0.054079     0.153866    -0.0234742  -0.238512     0.0861253   -0.079779    -0.0650947    -0.0618681    -0.0275135   -0.0015508   -0.101269      0.0173931    0.0136997 
 -0.0529489   -0.188879      0.164921    0.0203498   0.0183179     0.0208261    0.168229     0.10914     -0.0812523    0.0145752    -0.0159966    0.112264     -0.0353301    0.0560614    0.138199     0.212185   -0.228563    -0.0036025    0.0993138    0.0162916    -0.0862781     0.0024494    0.0183155   -0.0120511     0.0717833    0.0473859 
  0.0269826    0.0134161     0.0953768   0.0511653  -0.04796       0.0988589   -0.112648    -0.108932    -0.0220965   -0.015594     -0.152414    -0.154356      0.0034216    0.0267448    0.0610897    0.0556149   0.0555065    0.182278     0.0179641   -0.000171544   0.0870453     0.034138     0.0323371    0.0234826     0.0374954   -0.0283771 
  0.117465    -0.154135     -0.0577824  -0.139977    0.143977     -0.134604     0.0950945   -0.0230483   -0.0620732    0.0612383     0.183242     0.0357423     0.0332732    0.0345328   -0.138756     0.0163274   0.0592153    0.211633    -0.0738916   -0.0709147    -0.0430086    -0.112183    -0.0297519   -0.0253923     0.020429     0.0391898 
  0.119341    -0.128995      0.0275185  -0.0392097   0.126504     -0.0436401   -0.011029     0.0265204   -0.0931431   -0.0734001     0.0804444   -0.223186      0.0208915   -0.0796187    0.0710439   -0.181871   -0.0354613   -0.00372173  -0.175783     0.0228316     0.043386     -0.0532185   -0.0278105   -0.0544475     0.129448    -0.0245338 
  0.0792224   -0.0459159     0.0817034   0.062773   -0.071761      0.0458559    0.195421     0.126873     0.197507    -0.0394232     0.177786    -0.253479      0.180432     0.111539    -0.00230542   0.0989483   0.0174781   -0.0321431    0.052766    -0.0445887    -0.0113745    -0.0729594   -0.0453401    0.0286845     0.0596298    0.0523009 
  0.0622326    0.0125335    -0.0834563  -0.0806732   0.169292     -0.123955     0.0502374   -0.00562232   0.00989679  -0.0641349     0.0134418    0.0498819     0.074588    -0.0122959   -0.0627185   -0.128696    0.0509754   -0.0194903    0.122601    -0.138049     -0.0245971    -0.0101158   -0.0502187   -0.13658       0.0181302    0.105721  
  0.0857082   -0.139032     -0.107695    0.0244153  -0.000258133  -0.0934185   -0.0210735   -0.0119911    0.0599986    0.0307986    -0.0173323    0.000317228  -0.0447839   -0.0554781   -0.00759706   0.146903   -0.0451992   -0.00204091   0.128335     0.273433      0.00275796   -0.00857328   0.00241824   0.0838757     0.0278555   -0.0981573 
  0.0932729   -0.0276883    -0.172494    0.0696695   0.0642843     0.0412953    0.0433413    0.0146316   -0.0380814    0.117688      0.228219    -0.0246326    -0.0699567    0.0443851   -0.0201906    0.0192866  -0.0681152   -0.120552    -0.0252397   -0.0663804     0.211018     -0.261129     0.116223    -0.0871609     0.1413      -0.0678791 
 -0.0874913   -0.14988      -0.0465689   0.126671   -0.0225584    -0.268187     0.0903342   -0.0176601    0.20149      0.00734859    0.0956253   -0.0349247     0.0350396   -0.0419912    0.0444115    0.174692   -0.016719    -0.0684187    0.0527005   -0.184084      0.220001      0.200762    -0.0439304   -0.0386366     0.152428    -0.204972  kind diag, method split
0: avll = -1.4258899433028103
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.425984
INFO: iteration 2, average log likelihood -1.425904
INFO: iteration 3, average log likelihood -1.425333
INFO: iteration 4, average log likelihood -1.416575
INFO: iteration 5, average log likelihood -1.391149
INFO: iteration 6, average log likelihood -1.382748
INFO: iteration 7, average log likelihood -1.381606
INFO: iteration 8, average log likelihood -1.381078
INFO: iteration 9, average log likelihood -1.380679
INFO: iteration 10, average log likelihood -1.380406
INFO: iteration 11, average log likelihood -1.380226
INFO: iteration 12, average log likelihood -1.380119
INFO: iteration 13, average log likelihood -1.380055
INFO: iteration 14, average log likelihood -1.380013
INFO: iteration 15, average log likelihood -1.379983
INFO: iteration 16, average log likelihood -1.379963
INFO: iteration 17, average log likelihood -1.379947
INFO: iteration 18, average log likelihood -1.379936
INFO: iteration 19, average log likelihood -1.379928
INFO: iteration 20, average log likelihood -1.379922
INFO: iteration 21, average log likelihood -1.379918
INFO: iteration 22, average log likelihood -1.379915
INFO: iteration 23, average log likelihood -1.379913
INFO: iteration 24, average log likelihood -1.379912
INFO: iteration 25, average log likelihood -1.379911
INFO: iteration 26, average log likelihood -1.379910
INFO: iteration 27, average log likelihood -1.379910
INFO: iteration 28, average log likelihood -1.379909
INFO: iteration 29, average log likelihood -1.379909
INFO: iteration 30, average log likelihood -1.379909
INFO: iteration 31, average log likelihood -1.379909
INFO: iteration 32, average log likelihood -1.379908
INFO: iteration 33, average log likelihood -1.379908
INFO: iteration 34, average log likelihood -1.379908
INFO: iteration 35, average log likelihood -1.379908
INFO: iteration 36, average log likelihood -1.379908
INFO: iteration 37, average log likelihood -1.379908
INFO: iteration 38, average log likelihood -1.379908
INFO: iteration 39, average log likelihood -1.379908
INFO: iteration 40, average log likelihood -1.379907
INFO: iteration 41, average log likelihood -1.379907
INFO: iteration 42, average log likelihood -1.379907
INFO: iteration 43, average log likelihood -1.379907
INFO: iteration 44, average log likelihood -1.379907
INFO: iteration 45, average log likelihood -1.379907
INFO: iteration 46, average log likelihood -1.379907
INFO: iteration 47, average log likelihood -1.379907
INFO: iteration 48, average log likelihood -1.379907
INFO: iteration 49, average log likelihood -1.379907
INFO: iteration 50, average log likelihood -1.379907
INFO: EM with 100000 data points 50 iterations avll -1.379907
952.4 data points per parameter
1: avll = [-1.42598,-1.4259,-1.42533,-1.41658,-1.39115,-1.38275,-1.38161,-1.38108,-1.38068,-1.38041,-1.38023,-1.38012,-1.38005,-1.38001,-1.37998,-1.37996,-1.37995,-1.37994,-1.37993,-1.37992,-1.37992,-1.37992,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.380052
INFO: iteration 2, average log likelihood -1.379930
INFO: iteration 3, average log likelihood -1.379527
INFO: iteration 4, average log likelihood -1.375128
INFO: iteration 5, average log likelihood -1.358647
INFO: iteration 6, average log likelihood -1.345787
INFO: iteration 7, average log likelihood -1.341183
INFO: iteration 8, average log likelihood -1.338535
INFO: iteration 9, average log likelihood -1.336443
INFO: iteration 10, average log likelihood -1.334570
INFO: iteration 11, average log likelihood -1.332934
INFO: iteration 12, average log likelihood -1.331783
INFO: iteration 13, average log likelihood -1.331086
INFO: iteration 14, average log likelihood -1.330678
INFO: iteration 15, average log likelihood -1.330437
INFO: iteration 16, average log likelihood -1.330289
INFO: iteration 17, average log likelihood -1.330194
INFO: iteration 18, average log likelihood -1.330125
INFO: iteration 19, average log likelihood -1.330069
INFO: iteration 20, average log likelihood -1.330017
INFO: iteration 21, average log likelihood -1.329964
INFO: iteration 22, average log likelihood -1.329912
INFO: iteration 23, average log likelihood -1.329863
INFO: iteration 24, average log likelihood -1.329819
INFO: iteration 25, average log likelihood -1.329783
INFO: iteration 26, average log likelihood -1.329753
INFO: iteration 27, average log likelihood -1.329730
INFO: iteration 28, average log likelihood -1.329712
INFO: iteration 29, average log likelihood -1.329700
INFO: iteration 30, average log likelihood -1.329690
INFO: iteration 31, average log likelihood -1.329683
INFO: iteration 32, average log likelihood -1.329678
INFO: iteration 33, average log likelihood -1.329674
INFO: iteration 34, average log likelihood -1.329670
INFO: iteration 35, average log likelihood -1.329667
INFO: iteration 36, average log likelihood -1.329665
INFO: iteration 37, average log likelihood -1.329663
INFO: iteration 38, average log likelihood -1.329662
INFO: iteration 39, average log likelihood -1.329660
INFO: iteration 40, average log likelihood -1.329659
INFO: iteration 41, average log likelihood -1.329658
INFO: iteration 42, average log likelihood -1.329657
INFO: iteration 43, average log likelihood -1.329656
INFO: iteration 44, average log likelihood -1.329654
INFO: iteration 45, average log likelihood -1.329653
INFO: iteration 46, average log likelihood -1.329651
INFO: iteration 47, average log likelihood -1.329650
INFO: iteration 48, average log likelihood -1.329648
INFO: iteration 49, average log likelihood -1.329646
INFO: iteration 50, average log likelihood -1.329643
INFO: EM with 100000 data points 50 iterations avll -1.329643
473.9 data points per parameter
2: avll = [-1.38005,-1.37993,-1.37953,-1.37513,-1.35865,-1.34579,-1.34118,-1.33854,-1.33644,-1.33457,-1.33293,-1.33178,-1.33109,-1.33068,-1.33044,-1.33029,-1.33019,-1.33013,-1.33007,-1.33002,-1.32996,-1.32991,-1.32986,-1.32982,-1.32978,-1.32975,-1.32973,-1.32971,-1.3297,-1.32969,-1.32968,-1.32968,-1.32967,-1.32967,-1.32967,-1.32967,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32965,-1.32965,-1.32965,-1.32965,-1.32965,-1.32965,-1.32964]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.329873
INFO: iteration 2, average log likelihood -1.329633
INFO: iteration 3, average log likelihood -1.328346
INFO: iteration 4, average log likelihood -1.319135
INFO: iteration 5, average log likelihood -1.300668
INFO: iteration 6, average log likelihood -1.284512
INFO: iteration 7, average log likelihood -1.274592
INFO: iteration 8, average log likelihood -1.268926
INFO: iteration 9, average log likelihood -1.266452
INFO: iteration 10, average log likelihood -1.265424
INFO: iteration 11, average log likelihood -1.264627
INFO: iteration 12, average log likelihood -1.263836
INFO: iteration 13, average log likelihood -1.263019
INFO: iteration 14, average log likelihood -1.262208
INFO: iteration 15, average log likelihood -1.261496
INFO: iteration 16, average log likelihood -1.260987
INFO: iteration 17, average log likelihood -1.260680
INFO: iteration 18, average log likelihood -1.260493
INFO: iteration 19, average log likelihood -1.260373
INFO: iteration 20, average log likelihood -1.260294
INFO: iteration 21, average log likelihood -1.260241
INFO: iteration 22, average log likelihood -1.260205
INFO: iteration 23, average log likelihood -1.260180
INFO: iteration 24, average log likelihood -1.260163
INFO: iteration 25, average log likelihood -1.260151
INFO: iteration 26, average log likelihood -1.260142
INFO: iteration 27, average log likelihood -1.260135
INFO: iteration 28, average log likelihood -1.260129
INFO: iteration 29, average log likelihood -1.260125
INFO: iteration 30, average log likelihood -1.260122
INFO: iteration 31, average log likelihood -1.260119
INFO: iteration 32, average log likelihood -1.260117
INFO: iteration 33, average log likelihood -1.260115
INFO: iteration 34, average log likelihood -1.260113
INFO: iteration 35, average log likelihood -1.260111
INFO: iteration 36, average log likelihood -1.260110
INFO: iteration 37, average log likelihood -1.260109
INFO: iteration 38, average log likelihood -1.260108
INFO: iteration 39, average log likelihood -1.260107
INFO: iteration 40, average log likelihood -1.260106
INFO: iteration 41, average log likelihood -1.260105
INFO: iteration 42, average log likelihood -1.260104
INFO: iteration 43, average log likelihood -1.260104
INFO: iteration 44, average log likelihood -1.260103
INFO: iteration 45, average log likelihood -1.260102
INFO: iteration 46, average log likelihood -1.260102
INFO: iteration 47, average log likelihood -1.260101
INFO: iteration 48, average log likelihood -1.260101
INFO: iteration 49, average log likelihood -1.260100
INFO: iteration 50, average log likelihood -1.260100
INFO: EM with 100000 data points 50 iterations avll -1.260100
236.4 data points per parameter
3: avll = [-1.32987,-1.32963,-1.32835,-1.31913,-1.30067,-1.28451,-1.27459,-1.26893,-1.26645,-1.26542,-1.26463,-1.26384,-1.26302,-1.26221,-1.2615,-1.26099,-1.26068,-1.26049,-1.26037,-1.26029,-1.26024,-1.2602,-1.26018,-1.26016,-1.26015,-1.26014,-1.26013,-1.26013,-1.26013,-1.26012,-1.26012,-1.26012,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.260416
INFO: iteration 2, average log likelihood -1.260004
INFO: iteration 3, average log likelihood -1.256305
WARNING: Variances had to be floored 1
INFO: iteration 4, average log likelihood -1.228068
INFO: iteration 5, average log likelihood -1.203347
WARNING: Variances had to be floored 1 13
INFO: iteration 6, average log likelihood -1.175658
WARNING: Variances had to be floored 9
INFO: iteration 7, average log likelihood -1.186889
WARNING: Variances had to be floored 1
INFO: iteration 8, average log likelihood -1.174533
WARNING: Variances had to be floored 13
INFO: iteration 9, average log likelihood -1.172030
WARNING: Variances had to be floored 1
INFO: iteration 10, average log likelihood -1.164829
WARNING: Variances had to be floored 9 12
INFO: iteration 11, average log likelihood -1.163317
WARNING: Variances had to be floored 1 13
INFO: iteration 12, average log likelihood -1.169617
INFO: iteration 13, average log likelihood -1.179468
WARNING: Variances had to be floored 1
INFO: iteration 14, average log likelihood -1.157719
WARNING: Variances had to be floored 9 13
INFO: iteration 15, average log likelihood -1.160475
WARNING: Variances had to be floored 1 12
INFO: iteration 16, average log likelihood -1.164719
INFO: iteration 17, average log likelihood -1.178002
WARNING: Variances had to be floored 1 13
INFO: iteration 18, average log likelihood -1.157780
WARNING: Variances had to be floored 9
INFO: iteration 19, average log likelihood -1.172316
WARNING: Variances had to be floored 1
INFO: iteration 20, average log likelihood -1.160502
WARNING: Variances had to be floored 1 12 13
INFO: iteration 21, average log likelihood -1.160234
INFO: iteration 22, average log likelihood -1.182107
WARNING: Variances had to be floored 1 9
INFO: iteration 23, average log likelihood -1.159457
WARNING: Variances had to be floored 13
INFO: iteration 24, average log likelihood -1.167151
WARNING: Variances had to be floored 1 11 12
INFO: iteration 25, average log likelihood -1.157691
INFO: iteration 26, average log likelihood -1.178668
WARNING: Variances had to be floored 1 9 13
INFO: iteration 27, average log likelihood -1.159087
INFO: iteration 28, average log likelihood -1.178973
WARNING: Variances had to be floored 1
INFO: iteration 29, average log likelihood -1.152383
WARNING: Variances had to be floored 11 12 13
INFO: iteration 30, average log likelihood -1.153081
WARNING: Variances had to be floored 1 9
INFO: iteration 31, average log likelihood -1.172743
WARNING: Variances had to be floored 1
INFO: iteration 32, average log likelihood -1.176866
WARNING: Variances had to be floored 1 13
INFO: iteration 33, average log likelihood -1.163111
WARNING: Variances had to be floored 1
INFO: iteration 34, average log likelihood -1.164284
WARNING: Variances had to be floored 1 9 11 12
INFO: iteration 35, average log likelihood -1.153812
WARNING: Variances had to be floored 13
INFO: iteration 36, average log likelihood -1.178149
WARNING: Variances had to be floored 1
INFO: iteration 37, average log likelihood -1.168549
WARNING: Variances had to be floored 1
INFO: iteration 38, average log likelihood -1.164619
WARNING: Variances had to be floored 1 9 13
INFO: iteration 39, average log likelihood -1.153925
WARNING: Variances had to be floored 1 11 12
INFO: iteration 40, average log likelihood -1.166552
WARNING: Variances had to be floored 1
INFO: iteration 41, average log likelihood -1.177464
WARNING: Variances had to be floored 13
INFO: iteration 42, average log likelihood -1.166703
WARNING: Variances had to be floored 1 9
INFO: iteration 43, average log likelihood -1.159842
WARNING: Variances had to be floored 1
INFO: iteration 44, average log likelihood -1.163885
WARNING: Variances had to be floored 1 11 12 13
INFO: iteration 45, average log likelihood -1.152869
INFO: iteration 46, average log likelihood -1.181823
WARNING: Variances had to be floored 1 9
INFO: iteration 47, average log likelihood -1.159603
WARNING: Variances had to be floored 1 13
INFO: iteration 48, average log likelihood -1.166883
WARNING: Variances had to be floored 1
INFO: iteration 49, average log likelihood -1.165947
WARNING: Variances had to be floored 1 11 12
INFO: iteration 50, average log likelihood -1.154548
INFO: EM with 100000 data points 50 iterations avll -1.154548
118.1 data points per parameter
4: avll = [-1.26042,-1.26,-1.25631,-1.22807,-1.20335,-1.17566,-1.18689,-1.17453,-1.17203,-1.16483,-1.16332,-1.16962,-1.17947,-1.15772,-1.16047,-1.16472,-1.178,-1.15778,-1.17232,-1.1605,-1.16023,-1.18211,-1.15946,-1.16715,-1.15769,-1.17867,-1.15909,-1.17897,-1.15238,-1.15308,-1.17274,-1.17687,-1.16311,-1.16428,-1.15381,-1.17815,-1.16855,-1.16462,-1.15392,-1.16655,-1.17746,-1.1667,-1.15984,-1.16388,-1.15287,-1.18182,-1.1596,-1.16688,-1.16595,-1.15455]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 17 18 25 26
INFO: iteration 1, average log likelihood -1.172118
WARNING: Variances had to be floored 1 2 17 18 25 26
INFO: iteration 2, average log likelihood -1.155838
WARNING: Variances had to be floored 1 2 17 18 25 26
INFO: iteration 3, average log likelihood -1.157663
WARNING: Variances had to be floored 1 2 16 17 18 21 25 26
INFO: iteration 4, average log likelihood -1.129915
WARNING: Variances had to be floored 1 2 11 17 18 22 24 25 26
INFO: iteration 5, average log likelihood -1.101801
WARNING: Variances had to be floored 1 2 12 16 17 18 23 25 26
INFO: iteration 6, average log likelihood -1.094803
WARNING: Variances had to be floored 1 2 17 18 25 26
INFO: iteration 7, average log likelihood -1.098099
WARNING: Variances had to be floored 1 2 11 16 17 18 22 25 26
INFO: iteration 8, average log likelihood -1.065814
WARNING: Variances had to be floored 1 2 8 12 17 18 24 25 26
INFO: iteration 9, average log likelihood -1.072114
WARNING: Variances had to be floored 1 2 11 16 17 18 23 25 26
INFO: iteration 10, average log likelihood -1.073309
WARNING: Variances had to be floored 1 2 17 18 25 26
INFO: iteration 11, average log likelihood -1.086518
WARNING: Variances had to be floored 1 2 12 16 17 18 24 25 26
INFO: iteration 12, average log likelihood -1.061503
WARNING: Variances had to be floored 1 2 11 17 18 25 26
INFO: iteration 13, average log likelihood -1.073303
WARNING: Variances had to be floored 1 2 12 16 17 18 22 23 25 26
INFO: iteration 14, average log likelihood -1.058947
WARNING: Variances had to be floored 1 2 8 11 17 18 25 26
INFO: iteration 15, average log likelihood -1.083605
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 16, average log likelihood -1.077981
WARNING: Variances had to be floored 1 2 12 16 17 18 25 26
INFO: iteration 17, average log likelihood -1.062725
WARNING: Variances had to be floored 1 2 11 16 17 18 22 23 25 26
INFO: iteration 18, average log likelihood -1.053412
WARNING: Variances had to be floored 1 2 8 12 16 17 18 25 26
INFO: iteration 19, average log likelihood -1.073579
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 20, average log likelihood -1.076838
WARNING: Variances had to be floored 1 2 11 16 17 18 25 26
INFO: iteration 21, average log likelihood -1.055608
WARNING: Variances had to be floored 1 2 8 12 16 17 18 22 23 25 26
INFO: iteration 22, average log likelihood -1.051955
WARNING: Variances had to be floored 1 2 11 16 17 18 25 26
INFO: iteration 23, average log likelihood -1.082908
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 24, average log likelihood -1.072154
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 25, average log likelihood -1.053617
WARNING: Variances had to be floored 1 2 17 18 22 23 25 26
INFO: iteration 26, average log likelihood -1.068650
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 27, average log likelihood -1.070522
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 28, average log likelihood -1.059946
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 29, average log likelihood -1.075805
WARNING: Variances had to be floored 1 2 16 17 18 22 23 25 26
INFO: iteration 30, average log likelihood -1.057199
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 31, average log likelihood -1.065516
WARNING: Variances had to be floored 1 2 17 18 25 26
INFO: iteration 32, average log likelihood -1.082304
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 33, average log likelihood -1.057200
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 22 23 25 26
INFO: iteration 34, average log likelihood -1.044699
WARNING: Variances had to be floored 2 16 17 18 25 26
INFO: iteration 35, average log likelihood -1.089366
WARNING: Variances had to be floored 1 16 17 18 25 26
INFO: iteration 36, average log likelihood -1.062814
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 37, average log likelihood -1.053418
WARNING: Variances had to be floored 1 2 16 17 18 22 23 25 26
INFO: iteration 38, average log likelihood -1.068751
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 39, average log likelihood -1.077779
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 40, average log likelihood -1.059996
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 41, average log likelihood -1.075832
WARNING: Variances had to be floored 1 2 16 17 18 22 23 25 26
INFO: iteration 42, average log likelihood -1.057222
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 43, average log likelihood -1.065533
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 44, average log likelihood -1.082323
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 45, average log likelihood -1.064395
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 22 23 25 26
INFO: iteration 46, average log likelihood -1.044710
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 47, average log likelihood -1.089366
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 48, average log likelihood -1.071467
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 49, average log likelihood -1.053260
WARNING: Variances had to be floored 1 2 16 17 18 22 23 25 26
INFO: iteration 50, average log likelihood -1.068584
INFO: EM with 100000 data points 50 iterations avll -1.068584
59.0 data points per parameter
5: avll = [-1.17212,-1.15584,-1.15766,-1.12992,-1.1018,-1.0948,-1.0981,-1.06581,-1.07211,-1.07331,-1.08652,-1.0615,-1.0733,-1.05895,-1.0836,-1.07798,-1.06272,-1.05341,-1.07358,-1.07684,-1.05561,-1.05196,-1.08291,-1.07215,-1.05362,-1.06865,-1.07052,-1.05995,-1.07581,-1.0572,-1.06552,-1.0823,-1.0572,-1.0447,-1.08937,-1.06281,-1.05342,-1.06875,-1.07778,-1.06,-1.07583,-1.05722,-1.06553,-1.08232,-1.0644,-1.04471,-1.08937,-1.07147,-1.05326,-1.06858]
[-1.42589,-1.42598,-1.4259,-1.42533,-1.41658,-1.39115,-1.38275,-1.38161,-1.38108,-1.38068,-1.38041,-1.38023,-1.38012,-1.38005,-1.38001,-1.37998,-1.37996,-1.37995,-1.37994,-1.37993,-1.37992,-1.37992,-1.37992,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.37991,-1.38005,-1.37993,-1.37953,-1.37513,-1.35865,-1.34579,-1.34118,-1.33854,-1.33644,-1.33457,-1.33293,-1.33178,-1.33109,-1.33068,-1.33044,-1.33029,-1.33019,-1.33013,-1.33007,-1.33002,-1.32996,-1.32991,-1.32986,-1.32982,-1.32978,-1.32975,-1.32973,-1.32971,-1.3297,-1.32969,-1.32968,-1.32968,-1.32967,-1.32967,-1.32967,-1.32967,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32966,-1.32965,-1.32965,-1.32965,-1.32965,-1.32965,-1.32965,-1.32964,-1.32987,-1.32963,-1.32835,-1.31913,-1.30067,-1.28451,-1.27459,-1.26893,-1.26645,-1.26542,-1.26463,-1.26384,-1.26302,-1.26221,-1.2615,-1.26099,-1.26068,-1.26049,-1.26037,-1.26029,-1.26024,-1.2602,-1.26018,-1.26016,-1.26015,-1.26014,-1.26013,-1.26013,-1.26013,-1.26012,-1.26012,-1.26012,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.26011,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.2601,-1.26042,-1.26,-1.25631,-1.22807,-1.20335,-1.17566,-1.18689,-1.17453,-1.17203,-1.16483,-1.16332,-1.16962,-1.17947,-1.15772,-1.16047,-1.16472,-1.178,-1.15778,-1.17232,-1.1605,-1.16023,-1.18211,-1.15946,-1.16715,-1.15769,-1.17867,-1.15909,-1.17897,-1.15238,-1.15308,-1.17274,-1.17687,-1.16311,-1.16428,-1.15381,-1.17815,-1.16855,-1.16462,-1.15392,-1.16655,-1.17746,-1.1667,-1.15984,-1.16388,-1.15287,-1.18182,-1.1596,-1.16688,-1.16595,-1.15455,-1.17212,-1.15584,-1.15766,-1.12992,-1.1018,-1.0948,-1.0981,-1.06581,-1.07211,-1.07331,-1.08652,-1.0615,-1.0733,-1.05895,-1.0836,-1.07798,-1.06272,-1.05341,-1.07358,-1.07684,-1.05561,-1.05196,-1.08291,-1.07215,-1.05362,-1.06865,-1.07052,-1.05995,-1.07581,-1.0572,-1.06552,-1.0823,-1.0572,-1.0447,-1.08937,-1.06281,-1.05342,-1.06875,-1.07778,-1.06,-1.07583,-1.05722,-1.06553,-1.08232,-1.0644,-1.04471,-1.08937,-1.07147,-1.05326,-1.06858]
32Ã—26 Array{Float64,2}:
 -0.326054     -0.0793015   -0.0881663  -0.0565131   0.15843     -0.00735619  -0.00660087   0.130103     -0.2282      -0.082117      0.159594     0.236918   -0.0920917   -0.145722     0.0549323   -0.0250534   -0.166432     0.0649967     0.0163424   -0.0994648    0.186779     0.115779     0.0472295     0.0618869   -0.182951     -0.194607  
  0.893615     -0.032974    -0.113055    0.0399436  -0.0942669   -0.0143892   -0.00616202   0.133098      0.529892    -0.118965      0.163366    -0.936899   -0.108695    -0.0792704    0.0752287   -0.0205896    0.0945293   -0.309158     -0.0433395   -0.100455     0.222316     0.116053     0.0479621     0.0597819   -0.163548      0.439141  
 -0.0449557    -0.018067    -0.121418   -0.0317767   0.0317419   -0.00671694  -0.0487513    0.193572     -0.0674607    0.0256657    -0.044758    -0.0103434   0.0238947   -0.0402536    0.00156146   0.0881849   -0.0720627    0.0765099    -0.018727    -0.149273    -0.0413505    0.0189356   -0.0184561     0.146644    -1.3065       -0.0809005 
 -0.09002      -0.0264017   -0.132924    0.040573    0.0549886   -0.0112098   -0.0766668    0.189592     -0.0695188    0.0460198    -0.0399563   -0.0176783  -0.0685214   -0.0625371   -0.14556      0.0972602   -0.184976     0.0553485     0.0794711   -0.133301    -0.0559501    0.0222624   -0.0497668     0.171635     1.20954      -0.0802329 
  0.00363247    0.076597     0.0737403   0.113318    0.139381    -0.0326344    0.022953     0.0594202    -0.165884    -0.138672     -0.00724889  -0.133808    0.0138008    0.29651     -0.00141534  -0.0902461   -0.0965699   -0.0154891    -0.018147     0.0992452    0.0425083   -0.186721     0.0379907    -0.107332    -0.133224     -0.0526526 
  0.0435826     0.025565     0.0360656  -0.0803764   0.072618     0.10141      0.121068    -0.0283571    -0.0703027   -0.108148      0.0138147   -0.0138561  -0.0663627   -0.0856864   -0.235379     0.0743956   -0.0205018    0.0122817     0.0201263    0.139654    -0.0725666    0.132534     0.043845     -0.00274623   0.123937     -0.00740292
  0.0315076     0.0709503   -0.0516773  -0.0258037   0.0895201   -0.0998951    0.0490045    0.157437     -0.008069     0.0729044    -0.0521446   -0.0945303  -0.193855    -0.00903399   0.029008     0.0671638   -0.054393     0.0365287     0.0503847   -0.03747     -0.0479232   -0.0587834   -0.0502773    -0.0580221    0.0734305    -0.0648896 
 -0.0947809    -0.0101387    0.167328    0.0396879   0.0736162   -0.0235978    0.166428     0.032447      0.0863114   -0.148468      0.120551     0.0151773  -0.0823406    0.0228838    0.00414118   0.0986865   -0.142065     0.103758     -0.0863356    0.115769     0.0485346    0.0298089    0.0471979     0.101089     0.0848786    -0.101289  
 -0.104451     -0.144503    -0.040908    0.124293   -0.0251992   -0.264665     0.0888982   -0.0150341     0.199829     0.000346046   0.0909597   -0.038466    0.0460832   -0.0387101    0.0465509    0.174806     0.0362724   -0.0716008     0.0270079   -0.166879     0.226303     0.202393    -0.0430145    -0.0361281    0.154099     -0.245988  
  0.086543     -0.094684    -0.0692447  -0.0622686   0.027687    -0.0492732    0.0800903    0.0681655     0.0376582   -0.0271185    -0.145407    -0.0349015   0.0133782   -0.1224      -0.0574713    0.0423903   -0.0144728   -0.0194674     0.109837     0.113768     0.0458742   -0.0474707    0.0866183     0.0423083    0.000217528  -0.0779688 
 -0.0139198    -0.0437171    0.0874639  -0.029372   -0.0445475   -0.0655534    0.165063     0.163403      0.0353293   -0.189564     -0.144513    -0.179271    0.0396568   -0.113326     0.0804768   -0.202097     0.0829952   -0.0600327     0.0583073    0.167185     0.00962486  -0.0593126    0.0251263    -0.0780142    0.041627     -0.0225504 
  0.101265      0.051635    -0.0353461   0.0638314  -0.10035     -0.0813397   -0.0539478   -0.0864462    -0.167386    -0.0776024    -0.0790725    0.109872   -0.149172    -0.00039657   0.0403491    0.0536178    0.110288     0.164233      0.343645    -0.0753121   -0.0372926    0.0639348    0.0811406     0.00159052  -0.0538029     0.104436  
  0.00145828   -0.0485956   -0.0997826   0.0656042   0.0629499   -0.0414589    0.0264804    0.0264209     0.0545543   -0.041649     -0.0386049    0.0937308  -0.0236902   -0.0985758    0.0109423   -0.0289118    0.0895097   -0.000550398   0.0689669   -0.0382114    0.0454328    0.00911648  -0.142689      0.0549615    0.0253529     0.118034  
  0.0519016     0.143787    -0.0220863   0.039572    0.035793     0.0994526    0.0417816   -0.00393087   -0.00623915   0.0708382     0.00738679  -0.0594346   0.0828008   -0.0137108    0.10077      0.0822963    0.104986    -0.0720853    -0.0801813   -0.062864     0.126018     0.082768    -0.00502998   -0.0227267    0.0568256     0.0117112 
  0.0808059     0.193417     0.0558423   0.0916274   0.0687653    0.116994    -0.0496491   -0.000546077  -0.142314    -0.0182202     0.0578063   -0.135396   -0.0354473    0.115377     0.104531     0.143282     0.024676    -0.0966341     0.0618778    0.0792335    0.0158163   -0.147168    -0.14567      -0.0636597   -0.0404581     0.170698  
  0.130815      0.103049    -0.0194691   0.0882367  -0.0340951   -0.0596388   -0.126163    -0.0504382     0.0722942    0.0537174     0.00493471  -0.172332   -0.214929     0.0485218   -0.19062     -0.0466812   -0.0360592   -0.00845626    0.0734155    0.0162384    0.0367118   -0.0421264   -0.109457     -0.105687     0.0984491    -0.0734236 
 -0.190405     -0.144238     0.441715    0.0366048  -0.0527193    0.0495633    0.18187     -0.393416     -0.220698    -0.0209536     0.0101199    0.246463   -0.0347653   -0.0863422    0.24635      0.196902    -0.110802    -0.204171      0.0580043    0.0425854   -0.148858     0.0020303    0.0523913    -0.00953624  -0.157334      0.0464499 
  0.0753606    -0.233313    -0.0994873  -0.0314077   0.090575    -0.0260759    0.145883     0.485732      0.0480201   -0.0315287    -0.0171186   -0.0191444   0.00683259   0.251547     0.0461752    0.189305    -0.301591     0.0878512     0.134204    -0.00751492  -0.0184249    0.0032026   -0.0616176    -0.0231656    0.229843      0.0431765 
  0.0822063     0.201667    -0.0915198  -0.0275055   0.170864    -0.146449    -0.255254     0.0204304     0.0115421   -0.40585      -0.0434972   -0.0105133   0.1344       0.29125      0.144798    -0.0165966   -0.417391     0.0652943    -0.0870967   -0.0607206   -0.0689919   -0.0851602   -0.0209805    -0.0855152    0.242688      0.00485583
  0.0569234     0.190839     0.0511546  -0.103068    0.172476    -0.0386744   -0.176819     0.0277673    -0.176132     0.566904     -0.0575988   -0.179439    0.149037    -0.134174     0.186337    -0.0719963   -0.114426     0.0671806    -0.0842423   -0.0712436   -0.0213932   -0.0240464   -0.00763208   -0.106327    -0.106775      0.0339792 
  0.0342541    -0.00636237   0.0943694   0.0501186  -0.0510271    0.061135    -0.0571068   -0.107745      0.0431217   -0.0168465    -0.137231    -0.109237   -0.0235126    0.0362404    0.0984829    0.0435174    0.0815462    0.155915      0.0532514    0.00655693   0.0797239    0.0426064    0.0225007     0.0123773    0.0523493    -0.0409412 
  0.110864     -0.150227    -0.0208837  -0.140655    0.127181    -0.105365     0.00411262  -0.0242062    -0.0199468    0.0571936     0.180608     0.035238    0.0387737    0.0388822   -0.136124     0.00071509   0.0648459    0.24655      -0.0754879   -0.0724848   -0.0462039   -0.111284    -0.0319276    -0.0251622    0.032413      0.0337218 
  0.0814889    -0.0483399    0.0957931   0.0597129  -0.0827908    0.0765364    0.204412     0.126332      0.175314    -0.0373954     0.172599    -0.237174    0.181476     0.110185    -0.0218959    0.104196     0.0161127   -0.0341878     0.0437554   -0.0402016   -0.022561    -0.0553183   -0.0437328     0.0290593    0.0532992     0.0599331 
  0.118344     -0.165915     0.0343469   0.0180056   0.0956504   -0.0425905   -0.00389389   0.0224736    -0.0936576   -0.0736093     0.0716962   -0.232434    0.0225057   -0.0614129    0.066594    -0.173979    -0.0177685   -0.000302121  -0.179728     0.0398194    0.0388224   -0.0298891   -0.0329941    -0.0585658    0.122529     -0.0396471 
 -0.18555      -0.113355     0.250394    0.219419   -0.592594     0.0127205    0.311755     0.250072      0.17055      0.0167429    -0.0470255    0.0289572  -0.0198098    0.0794038    0.0961463    0.119327     0.032245     0.247225      0.00693891  -0.169332    -0.00236135  -0.0415199   -0.0395733     0.139317    -0.14023       0.120383  
 -0.16926      -0.0160169    0.242594    0.0734915   0.304881    -0.00565633  -0.504949     0.0252767     0.0705825    0.0132955     0.0542158   -0.0315525   0.00219303   0.0843747    0.244681    -0.0209312    0.00294607   0.247341      0.00693255  -0.169124     0.0262339    0.0304266   -0.0440255     0.0380619   -0.139045      0.094502  
 -0.156398     -0.0815792    0.370611   -0.0579328  -0.521657    -0.0279195    0.0442148   -0.00631862    0.0466112   -0.0679096     0.0829025    0.0345114   0.0935009   -0.0250288    0.0106251   -0.115047    -0.00098228   0.0426451     0.156219    -0.0194009    0.129799     0.0802961   -0.0877691    -0.108935    -0.031668     -0.0507459 
 -0.104086     -0.0563703   -0.0503431   0.0721092   0.522321     0.00679344  -0.155286     0.0820777     0.0335916   -0.0604713     0.105952     0.0344659   0.0849688   -0.12337     -0.0416437   -0.109199    -0.040079    -0.0159575     0.161108    -0.138286     0.0372513    0.0623853   -0.000206333   0.0304756   -0.052198      0.177433  
 -0.0396491    -0.272009    -0.210994   -0.0669316  -0.0410838   -0.147425    -0.0656993   -0.103641      0.0304853   -0.043989      0.0123082    0.0306895   0.00314287   0.0542485   -0.02641     -0.0505107   -0.0438422   -0.0906175    -0.0870568   -0.20552     -0.194678     0.281559    -0.0586545    -0.0101974   -0.0247981    -0.0619191 
 -0.000598746   0.00810091  -0.108867    0.0733389   0.00893316   0.0985551    0.0121212    0.0342148    -0.020956     0.141272      0.130201    -0.0789273   0.00175942  -0.0165107   -0.0308502    0.00099831   0.00873595  -0.0212193     0.0181038    0.00786837   0.0660002   -0.0968755    0.0599694    -0.0528233    0.106618     -0.0165158 
 -0.0155074     0.0365517   -0.0357715   0.0713515  -0.104585     0.196758    -0.025004     0.00936701   -0.018503     0.0346203     0.0441988   -0.0136249   0.140284     0.0199028    0.142656     0.0555729    0.138804    -0.030508      0.0771872    0.131563    -0.00101733  -0.028196    -0.0304919    -0.13354     -0.116443      0.0366585 
 -0.154756      0.0956357    0.0806039  -0.0631926   0.0485045   -0.0498196    0.0629462   -0.0676775    -0.0715756    0.103493      0.103552     0.165807   -0.015161     0.0292491   -0.0135109   -0.202557    -0.0955382   -0.040462      0.134479     0.0109999    0.064554    -0.0577156   -0.0144556    -0.137983     0.0445037    -0.0441319 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 1, average log likelihood -1.077581
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 2, average log likelihood -1.059685
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 3, average log likelihood -1.063547
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 22 23 25 26
INFO: iteration 4, average log likelihood -1.043391
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 5, average log likelihood -1.076053
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 6, average log likelihood -1.057828
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 7, average log likelihood -1.061914
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 22 23 25 26
INFO: iteration 8, average log likelihood -1.042669
WARNING: Variances had to be floored 1 2 16 17 18 25 26
INFO: iteration 9, average log likelihood -1.075205
WARNING: Variances had to be floored 1 2 8 11 12 16 17 18 25 26
INFO: iteration 10, average log likelihood -1.057595
INFO: EM with 100000 data points 10 iterations avll -1.057595
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.812105e+05
      1       6.966516e+05      -1.845588e+05 |       32
      2       6.671651e+05      -2.948651e+04 |       32
      3       6.494106e+05      -1.775455e+04 |       32
      4       6.400458e+05      -9.364732e+03 |       32
      5       6.360619e+05      -3.983936e+03 |       32
      6       6.336078e+05      -2.454096e+03 |       32
      7       6.315840e+05      -2.023791e+03 |       32
      8       6.295764e+05      -2.007597e+03 |       32
      9       6.278155e+05      -1.760911e+03 |       32
     10       6.267975e+05      -1.018044e+03 |       32
     11       6.261467e+05      -6.507624e+02 |       32
     12       6.256322e+05      -5.145305e+02 |       32
     13       6.250988e+05      -5.333858e+02 |       32
     14       6.243630e+05      -7.357854e+02 |       32
     15       6.232477e+05      -1.115269e+03 |       32
     16       6.221586e+05      -1.089110e+03 |       32
     17       6.215668e+05      -5.918489e+02 |       32
     18       6.213074e+05      -2.594305e+02 |       32
     19       6.211688e+05      -1.385348e+02 |       31
     20       6.210218e+05      -1.470050e+02 |       32
     21       6.208234e+05      -1.984551e+02 |       32
     22       6.204343e+05      -3.890182e+02 |       32
     23       6.198208e+05      -6.135375e+02 |       31
     24       6.193613e+05      -4.594833e+02 |       32
     25       6.191866e+05      -1.747131e+02 |       32
     26       6.190606e+05      -1.260180e+02 |       32
     27       6.189244e+05      -1.361632e+02 |       32
     28       6.187590e+05      -1.653814e+02 |       32
     29       6.185833e+05      -1.757565e+02 |       31
     30       6.184062e+05      -1.770795e+02 |       32
     31       6.182558e+05      -1.504238e+02 |       32
     32       6.181417e+05      -1.140613e+02 |       32
     33       6.180654e+05      -7.634988e+01 |       32
     34       6.180071e+05      -5.826674e+01 |       31
     35       6.179602e+05      -4.688799e+01 |       32
     36       6.179208e+05      -3.945512e+01 |       32
     37       6.178871e+05      -3.366735e+01 |       30
     38       6.178613e+05      -2.584227e+01 |       30
     39       6.178423e+05      -1.899085e+01 |       28
     40       6.178293e+05      -1.294833e+01 |       29
     41       6.178144e+05      -1.492171e+01 |       27
     42       6.178015e+05      -1.287200e+01 |       30
     43       6.177927e+05      -8.796288e+00 |       29
     44       6.177845e+05      -8.230255e+00 |       29
     45       6.177759e+05      -8.544098e+00 |       26
     46       6.177675e+05      -8.460130e+00 |       27
     47       6.177598e+05      -7.666925e+00 |       25
     48       6.177545e+05      -5.301021e+00 |       25
     49       6.177501e+05      -4.458510e+00 |       27
     50       6.177464e+05      -3.651950e+00 |       21
K-means terminated without convergence after 50 iterations (objv = 617746.4083407498)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.315056
INFO: iteration 2, average log likelihood -1.274659
INFO: iteration 3, average log likelihood -1.234455
INFO: iteration 4, average log likelihood -1.195001
WARNING: Variances had to be floored 29
INFO: iteration 5, average log likelihood -1.152425
WARNING: Variances had to be floored 13 14 16 19 20
INFO: iteration 6, average log likelihood -1.117878
WARNING: Variances had to be floored 3
INFO: iteration 7, average log likelihood -1.141946
WARNING: Variances had to be floored 5 8 10 11 30
INFO: iteration 8, average log likelihood -1.065793
WARNING: Variances had to be floored 14 20 29
INFO: iteration 9, average log likelihood -1.060782
WARNING: Variances had to be floored 13 16 19
INFO: iteration 10, average log likelihood -1.056669
WARNING: Variances had to be floored 3 8 10 30
INFO: iteration 11, average log likelihood -1.053640
WARNING: Variances had to be floored 5 11 14 20 29
INFO: iteration 12, average log likelihood -1.054277
WARNING: Variances had to be floored 13 16 19 32
INFO: iteration 13, average log likelihood -1.075626
WARNING: Variances had to be floored 3 10 30
INFO: iteration 14, average log likelihood -1.072925
WARNING: Variances had to be floored 8 11 14
INFO: iteration 15, average log likelihood -1.059540
WARNING: Variances had to be floored 13 16 19 20 29
INFO: iteration 16, average log likelihood -1.049667
WARNING: Variances had to be floored 3 10 30 32
INFO: iteration 17, average log likelihood -1.072996
WARNING: Variances had to be floored 5 11 14
INFO: iteration 18, average log likelihood -1.067898
WARNING: Variances had to be floored 13 16 19 20
INFO: iteration 19, average log likelihood -1.054889
WARNING: Variances had to be floored 3 10 29 30
INFO: iteration 20, average log likelihood -1.066561
WARNING: Variances had to be floored 8 11 32
INFO: iteration 21, average log likelihood -1.061060
WARNING: Variances had to be floored 5 13 14 16 19 20
INFO: iteration 22, average log likelihood -1.043300
WARNING: Variances had to be floored 3 10 30
INFO: iteration 23, average log likelihood -1.092681
WARNING: Variances had to be floored 11 29
INFO: iteration 24, average log likelihood -1.078411
WARNING: Variances had to be floored 13 14 16
INFO: iteration 25, average log likelihood -1.043448
WARNING: Variances had to be floored 3 8 10 19 20 29 30
INFO: iteration 26, average log likelihood -1.041806
WARNING: Variances had to be floored 11 32
INFO: iteration 27, average log likelihood -1.092456
WARNING: Variances had to be floored 5 13 14
INFO: iteration 28, average log likelihood -1.061230
WARNING: Variances had to be floored 8 16 19 29 30
INFO: iteration 29, average log likelihood -1.034405
WARNING: Variances had to be floored 3 10 11 20
INFO: iteration 30, average log likelihood -1.056669
WARNING: Variances had to be floored 5
INFO: iteration 31, average log likelihood -1.077619
WARNING: Variances had to be floored 8 13 14 16 19 32
INFO: iteration 32, average log likelihood -1.012669
WARNING: Variances had to be floored 3 10 11 20 29 30
INFO: iteration 33, average log likelihood -1.068481
INFO: iteration 34, average log likelihood -1.110153
WARNING: Variances had to be floored 13 14
INFO: iteration 35, average log likelihood -1.047783
WARNING: Variances had to be floored 3 5 11 16 19 20 30
INFO: iteration 36, average log likelihood -1.027396
WARNING: Variances had to be floored 29
INFO: iteration 37, average log likelihood -1.096827
WARNING: Variances had to be floored 8 10 14
INFO: iteration 38, average log likelihood -1.037614
WARNING: Variances had to be floored 3 11 13 16 19 20 30 32
INFO: iteration 39, average log likelihood -1.032765
WARNING: Variances had to be floored 29
INFO: iteration 40, average log likelihood -1.118923
WARNING: Variances had to be floored 5 14
INFO: iteration 41, average log likelihood -1.060350
WARNING: Variances had to be floored 10 11 13 16 19 20
INFO: iteration 42, average log likelihood -1.025542
WARNING: Variances had to be floored 3 29 30 32
INFO: iteration 43, average log likelihood -1.080985
WARNING: Variances had to be floored 8 14
INFO: iteration 44, average log likelihood -1.077208
WARNING: Variances had to be floored 11 13 16 19 20
INFO: iteration 45, average log likelihood -1.043368
WARNING: Variances had to be floored 3 10 30
INFO: iteration 46, average log likelihood -1.077560
WARNING: Variances had to be floored 14 29 32
INFO: iteration 47, average log likelihood -1.060490
WARNING: Variances had to be floored 5 8 11 13 16 19 20
INFO: iteration 48, average log likelihood -1.024057
WARNING: Variances had to be floored 3 10 30
INFO: iteration 49, average log likelihood -1.100699
INFO: iteration 50, average log likelihood -1.077719
INFO: EM with 100000 data points 50 iterations avll -1.077719
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0180552    -0.0221566    0.104615    0.0454078   -0.0496135    0.0855571   -0.122351    -0.102775      0.00470822   -0.00487135  -0.159659    -0.154289    -0.00302544   0.0268299    0.0649819    0.0680897    0.0651989     0.23223       0.0131617   -0.0149203    0.0760178    0.0286309    0.0362997    0.00725643    0.0330986   -0.0146402 
 -0.0172935     0.0371122   -0.0348062   0.0723135   -0.103937     0.196543    -0.0260483    0.00761528   -0.0185711     0.0338842    0.0455483   -0.0147687    0.138321     0.0198944    0.14393      0.0546763    0.138356     -0.0294025     0.0770328    0.131764    -0.00169196  -0.0277033   -0.0307986   -0.130586     -0.115497     0.0380257 
 -0.134853     -0.0500575    0.165293    0.15181     -0.173414     0.00424564  -0.121732     0.155248      0.10514       0.0493925   -0.0220369   -0.015131    -0.0140238    0.0655793    0.198382     0.0311936    0.000655072   0.222233      0.012346    -0.141815    -0.0108703    0.0106892   -0.055845     0.0373726    -0.0823731    0.0644531 
 -0.0514775    -0.022658    -0.122304   -0.00544671   0.0426337   -0.00965137  -0.0384389    0.19295      -0.0687863     0.0311267   -0.0419581   -0.0117922   -0.0293569   -0.0487759   -0.00609908   0.0911177   -0.110911      0.0769586    -0.00045198  -0.14198     -0.0581115    0.0194058   -0.0209943    0.156848     -0.254023    -0.0797184 
 -0.0567474    -0.221491     0.130932    0.00860461   0.00304565   0.0178764    0.162599     0.0257833    -0.101419     -0.0655555   -0.0037542    0.155365    -0.0129881    0.075708     0.18318      0.201146    -0.246872     -0.0278789     0.0871812    0.0227893   -0.130356     0.00549763  -0.00546674  -0.00238509    0.0283998    0.0459267 
  0.0436446     0.027651     0.0388901  -0.0796206    0.0709637    0.101808     0.119867    -0.0278338    -0.0741151    -0.10857      0.0142479   -0.0111247   -0.0674737   -0.086604    -0.245704     0.0793524   -0.0223765     0.0143868     0.0181118    0.143738    -0.0731799    0.134049     0.0425096   -0.0020148     0.124426    -0.00807825
  0.0588896    -0.0453288    0.0608111   0.0756911    0.112097    -0.0350999    0.0107233    0.0452479    -0.133055     -0.103058     0.0315516   -0.19139      0.0193848    0.127146     0.0230422   -0.122378    -0.0654853    -0.00461567   -0.102958     0.0824713    0.0397485   -0.129039     0.00366507  -0.0821894    -0.00811036  -0.0508024 
  0.0795265    -0.0471234    0.0738942   0.0652819   -0.0856162    0.113336     0.20752      0.138984      0.221846     -0.0170035    0.18001     -0.279388     0.206513     0.157294    -0.0550324    0.107132     0.0785699    -0.0427909     0.0302434   -0.136001    -0.0241881   -0.0589948   -0.0408636    0.0275567     0.0558328    0.0600319 
  0.0815176     0.192707     0.0574368   0.0928155    0.0697231    0.117009    -0.0513735   -0.000382403  -0.137307     -0.0128843    0.057389    -0.136361    -0.036779     0.115132     0.101065     0.142314     0.0241529    -0.0974346     0.0619876    0.0768354    0.0170154   -0.148593    -0.145951    -0.0650747    -0.0395173    0.171558  
 -0.116143      0.0624762   -0.0186064   0.0574711   -0.0630156    0.186838     0.00853905   0.0453202    -0.000710108   0.174157     0.045146    -0.138219     0.110959    -0.0635712   -0.0826161   -0.0140654    0.0513783     0.0455915     0.0623126    0.203917    -0.080713     0.0722127   -0.0209218    0.0146417     0.0640757    0.00205525
  0.0943175     0.0579708   -0.0297596   0.0655719   -0.0960742   -0.0722819   -0.0575099   -0.0922258    -0.162824     -0.0732837   -0.0756798    0.10683     -0.176862     0.00206033   0.0382878    0.0587486    0.102669      0.180067      0.31714     -0.0727085   -0.0547144    0.0637991    0.0640694   -0.00400787   -0.0466306    0.104484  
  0.041523      0.170901    -0.0781154  -0.0269142   -0.0241174    0.200117     0.0610977   -0.0839221    -0.00966577    0.116905     0.0161524   -0.0666417    0.0642379    0.0892347    0.0784451    0.0402402    0.180678     -0.0639034    -0.198581     0.0185637    0.129135     0.00326056   0.021471    -0.0240004     0.0721364   -0.036401  
  0.126143      0.10133     -0.0173439   0.0729655   -0.0293456   -0.0552256   -0.121856    -0.0545989     0.0590035     0.0640051    0.00882867  -0.187953    -0.231373     0.0480894   -0.225589    -0.0562853   -0.0312083     0.000745832   0.071221     0.00982104   0.0313257   -0.0426876   -0.115482    -0.124029      0.114666    -0.0798866 
 -0.0893968    -0.0880317    0.39837    -0.0124615   -0.0322314    0.0237901    0.197706     0.098504     -0.137106      0.163551     0.00123523   0.0743944   -0.0111948   -0.0288008    0.10255      0.189289    -0.215231     -0.137465      0.10542     -0.0373937    0.0350983    0.00823827   0.0061503   -0.0333367     0.0306755    0.0557819 
  0.0797181     0.0164456   -0.0182217  -0.00426126   0.0609098   -0.0416781    0.0873158   -0.0360891     0.102706     -0.0728205   -0.0322324    0.0560379   -0.0342566    0.0288963    0.0795442   -0.0854234    0.0821396    -0.0362248     0.150852    -0.0268873    0.0173066    0.0311591   -0.045771    -0.074417      0.0986724   -0.0173467 
  0.0457451    -0.0499628   -0.0988086  -0.00961567   0.0937322   -0.0113138   -0.0168428    0.121387      0.00551595   -0.0818775    0.144513    -0.135361    -0.0982592   -0.105604     0.0518384   -0.0274597   -0.0837605    -0.0400513     0.00795468  -0.0915164    0.180662     0.116809     0.0414051    0.0509224    -0.159825    -0.0090003 
  0.0868848    -0.139082    -0.109439    0.0180937    0.00736949  -0.0906626   -0.0219229   -0.00994259    0.0715499     0.0386994   -0.00849277  -6.80547e-5  -0.0132563   -0.0548881   -0.0142442    0.138641    -0.0548133    -0.0137937     0.0879571    0.269072    -0.00661653  -0.00597896   0.00592345   0.0906165     0.0252338   -0.0812046 
 -0.104445     -0.145246    -0.0419829   0.1246      -0.0240723   -0.264813     0.088512    -0.0147801     0.199491     -1.86144e-5   0.0904332   -0.0393574    0.046538    -0.0361939    0.0464955    0.174881     0.037496     -0.0706893     0.0251834   -0.168224     0.225017     0.202427    -0.0431594   -0.0361073     0.153974    -0.245362  
 -0.0790436     0.00236317   0.150132    0.0481366    0.0685275   -0.0184889    0.173209     0.0309894     0.0891943    -0.132895     0.10325      0.0429995   -0.073644     0.0322262    0.0221919    0.092434    -0.14498       0.122278     -0.0751395    0.122806     0.0353324    0.00151667   0.0226322    0.0728887     0.0796356   -0.0992624 
 -0.000716392  -0.0428606    0.0907043  -0.0226966   -0.0471415   -0.0784988    0.16489      0.171411      0.0256463    -0.181354    -0.122879    -0.186933     0.0553122   -0.109812     0.0869658   -0.210081     0.0809169    -0.0630546     0.0677946    0.165554     0.0165142   -0.050671     0.0188832   -0.0728721     0.0363335   -0.00789231
 -0.132601     -0.0672097    0.165475    0.0136446   -0.0195613   -0.0101577   -0.0731258    0.0514408     0.040203     -0.062304     0.0927235    0.0344591    0.08495     -0.0648788   -0.00873189  -0.105976    -0.0155472     0.0228835     0.150255    -0.0811255    0.0771753    0.0644681   -0.0428726   -0.035872     -0.0460267    0.0601487 
  0.0946696    -0.0226318   -0.171016    0.0835071    0.0591296    0.0283208    0.0283031    0.0170722    -0.0325217     0.123705     0.200393    -0.0391734   -0.0703054    0.0257978   -0.0037405    0.0101165   -0.0351588    -0.0663162    -0.0228179   -0.0710038    0.185432    -0.237327     0.110514    -0.112111      0.141433    -0.0469584 
 -0.0713538    -0.101602    -0.127916    0.169223     0.00883184  -0.0171275    0.00445605   0.0524883     0.0627547    -0.00180169  -0.0745814    0.125132    -0.0196027   -0.185025     0.0119716    0.0479624    0.107144      0.0345518     0.0101652    0.0229129    0.0884414   -0.00446597  -0.215518     0.241938     -0.0395007    0.196757  
 -0.172504     -0.0230214   -0.16507     0.0775714    0.0556962   -0.00620146  -0.215895     0.182192     -0.0680272     0.0668729   -0.0431609   -0.0297428    0.00288258  -0.074796    -0.503135     0.103315    -0.2618       -0.00813022    0.232519    -0.133642     0.00674159   0.0292452   -0.12238      0.1774        1.76748     -0.0858241 
  0.0702186     0.199912    -0.0280117  -0.0642271    0.171493    -0.0927754   -0.217111     0.0247064    -0.0776111     0.0637301   -0.0498266   -0.0947836    0.139078     0.0856196    0.164894    -0.0443003   -0.273832      0.0670528    -0.0858226   -0.0658842   -0.046756    -0.0541473   -0.014108    -0.0955908     0.0740659    0.019495  
 -0.0416867    -0.270287    -0.211289   -0.0675766   -0.0434115   -0.145966    -0.0665895   -0.106541      0.0281216    -0.0414641    0.0133033    0.0309427    0.00624669   0.0531715   -0.0308449   -0.0510668   -0.0442174    -0.0882609    -0.0891246   -0.204207    -0.193662     0.279993    -0.0608236   -0.010215     -0.0236089   -0.0630526 
  0.0800352    -0.0410004   -0.0434386  -0.141117     0.0445471   -0.0112746    0.176128     0.159608     -0.000529865  -0.080518    -0.290108    -0.093675     0.0428103   -0.210499    -0.124169    -0.029221    -0.00027852   -0.0301702     0.119121    -0.0291531    0.105744    -0.0998493    0.161547     0.000607659  -0.0260876   -0.0740469 
 -0.155003      0.0955958    0.0803403  -0.0636748    0.047747    -0.0492397    0.0632329   -0.0673962    -0.0717049     0.103995     0.104554     0.165587    -0.0137318    0.0306699   -0.0130039   -0.202618    -0.0955743    -0.0404477     0.134469     0.0103749    0.0634654   -0.0578347   -0.0152404   -0.137835      0.0444634   -0.0443589 
  0.104069     -0.140304    -0.0099561  -0.122097     0.111573    -0.0910239    0.0153506   -0.016516     -0.00577213    0.0562689    0.17812      0.034573     0.0388362    0.0386847   -0.128246    -0.00568823   0.0680577     0.227768     -0.0637096   -0.0783868   -0.0473579   -0.107107    -0.0325569   -0.021385      0.0281624    0.0422714 
  0.0330555     0.319233    -0.108698    0.0276073    0.0527119    0.025214     0.00848244   0.143813      0.0174146     0.229215    -0.145289     0.0539641   -0.281857     0.0165342    0.0384249   -0.0323029   -0.0721947     0.146389      0.0611875   -0.0175554   -0.17919     -0.203284    -0.134125    -0.200218      0.135732    -0.148882  
 -0.0131286    -0.136495     0.0290087  -0.126054     0.197471    -0.239852     0.0867139    0.217781     -0.0575247    -0.0707044    0.0421388   -0.250216    -0.193049    -0.0468461   -0.0295338    0.192415    -0.036432     -0.0791294     0.0166584   -0.0750259    0.0663696    0.0187348    0.0485956    0.0974446    -0.016657     0.0270805 
  0.0538872     0.0929184    0.013135    0.100966     0.0866402   -0.00198346   0.0205027    0.0774427    -0.013854      0.0123645    0.00604278  -0.0559993    0.0960492   -0.121762     0.110511     0.113762     0.0291719    -0.0784679     0.0343176   -0.16316      0.118205     0.158537    -0.0315238   -0.0136287     0.040043     0.0647747 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 8 11 13 14 16 19 20 29 32
INFO: iteration 1, average log likelihood -1.013701
WARNING: Variances had to be floored 3 5 8 10 11 13 16 19 20 29 30 32
INFO: iteration 2, average log likelihood -0.993445
WARNING: Variances had to be floored 8 11 13 14 16 19 20 29 32
INFO: iteration 3, average log likelihood -1.012874
WARNING: Variances had to be floored 3 5 8 10 11 13 16 19 20 29 30 32
INFO: iteration 4, average log likelihood -0.993269
WARNING: Variances had to be floored 8 11 13 14 16 19 20 29 32
INFO: iteration 5, average log likelihood -1.012764
WARNING: Variances had to be floored 3 5 8 10 11 13 16 19 20 29 30 32
INFO: iteration 6, average log likelihood -0.993352
WARNING: Variances had to be floored 8 11 13 14 16 19 20 29 32
INFO: iteration 7, average log likelihood -1.012673
WARNING: Variances had to be floored 3 5 8 10 11 13 16 19 20 29 30 32
INFO: iteration 8, average log likelihood -0.993422
WARNING: Variances had to be floored 8 11 13 14 16 19 20 29 32
INFO: iteration 9, average log likelihood -1.012597
WARNING: Variances had to be floored 3 5 8 10 11 13 16 19 20 29 30 32
INFO: iteration 10, average log likelihood -0.993481
INFO: EM with 100000 data points 10 iterations avll -0.993481
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0280311    0.0570146     0.0886765    0.175525    -0.0737821   0.175288    -0.0693773    0.0477741     0.15339      0.148705     0.0498162   0.0356014   -0.0557541     0.0666044    0.183501    -0.147786     0.0206565     0.108661    -0.113725     0.105411     0.0956913  -0.0201188     0.0992141   -0.219248    -0.198677    -0.279675  
 -0.0853898    0.124093     -0.0606465   -0.0403222    0.0963487  -0.139475    -0.0225232   -0.18005       0.0930659    0.0143439   -0.127677    0.0560238    0.0850022     0.0622377    0.0397736    0.0482664   -0.0301434     0.0266744    0.0278347    0.0124499   -0.10293     0.0161292     0.0305358   -0.21007     -0.0786109   -0.055563  
  0.0701133    0.00708567   -0.0363695    0.0792916    0.0214044  -0.137729    -0.10723      0.000344215  -0.00847656  -0.0960238   -0.107424   -0.0308898   -0.00414459   -0.197047    -0.00437883  -0.00191699  -0.136671      0.0184675   -0.0365021    0.00324149  -0.0880302  -0.0711677     0.0818246   -0.0422793    0.0290542    0.0422962 
 -0.0608642   -0.0503317     0.0612091   -0.10613      0.0213371   0.0322108    0.124131    -0.118181      0.143958     0.100981     0.0721724  -0.0432234   -0.0345561    -0.0689645   -0.0637063   -0.0208391   -0.0387588    -0.0628073    0.072571     0.0833039    0.0874175  -0.0383482    -0.0390236    0.154753     0.152531    -0.0611372 
  0.00638748  -0.0563151     0.0152888    0.0336677    0.0511184   0.0820018   -0.0831463   -0.103867     -0.0337764   -0.0646159   -0.0164523  -0.193815    -0.0334637    -0.244694     0.0167766   -0.0189445   -0.0427956     0.213296     0.0854822   -0.168088    -0.0284235  -0.0378229    -0.0346873    0.0473926   -0.0948728   -0.0192874 
  0.00181544   0.132692     -0.126918    -0.114243    -0.0207142  -0.00862845   0.0432792    0.0234281    -0.0403894    0.0862133    0.0744316   0.136226    -0.172222     -0.0588074   -0.00438612   0.032504    -0.0238117    -0.0327441    0.108422     0.0540668   -0.113188   -0.107218     -0.142752     0.00788851  -0.0141001    0.0198001 
 -0.128338    -0.000264244   0.0119906   -0.0767755   -0.106339    0.14801      0.0368499    0.135146      0.17371      0.139629     0.101749    0.107886     0.0590109    -0.00870238  -0.130635     0.104385    -0.105668      0.0889509   -0.045935    -0.0402427   -0.0275369   0.000562446   0.00679014   0.10277      0.0984184    0.0524678 
 -0.384576     0.0667104     0.148889    -0.00383867   0.0541961   0.0237723    0.124158    -0.0591547     0.0118797   -0.029406    -0.117211    0.121311    -0.000980952   0.15532      0.145917    -0.0770316   -0.0411026    -0.0450877    0.0575192    0.164886     0.0434214   0.195444      0.0746154    0.114811    -0.365776    -0.0163366 
  0.00795226   0.0850693     0.0613066   -0.0146832    0.0422255   0.0121051   -0.0457454   -0.209098      0.0818122   -0.0354917    0.0477877   0.0502913   -0.030174     -0.0850833   -0.0670494   -0.0971019    0.00633752    0.0931448    0.023113     0.146383     0.0333572  -0.00910068   -0.0849905   -0.00324047  -0.0806449   -0.00310444
  0.070185    -0.200261      0.0913189    0.220926    -0.0223841  -0.0473346   -0.0466216   -0.0492171     0.0936073   -0.0288752    0.118906    0.00356416  -0.0641167    -0.0672925    0.1084       0.135029     0.132382      0.168341    -0.152596     0.0835732    0.091424    0.0793002    -0.0593073    0.124605     0.00592004   0.0485449 
  0.0241297   -0.0318103    -0.235958    -0.0860281   -0.136456   -0.0662479   -0.0313352    0.0455307     0.23266     -0.112878    -0.188246    0.0339358    0.179064      0.0896002   -0.0514745   -0.0588098    0.116298     -0.0748338   -0.0191902   -0.0901797    0.0574773   0.0313486    -0.0486764    0.118081     0.134411    -0.045556  
 -0.0118184    0.0691807     0.0792587    0.127684    -0.0397151  -0.0263515    0.0943092   -0.0504982     0.027776     0.089436     0.0667838   0.0103233   -0.22486       0.0794537   -0.0147774    0.146884    -0.107941      0.12812     -0.13189     -0.237334    -0.125003   -0.12811      -0.00573925  -0.0503763   -0.149464     0.10816   
  0.0218193    0.0783975     0.0351375   -0.0827897    0.127837    0.0342119   -0.0316114   -0.0525366    -0.104149     0.113046     0.0864452   0.0339048   -0.162785     -0.0835962    0.0692482   -0.0128896   -0.0509929     0.0158884   -0.0409437    0.0897767    0.0172407   0.0524908    -0.124426     0.142167    -0.168482     0.0186526 
  0.0727364   -0.176618     -0.0571415   -0.156528     0.0106318  -0.0103315    0.058752     0.0174732    -0.0286152    0.0353401   -0.0493571  -0.140905    -0.10715      -0.21641      0.0707234   -0.0218403   -0.0430766     0.0726561   -0.157286     0.0676511   -0.117283    0.015619     -0.0646702   -0.0576267   -0.198992    -0.0717997 
 -0.106311    -0.157026      0.114137    -0.0905352    0.120362   -0.00738865   0.0246331    0.00192925   -0.110388    -0.0593617   -0.0553754   0.177296     0.138409      0.0213768    0.0376311    0.156787    -0.00576054   -0.00286959   0.0470348    0.0327204    0.057813    0.141232      0.0695247    0.208957    -0.0352327   -0.12113   
  0.0145854   -0.0497444    -0.114928     0.0740402   -0.0589796  -0.0888038    0.0944551   -0.0145583    -0.0303018    0.082455    -0.25831    -0.0931756   -0.100637      0.0335854   -0.0341058    0.176687    -0.149404     -0.00151017   0.0139302   -0.0991924   -0.0991634   0.0155621     0.0871112    0.0819697   -0.0898997   -0.163567  
  0.0876677    0.0356404    -0.00271432  -0.0608813   -0.0945284   0.0231396    0.0989935   -0.0115562     0.0939879   -0.10092     -0.0256622   0.128512     0.0606774     0.0380901   -0.108031    -0.164991     0.00601923    0.0459725   -0.0879944   -0.0108122    0.113683   -0.0927272    -0.0252022    0.113273     0.0230005   -0.0442838 
 -0.0789351    0.0448733    -0.0325474    0.0187628   -0.13318    -0.199122     0.115265    -0.0634106     0.0752414    0.0871158   -0.111737    0.13558      0.00472255   -0.181387     0.0863503   -0.00407318  -0.000258064   0.069525     0.275933    -0.0542304    0.0207036   0.0575131    -0.00197729   0.0917957    0.0228896   -0.163208  
  0.0306496   -0.135848     -0.0252073    0.0500269    0.029308    0.0995318   -0.0370457    0.181918     -0.0675739   -0.0414214   -0.0444942  -0.159889     0.216772     -0.0313764   -0.00589669   0.0247833   -0.15827      -0.0256252   -0.12385      0.0392896    0.0342186  -0.119668      0.10513      0.151622    -0.0312106    0.0567867 
 -0.136956     0.107971     -0.11273      0.07989     -0.0887566   0.167383     0.192758    -0.024017      0.100329     0.228724    -0.0477726  -0.0258335    0.139057     -0.0835698   -0.0163966    0.0269394   -0.238253      0.0845811   -0.136022    -0.0543898   -0.107075   -0.0342781     0.122647    -0.191439     0.0857245   -0.0560261 
 -0.0342211    0.18395      -0.270226     0.123353    -0.142008   -0.0299915    0.0409947    0.0202106     0.0884096   -0.0394163    0.124578    0.175529     0.00656987    0.0171611   -0.179317     0.0755756    0.173156     -0.126082     0.0589813   -0.0153966   -0.0572301  -0.069344     -0.0211329    0.112812    -0.0220419   -0.0439306 
 -0.133301     0.153104     -0.055142     0.0987825    0.0971991  -0.153786    -0.0587931   -0.0484609     0.0875745   -0.0543513   -0.135558   -0.0509247   -0.00765502    0.0872236   -0.0533736    0.124023     0.00831999   -0.119392     0.0203309   -0.0980288    0.0704777  -0.110975     -0.143375     0.0763465   -0.0612242   -0.0530241 
  0.0707293    0.056367      0.0890032   -0.0675501    0.121258   -0.138205    -0.00496628   0.120226      0.022803    -0.220592    -0.0579415  -0.0962941   -0.220725      0.0799237    0.00839223   0.0121082   -0.00936049    0.0107486   -0.00368222  -0.0209974   -0.0396985  -0.0402436    -0.150903     0.0183092   -0.0237628    0.0540472 
 -0.0921293   -0.130871     -0.0101303    0.0135213    0.039178    0.0145173    0.0556148    0.0520742     0.107379    -0.00900381  -0.153498    0.0855883    0.0699092    -0.0539052    0.0572542    0.104977    -0.0419576     0.056748    -0.0450715   -0.0331926   -0.0775324   0.0347208     0.0327608    0.0215309   -0.0659201   -0.0287902 
 -0.0589264   -0.0238055    -0.112471     0.0908622    0.0968223  -0.123943     0.062343     0.113789      0.0623569   -0.108652    -0.0346895   0.177283    -0.0627206     0.0611428    0.176973     0.0520821    0.166918      0.245432    -0.112706     0.0350968    0.0837609  -0.104579     -0.128025     0.0802553    0.107275    -0.00211574
 -0.174305    -0.108746      0.202438     0.0275662    0.165148   -0.0645723    0.118904    -0.0738719    -0.0373962    0.0805375    0.0541933  -0.0200393   -0.0703495    -0.00653491   0.149475     0.080954     0.180383      0.0409148   -0.214907    -0.0800995    0.0144951   0.126548     -0.052912     0.0570568    0.103642    -0.111274  
  0.054176    -0.138097      0.0075186   -0.0596975   -0.108622   -0.0136975    0.0188721    0.0147456     0.0109246    0.129406     0.0769382  -0.0584774    0.304905      0.0680712   -0.162765    -0.0510384    0.000331203   0.0895146    0.0767285    0.0382178    0.032513   -0.125109      0.0602975    0.0279725    0.0763888    0.213374  
  0.143266     0.0578399     0.0625019   -0.00336878  -0.0464291  -0.0173506   -0.194117     0.034197      0.0794937    0.0222399    0.116692   -0.0382643    0.202314      0.097935     0.180724     0.0191636    0.188512     -0.0117821   -0.015781     0.0880052    0.0498859   0.056585     -0.0447811    0.0595973    0.0476558   -0.0596325 
  0.166604    -0.0259002     0.260288     0.0748404   -0.0362504   0.114412    -0.0380443   -0.025155      0.0270131    0.129821    -0.0278201   0.167727     0.046064     -0.0460259    0.104818     0.0659533    0.0528353    -0.0249776   -0.0151396   -0.0267853    0.184685    0.115733      0.019248    -0.0210068   -0.239907     0.122693  
 -0.0543084    0.0454469     0.0847272    0.0664486    0.0646758   0.0932326   -0.196448    -0.107297     -0.0768629   -0.0228009    0.0788645  -0.115916     0.0708514     0.0309749    0.0158438   -0.0913649    0.156344      0.0157822   -0.0422531   -0.0253001    0.0272034   0.0077825    -0.047536     0.00439055   0.00267714  -0.00402198
  0.162979    -0.323501     -0.155981     0.092246     0.1021      0.10616      0.0579737   -0.03014       0.0435578   -0.0104118    0.0984764  -0.153886    -0.145038      0.0150254    0.0275149    0.0471375    0.105862      0.0622806    0.0181283    0.220954    -0.0447829   0.0439125    -0.121774     0.0567596    0.0980148   -0.125489  
  0.00396921  -0.159422      0.0355421   -0.127807    -0.105913    0.0600845   -0.165159     0.070155     -0.151034     0.136413     0.225133    0.174032     0.0242798     0.135492    -0.0349401    0.0311875    0.138279     -0.155706    -0.00369001  -0.0845363   -0.0716322   0.0254254    -0.0148814    0.151911    -0.0153623    0.019801  kind full, method split
0: avll = -1.4274072011113867
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.427429
INFO: iteration 2, average log likelihood -1.427345
INFO: iteration 3, average log likelihood -1.427268
INFO: iteration 4, average log likelihood -1.427168
INFO: iteration 5, average log likelihood -1.427038
INFO: iteration 6, average log likelihood -1.426885
INFO: iteration 7, average log likelihood -1.426724
INFO: iteration 8, average log likelihood -1.426574
INFO: iteration 9, average log likelihood -1.426436
INFO: iteration 10, average log likelihood -1.426286
INFO: iteration 11, average log likelihood -1.426080
INFO: iteration 12, average log likelihood -1.425758
INFO: iteration 13, average log likelihood -1.425257
INFO: iteration 14, average log likelihood -1.424561
INFO: iteration 15, average log likelihood -1.423771
INFO: iteration 16, average log likelihood -1.423076
INFO: iteration 17, average log likelihood -1.422606
INFO: iteration 18, average log likelihood -1.422345
INFO: iteration 19, average log likelihood -1.422217
INFO: iteration 20, average log likelihood -1.422157
INFO: iteration 21, average log likelihood -1.422129
INFO: iteration 22, average log likelihood -1.422117
INFO: iteration 23, average log likelihood -1.422111
INFO: iteration 24, average log likelihood -1.422108
INFO: iteration 25, average log likelihood -1.422106
INFO: iteration 26, average log likelihood -1.422105
INFO: iteration 27, average log likelihood -1.422104
INFO: iteration 28, average log likelihood -1.422104
INFO: iteration 29, average log likelihood -1.422103
INFO: iteration 30, average log likelihood -1.422103
INFO: iteration 31, average log likelihood -1.422103
INFO: iteration 32, average log likelihood -1.422102
INFO: iteration 33, average log likelihood -1.422102
INFO: iteration 34, average log likelihood -1.422102
INFO: iteration 35, average log likelihood -1.422102
INFO: iteration 36, average log likelihood -1.422101
INFO: iteration 37, average log likelihood -1.422101
INFO: iteration 38, average log likelihood -1.422101
INFO: iteration 39, average log likelihood -1.422101
INFO: iteration 40, average log likelihood -1.422101
INFO: iteration 41, average log likelihood -1.422101
INFO: iteration 42, average log likelihood -1.422101
INFO: iteration 43, average log likelihood -1.422101
INFO: iteration 44, average log likelihood -1.422100
INFO: iteration 45, average log likelihood -1.422100
INFO: iteration 46, average log likelihood -1.422100
INFO: iteration 47, average log likelihood -1.422100
INFO: iteration 48, average log likelihood -1.422100
INFO: iteration 49, average log likelihood -1.422100
INFO: iteration 50, average log likelihood -1.422100
INFO: EM with 100000 data points 50 iterations avll -1.422100
952.4 data points per parameter
1: avll = [-1.42743,-1.42734,-1.42727,-1.42717,-1.42704,-1.42688,-1.42672,-1.42657,-1.42644,-1.42629,-1.42608,-1.42576,-1.42526,-1.42456,-1.42377,-1.42308,-1.42261,-1.42235,-1.42222,-1.42216,-1.42213,-1.42212,-1.42211,-1.42211,-1.42211,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.422122
INFO: iteration 2, average log likelihood -1.422034
INFO: iteration 3, average log likelihood -1.421953
INFO: iteration 4, average log likelihood -1.421846
INFO: iteration 5, average log likelihood -1.421710
INFO: iteration 6, average log likelihood -1.421554
INFO: iteration 7, average log likelihood -1.421405
INFO: iteration 8, average log likelihood -1.421286
INFO: iteration 9, average log likelihood -1.421201
INFO: iteration 10, average log likelihood -1.421145
INFO: iteration 11, average log likelihood -1.421107
INFO: iteration 12, average log likelihood -1.421078
INFO: iteration 13, average log likelihood -1.421055
INFO: iteration 14, average log likelihood -1.421035
INFO: iteration 15, average log likelihood -1.421017
INFO: iteration 16, average log likelihood -1.421000
INFO: iteration 17, average log likelihood -1.420984
INFO: iteration 18, average log likelihood -1.420968
INFO: iteration 19, average log likelihood -1.420953
INFO: iteration 20, average log likelihood -1.420938
INFO: iteration 21, average log likelihood -1.420924
INFO: iteration 22, average log likelihood -1.420911
INFO: iteration 23, average log likelihood -1.420898
INFO: iteration 24, average log likelihood -1.420886
INFO: iteration 25, average log likelihood -1.420875
INFO: iteration 26, average log likelihood -1.420866
INFO: iteration 27, average log likelihood -1.420858
INFO: iteration 28, average log likelihood -1.420851
INFO: iteration 29, average log likelihood -1.420845
INFO: iteration 30, average log likelihood -1.420840
INFO: iteration 31, average log likelihood -1.420836
INFO: iteration 32, average log likelihood -1.420832
INFO: iteration 33, average log likelihood -1.420830
INFO: iteration 34, average log likelihood -1.420828
INFO: iteration 35, average log likelihood -1.420826
INFO: iteration 36, average log likelihood -1.420824
INFO: iteration 37, average log likelihood -1.420823
INFO: iteration 38, average log likelihood -1.420822
INFO: iteration 39, average log likelihood -1.420821
INFO: iteration 40, average log likelihood -1.420820
INFO: iteration 41, average log likelihood -1.420819
INFO: iteration 42, average log likelihood -1.420819
INFO: iteration 43, average log likelihood -1.420818
INFO: iteration 44, average log likelihood -1.420818
INFO: iteration 45, average log likelihood -1.420817
INFO: iteration 46, average log likelihood -1.420817
INFO: iteration 47, average log likelihood -1.420816
INFO: iteration 48, average log likelihood -1.420816
INFO: iteration 49, average log likelihood -1.420815
INFO: iteration 50, average log likelihood -1.420815
INFO: EM with 100000 data points 50 iterations avll -1.420815
473.9 data points per parameter
2: avll = [-1.42212,-1.42203,-1.42195,-1.42185,-1.42171,-1.42155,-1.42141,-1.42129,-1.4212,-1.42115,-1.42111,-1.42108,-1.42105,-1.42103,-1.42102,-1.421,-1.42098,-1.42097,-1.42095,-1.42094,-1.42092,-1.42091,-1.4209,-1.42089,-1.42088,-1.42087,-1.42086,-1.42085,-1.42084,-1.42084,-1.42084,-1.42083,-1.42083,-1.42083,-1.42083,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42081]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.420830
INFO: iteration 2, average log likelihood -1.420782
INFO: iteration 3, average log likelihood -1.420749
INFO: iteration 4, average log likelihood -1.420714
INFO: iteration 5, average log likelihood -1.420672
INFO: iteration 6, average log likelihood -1.420623
INFO: iteration 7, average log likelihood -1.420568
INFO: iteration 8, average log likelihood -1.420509
INFO: iteration 9, average log likelihood -1.420449
INFO: iteration 10, average log likelihood -1.420390
INFO: iteration 11, average log likelihood -1.420334
INFO: iteration 12, average log likelihood -1.420282
INFO: iteration 13, average log likelihood -1.420233
INFO: iteration 14, average log likelihood -1.420187
INFO: iteration 15, average log likelihood -1.420143
INFO: iteration 16, average log likelihood -1.420102
INFO: iteration 17, average log likelihood -1.420063
INFO: iteration 18, average log likelihood -1.420027
INFO: iteration 19, average log likelihood -1.419993
INFO: iteration 20, average log likelihood -1.419962
INFO: iteration 21, average log likelihood -1.419933
INFO: iteration 22, average log likelihood -1.419907
INFO: iteration 23, average log likelihood -1.419883
INFO: iteration 24, average log likelihood -1.419861
INFO: iteration 25, average log likelihood -1.419841
INFO: iteration 26, average log likelihood -1.419823
INFO: iteration 27, average log likelihood -1.419805
INFO: iteration 28, average log likelihood -1.419790
INFO: iteration 29, average log likelihood -1.419775
INFO: iteration 30, average log likelihood -1.419760
INFO: iteration 31, average log likelihood -1.419747
INFO: iteration 32, average log likelihood -1.419734
INFO: iteration 33, average log likelihood -1.419722
INFO: iteration 34, average log likelihood -1.419710
INFO: iteration 35, average log likelihood -1.419698
INFO: iteration 36, average log likelihood -1.419687
INFO: iteration 37, average log likelihood -1.419676
INFO: iteration 38, average log likelihood -1.419665
INFO: iteration 39, average log likelihood -1.419655
INFO: iteration 40, average log likelihood -1.419645
INFO: iteration 41, average log likelihood -1.419634
INFO: iteration 42, average log likelihood -1.419625
INFO: iteration 43, average log likelihood -1.419615
INFO: iteration 44, average log likelihood -1.419606
INFO: iteration 45, average log likelihood -1.419597
INFO: iteration 46, average log likelihood -1.419588
INFO: iteration 47, average log likelihood -1.419579
INFO: iteration 48, average log likelihood -1.419571
INFO: iteration 49, average log likelihood -1.419563
INFO: iteration 50, average log likelihood -1.419555
INFO: EM with 100000 data points 50 iterations avll -1.419555
236.4 data points per parameter
3: avll = [-1.42083,-1.42078,-1.42075,-1.42071,-1.42067,-1.42062,-1.42057,-1.42051,-1.42045,-1.42039,-1.42033,-1.42028,-1.42023,-1.42019,-1.42014,-1.4201,-1.42006,-1.42003,-1.41999,-1.41996,-1.41993,-1.41991,-1.41988,-1.41986,-1.41984,-1.41982,-1.41981,-1.41979,-1.41977,-1.41976,-1.41975,-1.41973,-1.41972,-1.41971,-1.4197,-1.41969,-1.41968,-1.41967,-1.41965,-1.41964,-1.41963,-1.41962,-1.41962,-1.41961,-1.4196,-1.41959,-1.41958,-1.41957,-1.41956,-1.41955]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419555
INFO: iteration 2, average log likelihood -1.419499
INFO: iteration 3, average log likelihood -1.419448
INFO: iteration 4, average log likelihood -1.419389
INFO: iteration 5, average log likelihood -1.419319
INFO: iteration 6, average log likelihood -1.419234
INFO: iteration 7, average log likelihood -1.419135
INFO: iteration 8, average log likelihood -1.419026
INFO: iteration 9, average log likelihood -1.418911
INFO: iteration 10, average log likelihood -1.418796
INFO: iteration 11, average log likelihood -1.418685
INFO: iteration 12, average log likelihood -1.418583
INFO: iteration 13, average log likelihood -1.418491
INFO: iteration 14, average log likelihood -1.418410
INFO: iteration 15, average log likelihood -1.418340
INFO: iteration 16, average log likelihood -1.418280
INFO: iteration 17, average log likelihood -1.418228
INFO: iteration 18, average log likelihood -1.418184
INFO: iteration 19, average log likelihood -1.418145
INFO: iteration 20, average log likelihood -1.418111
INFO: iteration 21, average log likelihood -1.418080
INFO: iteration 22, average log likelihood -1.418052
INFO: iteration 23, average log likelihood -1.418026
INFO: iteration 24, average log likelihood -1.418002
INFO: iteration 25, average log likelihood -1.417980
INFO: iteration 26, average log likelihood -1.417959
INFO: iteration 27, average log likelihood -1.417939
INFO: iteration 28, average log likelihood -1.417921
INFO: iteration 29, average log likelihood -1.417904
INFO: iteration 30, average log likelihood -1.417888
INFO: iteration 31, average log likelihood -1.417873
INFO: iteration 32, average log likelihood -1.417859
INFO: iteration 33, average log likelihood -1.417845
INFO: iteration 34, average log likelihood -1.417833
INFO: iteration 35, average log likelihood -1.417821
INFO: iteration 36, average log likelihood -1.417810
INFO: iteration 37, average log likelihood -1.417800
INFO: iteration 38, average log likelihood -1.417790
INFO: iteration 39, average log likelihood -1.417781
INFO: iteration 40, average log likelihood -1.417773
INFO: iteration 41, average log likelihood -1.417764
INFO: iteration 42, average log likelihood -1.417757
INFO: iteration 43, average log likelihood -1.417749
INFO: iteration 44, average log likelihood -1.417742
INFO: iteration 45, average log likelihood -1.417736
INFO: iteration 46, average log likelihood -1.417729
INFO: iteration 47, average log likelihood -1.417723
INFO: iteration 48, average log likelihood -1.417717
INFO: iteration 49, average log likelihood -1.417712
INFO: iteration 50, average log likelihood -1.417706
INFO: EM with 100000 data points 50 iterations avll -1.417706
118.1 data points per parameter
4: avll = [-1.41956,-1.4195,-1.41945,-1.41939,-1.41932,-1.41923,-1.41914,-1.41903,-1.41891,-1.4188,-1.41869,-1.41858,-1.41849,-1.41841,-1.41834,-1.41828,-1.41823,-1.41818,-1.41815,-1.41811,-1.41808,-1.41805,-1.41803,-1.418,-1.41798,-1.41796,-1.41794,-1.41792,-1.4179,-1.41789,-1.41787,-1.41786,-1.41785,-1.41783,-1.41782,-1.41781,-1.4178,-1.41779,-1.41778,-1.41777,-1.41776,-1.41776,-1.41775,-1.41774,-1.41774,-1.41773,-1.41772,-1.41772,-1.41771,-1.41771]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417710
INFO: iteration 2, average log likelihood -1.417651
INFO: iteration 3, average log likelihood -1.417596
INFO: iteration 4, average log likelihood -1.417532
INFO: iteration 5, average log likelihood -1.417453
INFO: iteration 6, average log likelihood -1.417354
INFO: iteration 7, average log likelihood -1.417234
INFO: iteration 8, average log likelihood -1.417097
INFO: iteration 9, average log likelihood -1.416950
INFO: iteration 10, average log likelihood -1.416800
INFO: iteration 11, average log likelihood -1.416654
INFO: iteration 12, average log likelihood -1.416516
INFO: iteration 13, average log likelihood -1.416388
INFO: iteration 14, average log likelihood -1.416273
INFO: iteration 15, average log likelihood -1.416171
INFO: iteration 16, average log likelihood -1.416081
INFO: iteration 17, average log likelihood -1.416002
INFO: iteration 18, average log likelihood -1.415933
INFO: iteration 19, average log likelihood -1.415873
INFO: iteration 20, average log likelihood -1.415821
INFO: iteration 21, average log likelihood -1.415774
INFO: iteration 22, average log likelihood -1.415732
INFO: iteration 23, average log likelihood -1.415694
INFO: iteration 24, average log likelihood -1.415659
INFO: iteration 25, average log likelihood -1.415627
INFO: iteration 26, average log likelihood -1.415596
INFO: iteration 27, average log likelihood -1.415568
INFO: iteration 28, average log likelihood -1.415541
INFO: iteration 29, average log likelihood -1.415515
INFO: iteration 30, average log likelihood -1.415491
INFO: iteration 31, average log likelihood -1.415467
INFO: iteration 32, average log likelihood -1.415445
INFO: iteration 33, average log likelihood -1.415423
INFO: iteration 34, average log likelihood -1.415402
INFO: iteration 35, average log likelihood -1.415382
INFO: iteration 36, average log likelihood -1.415362
INFO: iteration 37, average log likelihood -1.415343
INFO: iteration 38, average log likelihood -1.415325
INFO: iteration 39, average log likelihood -1.415308
INFO: iteration 40, average log likelihood -1.415291
INFO: iteration 41, average log likelihood -1.415275
INFO: iteration 42, average log likelihood -1.415259
INFO: iteration 43, average log likelihood -1.415244
INFO: iteration 44, average log likelihood -1.415230
INFO: iteration 45, average log likelihood -1.415216
INFO: iteration 46, average log likelihood -1.415202
INFO: iteration 47, average log likelihood -1.415189
INFO: iteration 48, average log likelihood -1.415176
INFO: iteration 49, average log likelihood -1.415164
INFO: iteration 50, average log likelihood -1.415152
INFO: EM with 100000 data points 50 iterations avll -1.415152
59.0 data points per parameter
5: avll = [-1.41771,-1.41765,-1.4176,-1.41753,-1.41745,-1.41735,-1.41723,-1.4171,-1.41695,-1.4168,-1.41665,-1.41652,-1.41639,-1.41627,-1.41617,-1.41608,-1.416,-1.41593,-1.41587,-1.41582,-1.41577,-1.41573,-1.41569,-1.41566,-1.41563,-1.4156,-1.41557,-1.41554,-1.41552,-1.41549,-1.41547,-1.41544,-1.41542,-1.4154,-1.41538,-1.41536,-1.41534,-1.41533,-1.41531,-1.41529,-1.41527,-1.41526,-1.41524,-1.41523,-1.41522,-1.4152,-1.41519,-1.41518,-1.41516,-1.41515]
[-1.42741,-1.42743,-1.42734,-1.42727,-1.42717,-1.42704,-1.42688,-1.42672,-1.42657,-1.42644,-1.42629,-1.42608,-1.42576,-1.42526,-1.42456,-1.42377,-1.42308,-1.42261,-1.42235,-1.42222,-1.42216,-1.42213,-1.42212,-1.42211,-1.42211,-1.42211,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.4221,-1.42212,-1.42203,-1.42195,-1.42185,-1.42171,-1.42155,-1.42141,-1.42129,-1.4212,-1.42115,-1.42111,-1.42108,-1.42105,-1.42103,-1.42102,-1.421,-1.42098,-1.42097,-1.42095,-1.42094,-1.42092,-1.42091,-1.4209,-1.42089,-1.42088,-1.42087,-1.42086,-1.42085,-1.42084,-1.42084,-1.42084,-1.42083,-1.42083,-1.42083,-1.42083,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42082,-1.42081,-1.42083,-1.42078,-1.42075,-1.42071,-1.42067,-1.42062,-1.42057,-1.42051,-1.42045,-1.42039,-1.42033,-1.42028,-1.42023,-1.42019,-1.42014,-1.4201,-1.42006,-1.42003,-1.41999,-1.41996,-1.41993,-1.41991,-1.41988,-1.41986,-1.41984,-1.41982,-1.41981,-1.41979,-1.41977,-1.41976,-1.41975,-1.41973,-1.41972,-1.41971,-1.4197,-1.41969,-1.41968,-1.41967,-1.41965,-1.41964,-1.41963,-1.41962,-1.41962,-1.41961,-1.4196,-1.41959,-1.41958,-1.41957,-1.41956,-1.41955,-1.41956,-1.4195,-1.41945,-1.41939,-1.41932,-1.41923,-1.41914,-1.41903,-1.41891,-1.4188,-1.41869,-1.41858,-1.41849,-1.41841,-1.41834,-1.41828,-1.41823,-1.41818,-1.41815,-1.41811,-1.41808,-1.41805,-1.41803,-1.418,-1.41798,-1.41796,-1.41794,-1.41792,-1.4179,-1.41789,-1.41787,-1.41786,-1.41785,-1.41783,-1.41782,-1.41781,-1.4178,-1.41779,-1.41778,-1.41777,-1.41776,-1.41776,-1.41775,-1.41774,-1.41774,-1.41773,-1.41772,-1.41772,-1.41771,-1.41771,-1.41771,-1.41765,-1.4176,-1.41753,-1.41745,-1.41735,-1.41723,-1.4171,-1.41695,-1.4168,-1.41665,-1.41652,-1.41639,-1.41627,-1.41617,-1.41608,-1.416,-1.41593,-1.41587,-1.41582,-1.41577,-1.41573,-1.41569,-1.41566,-1.41563,-1.4156,-1.41557,-1.41554,-1.41552,-1.41549,-1.41547,-1.41544,-1.41542,-1.4154,-1.41538,-1.41536,-1.41534,-1.41533,-1.41531,-1.41529,-1.41527,-1.41526,-1.41524,-1.41523,-1.41522,-1.4152,-1.41519,-1.41518,-1.41516,-1.41515]
32Ã—26 Array{Float64,2}:
 -0.62608     0.0614111   -0.10164     -0.112459     0.296025    -0.650723    1.13478     0.151221     -0.290878     0.281535     0.323585    0.100929   -0.023105     0.206754    -0.369059     0.0413869    0.0334012  -0.487521    -0.0856331  -0.205643     0.281515   -0.0102939    -0.224573    -0.611661    -0.278975    -0.0617213 
 -0.027558    0.213482     0.293639    -0.749152    -0.349826     0.352439    0.7931      0.295436      0.0196736    0.316413     0.0499625  -0.0549684  -0.66507      0.310818     0.385936    -0.0689827   -0.0988673  -0.346904     0.0552176   0.12996      0.396939    0.339328     -0.676706     0.249129    -0.773298     0.0832304 
 -0.226652    0.543604    -0.503827    -0.0640324    0.284869     0.401688    0.242336   -0.293706     -0.241352     0.0744672    0.226721   -0.0145145   0.156364     0.382954     0.0404723   -0.767046     0.281525   -0.323558     0.141693    0.398535    -0.0843996   0.248019      0.0972165   -0.265239    -0.155069    -0.429909  
  0.226289   -0.113648    -0.821321    -0.43437     -0.668348     0.482668    0.389013   -0.319459      0.217082     0.739415     0.174384   -0.460265   -0.281612     0.39102     -0.554612    -0.325571     0.0578999   0.176577     0.0614767   0.059323    -0.317175   -0.0778772    -0.611466     0.228864     0.233488    -0.207489  
  0.0376484   0.352127    -0.472038     0.823357    -0.299442    -0.108604    0.0796636  -0.295175     -0.240386    -0.189537    -0.726995    0.205201    0.00412056   0.182739     0.340932    -0.0480815   -0.034248   -0.427271     0.379895    0.106761     0.75801    -0.239985     -0.375019    -0.00903128  -0.127955    -1.07429   
 -0.0965126   0.612502     0.0966955    0.428464    -0.226221    -0.496299    0.115873   -0.0918879     0.00701153  -0.302288    -0.994966    0.365197    0.183595    -0.091514     0.239364    -0.242571     0.326836    0.218439     0.0213724  -0.29383      0.467241   -0.38419      -0.460187    -0.175909    -0.401712     0.141667  
  0.0462355  -0.279738    -0.119132     0.685464     0.266422    -0.138778   -0.0849829   0.452016     -0.334919     0.034871     0.0878486   0.416191   -0.59211      0.124454    -0.269823    -0.361663    -0.111002   -0.528635    -0.733746    0.203178    -0.14928    -0.22457      -0.0552908   -0.489981    -0.304586     0.228391  
 -0.543106    0.684435    -0.164101     0.595509     0.0142843   -0.0304509  -0.346039   -0.00799774    0.372522    -0.0534629   -0.266607    0.360223   -0.160332     0.602423    -0.416557     0.451401    -0.0625336   0.116657     0.530437    0.644276    -0.133339   -0.321509      0.155989    -0.488458    -0.245184     0.473229  
  0.620542    0.064978     0.182693    -0.0302682    0.39254      0.2453      0.468473    0.208985      0.280936     0.717918    -0.356599    0.0248253   0.505142     0.23157     -0.00682614  -0.32166     -0.694917   -0.631822    -0.379032   -0.219503    -3.5796e-5  -0.205267      0.564083     0.473184     0.301483    -0.544529  
  0.328185   -0.731039    -0.199543    -0.152327     0.143274    -0.26978    -0.0271654   0.287194     -0.325346    -0.0994812   -0.0154296  -0.272665    0.385393    -0.726788     0.450278    -0.207872     0.0468996   0.0244725   -0.600372   -0.433533    -0.0277023   0.228035     -0.277931     0.146148     0.243865    -0.328209  
  0.0951337   0.159988     1.13059      0.225784     0.810979     0.582725   -0.0418054   0.282294      0.0646139   -0.113298     0.265946    0.408794   -0.222239     0.0501216   -0.141083    -0.080502     0.317325    0.390007    -0.118799    0.439646    -0.002443    1.08936       0.156182     0.467491    -0.143474    -0.318712  
  0.200889   -0.502467     0.593283    -0.50813      0.53831      0.347468   -0.368797    0.124445      0.306214     0.115165     0.578888   -0.31664    -0.0888497    0.0454703   -0.220662     0.0136186   -0.116219    0.349844    -0.861052   -0.262417    -0.383076    0.188332      0.513265     0.180952    -0.241432     1.0062    
  0.1812      0.0562345   -0.210147    -0.203923    -0.137387    -0.166361   -0.204396   -0.823235      0.209477    -0.0166587    0.0134278   0.0662435   0.308631    -0.269776     0.227913     0.00932174   0.0169434   0.403045     0.145838   -0.335431    -0.034504   -0.200258      0.286673     0.250215     0.00473448  -0.146062  
 -0.208264   -0.187394     0.100147     0.178396     0.220022    -0.117334    0.157333    0.693286      0.0626802   -0.0992569   -0.123859    0.0910641   0.29697      0.298559    -0.0582317    0.285478     0.0241796  -0.00839403  -0.208993    0.190582     0.0322698   0.169429     -0.0699097   -0.22832      0.232002     0.0325585 
  0.524073   -0.0967305    0.533694    -0.102898    -0.240048     0.719809   -0.578024    0.371252      0.417859     0.288093     0.264546   -0.297689   -0.649342    -0.400835     0.534504     0.198352    -0.225188   -0.527412     0.588496   -0.068671    -0.109309   -0.103743      0.297988     0.309915     0.0707029   -0.128925  
 -0.0175756  -0.6603      -0.0744634    0.105014    -0.512196     0.506421   -1.15374    -0.00376408   -0.0385984   -0.222994    -0.239896   -0.355518    0.0398482   -0.668572     0.475262     0.17436     -0.162603    0.792181     0.0375485   0.0770952   -0.513288    0.196427      0.021628     0.549702     0.202648     0.173283  
 -0.0491348  -0.125054    -0.0831492    0.0573197    0.00784634   0.0359754  -0.128766   -0.0978229    -0.0143708   -0.0789885    0.0602455  -0.0268298   0.0467552   -0.091864    -0.00698257   0.0536746   -0.0197543   0.0790836   -0.0136538   0.00175469  -0.227756   -0.0278065     0.0247429    0.119692     0.0250493    0.00688455
 -0.0613096   0.124837     0.041317    -0.050686     0.0763753   -0.399135    0.334009    0.0282637     0.063738     0.19388     -0.0271591   0.106412   -0.180243     0.0941514   -0.183251     0.00517283   0.0688492  -0.151337    -0.0564791  -0.125163     0.446127   -0.0514004    -0.0736079   -0.225532    -0.268513     0.00576033
  0.0997565   0.207941     0.193667    -0.0787069    0.0953856    0.312967   -0.136979   -0.000532216  -0.131109     0.366974    -0.0915994   0.0979285  -0.441952     0.043237     0.228341    -0.245301    -0.661798   -0.169029    -0.112274    0.174159    -0.351091   -0.122773     -0.277149     0.224447    -0.177869     0.209465  
  0.129132    0.329642     0.00143272  -0.0560226   -0.0215719    0.551527    0.106568    0.276495      0.127184    -0.062082     0.167885    0.139746   -0.0601347    0.420771     0.281451    -0.179218     0.134955   -0.0944141   -0.0651043   0.334556     0.329846    0.000821979   0.00459768  -0.0328626   -0.0159611   -0.245483  
  0.0987741  -0.322959     0.247212    -0.0438158    0.0459503   -0.664082   -0.0212494   0.00832437    0.381991    -0.149825    -0.152838   -0.101753   -0.0105901    0.0435854   -0.617845     1.15229      0.225989   -0.215867     0.190912   -0.323426     0.283806    0.270926     -0.144037     0.104225    -0.0882997    0.13572   
  0.198389   -0.474955     0.0582886   -0.0625448   -0.180053     0.0458201   0.0201081   0.590075      0.174091     0.0709226    0.190226    0.173293   -0.152884     0.316101     0.305077     0.478625     0.516765   -0.377956     0.127444   -0.0904252    0.517363   -0.0606491     0.0163195    0.00375521   0.289659    -0.115812  
 -0.0352512   0.119264     0.455208    -0.0958673   -0.438632    -0.288725    0.0072311   0.336157      0.603426     0.7634      -0.305105   -0.0175412   0.245975    -0.0381108   -0.269223     0.597947    -0.444162    0.952397    -0.210536    0.00838564   0.193943   -0.365173      0.315041     0.113279     0.386887     0.0954058 
 -0.267942   -0.508815     0.200144    -0.714015     0.320495     0.158063    0.563877    0.263215      0.486961     0.125689     0.467579   -0.0178665   0.411913    -0.0207283   -0.257871     0.367159    -0.0103598   0.0863409   -0.165059    0.236707    -0.397289    0.24179       0.315888    -0.00636693   0.398377     0.226047  
 -0.449023   -0.31924     -0.205618    -0.113514    -0.00937792  -0.0784662   0.241277   -0.451887     -0.682948    -0.631843     0.0873602  -0.163089   -0.501445    -0.549483     0.220703    -0.229724    -0.0800009  -0.927836     0.722206    0.0220831    0.0880212  -0.105778     -0.630458     0.179903    -0.14598     -0.0583991 
 -0.89395     0.0110471   -0.0415822   -0.33425     -0.143822    -0.113852    0.313226   -0.481245     -0.0649096   -0.239534     0.111184   -0.0218381   0.12095     -0.277191     0.350412     0.167658     0.372961    0.178516     0.498256   -0.0784864   -0.304541    0.216667     -0.140774     0.252879    -0.385999     0.0213881 
  0.314916   -0.00412248   0.241369     0.0265197   -0.31138      0.109406   -0.151189   -0.168354      0.112044    -0.0536912   -0.520028   -0.140074    0.072383    -0.310336     0.351364     0.151296     0.386003    0.457405     0.533011    0.0255108    0.0782087   0.489309     -0.00286768   0.375337     0.25113     -0.51496   
  0.210811   -0.0857697   -0.199452     0.00457683  -0.0661693   -0.099906   -0.219479   -0.19852      -0.126397    -0.231073     0.0846011  -0.41611    -0.455905     0.00877548   0.330667    -0.0780539    0.396755    0.540255     0.0364095   0.542612    -0.234128   -0.00187001   -0.36013      0.0262547   -0.174383     0.824691  
  0.150469    0.456345    -0.166669    -0.0809934   -0.0845732   -0.0624436  -0.48251    -0.867434      0.0938927   -0.13684     -0.322746   -0.200462    0.663087    -0.18407     -0.277151    -0.040595    -0.497102    0.864013     0.234905   -0.148506    -0.167958   -0.175792      0.330326    -0.185916     0.156394    -0.125743  
 -0.286624   -0.0312113    0.139983     0.566793     0.214831    -0.120662   -0.343094    0.246937     -0.154759    -0.447231    -0.202788    0.0369144   0.684384     0.0453513   -0.208975     0.180665    -0.412919    0.15397     -0.504832   -0.159811    -0.397769   -0.109189      0.0693222   -0.09976     -0.122022     0.131489  
  0.315632   -0.0503023    0.114629     0.0318928    0.249393     0.21621    -0.502151   -0.543444      0.0438379    0.00945768   0.605562   -0.0425621  -0.0654797   -0.456443    -0.0728432   -0.131487     0.103678    0.405682    -0.730282   -0.555264     0.20626    -0.243074      0.528696     0.196864    -0.142467    -0.173179  
 -0.0874337  -0.162422    -0.404897     0.451045    -0.205233    -0.43617    -0.219859   -0.658334      0.0733864   -0.208183     0.78307     0.322027    0.0756008   -0.139685    -0.401584    -0.295356     0.668323    0.0651524    0.431655   -0.165429    -0.0267235  -0.387843      0.448799     0.407735     0.296187    -0.133229  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.415141
INFO: iteration 2, average log likelihood -1.415129
INFO: iteration 3, average log likelihood -1.415119
INFO: iteration 4, average log likelihood -1.415108
INFO: iteration 5, average log likelihood -1.415098
INFO: iteration 6, average log likelihood -1.415088
INFO: iteration 7, average log likelihood -1.415078
INFO: iteration 8, average log likelihood -1.415068
INFO: iteration 9, average log likelihood -1.415059
INFO: iteration 10, average log likelihood -1.415050
INFO: EM with 100000 data points 10 iterations avll -1.415050
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.560911e+05
      1       7.113424e+05      -2.447487e+05 |       32
      2       6.993357e+05      -1.200673e+04 |       32
      3       6.944138e+05      -4.921899e+03 |       32
      4       6.916586e+05      -2.755197e+03 |       32
      5       6.898346e+05      -1.823972e+03 |       32
      6       6.885311e+05      -1.303583e+03 |       32
      7       6.875092e+05      -1.021885e+03 |       32
      8       6.866849e+05      -8.242585e+02 |       32
      9       6.860092e+05      -6.756864e+02 |       32
     10       6.854413e+05      -5.678851e+02 |       32
     11       6.849564e+05      -4.849154e+02 |       32
     12       6.845360e+05      -4.204442e+02 |       32
     13       6.841665e+05      -3.695246e+02 |       32
     14       6.838299e+05      -3.365177e+02 |       32
     15       6.835160e+05      -3.139281e+02 |       32
     16       6.832211e+05      -2.948643e+02 |       32
     17       6.829502e+05      -2.709620e+02 |       32
     18       6.827144e+05      -2.358223e+02 |       32
     19       6.825143e+05      -2.000132e+02 |       32
     20       6.823428e+05      -1.715618e+02 |       32
     21       6.821957e+05      -1.471291e+02 |       32
     22       6.820711e+05      -1.245639e+02 |       32
     23       6.819601e+05      -1.109682e+02 |       32
     24       6.818606e+05      -9.955407e+01 |       32
     25       6.817715e+05      -8.903395e+01 |       32
     26       6.816795e+05      -9.198822e+01 |       32
     27       6.815986e+05      -8.096430e+01 |       32
     28       6.815244e+05      -7.417689e+01 |       32
     29       6.814469e+05      -7.750408e+01 |       32
     30       6.813642e+05      -8.270340e+01 |       32
     31       6.812787e+05      -8.552047e+01 |       32
     32       6.812033e+05      -7.539843e+01 |       32
     33       6.811310e+05      -7.230205e+01 |       32
     34       6.810588e+05      -7.222361e+01 |       32
     35       6.809855e+05      -7.329481e+01 |       32
     36       6.809194e+05      -6.604811e+01 |       32
     37       6.808584e+05      -6.104795e+01 |       32
     38       6.807974e+05      -6.100081e+01 |       32
     39       6.807397e+05      -5.767785e+01 |       32
     40       6.806859e+05      -5.376693e+01 |       32
     41       6.806357e+05      -5.020772e+01 |       32
     42       6.805881e+05      -4.764231e+01 |       32
     43       6.805412e+05      -4.686297e+01 |       32
     44       6.804980e+05      -4.320562e+01 |       32
     45       6.804615e+05      -3.650001e+01 |       32
     46       6.804284e+05      -3.308896e+01 |       32
     47       6.803987e+05      -2.971239e+01 |       32
     48       6.803675e+05      -3.115899e+01 |       32
     49       6.803383e+05      -2.925051e+01 |       32
     50       6.803133e+05      -2.494801e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 680313.340434313)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.426673
INFO: iteration 2, average log likelihood -1.421697
INFO: iteration 3, average log likelihood -1.420385
INFO: iteration 4, average log likelihood -1.419430
INFO: iteration 5, average log likelihood -1.418405
INFO: iteration 6, average log likelihood -1.417415
INFO: iteration 7, average log likelihood -1.416712
INFO: iteration 8, average log likelihood -1.416323
INFO: iteration 9, average log likelihood -1.416117
INFO: iteration 10, average log likelihood -1.415990
INFO: iteration 11, average log likelihood -1.415898
INFO: iteration 12, average log likelihood -1.415825
INFO: iteration 13, average log likelihood -1.415763
INFO: iteration 14, average log likelihood -1.415708
INFO: iteration 15, average log likelihood -1.415658
INFO: iteration 16, average log likelihood -1.415612
INFO: iteration 17, average log likelihood -1.415569
INFO: iteration 18, average log likelihood -1.415529
INFO: iteration 19, average log likelihood -1.415492
INFO: iteration 20, average log likelihood -1.415456
INFO: iteration 21, average log likelihood -1.415422
INFO: iteration 22, average log likelihood -1.415390
INFO: iteration 23, average log likelihood -1.415359
INFO: iteration 24, average log likelihood -1.415330
INFO: iteration 25, average log likelihood -1.415302
INFO: iteration 26, average log likelihood -1.415275
INFO: iteration 27, average log likelihood -1.415249
INFO: iteration 28, average log likelihood -1.415225
INFO: iteration 29, average log likelihood -1.415201
INFO: iteration 30, average log likelihood -1.415178
INFO: iteration 31, average log likelihood -1.415156
INFO: iteration 32, average log likelihood -1.415135
INFO: iteration 33, average log likelihood -1.415115
INFO: iteration 34, average log likelihood -1.415095
INFO: iteration 35, average log likelihood -1.415077
INFO: iteration 36, average log likelihood -1.415058
INFO: iteration 37, average log likelihood -1.415041
INFO: iteration 38, average log likelihood -1.415024
INFO: iteration 39, average log likelihood -1.415008
INFO: iteration 40, average log likelihood -1.414992
INFO: iteration 41, average log likelihood -1.414977
INFO: iteration 42, average log likelihood -1.414963
INFO: iteration 43, average log likelihood -1.414949
INFO: iteration 44, average log likelihood -1.414936
INFO: iteration 45, average log likelihood -1.414923
INFO: iteration 46, average log likelihood -1.414911
INFO: iteration 47, average log likelihood -1.414899
INFO: iteration 48, average log likelihood -1.414888
INFO: iteration 49, average log likelihood -1.414878
INFO: iteration 50, average log likelihood -1.414867
INFO: EM with 100000 data points 50 iterations avll -1.414867
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.289677    -0.181199   -0.339759     0.196897    -0.442486   -0.254019   -0.130637   -0.935386     0.0652361   -0.686397    0.879966     0.160722    -0.179047   -0.103536   -0.0646118  -0.33296      0.667214     0.00300702   0.609173   -0.0703803  -0.0739839   -0.320938    0.160324     0.424151    -0.00546905   0.342292  
 -0.110051     0.287765   -0.366142    -0.824269    -0.78389     0.602744    0.096456   -0.144864    -0.18424      0.650424    0.544038    -0.142014     0.0794898   0.424088   -0.100528   -0.104654     0.176576     0.074694     0.43632    -0.0364159  -0.36323      0.173823   -0.222795     0.449008     0.0670295   -0.44586   
  0.602441    -0.156436    0.770449    -0.0667162    0.489554    0.450842    0.011514    0.313682    -0.00217408  -0.103342   -0.250864     0.339856     0.166915   -0.0756264   0.285782    0.165431     0.249264     0.32735      0.221807    0.0718782   0.566206     0.752188   -0.0700539    0.302651     0.191155    -0.754553  
 -0.396473     0.0886246  -0.614366    -0.00720003   0.337382    0.26275     0.365932   -0.320971    -0.332098    -0.416181   -0.0463391    0.0128537   -0.0809878   0.0800593   0.348962   -0.420212     0.246804    -0.980652     0.561432    0.249158    0.0739416    0.27957    -0.45576      0.0164296   -0.444753    -0.320803  
  0.465041     0.143934    0.240505    -0.374438    -0.0812675   0.825533    0.165797    0.282572     0.242129     0.214668    0.275928    -0.192686    -0.615669    0.206371    0.675641   -0.413632    -0.245183    -0.0966405   -0.369529    0.0239766   0.299717     0.0429468  -0.0458101    0.255926    -0.534774     0.141927  
  0.0925815   -0.3385      0.530106    -0.120586     0.587075    0.212959   -0.528348   -0.0329179    0.256249    -0.178072    0.517033    -0.146514     0.0336717  -0.111981   -0.090455    0.106024    -0.00273705   0.514334    -0.510644   -0.16666    -0.308369     0.201575    0.556783     0.241304    -0.0843734    0.464522  
  0.43638     -0.0426521   0.123226     0.0889673    0.297334    0.313149   -0.476252   -0.597909     0.116843     0.384326    0.725072     0.0544397    0.0430098  -0.609584   -0.458265   -0.191829     0.058338    -0.0238545   -0.453137   -0.466033   -0.024656    -0.339082    0.717067     0.326694     0.330654    -0.336332  
 -0.269904    -0.570692    0.271135    -0.726676     0.266875    0.224396    0.39645     0.147681     0.382845     0.0350205   0.564781     0.0483218    0.314062   -0.153064   -0.154076    0.232875     0.0831597    0.272675    -0.221071    0.207836   -0.561669     0.291892    0.305546     0.0634071    0.322783     0.295798  
 -0.597262     0.481594    0.101211     0.695581    -0.0373794  -0.132661   -0.540058    0.141785     0.265141    -0.293284   -0.498487     0.313562     0.207606    0.14573    -0.0513744   0.529643    -0.0258586    0.325672     0.356004    0.284008   -0.116071    -0.171424    0.171334    -0.548296    -0.244793     0.437662  
 -0.158724    -0.187634   -0.662198     0.527692    -0.100529   -0.568443   -0.580134   -0.339365    -0.0847967   -0.0306691  -0.132549     0.00417277   0.254537   -0.0594265  -0.359915    0.260465    -0.28307      0.162315    -0.0345849  -0.0313723  -0.539918    -0.459363    0.201199    -0.154412     0.161364    -0.0479478 
 -0.304106    -0.204009    0.103987    -0.412298     0.239326   -0.333277    0.853817    0.28931      0.441821     0.396525    0.0742582   -0.366254     0.205196    0.223943   -0.539331    0.61629     -0.168136    -0.553699    -0.147189   -0.0904276  -0.061974     0.239096   -0.0928774   -0.100044    -0.232191     0.339673  
 -0.385019    -0.0985084   0.659373    -0.255594     0.0826254  -0.112925   -0.228209   -0.439715    -0.300518    -0.111486   -0.288066     0.0512672   -0.401669   -0.574376   -0.0495653   0.0169209   -0.893225    -0.099106     0.371629   -0.353422   -0.333243    -0.155109   -0.587273     0.351772    -0.205477     0.116257  
  0.399316    -0.424329   -0.0408208    0.161263    -0.589985    0.720629   -0.957783   -0.049569     0.178014     0.105693   -0.46251     -0.396787     0.173629   -0.72382     0.427999    0.219365    -0.0711551    0.362942     0.332875    0.230201   -0.531937     0.506044    0.276509     0.862107     0.286026    -0.0889891 
 -0.101726     0.0686926  -0.0525919    0.0937242   -0.168225    0.0480435  -0.158171   -0.350499    -0.109717    -0.194177   -0.0416801   -0.0747025   -0.232086   -0.133804    0.181575    0.0581352    0.292239     0.316871     0.356691    0.241386   -0.290861     0.0948762  -0.0458894    0.226293    -0.121726     0.0486954 
 -0.0509371   -0.30951     0.0441451    0.20598     -0.119549    0.0725101  -0.0215632   0.541206     0.296909    -0.329563    0.0192449    0.253791     0.132849    0.612989    0.0154644   0.527083     0.385743    -0.295609     0.242943    0.0908409   0.379653     0.182289   -0.0573503    1.79994e-5   0.256521    -0.150028  
 -0.588252     0.562538   -0.268618     0.0502384    0.409908   -0.241089    0.586983    0.0681631   -0.357892     0.371982    0.166027     0.0828387    0.269088    0.0626124   0.0244478  -0.523742    -0.0178768   -0.0588749    0.0690815   0.0874293   0.260074    -0.188723    0.298773    -0.584264     0.0160608   -0.500624  
 -0.392283     0.333235   -0.100501     0.57637      0.288185   -0.28817     0.197939   -0.35436     -0.223086    -0.695691   -0.325943     0.0521781    1.03593     0.0955573  -0.580492   -0.344684    -0.029465     0.284444    -0.641148   -0.068357   -0.158101     0.297839    0.0086355   -0.0833096   -0.57333     -0.178619  
 -0.497448     0.0162095   0.0265986   -0.251767     0.0951903  -0.250918    0.934596    0.0977768   -0.323653     0.0589505   0.209703     0.141899    -0.445416    0.263298   -0.161514    0.020868     0.297564    -0.328697     0.0571735   0.123938    0.232957     0.258012   -0.610808    -0.265744    -0.307068    -0.0776404 
  0.440598     0.395592   -0.43364      0.673361    -0.310742    0.0104242  -0.549508   -0.463374    -0.18316     -0.178215   -0.426147    -0.0883337   -0.288623   -0.0592989   0.306155   -0.372461     0.142996     0.139251    -0.0215292  -0.3248      0.586972    -0.300703   -0.183573    -0.00408137  -0.265806    -0.516672  
  0.00247825  -0.707331   -0.117052    -0.15732     -0.0428993  -0.0686289  -0.467077    0.227815    -0.362774    -0.386786    0.0658339   -0.441953     0.246343   -0.718724    0.579003   -0.00320192  -0.133162     0.609733    -0.463289   -0.20272    -0.249117     0.185977   -0.414316     0.137473    -0.0150173    0.200717  
 -0.0821223   -0.575447   -0.103032    -0.118881    -0.194861   -0.702865    0.360897   -0.00327963  -0.581449    -0.127822    0.00974514  -0.119791     0.418128   -0.778203    0.116504    0.380294     0.878711    -0.0332407    0.140624   -0.464015    0.00444253   0.0791013   0.0355201    0.066535     0.450722    -0.337575  
  0.0193228   -0.369613    0.143739     0.516313     0.279482   -0.107798    0.0102169   0.619412    -0.414665     0.0974076   0.116017     0.447649    -0.602102    0.0438672  -0.188949   -0.268092    -0.13231     -0.663032    -0.758954    0.118091   -0.14929     -0.0191649  -0.115464    -0.380163    -0.308703     0.242211  
  0.299871     0.373683   -0.212936    -0.098959     0.212702    0.104973   -0.111885    0.16732     -0.187016    -0.17963     0.0708891   -0.237943    -0.206771    0.587205    0.0234543  -0.240862     0.34403      0.48168     -0.204663    0.798273    0.11725     -0.236791   -0.151846    -0.380364    -0.0471175    0.732454  
  0.158339     0.467449    0.130299    -0.6204      -0.189229   -0.103631   -0.191108   -0.70108      0.640661     0.0279381  -0.3324      -0.22087      0.84878    -0.231542    0.0795708   0.245972    -0.233101     1.03723      0.491232   -0.259571    0.0631435   -0.14066     0.328636     0.0963741    0.305397    -0.0840667 
  0.11963     -0.606973   -0.63383     -0.0461219   -0.532719    0.588231    0.577555   -0.329647     0.384517     0.694074   -0.0509777   -0.979231    -0.827903    0.234475   -0.422665   -0.70655     -0.238784     0.374265    -0.0798274   0.260759   -0.464608    -0.163016   -0.694984     0.126875     0.177171     0.197638  
  0.448414    -0.267896   -0.181197     0.0655303    0.183944   -0.0136601   0.26159     0.311754     0.208991     0.309459   -0.298761     0.114772     0.55203     0.0629185   0.162021   -0.110966    -0.415164    -0.514455    -0.390736   -0.310176    0.0654398   -0.200498    0.237178     0.237216     0.382796    -0.514365  
  0.0709351   -0.0954265   0.0518967   -0.0825222   -0.0337802  -0.420115    0.163418   -0.0307588    0.156046     0.0824882   0.0507301    0.0064314   -0.227581   -0.0281288  -0.122406    0.236773     0.252126    -0.0466641   -0.0307959  -0.291201    0.488014     0.0018897  -0.0370158   -0.0275623   -0.240429     0.0608052 
 -0.320569     0.488668    0.00699474   0.297046    -0.77027    -0.428153    0.817563   -0.0965351    0.145383    -0.0493984  -0.767594     0.443165    -0.0597144  -0.123317    0.4791     -0.00851266   0.120523    -0.202431     0.507851    0.21442     0.681002    -0.0824204  -0.738439     0.0288027   -0.18724     -0.389094  
  0.183657    -0.273668    0.539024    -0.476582    -0.226927   -0.0323211  -0.0630284   0.559216     0.57735      0.425465    0.245025    -0.197673    -1.24226    -0.246502    0.332682    0.666448     0.112721    -0.789497     0.829325   -0.113614    0.23043     -0.394498   -0.083938     0.0141347    0.17848      0.117954  
  0.0310168    0.0756095   0.0144157    0.0169493    0.121408    0.23382    -0.0608511   0.114443     0.0205254    0.0447109  -0.0104039    0.0225943    0.155623    0.0542485   0.0786431  -0.146788    -0.280359    -0.0150105   -0.242537    0.0358967  -0.114572    -0.112362   -0.00513526   0.0170939    0.0329026   -0.0454374 
  0.0139143   -0.167972    0.504788     0.223296    -0.333583   -0.20763    -0.0788939   0.518918     0.797597     0.641668   -0.19049      0.0748257    0.134935    0.142945   -0.323224    0.591965    -0.368123     1.10852     -0.597032    0.109127    0.11807     -0.075276    0.372553     0.199395     0.400318     0.0585384 
  0.185955     0.776505    0.267275    -0.0758203    0.247445    0.0298034   0.212108   -0.17436      0.119382     0.79715    -0.286495     0.581308    -0.307753    0.823989   -0.417643    0.0699237   -0.202877    -0.315464     0.109877    0.478749    0.0183867   -0.107821    0.0421188    0.00615605  -0.133259    -0.00745945INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414857
INFO: iteration 2, average log likelihood -1.414848
INFO: iteration 3, average log likelihood -1.414839
INFO: iteration 4, average log likelihood -1.414830
INFO: iteration 5, average log likelihood -1.414822
INFO: iteration 6, average log likelihood -1.414813
INFO: iteration 7, average log likelihood -1.414806
INFO: iteration 8, average log likelihood -1.414798
INFO: iteration 9, average log likelihood -1.414791
INFO: iteration 10, average log likelihood -1.414784
INFO: EM with 100000 data points 10 iterations avll -1.414784
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
