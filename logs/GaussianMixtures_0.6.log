>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.1.0
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StaticArrays v0.0.5
INFO: Installing StatsBase v0.10.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.787
Commit c71f205 (2016-09-26 16:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (663.12890625 MB free)
Uptime: 23739.0 sec
Load Avg:  1.107421875  1.01806640625  1.0400390625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1302430 s         70 s     147189 s     634591 s         71 s
#2  3500 MHz     696676 s       6079 s      88609 s    1429328 s          6 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
20 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.1.0
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StaticArrays                  0.0.5
 - StatsBase                     0.10.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-938919.7859492179,[166.216,99833.8],
[240.752 304.078 -9.51591; -457.213 151.251 -255.327],

Array{Float64,2}[
[440.379 400.47 77.1117; 400.47 613.064 -46.6825; 77.1117 -46.6825 93.8821],

[98861.2 -147.561 -318.914; -147.561 99137.0 202.695; -318.914 202.695 99786.3]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.140240e+03
      1       9.116481e+02      -2.285916e+02 |        5
      2       8.950080e+02      -1.664009e+01 |        0
      3       8.950080e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 895.0079946719525)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.070410
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.838210
INFO: iteration 2, lowerbound -3.746783
INFO: iteration 3, lowerbound -3.645280
INFO: iteration 4, lowerbound -3.510846
INFO: iteration 5, lowerbound -3.341845
INFO: iteration 6, lowerbound -3.150590
INFO: iteration 7, lowerbound -2.958738
INFO: dropping number of Gaussions to 7
INFO: iteration 8, lowerbound -2.777341
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.605928
INFO: iteration 10, lowerbound -2.475182
INFO: iteration 11, lowerbound -2.395492
INFO: dropping number of Gaussions to 4
INFO: iteration 12, lowerbound -2.348213
INFO: dropping number of Gaussions to 3
INFO: iteration 13, lowerbound -2.319060
INFO: iteration 14, lowerbound -2.307428
INFO: dropping number of Gaussions to 2
INFO: iteration 15, lowerbound -2.302957
INFO: iteration 16, lowerbound -2.299263
INFO: iteration 17, lowerbound -2.299257
INFO: iteration 18, lowerbound -2.299255
INFO: iteration 19, lowerbound -2.299254
INFO: iteration 20, lowerbound -2.299253
INFO: iteration 21, lowerbound -2.299253
INFO: iteration 22, lowerbound -2.299253
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Thu 29 Sep 2016 11:05:30 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Thu 29 Sep 2016 11:05:32 AM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Thu 29 Sep 2016 11:05:33 AM UTC: EM with 272 data points 0 iterations avll -2.070410
5.8 data points per parameter
,Thu 29 Sep 2016 11:05:34 AM UTC: GMM converted to Variational GMM
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 1, lowerbound -3.838210
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 2, lowerbound -3.746783
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 3, lowerbound -3.645280
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 4, lowerbound -3.510846
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 5, lowerbound -3.341845
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 6, lowerbound -3.150590
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 7, lowerbound -2.958738
,Thu 29 Sep 2016 11:05:37 AM UTC: dropping number of Gaussions to 7
,Thu 29 Sep 2016 11:05:37 AM UTC: iteration 8, lowerbound -2.777341
,Thu 29 Sep 2016 11:05:38 AM UTC: dropping number of Gaussions to 5
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 9, lowerbound -2.605928
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 10, lowerbound -2.475182
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 11, lowerbound -2.395492
,Thu 29 Sep 2016 11:05:38 AM UTC: dropping number of Gaussions to 4
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 12, lowerbound -2.348213
,Thu 29 Sep 2016 11:05:38 AM UTC: dropping number of Gaussions to 3
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 13, lowerbound -2.319060
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 14, lowerbound -2.307428
,Thu 29 Sep 2016 11:05:38 AM UTC: dropping number of Gaussions to 2
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 15, lowerbound -2.302957
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 16, lowerbound -2.299263
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 17, lowerbound -2.299257
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 18, lowerbound -2.299255
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 19, lowerbound -2.299254
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 20, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 21, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 22, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 23, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:38 AM UTC: iteration 24, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 25, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 26, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 27, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 28, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 29, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 30, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 31, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 32, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 33, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 34, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 35, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 36, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 37, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 38, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 39, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:39 AM UTC: iteration 40, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 41, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 42, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 43, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 44, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 45, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 46, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 47, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 48, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: iteration 49, lowerbound -2.299253
,Thu 29 Sep 2016 11:05:40 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.9549,178.045]
Î² = [95.9549,178.045]
m = [2.00023 53.852; 4.2503 79.2869]
Î½ = [97.9549,180.045]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.375876 -0.00895312; 0.0 0.0127487],

[0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -1.026536742469529
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -1.026536742469527
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -1.026536742469527
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 99999.99999999999
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9854506993955016
avll from llpg:  -0.9854506993955016
avll direct:     -0.9854506993955016
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0607506     0.205203    -0.163931    -0.151155     0.023196    -0.112349     0.124858     0.0115312     0.114279   -0.0547772    0.0126841    -0.00869795   -0.0529755    0.0169515    0.114766    -0.0367528    0.186354     0.0471491    0.0946428    -0.0882375    0.191553     0.00238822  -0.0768226   -0.0620713   -0.0657907   0.0970212 
 -0.0629849    -0.056414    -0.0585538    0.0377339   -0.0350607    0.161577    -0.0450834    0.113621     -0.0256406  -0.168416    -0.000336883   0.0912754    -0.0591486    0.0223571    0.057428    -0.0177448    0.0572851    0.148928     0.138857      0.15881     -0.0967281    0.17692     -0.0511861   -0.0140813    0.217545    0.0996888 
  0.0503111     0.174435    -0.12675      0.0918897   -0.0176711    0.0971451    0.00617456   0.129472      0.012625   -0.0299891    0.244577     -0.0688604     0.193492    -0.204976    -0.120594    -0.19826     -0.0414234   -0.0401892    0.209279      0.00155588  -0.170296     0.0677659    0.0620261   -0.234331     0.101038   -0.0283674 
  0.0515181     0.137052    -0.0682738    0.0463461    0.238057     0.0268766   -0.0746737    0.000642496  -0.0778093   0.0176383    0.0758456    -0.0194356     0.110089     0.0726043   -0.0227609    0.087102     0.107057     0.174398     0.0765933    -0.0432984    0.0176306   -0.0572427   -0.0214095    0.170417    -0.11557     0.0135621 
 -0.0318518    -0.11967      0.0226878   -0.0171189    0.113067     0.0314907   -0.0356349   -0.075802     -0.139997    0.093924     0.123695      0.058793      0.0120658   -0.0432369   -0.0105554   -0.138979    -0.0822971    0.0305177   -0.0995356     0.077224    -0.0635172   -0.0289587    0.0283876    0.179149     0.10219     0.0593451 
 -0.146739     -0.0381155    0.0905833   -0.16327      0.151082     0.192602    -0.0650706   -0.0987741     0.0532589   0.170456    -0.0866959     0.101466      0.0725528    0.118606    -0.157771     0.0452056    0.145767     0.0635601    0.150445      0.0594226   -0.0599531    0.126362    -0.0477733   -0.101481    -0.101576   -0.0786422 
  0.00895372    0.121693     0.0322658    0.0205967   -0.129969     0.106958     0.0753961   -0.108275     -0.123484    0.142254     0.0378047    -0.0294772     0.159797     0.0614883   -0.186905    -0.114732    -0.115304    -0.119526     0.0522006     0.162182    -0.0317672    0.0489295    0.0615283    0.02328     -0.0481094   0.0464505 
 -0.106135      0.00943392   0.0827357    0.0626898   -0.00598122   0.143122    -0.196961     0.078884      0.121485    0.0426332    0.0454969     0.0694022     0.144383    -0.0107633   -0.0336745   -0.0156841    0.0137103    0.164828     0.172285     -0.0146284   -0.0551399   -0.107307    -0.0132182   -0.0844247   -0.192314   -0.0774685 
 -0.0412158    -0.00825686  -0.0993025   -0.0428674    0.0513224   -0.0778671   -0.0185539   -0.0415522     0.113669   -0.0748496    0.026422      0.0537049     0.0655463   -0.112626     0.0134878   -0.118861    -0.0417827    0.173961    -0.054809      0.083616     0.0920817    0.0479283   -0.0733739   -0.0677583    0.0801479  -0.1356    
 -0.000397391   0.0238824   -0.0242661   -0.216369     0.0756703   -0.0215706    0.0573634   -0.026341      0.0968724  -0.00176089   0.0179136     0.0192578     0.0231603   -0.0582776    0.0728075   -0.011326     0.0451197   -0.0342867    0.223179     -0.0779637   -0.098565    -0.06935     -0.0629497   -0.00324184  -0.0278223  -0.00457987
 -0.0455974    -0.0113724   -0.0606346    0.097796    -0.0261794    0.115658     0.164886    -0.0361587     0.0067215   0.0162932   -0.197903      0.0716628    -0.11453     -0.0954325   -0.0720774   -0.00554885  -0.00655015   0.0397582    0.103964      0.0290758   -0.0187536   -0.00771902   0.00773979  -0.133347     0.117697   -0.170975  
 -0.0779319     0.00278743   0.0855166   -0.0451553    0.0875402    0.05105      0.154746     0.0592829     0.0627037  -0.0852411   -0.00769475   -0.0526281     0.162219     0.00769771  -0.116693    -0.00137914  -0.0105879   -0.029128     0.0416337    -0.077806    -0.0137778   -0.085114     0.0749975    0.0916086   -0.0459226  -0.0194739 
  0.102079     -0.0112551   -0.113937     0.0208006   -0.00480903   0.111548    -0.0402624    0.0631937    -0.114035   -0.118035     0.0308181    -0.0236968     0.0452401   -0.102321     0.104015     0.0332794    0.112367     0.270024    -0.111045      0.194071     0.062384     0.064545    -0.0351075    0.117698    -0.0560631   0.084525  
 -0.0480289    -0.156678    -0.124606     0.21707      0.0255514   -0.0839566   -0.0819402    0.0187693     0.0374305  -0.0811848   -0.0127835     0.00595928    0.1312       0.0472572    0.0865069   -0.0454691    0.097698     0.121332     0.16565      -0.0131116   -0.141573     0.0955311    0.0815398   -0.0123831    0.0344708   0.0824111 
 -0.0442108    -0.0568145    0.041457    -0.073098    -0.151195     0.0246364    0.0495299   -0.256734      0.243411   -0.0901169   -0.0852956    -0.0317668     0.0516234   -0.103391    -0.040376     0.0725511   -0.0598596    0.0240587   -0.081709      0.110214    -0.029601    -0.0629429   -0.132801    -0.1134      -0.0921896   0.0138385 
 -0.0585048    -0.0627481    0.118999     0.0774902   -0.0434356    0.159131    -0.0349355   -0.222911     -0.0625857   0.102344    -0.0963853     0.000265322   0.00115731   0.0697653    0.00909672   0.134312     0.0439449    0.0162678    0.137928     -0.0522808   -0.276389    -0.178928    -0.0245395   -0.0269413    0.11017    -0.0692512 
 -0.0823776     0.133336     0.0258716    0.0494464    0.074056    -0.0999728    0.129015     0.197646      0.173639   -0.00592466  -0.0589684     0.0307604    -0.145609     0.0235359   -0.0936782   -0.0340664    0.137353     0.262449     0.0707571     0.105961    -0.0773305   -0.156043     0.117132     0.0130993   -0.107989    0.0775682 
  0.141115      0.121026    -0.179339    -0.0291503    0.00015911  -0.176631    -0.0473012    0.0799723     0.15903    -0.0930319    0.0823365     0.122555     -0.0215544   -0.131824    -0.038249    -0.0530421   -0.057022    -0.0947881    0.0862085     0.13603      0.0036801   -0.172917    -0.0259699   -0.180811     0.124093    0.0840202 
 -0.0316631    -0.0405444    0.0325625    0.0226667   -0.0342105   -0.188085    -0.0291817    0.0658515     0.0492724   0.131624    -0.0550909     0.0244392    -0.0890976    0.10726      0.170104    -0.0221904    0.0445777   -0.0287391   -0.0595013     0.0210903   -0.0561278   -0.32572      0.0750183   -0.0987372    0.0386204  -0.199977  
  0.119194     -0.106365     0.0574415   -0.00409128   0.0551324    0.00448711  -0.133077     0.0686088     0.11698    -0.118316    -0.0542706    -0.0257957    -0.108272     0.166191    -0.0540824   -0.127258     0.0770146    0.157001    -0.000514057  -0.152345    -0.0247742   -0.105333    -0.101077    -0.0792176   -0.0933194   0.0386612 
 -0.00936482   -0.061085     0.102851     0.207615     0.0148724    0.110781    -0.0670714    0.144564      0.0309767  -0.019391     0.0665399    -0.188733      0.168725    -0.0194689    0.0119775   -0.0761858    0.057032    -0.0693361    0.016299     -0.026837    -0.00815617   0.215032     0.247921     0.12543      0.0434216  -0.0229824 
 -0.0323419     0.0116801   -0.018586    -0.113532     0.111227     0.159358    -0.00629071  -0.010182     -0.0422726   0.0254797   -0.0712261     0.0791944    -0.234858     0.0184892   -0.037754    -0.0247892   -0.0850351   -0.113338     0.00366242    0.0158483   -0.0272466    0.0697277   -0.0540368   -0.0396652   -0.0784548   0.184285  
  0.098761      0.0549942    0.140518    -0.0298446    0.156668    -0.0902991   -0.162607    -0.203112     -0.0759963   0.0434441   -0.194859      0.195297      0.0992156    0.0290926   -0.21203     -0.0384258    0.120323     0.0690162    0.00171873   -0.0783919    0.0459867   -0.0120229    0.0366911    0.0510718    0.0446492   0.147224  
  0.0541434    -0.0480603   -0.0766524    0.0551231   -0.07371     -0.164279     0.0887244   -0.156985      0.132627   -0.0812838   -0.171143      0.140278      0.00342275  -0.0988897   -0.109191    -0.132972     0.155246     0.0528765    0.0492359     0.187675    -0.0491936   -0.179419     0.148003     0.0900738    0.0632856  -0.00176496
  0.100903      0.0603066   -0.0892025   -0.0360871   -0.0281833    0.0285287   -0.0406983   -0.230403      0.0966191   0.0765542   -0.0238429     0.124666     -0.0641074   -0.0485542   -0.0907624   -0.0039652   -0.267539     0.00815343  -0.117557      0.162812    -0.0730505   -0.0374337    0.21971     -0.0694498   -0.0984859   0.00776378
  0.00371455    0.0579728   -0.0532414    0.0583822    0.0646659   -0.0322715    0.0345641    0.197567      0.0369019  -0.0734758    0.0584105     0.113512      0.153963    -0.0249355   -0.0325674   -0.0752926   -0.18789     -0.266501    -0.0197662    -0.075843     0.0922741   -0.117411     0.0594556    0.00623425  -0.0354316  -0.0266663 
  0.0654786     0.0962337   -0.0940783   -0.153341     0.0486573    0.0576454   -0.038573     0.0460881    -0.167469   -0.129821    -0.134637     -0.0557431     0.154994    -0.0853154    0.121766    -0.0442987    0.0744226    0.094014    -0.0338296     0.0433927    0.0204017    0.12486     -0.267002    -0.0604319    0.0538212   0.150324  
  0.0219259     0.0581889   -0.039278    -0.061336     0.0038264   -0.0469163   -0.121323    -0.00613423   -0.0177342  -0.0175311    0.12995       0.00389793    0.0413714   -0.0344536   -0.0414075   -0.0703346   -0.0695768   -0.0124341   -0.129029      0.0171461   -0.0695935    0.118519    -0.0214457   -0.125449     0.0275351  -0.00882885
  0.0814873    -0.0463851    0.0194221   -0.0209678   -0.0130306   -0.0191676   -0.141711     0.125402      0.150352   -0.147331     0.124599     -0.0210561    -0.0841756    0.0297257   -0.0257768   -0.0128723    0.0206497    0.0387488    0.0597271     0.0563965   -0.111574    -0.0748355   -0.0999615    0.0270692   -0.238415    0.113699  
  0.122099      0.0206149   -0.04813     -0.100448    -0.19324      0.0588768    0.0746497   -0.0680678    -0.0543972   0.0580372   -0.078728      0.15179       0.00983088   0.238019    -0.176054     0.00998058   0.0216033   -0.182049     0.0104648    -0.0141713    0.159032     0.0623104    0.0811563   -0.149448     0.0257669   0.00960323
 -0.145961     -0.0491627    0.00853851  -0.0259198   -0.0472576   -0.0133952   -0.00134726   0.110143     -0.115761   -0.173906     0.046385     -0.117964      0.0164892    0.132883     0.0788552   -0.0974415    0.130867     0.0625907   -0.0160979    -0.032354    -0.0472302   -0.0738606    0.0268205   -0.157331    -0.0128218  -0.102002  
  0.114699     -0.0440629    0.117633     0.240288    -0.106545     0.140173    -0.0508484    0.11385      -0.100932   -0.135539     0.0608135    -0.0492326     0.200288    -0.156243    -0.0792967   -0.0461063   -0.0339782    0.0232924   -0.177316     -0.054287    -0.123844    -0.080007    -0.180031     0.188692    -0.0869264  -0.0176345 kind diag, method split
0: avll = -1.4040882099983725
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.404193
INFO: iteration 2, average log likelihood -1.404105
INFO: iteration 3, average log likelihood -1.403331
INFO: iteration 4, average log likelihood -1.393719
INFO: iteration 5, average log likelihood -1.370210
INFO: iteration 6, average log likelihood -1.362064
INFO: iteration 7, average log likelihood -1.360030
INFO: iteration 8, average log likelihood -1.358467
INFO: iteration 9, average log likelihood -1.357665
INFO: iteration 10, average log likelihood -1.357305
INFO: iteration 11, average log likelihood -1.357088
INFO: iteration 12, average log likelihood -1.356921
INFO: iteration 13, average log likelihood -1.356766
INFO: iteration 14, average log likelihood -1.356618
INFO: iteration 15, average log likelihood -1.356490
INFO: iteration 16, average log likelihood -1.356385
INFO: iteration 17, average log likelihood -1.356301
INFO: iteration 18, average log likelihood -1.356234
INFO: iteration 19, average log likelihood -1.356182
INFO: iteration 20, average log likelihood -1.356140
INFO: iteration 21, average log likelihood -1.356107
INFO: iteration 22, average log likelihood -1.356080
INFO: iteration 23, average log likelihood -1.356059
INFO: iteration 24, average log likelihood -1.356041
INFO: iteration 25, average log likelihood -1.356027
INFO: iteration 26, average log likelihood -1.356015
INFO: iteration 27, average log likelihood -1.356006
INFO: iteration 28, average log likelihood -1.355997
INFO: iteration 29, average log likelihood -1.355991
INFO: iteration 30, average log likelihood -1.355985
INFO: iteration 31, average log likelihood -1.355980
INFO: iteration 32, average log likelihood -1.355976
INFO: iteration 33, average log likelihood -1.355973
INFO: iteration 34, average log likelihood -1.355970
INFO: iteration 35, average log likelihood -1.355967
INFO: iteration 36, average log likelihood -1.355965
INFO: iteration 37, average log likelihood -1.355963
INFO: iteration 38, average log likelihood -1.355962
INFO: iteration 39, average log likelihood -1.355960
INFO: iteration 40, average log likelihood -1.355959
INFO: iteration 41, average log likelihood -1.355958
INFO: iteration 42, average log likelihood -1.355957
INFO: iteration 43, average log likelihood -1.355956
INFO: iteration 44, average log likelihood -1.355956
INFO: iteration 45, average log likelihood -1.355955
INFO: iteration 46, average log likelihood -1.355955
INFO: iteration 47, average log likelihood -1.355954
INFO: iteration 48, average log likelihood -1.355954
INFO: iteration 49, average log likelihood -1.355954
INFO: iteration 50, average log likelihood -1.355953
INFO: EM with 100000 data points 50 iterations avll -1.355953
952.4 data points per parameter
1: avll = [-1.40419,-1.4041,-1.40333,-1.39372,-1.37021,-1.36206,-1.36003,-1.35847,-1.35766,-1.3573,-1.35709,-1.35692,-1.35677,-1.35662,-1.35649,-1.35638,-1.3563,-1.35623,-1.35618,-1.35614,-1.35611,-1.35608,-1.35606,-1.35604,-1.35603,-1.35602,-1.35601,-1.356,-1.35599,-1.35598,-1.35598,-1.35598,-1.35597,-1.35597,-1.35597,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35595,-1.35595,-1.35595,-1.35595,-1.35595]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.356118
INFO: iteration 2, average log likelihood -1.355972
INFO: iteration 3, average log likelihood -1.355116
INFO: iteration 4, average log likelihood -1.347808
INFO: iteration 5, average log likelihood -1.330613
INFO: iteration 6, average log likelihood -1.320436
INFO: iteration 7, average log likelihood -1.316094
INFO: iteration 8, average log likelihood -1.313670
INFO: iteration 9, average log likelihood -1.312199
INFO: iteration 10, average log likelihood -1.311051
INFO: iteration 11, average log likelihood -1.309882
INFO: iteration 12, average log likelihood -1.308629
INFO: iteration 13, average log likelihood -1.307486
INFO: iteration 14, average log likelihood -1.306623
INFO: iteration 15, average log likelihood -1.306033
INFO: iteration 16, average log likelihood -1.305604
INFO: iteration 17, average log likelihood -1.305229
INFO: iteration 18, average log likelihood -1.304843
INFO: iteration 19, average log likelihood -1.304375
INFO: iteration 20, average log likelihood -1.303760
INFO: iteration 21, average log likelihood -1.303034
INFO: iteration 22, average log likelihood -1.302439
INFO: iteration 23, average log likelihood -1.302079
INFO: iteration 24, average log likelihood -1.301772
INFO: iteration 25, average log likelihood -1.301412
INFO: iteration 26, average log likelihood -1.300911
INFO: iteration 27, average log likelihood -1.300195
INFO: iteration 28, average log likelihood -1.299216
INFO: iteration 29, average log likelihood -1.298387
INFO: iteration 30, average log likelihood -1.298176
INFO: iteration 31, average log likelihood -1.298115
INFO: iteration 32, average log likelihood -1.298086
INFO: iteration 33, average log likelihood -1.298068
INFO: iteration 34, average log likelihood -1.298055
INFO: iteration 35, average log likelihood -1.298043
INFO: iteration 36, average log likelihood -1.298032
INFO: iteration 37, average log likelihood -1.298020
INFO: iteration 38, average log likelihood -1.298008
INFO: iteration 39, average log likelihood -1.297995
INFO: iteration 40, average log likelihood -1.297981
INFO: iteration 41, average log likelihood -1.297965
INFO: iteration 42, average log likelihood -1.297948
INFO: iteration 43, average log likelihood -1.297929
INFO: iteration 44, average log likelihood -1.297908
INFO: iteration 45, average log likelihood -1.297885
INFO: iteration 46, average log likelihood -1.297858
INFO: iteration 47, average log likelihood -1.297827
INFO: iteration 48, average log likelihood -1.297790
INFO: iteration 49, average log likelihood -1.297744
INFO: iteration 50, average log likelihood -1.297687
INFO: EM with 100000 data points 50 iterations avll -1.297687
473.9 data points per parameter
2: avll = [-1.35612,-1.35597,-1.35512,-1.34781,-1.33061,-1.32044,-1.31609,-1.31367,-1.3122,-1.31105,-1.30988,-1.30863,-1.30749,-1.30662,-1.30603,-1.3056,-1.30523,-1.30484,-1.30438,-1.30376,-1.30303,-1.30244,-1.30208,-1.30177,-1.30141,-1.30091,-1.30019,-1.29922,-1.29839,-1.29818,-1.29811,-1.29809,-1.29807,-1.29805,-1.29804,-1.29803,-1.29802,-1.29801,-1.29799,-1.29798,-1.29797,-1.29795,-1.29793,-1.29791,-1.29788,-1.29786,-1.29783,-1.29779,-1.29774,-1.29769]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.297812
INFO: iteration 2, average log likelihood -1.297561
INFO: iteration 3, average log likelihood -1.296843
INFO: iteration 4, average log likelihood -1.290634
INFO: iteration 5, average log likelihood -1.272286
INFO: iteration 6, average log likelihood -1.254773
INFO: iteration 7, average log likelihood -1.246702
INFO: iteration 8, average log likelihood -1.243030
INFO: iteration 9, average log likelihood -1.240752
INFO: iteration 10, average log likelihood -1.239145
INFO: iteration 11, average log likelihood -1.237902
INFO: iteration 12, average log likelihood -1.236861
INFO: iteration 13, average log likelihood -1.236002
INFO: iteration 14, average log likelihood -1.235360
INFO: iteration 15, average log likelihood -1.234903
INFO: iteration 16, average log likelihood -1.234579
INFO: iteration 17, average log likelihood -1.234371
INFO: iteration 18, average log likelihood -1.234247
INFO: iteration 19, average log likelihood -1.234171
INFO: iteration 20, average log likelihood -1.234120
INFO: iteration 21, average log likelihood -1.234081
INFO: iteration 22, average log likelihood -1.234048
INFO: iteration 23, average log likelihood -1.234017
INFO: iteration 24, average log likelihood -1.233988
INFO: iteration 25, average log likelihood -1.233957
INFO: iteration 26, average log likelihood -1.233925
INFO: iteration 27, average log likelihood -1.233889
INFO: iteration 28, average log likelihood -1.233850
INFO: iteration 29, average log likelihood -1.233807
INFO: iteration 30, average log likelihood -1.233757
INFO: iteration 31, average log likelihood -1.233698
INFO: iteration 32, average log likelihood -1.233626
INFO: iteration 33, average log likelihood -1.233540
INFO: iteration 34, average log likelihood -1.233435
INFO: iteration 35, average log likelihood -1.233305
INFO: iteration 36, average log likelihood -1.233145
INFO: iteration 37, average log likelihood -1.232964
INFO: iteration 38, average log likelihood -1.232769
INFO: iteration 39, average log likelihood -1.232593
INFO: iteration 40, average log likelihood -1.232462
INFO: iteration 41, average log likelihood -1.232377
INFO: iteration 42, average log likelihood -1.232309
INFO: iteration 43, average log likelihood -1.232253
INFO: iteration 44, average log likelihood -1.232209
INFO: iteration 45, average log likelihood -1.232174
INFO: iteration 46, average log likelihood -1.232146
INFO: iteration 47, average log likelihood -1.232122
INFO: iteration 48, average log likelihood -1.232102
INFO: iteration 49, average log likelihood -1.232084
INFO: iteration 50, average log likelihood -1.232066
INFO: EM with 100000 data points 50 iterations avll -1.232066
236.4 data points per parameter
3: avll = [-1.29781,-1.29756,-1.29684,-1.29063,-1.27229,-1.25477,-1.2467,-1.24303,-1.24075,-1.23914,-1.2379,-1.23686,-1.236,-1.23536,-1.2349,-1.23458,-1.23437,-1.23425,-1.23417,-1.23412,-1.23408,-1.23405,-1.23402,-1.23399,-1.23396,-1.23392,-1.23389,-1.23385,-1.23381,-1.23376,-1.2337,-1.23363,-1.23354,-1.23343,-1.2333,-1.23315,-1.23296,-1.23277,-1.23259,-1.23246,-1.23238,-1.23231,-1.23225,-1.23221,-1.23217,-1.23215,-1.23212,-1.2321,-1.23208,-1.23207]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.232319
INFO: iteration 2, average log likelihood -1.232045
INFO: iteration 3, average log likelihood -1.231341
INFO: iteration 4, average log likelihood -1.223557
INFO: iteration 5, average log likelihood -1.195630
INFO: iteration 6, average log likelihood -1.168255
WARNING: Variances had to be floored 11 12
INFO: iteration 7, average log likelihood -1.151335
WARNING: Variances had to be floored 5
INFO: iteration 8, average log likelihood -1.160020
WARNING: Variances had to be floored 12
INFO: iteration 9, average log likelihood -1.157990
WARNING: Variances had to be floored 11
INFO: iteration 10, average log likelihood -1.147752
WARNING: Variances had to be floored 12
INFO: iteration 11, average log likelihood -1.149202
WARNING: Variances had to be floored 5
INFO: iteration 12, average log likelihood -1.140350
WARNING: Variances had to be floored 9 11 12
INFO: iteration 13, average log likelihood -1.140534
INFO: iteration 14, average log likelihood -1.158545
WARNING: Variances had to be floored 12
INFO: iteration 15, average log likelihood -1.141264
WARNING: Variances had to be floored 5 11
INFO: iteration 16, average log likelihood -1.134187
WARNING: Variances had to be floored 12
INFO: iteration 17, average log likelihood -1.153007
INFO: iteration 18, average log likelihood -1.143078
WARNING: Variances had to be floored 9 11 12
INFO: iteration 19, average log likelihood -1.129104
WARNING: Variances had to be floored 5
INFO: iteration 20, average log likelihood -1.150282
WARNING: Variances had to be floored 12
INFO: iteration 21, average log likelihood -1.151421
WARNING: Variances had to be floored 11
INFO: iteration 22, average log likelihood -1.142836
WARNING: Variances had to be floored 12
INFO: iteration 23, average log likelihood -1.143929
WARNING: Variances had to be floored 5
INFO: iteration 24, average log likelihood -1.135862
WARNING: Variances had to be floored 11 12
INFO: iteration 25, average log likelihood -1.139229
WARNING: Variances had to be floored 9
INFO: iteration 26, average log likelihood -1.149481
WARNING: Variances had to be floored 12
INFO: iteration 27, average log likelihood -1.144662
WARNING: Variances had to be floored 5 11
INFO: iteration 28, average log likelihood -1.136613
WARNING: Variances had to be floored 12
INFO: iteration 29, average log likelihood -1.154925
INFO: iteration 30, average log likelihood -1.144469
WARNING: Variances had to be floored 11 12
INFO: iteration 31, average log likelihood -1.130519
WARNING: Variances had to be floored 5
INFO: iteration 32, average log likelihood -1.142509
WARNING: Variances had to be floored 9 12
INFO: iteration 33, average log likelihood -1.145792
WARNING: Variances had to be floored 11
INFO: iteration 34, average log likelihood -1.147286
WARNING: Variances had to be floored 12
INFO: iteration 35, average log likelihood -1.146755
WARNING: Variances had to be floored 5
INFO: iteration 36, average log likelihood -1.137883
WARNING: Variances had to be floored 11 12
INFO: iteration 37, average log likelihood -1.140859
INFO: iteration 38, average log likelihood -1.150980
WARNING: Variances had to be floored 12
INFO: iteration 39, average log likelihood -1.136777
WARNING: Variances had to be floored 5 9 11
INFO: iteration 40, average log likelihood -1.130689
WARNING: Variances had to be floored 12
INFO: iteration 41, average log likelihood -1.158924
INFO: iteration 42, average log likelihood -1.147064
WARNING: Variances had to be floored 11 12
INFO: iteration 43, average log likelihood -1.132432
WARNING: Variances had to be floored 5
INFO: iteration 44, average log likelihood -1.143818
WARNING: Variances had to be floored 12
INFO: iteration 45, average log likelihood -1.147134
WARNING: Variances had to be floored 11
INFO: iteration 46, average log likelihood -1.139321
WARNING: Variances had to be floored 9 12
INFO: iteration 47, average log likelihood -1.140808
WARNING: Variances had to be floored 5
INFO: iteration 48, average log likelihood -1.142071
WARNING: Variances had to be floored 11 12
INFO: iteration 49, average log likelihood -1.143582
INFO: iteration 50, average log likelihood -1.153002
INFO: EM with 100000 data points 50 iterations avll -1.153002
118.1 data points per parameter
4: avll = [-1.23232,-1.23204,-1.23134,-1.22356,-1.19563,-1.16826,-1.15134,-1.16002,-1.15799,-1.14775,-1.1492,-1.14035,-1.14053,-1.15854,-1.14126,-1.13419,-1.15301,-1.14308,-1.1291,-1.15028,-1.15142,-1.14284,-1.14393,-1.13586,-1.13923,-1.14948,-1.14466,-1.13661,-1.15493,-1.14447,-1.13052,-1.14251,-1.14579,-1.14729,-1.14675,-1.13788,-1.14086,-1.15098,-1.13678,-1.13069,-1.15892,-1.14706,-1.13243,-1.14382,-1.14713,-1.13932,-1.14081,-1.14207,-1.14358,-1.153]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 23 24
INFO: iteration 1, average log likelihood -1.138763
WARNING: Variances had to be floored 9 10 21 22 23 24
INFO: iteration 2, average log likelihood -1.128858
WARNING: Variances had to be floored 23 24
INFO: iteration 3, average log likelihood -1.135270
WARNING: Variances had to be floored 9 10 17 21 22 23 24
INFO: iteration 4, average log likelihood -1.114015
WARNING: Variances had to be floored 18 23 24
INFO: iteration 5, average log likelihood -1.086660
WARNING: Variances had to be floored 9 10 14 21 22 23 24
INFO: iteration 6, average log likelihood -1.049644
WARNING: Variances had to be floored 1 9 10 17 23 24
INFO: iteration 7, average log likelihood -1.045595
WARNING: Variances had to be floored 9 10 18 21 22 23 24 29
INFO: iteration 8, average log likelihood -1.039095
WARNING: Variances had to be floored 14 23 24
INFO: iteration 9, average log likelihood -1.051261
WARNING: Variances had to be floored 9 10 21 22 23 24
INFO: iteration 10, average log likelihood -1.035422
WARNING: Variances had to be floored 1 9 10 18 23 24
INFO: iteration 11, average log likelihood -1.034926
WARNING: Variances had to be floored 9 10 14 21 22 23 24 29
INFO: iteration 12, average log likelihood -1.040447
WARNING: Variances had to be floored 23 24
INFO: iteration 13, average log likelihood -1.055490
WARNING: Variances had to be floored 9 10 18 21 22 23 24
INFO: iteration 14, average log likelihood -1.028070
WARNING: Variances had to be floored 1 9 10 14 17 23 24
INFO: iteration 15, average log likelihood -1.028721
WARNING: Variances had to be floored 18 21 22 23 29
INFO: iteration 16, average log likelihood -1.047342
WARNING: Variances had to be floored 9 10 17 23 24
INFO: iteration 17, average log likelihood -1.039301
WARNING: Variances had to be floored 14 18 21 22 23
INFO: iteration 18, average log likelihood -1.032792
WARNING: Variances had to be floored 1 9 10 17 24 27
INFO: iteration 19, average log likelihood -1.024427
WARNING: Variances had to be floored 9 10 18 21 22 23 24 29
INFO: iteration 20, average log likelihood -1.045673
WARNING: Variances had to be floored 9 10 14 23 24
INFO: iteration 21, average log likelihood -1.049223
WARNING: Variances had to be floored 1 9 10 17 18 21 22 23 24
INFO: iteration 22, average log likelihood -1.028440
WARNING: Variances had to be floored 23
INFO: iteration 23, average log likelihood -1.053615
WARNING: Variances had to be floored 9 10 14 21 22 24 29
INFO: iteration 24, average log likelihood -1.020180
WARNING: Variances had to be floored 1 9 10 17 18 23 24 27
INFO: iteration 25, average log likelihood -1.031156
WARNING: Variances had to be floored 9 10 21 22 23 24
INFO: iteration 26, average log likelihood -1.054549
WARNING: Variances had to be floored 9 10 14 23 24
INFO: iteration 27, average log likelihood -1.041281
WARNING: Variances had to be floored 1 9 10 17 18 21 22 23 24 29
INFO: iteration 28, average log likelihood -1.024964
WARNING: Variances had to be floored 23 24
INFO: iteration 29, average log likelihood -1.061418
WARNING: Variances had to be floored 9 10 14 21 22 23 24
INFO: iteration 30, average log likelihood -1.029648
WARNING: Variances had to be floored 1 9 10 17 18 23 24
INFO: iteration 31, average log likelihood -1.025522
WARNING: Variances had to be floored 21 22 23 27 29
INFO: iteration 32, average log likelihood -1.041492
WARNING: Variances had to be floored 9 10 14 24
INFO: iteration 33, average log likelihood -1.045952
WARNING: Variances had to be floored 1 9 10 17 18 21 22 23 24
INFO: iteration 34, average log likelihood -1.025736
WARNING: Variances had to be floored 23
INFO: iteration 35, average log likelihood -1.053135
WARNING: Variances had to be floored 9 10 14 21 22 24 27 29
INFO: iteration 36, average log likelihood -1.019002
WARNING: Variances had to be floored 9 10 17 18 23 24
INFO: iteration 37, average log likelihood -1.042494
WARNING: Variances had to be floored 1 21 22 23 24
INFO: iteration 38, average log likelihood -1.037647
WARNING: Variances had to be floored 9 10 14 23 24
INFO: iteration 39, average log likelihood -1.039008
WARNING: Variances had to be floored 9 10 17 18 21 22 23 24 29
INFO: iteration 40, average log likelihood -1.021590
WARNING: Variances had to be floored 23 27
INFO: iteration 41, average log likelihood -1.045868
WARNING: Variances had to be floored 1 9 10 14 21 22 24
INFO: iteration 42, average log likelihood -1.027738
WARNING: Variances had to be floored 9 10 17 18 23 24
INFO: iteration 43, average log likelihood -1.041231
WARNING: Variances had to be floored 21 22 23 29
INFO: iteration 44, average log likelihood -1.036751
WARNING: Variances had to be floored 9 10 14 24 27
INFO: iteration 45, average log likelihood -1.030028
WARNING: Variances had to be floored 1 9 10 17 18 21 22 23 24
INFO: iteration 46, average log likelihood -1.029945
WARNING: Variances had to be floored 23 24
INFO: iteration 47, average log likelihood -1.054532
WARNING: Variances had to be floored 9 10 14 21 22 23 24 29
INFO: iteration 48, average log likelihood -1.023165
WARNING: Variances had to be floored 1 9 17 18 23 24 27
INFO: iteration 49, average log likelihood -1.032642
WARNING: Variances had to be floored 10 21 22 23 24
INFO: iteration 50, average log likelihood -1.051480
INFO: EM with 100000 data points 50 iterations avll -1.051480
59.0 data points per parameter
5: avll = [-1.13876,-1.12886,-1.13527,-1.11402,-1.08666,-1.04964,-1.0456,-1.0391,-1.05126,-1.03542,-1.03493,-1.04045,-1.05549,-1.02807,-1.02872,-1.04734,-1.0393,-1.03279,-1.02443,-1.04567,-1.04922,-1.02844,-1.05361,-1.02018,-1.03116,-1.05455,-1.04128,-1.02496,-1.06142,-1.02965,-1.02552,-1.04149,-1.04595,-1.02574,-1.05313,-1.019,-1.04249,-1.03765,-1.03901,-1.02159,-1.04587,-1.02774,-1.04123,-1.03675,-1.03003,-1.02995,-1.05453,-1.02316,-1.03264,-1.05148]
[-1.40409,-1.40419,-1.4041,-1.40333,-1.39372,-1.37021,-1.36206,-1.36003,-1.35847,-1.35766,-1.3573,-1.35709,-1.35692,-1.35677,-1.35662,-1.35649,-1.35638,-1.3563,-1.35623,-1.35618,-1.35614,-1.35611,-1.35608,-1.35606,-1.35604,-1.35603,-1.35602,-1.35601,-1.356,-1.35599,-1.35598,-1.35598,-1.35598,-1.35597,-1.35597,-1.35597,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35596,-1.35595,-1.35595,-1.35595,-1.35595,-1.35595,-1.35612,-1.35597,-1.35512,-1.34781,-1.33061,-1.32044,-1.31609,-1.31367,-1.3122,-1.31105,-1.30988,-1.30863,-1.30749,-1.30662,-1.30603,-1.3056,-1.30523,-1.30484,-1.30438,-1.30376,-1.30303,-1.30244,-1.30208,-1.30177,-1.30141,-1.30091,-1.30019,-1.29922,-1.29839,-1.29818,-1.29811,-1.29809,-1.29807,-1.29805,-1.29804,-1.29803,-1.29802,-1.29801,-1.29799,-1.29798,-1.29797,-1.29795,-1.29793,-1.29791,-1.29788,-1.29786,-1.29783,-1.29779,-1.29774,-1.29769,-1.29781,-1.29756,-1.29684,-1.29063,-1.27229,-1.25477,-1.2467,-1.24303,-1.24075,-1.23914,-1.2379,-1.23686,-1.236,-1.23536,-1.2349,-1.23458,-1.23437,-1.23425,-1.23417,-1.23412,-1.23408,-1.23405,-1.23402,-1.23399,-1.23396,-1.23392,-1.23389,-1.23385,-1.23381,-1.23376,-1.2337,-1.23363,-1.23354,-1.23343,-1.2333,-1.23315,-1.23296,-1.23277,-1.23259,-1.23246,-1.23238,-1.23231,-1.23225,-1.23221,-1.23217,-1.23215,-1.23212,-1.2321,-1.23208,-1.23207,-1.23232,-1.23204,-1.23134,-1.22356,-1.19563,-1.16826,-1.15134,-1.16002,-1.15799,-1.14775,-1.1492,-1.14035,-1.14053,-1.15854,-1.14126,-1.13419,-1.15301,-1.14308,-1.1291,-1.15028,-1.15142,-1.14284,-1.14393,-1.13586,-1.13923,-1.14948,-1.14466,-1.13661,-1.15493,-1.14447,-1.13052,-1.14251,-1.14579,-1.14729,-1.14675,-1.13788,-1.14086,-1.15098,-1.13678,-1.13069,-1.15892,-1.14706,-1.13243,-1.14382,-1.14713,-1.13932,-1.14081,-1.14207,-1.14358,-1.153,-1.13876,-1.12886,-1.13527,-1.11402,-1.08666,-1.04964,-1.0456,-1.0391,-1.05126,-1.03542,-1.03493,-1.04045,-1.05549,-1.02807,-1.02872,-1.04734,-1.0393,-1.03279,-1.02443,-1.04567,-1.04922,-1.02844,-1.05361,-1.02018,-1.03116,-1.05455,-1.04128,-1.02496,-1.06142,-1.02965,-1.02552,-1.04149,-1.04595,-1.02574,-1.05313,-1.019,-1.04249,-1.03765,-1.03901,-1.02159,-1.04587,-1.02774,-1.04123,-1.03675,-1.03003,-1.02995,-1.05453,-1.02316,-1.03264,-1.05148]
32Ã—26 Array{Float64,2}:
 -0.14801     -0.00740085   0.0217104  -0.0249943   -0.0484556    0.000428094   0.00547708   0.106504   -0.113431   -0.165589     0.0453372   -0.120354     0.0205673    0.132915     0.0711067   -0.094811      0.128301     0.0969268   -0.0318408   -0.0728906   -0.0321162   -0.068147    0.0214056   -0.143901    -0.00168909   -0.107555  
 -0.0448609   -0.00846994  -0.0978757  -0.0276438    0.0529167   -0.0650104    -0.0205481   -0.0298784   0.122852   -0.0667506    0.0266353    0.0356923    0.069278    -0.112894     0.00469882  -0.0874414    -0.0488355    0.166833    -0.0598836    0.109929     0.0835667    0.0504494  -0.0638142   -0.080875     0.092853     -0.134055  
  0.0520147    0.121903    -0.149207   -0.16225      0.013761    -0.132414      0.175883     0.063384    0.138342   -0.812784     0.0208149   -0.0820049   -0.0570508    0.0177437    0.0101806   -0.134802      0.15507      0.0214051    0.0544515   -0.0971256    0.194526     0.0309524  -0.118664    -0.0715095   -0.169405      0.144242  
  0.0646041    0.337781    -0.121723   -0.175141     0.0352203   -0.0931064     0.0192382    0.0370403   0.0736034   0.520983     0.00622472   0.215275    -0.0507828    0.0157784    0.195198     0.0926627     0.205927     0.0763677    0.221634    -0.0543738    0.173058    -0.0245828  -0.063188    -0.0410402   -0.00469098    0.0416031 
  0.0943129    0.0966527    0.0082817  -0.00541266  -0.0914474   -0.00703427   -0.175991     0.153464    0.112604   -0.181267     0.104613    -0.00617764  -0.103622     0.0317426   -0.0277688   -0.0043731     0.179033     0.0987367    0.0537664   -0.0356338   -0.120497    -0.0718769  -0.12578      0.108843    -0.881712      0.100103  
  0.0634199   -0.112647     0.0290518  -0.0552854    0.0399681   -0.0354302    -0.0912912    0.0696601   0.190822   -0.162664     0.160825    -0.038854    -0.0546246    0.0373991   -0.0257937    0.0254488    -0.0303805   -0.00572744   0.0637819    0.079598    -0.106583    -0.0645432  -0.0480438   -0.0317925    0.530327      0.123083  
 -0.0319039   -0.1181       0.0124519  -0.0173962    0.109807     0.0105237     0.00572041  -0.074739   -0.147392    0.076723     0.120708     0.0623534   -0.00306626  -0.0455429    0.00368079  -0.144303     -0.0946863    0.0205406   -0.0926997    0.074473    -0.0724751   -0.0281334   0.0391492    0.181526     0.106796      0.0600833 
 -0.0766081    0.00287414   0.0263494  -0.0435513    0.0807078    0.0578021     0.15824      0.0596328   0.0272002  -0.0885145   -0.0289586   -0.0423134    0.164041     0.00591821  -0.125208    -0.000330078  -0.0122193   -0.0380985    0.041557    -0.0702646   -0.0067218   -0.0920657   0.081224     0.0624527   -0.049824     -0.0135568 
 -0.0316639    0.0249022   -0.0405819  -0.192862     0.139446    -0.481728      0.0470967   -0.0731315  -0.0228157   0.00226169   0.0264761    0.0203338   -0.0392411   -0.155332     0.0680131    0.0139905     0.0344134    0.244701     0.102577    -0.587297    -0.268879    -0.119491   -0.0683074   -0.0490656   -0.049179     -0.152945  
 -0.00317948   0.0243621   -0.0128011  -0.216418     0.0301198    0.00106878    0.0587403   -0.0170972   0.0947577  -0.0010243    0.0181851    0.0221839    0.0396248   -0.0670833    0.0771992   -0.0175175     0.0342903   -0.0646823    0.242865    -0.0681187   -0.0821411   -0.0508261  -0.0853172    0.0223727   -0.000703684   0.0470354 
  0.0664954    0.0658096   -0.0946842  -0.0429165   -0.0431246    0.0224454    -0.0577139   -0.215963    0.106251    0.0636532   -0.0281014    0.116078    -0.0653186   -0.0714419   -0.0837841   -0.00889444   -0.230722     0.00776669  -0.0715509    0.149822    -0.0695562   -0.0354012   0.190834    -0.0816565   -0.0791869     0.0180951 
  0.0343529    0.124243     0.035542    0.0204479   -0.122647     0.0961041     0.074645    -0.106756   -0.113331    0.146427     0.0424026   -0.0298395    0.144815     0.0619785   -0.180025    -0.113039     -0.132502    -0.119857     0.0829345    0.149789    -0.0340532    0.0364173  -0.0513508    0.0262873   -0.0523791     0.0629885 
 -0.146295    -0.0480574    0.0948618  -0.122045     0.151682     0.188155     -0.0615723   -0.091982    0.0574333   0.197253    -0.061672     0.0958899    0.0612763    0.118077    -0.158892     0.0398659     0.148757     0.0280309    0.16154      0.05502     -0.00216402   0.118628   -0.058016    -0.0836609   -0.102628     -0.0732325 
 -0.0377117   -0.0402104    0.0379272   0.0367014   -0.00139679  -0.16862      -0.0367111    0.0149022   0.0448638   0.129753    -0.058116     0.0227933   -0.050513     0.121573     0.174104     0.0123887     0.0749444    0.0592528   -0.0541158   -0.00241797  -0.0709873   -0.3438      0.070622    -0.109331     0.0399079    -0.196276  
  0.14038      0.115416     0.0932732   0.00828837   0.0165936   -0.0803801     0.143902     0.0479766   0.0133586  -0.0945895   -0.163871     0.0926195   -0.0641373   -0.0551741   -0.0262591   -0.403885      0.0186028    0.0433771    0.143521     0.0388053   -0.0290676   -0.0695763   0.0120591   -0.124731     0.130792     -0.164911  
 -0.167041    -0.177961    -0.222183    0.128644    -0.028112     0.281134      0.186424    -0.0743006   0.0188379   0.099524    -0.17606      0.0571828   -0.114729    -0.133143    -0.125583     0.268657     -0.0158824    0.2408       0.0241959    0.0400167    0.00745215   0.133871    0.00378477  -0.158812     0.100598     -0.174014  
  0.0423627    0.139934    -0.111862    0.0769507   -0.00645467   0.114512      0.0616425    0.10173     0.0193578  -0.0749357    0.121009    -0.0691379    0.173415    -0.161272    -0.12159     -0.197571      0.00752778  -0.0248949    0.188404     0.0539822   -0.161579     0.0354428   0.0710292   -0.196168     0.092713     -0.0205888 
  0.0500602   -0.0563334   -0.0731071   0.0562089   -0.0768424   -0.169438      0.10141     -0.174918    0.144194   -0.0590941   -0.162585     0.171305    -0.00457602  -0.0919668   -0.107641    -0.126258      0.156911     0.0570291    0.0295641    0.1893      -0.0400737   -0.178721    0.151098     0.107397     0.0578765    -0.00313409
  0.113118    -0.130087     0.0513353  -0.00876223   0.054522    -0.000819248  -0.141605     0.070919    0.118727   -0.0709266   -0.0350562   -0.026994    -0.0843586    0.158768    -0.0599754   -0.131824      0.0682642    0.150662     0.00707332  -0.170906    -0.0265278   -0.121556   -0.104517    -0.0822302   -0.0911437     0.033274  
 -0.0839686    0.110474     0.031026    0.0504576    0.0727462   -0.0806078     0.0874919    0.192383    0.182903    0.0175567   -0.0500155    0.0310112   -0.138063     0.0241492   -0.0900329   -0.025886      0.13222      0.259106     0.054486     0.0528453   -0.0719927   -0.140098    0.102974     0.0184777   -0.112886      0.0716688 
 -0.110598    -0.0259648    0.0975261  -0.0728916   -0.402962     0.0191459     0.0462446   -0.248606    0.234071   -0.0841092   -0.0516896   -0.0351302    0.0562481   -0.131364    -0.039619     0.0754905    -0.0621167    0.0262599   -0.0815913    0.145664    -0.0281373   -0.221003   -0.137868    -0.100599    -0.0922122     0.0716932 
 -0.0140348   -0.0477984   -0.084026   -0.0724009    0.538561     0.0279806     0.0403893   -0.241504    0.256707   -0.0606105   -0.149982    -0.0196367    0.0798295   -0.0235181   -0.0401441    0.084964     -0.0412736    0.0153608   -0.0795379   -0.0222829   -0.0297729    0.390168   -0.112315    -0.0876641   -0.0921823    -0.184956  
 -0.1742      -0.0763135   -0.123157    0.20778     -0.0478405   -0.250618     -0.414856    -0.0495781   0.082763   -0.138089    -0.713812    -0.0495028    0.217621     0.0533813    0.193366     0.104636      0.117861     0.129642     0.576354     0.471298    -0.141632     0.143841    0.0820641    1.15936     -0.00773122    0.0673065 
 -0.0395458   -0.152006    -0.12389     0.212053     0.042984    -0.0326915    -0.0570132    0.0422162   0.0103769  -0.0630871    0.080626     0.01754      0.107758     0.0455932    0.0676925   -0.073423      0.0908569    0.123006     0.0363225   -0.157172    -0.138246     0.0783027   0.081906    -0.197887     0.0313906     0.0937738 
 -0.0494785   -0.0602013   -0.0627861   0.00859644  -0.0324733    0.198447     -0.0325664    0.0520681   0.0149212  -0.19353     -0.04568     -0.130699    -0.878197    -0.0105306    0.0523118   -0.0108216     0.0824414    0.181695     0.225308     0.188245    -0.13629      0.18591     0.0212033   -0.0413648    0.278668      0.0920097 
 -0.102067    -0.0527372   -0.044121    0.0426184   -0.0481428    0.137094     -0.0622662    0.116911   -0.114297   -0.126101     0.0215983    0.244194     0.788233     0.0576852    0.0558281   -0.0336084     0.036589     0.11854      0.0940865    0.13263     -0.0340337    0.166895   -0.0825378    0.00951806   0.162026      0.103771  
  0.0108539    0.107505    -0.0839518  -0.00997452   0.0062195    0.00596295   -0.00474991   0.052186    0.0169623  -0.0291911    0.165856    -0.0322902    0.10724     -0.0936378   -0.071275    -0.114862     -0.0605364   -0.0257116    0.0215881    0.0115767   -0.104115     0.0952131   0.0101249   -0.16414      0.0706087     0.0188576 
  0.115387     0.042579     0.144883   -0.0373493    0.15999     -0.0927137    -0.185081    -0.20907    -0.0766875   0.0367694   -0.193914     0.169793     0.0979207    0.0212224   -0.188425    -0.0385922     0.125001     0.0695066    0.00181973  -0.0979243    0.0833414   -0.011368    0.017717     0.050669     0.0450754     0.150438  
 -0.0688355   -0.0444333    0.116916    0.0366361   -0.0274545    0.0997847    -0.0361783   -0.18532    -0.0829797   0.070405    -0.0546984   -0.00110387   0.0204994    0.0521188    0.00367248   0.115908      0.0617652   -0.0168448    0.155793    -0.0437142   -0.25507     -0.169095   -0.0463512   -0.0070692    0.11512      -0.0477358 
  0.0784364    0.0134742   -0.106148   -0.0464583    0.0194522    0.0791818    -0.0382295    0.0592331  -0.125981   -0.128585    -0.032778    -0.0384531    0.100353    -0.0852724    0.0883083    0.0088739     0.0908033    0.18643     -0.0755377    0.137808     0.0490107    0.0850634  -0.143        0.0442949   -0.00908592    0.0931515 
 -0.0173427    0.00204943   0.0192905   0.0602993    0.0437884    0.0893065    -0.058792     0.125867    0.0366322  -0.0081136    0.0448142    0.00803034   0.0724253   -0.0175357   -0.0236648   -0.0492711    -0.04845     -0.0791257    0.0374317   -0.0237903    0.0118877    0.013311    0.0562742    0.0136878   -0.0584558     0.0178422 
  0.0954353    0.0531896   -0.0294275   0.0448464   -0.0161076    0.0299904    -0.0188666    0.0261166  -0.0118364  -0.0390934    0.0305998    0.0461796    0.0648458    0.00929301  -0.084069    -0.00843495    0.00365724  -0.0350238   -0.0193862   -0.00417288   0.00304413  -0.060302   -0.0330498    0.0304162   -0.0302602     0.0398468 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 9 10 14 23 24
INFO: iteration 1, average log likelihood -1.041170
WARNING: Variances had to be floored 1 9 10 14 17 18 21 22 23 24 29
INFO: iteration 2, average log likelihood -1.018339
WARNING: Variances had to be floored 9 14 23 24
INFO: iteration 3, average log likelihood -1.039279
WARNING: Variances had to be floored 1 10 14 17 18 21 22 23 24 29
INFO: iteration 4, average log likelihood -1.008019
WARNING: Variances had to be floored 9 10 14 23 24 27
INFO: iteration 5, average log likelihood -1.036691
WARNING: Variances had to be floored 1 9 10 14 17 18 21 22 23 24 29
INFO: iteration 6, average log likelihood -1.016583
WARNING: Variances had to be floored 9 14 23 24
INFO: iteration 7, average log likelihood -1.038958
WARNING: Variances had to be floored 1 10 14 17 18 21 22 23 24 29
INFO: iteration 8, average log likelihood -1.006873
WARNING: Variances had to be floored 10 14 23 24 27
INFO: iteration 9, average log likelihood -1.035865
WARNING: Variances had to be floored 1 10 14 17 18 21 22 23 24 29
INFO: iteration 10, average log likelihood -1.016423
INFO: EM with 100000 data points 10 iterations avll -1.016423
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.749678e+05
      1       6.691172e+05      -2.058506e+05 |       32
      2       6.393423e+05      -2.977485e+04 |       32
      3       6.204467e+05      -1.889568e+04 |       32
      4       6.091851e+05      -1.126160e+04 |       32
      5       6.019219e+05      -7.263170e+03 |       32
      6       5.976375e+05      -4.284409e+03 |       32
      7       5.948010e+05      -2.836513e+03 |       32
      8       5.930354e+05      -1.765588e+03 |       32
      9       5.921092e+05      -9.262181e+02 |       32
     10       5.916472e+05      -4.619253e+02 |       32
     11       5.913556e+05      -2.916158e+02 |       32
     12       5.911202e+05      -2.354523e+02 |       32
     13       5.909297e+05      -1.904814e+02 |       32
     14       5.907156e+05      -2.140834e+02 |       32
     15       5.905420e+05      -1.735905e+02 |       32
     16       5.904368e+05      -1.052323e+02 |       32
     17       5.903828e+05      -5.401407e+01 |       32
     18       5.903382e+05      -4.460812e+01 |       32
     19       5.902976e+05      -4.059245e+01 |       32
     20       5.902376e+05      -5.999705e+01 |       32
     21       5.901650e+05      -7.256357e+01 |       32
     22       5.900881e+05      -7.694055e+01 |       31
     23       5.900072e+05      -8.089202e+01 |       31
     24       5.899318e+05      -7.533964e+01 |       31
     25       5.898495e+05      -8.234594e+01 |       31
     26       5.897812e+05      -6.825780e+01 |       32
     27       5.897267e+05      -5.456940e+01 |       32
     28       5.896832e+05      -4.348553e+01 |       29
     29       5.896524e+05      -3.078390e+01 |       31
     30       5.896288e+05      -2.363798e+01 |       30
     31       5.896118e+05      -1.697011e+01 |       31
     32       5.895964e+05      -1.537325e+01 |       29
     33       5.895862e+05      -1.020622e+01 |       28
     34       5.895771e+05      -9.123091e+00 |       27
     35       5.895662e+05      -1.086546e+01 |       28
     36       5.895551e+05      -1.111130e+01 |       29
     37       5.895426e+05      -1.251834e+01 |       27
     38       5.895328e+05      -9.801406e+00 |       19
     39       5.895225e+05      -1.031611e+01 |       26
     40       5.895109e+05      -1.159204e+01 |       27
     41       5.895007e+05      -1.014498e+01 |       26
     42       5.894912e+05      -9.505850e+00 |       28
     43       5.894798e+05      -1.138514e+01 |       28
     44       5.894712e+05      -8.644187e+00 |       27
     45       5.894643e+05      -6.913594e+00 |       28
     46       5.894598e+05      -4.490613e+00 |       28
     47       5.894559e+05      -3.900039e+00 |       22
     48       5.894530e+05      -2.882227e+00 |       23
     49       5.894504e+05      -2.643160e+00 |       23
     50       5.894477e+05      -2.717536e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 589447.6572886957)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.293224
INFO: iteration 2, average log likelihood -1.252134
INFO: iteration 3, average log likelihood -1.216337
INFO: iteration 4, average log likelihood -1.179193
INFO: iteration 5, average log likelihood -1.137785
WARNING: Variances had to be floored 7 20
INFO: iteration 6, average log likelihood -1.084425
WARNING: Variances had to be floored 5
INFO: iteration 7, average log likelihood -1.063026
WARNING: Variances had to be floored 4 13 27 28 29
INFO: iteration 8, average log likelihood -1.015763
WARNING: Variances had to be floored 1 6 14
INFO: iteration 9, average log likelihood -1.052429
WARNING: Variances had to be floored 11
INFO: iteration 10, average log likelihood -1.061151
WARNING: Variances had to be floored 5 7 20
INFO: iteration 11, average log likelihood -1.011849
WARNING: Variances had to be floored 1 4 27 28 29
INFO: iteration 12, average log likelihood -1.017947
WARNING: Variances had to be floored 13 14
INFO: iteration 13, average log likelihood -1.052739
WARNING: Variances had to be floored 30
INFO: iteration 14, average log likelihood -1.045786
WARNING: Variances had to be floored 1 5 7 28
INFO: iteration 15, average log likelihood -1.007389
WARNING: Variances had to be floored 4 11 13 14 20 27 29
INFO: iteration 16, average log likelihood -1.020075
WARNING: Variances had to be floored 6
INFO: iteration 17, average log likelihood -1.072861
WARNING: Variances had to be floored 1 28
INFO: iteration 18, average log likelihood -1.038761
WARNING: Variances had to be floored 5 7
INFO: iteration 19, average log likelihood -1.030762
WARNING: Variances had to be floored 20 29 30
INFO: iteration 20, average log likelihood -1.011779
WARNING: Variances had to be floored 1 4 14 27 28
INFO: iteration 21, average log likelihood -1.003294
WARNING: Variances had to be floored 5 7 11 13
INFO: iteration 22, average log likelihood -1.041037
WARNING: Variances had to be floored 6
INFO: iteration 23, average log likelihood -1.062590
WARNING: Variances had to be floored 1
INFO: iteration 24, average log likelihood -1.026754
WARNING: Variances had to be floored 4 7 20 27 28
INFO: iteration 25, average log likelihood -1.002169
WARNING: Variances had to be floored 5 14 30
INFO: iteration 26, average log likelihood -1.040960
WARNING: Variances had to be floored 1
INFO: iteration 27, average log likelihood -1.045530
WARNING: Variances had to be floored 6 13 28
INFO: iteration 28, average log likelihood -0.997229
WARNING: Variances had to be floored 4 5 7 11 20 30
INFO: iteration 29, average log likelihood -0.992807
WARNING: Variances had to be floored 1 14 27 29
INFO: iteration 30, average log likelihood -1.052530
INFO: iteration 31, average log likelihood -1.064418
WARNING: Variances had to be floored 1 28
INFO: iteration 32, average log likelihood -1.017456
WARNING: Variances had to be floored 5 7
INFO: iteration 33, average log likelihood -1.003722
WARNING: Variances had to be floored 4 11 14 20 30
INFO: iteration 34, average log likelihood -0.989836
WARNING: Variances had to be floored 1 13 28
INFO: iteration 35, average log likelihood -1.026541
WARNING: Variances had to be floored 7 27 29
INFO: iteration 36, average log likelihood -1.029740
WARNING: Variances had to be floored 5
INFO: iteration 37, average log likelihood -1.028195
WARNING: Variances had to be floored 1 6 14 30
INFO: iteration 38, average log likelihood -0.994389
WARNING: Variances had to be floored 4 7 11 20 28
INFO: iteration 39, average log likelihood -1.002119
WARNING: Variances had to be floored 27
INFO: iteration 40, average log likelihood -1.034372
WARNING: Variances had to be floored 1 5 13 29
INFO: iteration 41, average log likelihood -1.003291
WARNING: Variances had to be floored 6 14 30
INFO: iteration 42, average log likelihood -1.023906
WARNING: Variances had to be floored 7 28
INFO: iteration 43, average log likelihood -1.013149
WARNING: Variances had to be floored 1 4 11 20 27
INFO: iteration 44, average log likelihood -1.002697
WARNING: Variances had to be floored 5
INFO: iteration 45, average log likelihood -1.027383
WARNING: Variances had to be floored 13 14 28 30
INFO: iteration 46, average log likelihood -0.989774
WARNING: Variances had to be floored 1 6 7
INFO: iteration 47, average log likelihood -1.018479
WARNING: Variances had to be floored 5 20 29
INFO: iteration 48, average log likelihood -1.018358
WARNING: Variances had to be floored 4 27
INFO: iteration 49, average log likelihood -1.022571
WARNING: Variances had to be floored 1 7 11 28
INFO: iteration 50, average log likelihood -1.005542
INFO: EM with 100000 data points 50 iterations avll -1.005542
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0378534   -0.0483883    0.0401076   0.0367854  -0.00156159   -0.169429    -0.034855     0.0193832    0.0448465    0.131101     -0.0606302   0.0233539   -0.0555658    0.116651     0.175623     0.0126439     0.0775176    0.0565606  -0.0584618   -0.00431434   -0.0763253   -0.347308      0.0704779   -0.112407     0.0400121   -0.196499  
 -0.109261     0.007534     0.0506347   0.0587425  -0.0175856     0.143963    -0.199348     0.0808985    0.149861     0.0659662     0.0449541   0.070941     0.165339    -0.0152536   -0.0374464   -0.0166916     0.0199269    0.166366    0.172988    -0.0113843    -0.0471727   -0.113432     -0.0416984   -0.0718449   -0.186397    -0.0892056 
  0.058178     0.0414922   -0.114005   -0.130295   -0.0970918    -0.00711267   0.00982039  -0.0108934    0.0589496   -0.0078833     0.0231975   0.140481     0.00390415   0.0632243   -0.112908    -0.0362912    -0.0509632   -0.0978965   0.0898511    0.0694551     0.0606351   -0.029107      0.0710153   -0.142926     0.0745589    0.102678  
 -0.147889    -0.0471901    0.0344265  -0.0109348  -0.0525029    -0.0197608    0.0100365    0.0997841   -0.147297    -0.183584      0.0441481  -0.149121     0.0137805    0.166096     0.0704023   -0.089333      0.110665     0.10805    -0.0446057   -0.0843096    -0.0470401   -0.0707188     0.032413    -0.163334    -0.0179263   -0.0900363 
 -0.027055     0.0198229   -0.0297725  -0.0909385   0.10411       0.140178    -0.00299012   0.0184554   -0.0638322    0.0203163    -0.011409    0.0618529   -0.224192    -0.018208    -0.0408645   -0.0354892    -0.0847285   -0.109961    0.0115558    0.0277196    -0.0289897    0.00980214   -0.0457283   -0.0527449   -0.072147     0.181654  
  0.121248     0.118246    -0.174451   -0.058342    0.0116437    -0.197797    -0.0349079    0.0888234    0.155972    -0.07796       0.0854264   0.100483     0.0302607   -0.170781    -0.025592    -0.069796     -0.0521565   -0.10417     0.104672     0.155146     -0.0121756   -0.160594     -0.0570077   -0.226792     0.142723     0.0962331 
 -0.00151471   0.0245534   -0.0137474  -0.2151      0.0413696    -0.0694175    0.0591162   -0.0196802    0.0837567   -0.000973427   0.0179035   0.0216141    0.0272027   -0.0758941    0.077428    -0.0128852     0.0348819   -0.0344248   0.230698    -0.142129     -0.104712    -0.0610101    -0.0817286    0.0160898   -0.00173193   0.0321426 
  0.037589     0.125908     0.0301475   0.0202065  -0.123896      0.0986657    0.0724355   -0.106495    -0.10954      0.146913      0.0415341  -0.028909     0.142894     0.0616003   -0.181325    -0.114402     -0.132266    -0.118479    0.0880781    0.154069     -0.0346549    0.0301506    -0.0548606    0.0256907   -0.0548862    0.0642358 
  0.0228787    0.0679867   -0.0410403   0.0518151   0.0443789    -0.0345153    0.0140327    0.235099     0.0361363   -0.0743525     0.0495625   0.121043     0.13796     -0.0277422   -0.0322023   -0.0757855    -0.17909     -0.240267   -0.0180002   -0.0747846     0.0883686   -0.108014      0.049933     0.00451892  -0.0233169   -0.045874  
  0.0861855   -0.0388002   -0.116789    0.0638276  -0.00327309    0.0894982   -0.0355525    0.0611944   -0.0922832   -0.113775      0.0514835  -0.0190841    0.0516594   -0.0885111    0.0896086    0.052192      0.0921904    0.247507   -0.085455     0.1916        0.071687     0.0520725    -0.0392734    0.114216    -0.0497584    0.039772  
  0.109324     0.0207631   -0.0362916  -0.0908434  -0.198556      0.0497782    0.0781952   -0.078994     0.0386348    0.0333949    -0.0772794   0.152515     0.013085     0.233471    -0.189968    -0.00547514    0.0424549   -0.186527   -0.00398138  -0.0164798     0.168258     0.0532215     0.079384    -0.159394    -0.0021169    0.0363969 
  0.0569002    0.231154    -0.135856   -0.164295    0.0242233    -0.115809     0.0953208    0.0461063    0.102715    -0.143148      0.0105373   0.0640123   -0.0535117    0.0168471    0.10097     -0.0194281     0.179861     0.0452881   0.134569    -0.0755747     0.177908     0.00376084   -0.0887832   -0.0592622   -0.0903238    0.0878475 
  0.0571163    0.129171    -0.0666896   0.0523346   0.231229      0.0117273   -0.0704091   -0.00618283  -0.0817578    0.0234173     0.0758996  -0.050292     0.109293     0.104511    -0.0310713    0.0866971     0.112095     0.169712    0.0706638   -0.0370566    -0.0328108   -0.0629204     0.00383512   0.162901    -0.106496     0.0150934 
 -0.079011    -0.0251594    0.0372142  -0.0672149  -0.125472      0.0212881    0.0464293   -0.238805     0.23706     -0.0761978    -0.0712742  -0.0300719    0.064613    -0.0985645   -0.0393699    0.072693     -0.0521062    0.023978   -0.0778835    0.0917564    -0.0307716   -0.037694     -0.126089    -0.0948018   -0.0904782   -0.00391181
 -0.145431    -0.0531177    0.0939875  -0.12435     0.151306      0.182117    -0.0611188   -0.0889972    0.0580975    0.19414      -0.0628607   0.094756     0.055391     0.119007    -0.161745     0.0396033     0.151276     0.0310525   0.15978      0.058263      0.00115383   0.117155     -0.0554385   -0.0849759   -0.102614    -0.0724339 
 -0.0740415   -0.0567953   -0.0562609   0.0257853  -0.0397084     0.171356    -0.0447449    0.0811424   -0.0496485   -0.162225     -0.0120405   0.0407257   -0.0789785    0.0192329    0.0556576   -0.0226734     0.0618699    0.150924    0.157643     0.16391      -0.0910984    0.177863     -0.0316744   -0.0142311    0.225486     0.0974091 
  0.115336    -0.0342196    0.11374     0.218373   -0.108318      0.139395    -0.050323     0.0938168   -0.0882845   -0.138369      0.0810273  -0.0288098    0.173745    -0.15409     -0.0757805   -0.04898      -0.0356828    0.0249515  -0.184178    -0.0547315    -0.110771    -0.0843093    -0.18246      0.218416    -0.10177      0.0134349 
 -0.0545741   -0.00647063  -0.098565   -0.0339025   0.0463155    -0.0710143   -0.0166142   -0.0221136    0.108929    -0.0753025     0.0258686   0.0292236    0.065776    -0.102041     0.012449    -0.0906353    -0.0325554    0.165375   -0.0631772    0.101033      0.0841499    0.0405403    -0.0573272   -0.0843069    0.0890057   -0.135948  
 -0.0764632    0.00288463   0.0123438  -0.0483536   0.0831326     0.0580731    0.170271     0.0595127    0.0297867   -0.090352     -0.0316486  -0.0485596    0.163869     0.00682688  -0.131257     0.000121059  -0.0107284   -0.0440166   0.041187    -0.0727193    -0.00794789  -0.092336      0.0859706    0.0634942   -0.0480006   -0.0165884 
 -0.014692     0.0779583   -0.0614884  -0.0381058   0.00204733   -0.0247056   -0.0359061    0.0298358    0.00539991  -0.0374219     0.13225    -0.0215555    0.0719507   -0.0601355   -0.0493036   -0.0896156    -0.0427825   -0.0103096  -0.090896     0.0179448    -0.0840118    0.0873897    -0.00553686  -0.144112     0.0600762    0.0106322 
 -0.0213308   -0.0427938   -0.0613958   0.0702679  -0.0126624     0.11434      0.164551    -0.0179584    0.0167936    0.00671122   -0.170083    0.0741465   -0.0886694   -0.092803    -0.0772002   -0.0530784     0.00416798   0.159896    0.0787485    0.0384032    -0.0110859    0.0345693     0.00830836  -0.144978     0.113928    -0.168292  
  0.0803776    0.0686749   -0.0931557  -0.0460684  -0.0284779     0.0231755   -0.047467    -0.228132     0.107726     0.0618769    -0.0314532   0.11453     -0.0771256   -0.0915647   -0.0940556    2.55084e-6   -0.251335     0.0122828  -0.0967205    0.15655      -0.0824086   -0.029009      0.207404    -0.059635    -0.0801898    0.0143375 
  0.0709011    0.0817003   -0.093253   -0.16662     0.0441897     0.0569865   -0.0404541    0.0499849   -0.169898    -0.137084     -0.144045   -0.0532989    0.150441    -0.0700688    0.0843438   -0.0401281     0.0794732    0.0964754  -0.0269836    0.0550558     0.0114936    0.0809871    -0.264305    -0.0454443    0.054909     0.144221  
  0.00943119  -0.0600189    0.104567    0.21173     0.0215317     0.133459    -0.0627759    0.146419     0.0386438   -0.0242728     0.0776892  -0.19021      0.176507    -0.0379485    0.0118483   -0.0876366     0.0535615   -0.0870858   0.0175349   -0.0268829    -0.00768115   0.233515      0.236837     0.124536     0.0415245   -0.0107957 
  0.07008     -0.0103145    0.0168689  -0.0305892  -0.0232122    -0.0236119   -0.129084     0.1139       0.156055    -0.171762      0.12908    -0.023882    -0.0772821    0.0353318   -0.0263005    0.00780496    0.075531     0.0487689   0.05735      0.019677     -0.113786    -0.0724642    -0.0836171    0.0295308   -0.149176     0.106399  
  0.0640786   -0.0599459   -0.0156901   0.0325612   0.000521596  -0.0731567   -0.00666476  -0.00383032   0.124067    -0.0545572    -0.0750222   0.0577954   -0.0421631    0.0323443   -0.0926543   -0.126388      0.10235      0.107089    0.0425694   -0.000724228  -0.0482923   -0.129587      0.0239597   -0.0116634   -0.0208731    0.0202702 
  0.0124836    0.201061    -0.123451    0.0590625  -0.0211298     0.160255     0.0854873    0.103414     0.023438    -0.0581658     0.172724   -0.112613     0.192282    -0.180739    -0.0815141   -0.195386      0.0107067   -0.0443087   0.238468     0.00238326   -0.137794    -0.000569087   0.0592141   -0.202776     0.119902    -0.0254972 
 -0.10349     -0.072404     0.146325    0.0678771  -0.0452885     0.12422     -0.0343691   -0.221776    -0.0862246    0.102092     -0.0546672   0.00415103   0.00294801   0.0688413    0.00810769   0.131435      0.0540979   -0.0210833   0.164287    -0.0527408    -0.294325    -0.178747     -0.0130866    0.00429469   0.115097    -0.0711396 
 -0.0487924    0.130428     0.0487651   0.0677549   0.0727443    -0.0989035    0.0990234    0.180631     0.188303    -0.0207764    -0.0190537   0.0399247   -0.147151     0.0255377   -0.0843139   -0.0288718     0.101808     0.215538    0.05626      0.0727964    -0.0700492   -0.148283      0.143322     0.0452825   -0.0781717    0.0844977 
 -0.0629752   -0.137815    -0.125139    0.210131    0.0280968    -0.082837    -0.122973     0.0211298    0.0242343   -0.077693     -0.0684437   0.00536002   0.131889     0.0474207    0.0910064   -0.0402847     0.0958796    0.123632    0.147148    -0.0359012    -0.140301     0.0940654     0.0814149    0.0620955    0.0238636    0.0892133 
  0.114715     0.0431957    0.145308   -0.037046    0.159888     -0.0921687   -0.185812    -0.208858    -0.0766777    0.0372623    -0.193902    0.169945     0.0979751    0.0213985   -0.188222    -0.0388585     0.125611     0.069436    0.00248924  -0.098902      0.0834467   -0.0114129     0.0178273    0.0504691    0.0450302    0.150282  
 -0.0321235   -0.117649     0.0129754  -0.0172238   0.109623      0.00912561   0.00885689  -0.0725242   -0.147104     0.0772735     0.120067    0.0626153   -0.00412089  -0.0453033    0.00258994  -0.143785     -0.0931164    0.0212177  -0.0921636    0.0764061    -0.0721073   -0.0284068     0.0410501    0.179877     0.104228     0.0598168 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 13 14 30
INFO: iteration 1, average log likelihood -1.009031
WARNING: Variances had to be floored 1 3 5 6 13 14 20 30
INFO: iteration 2, average log likelihood -0.951127
WARNING: Variances had to be floored 4 5 7 13 14 27 28 29 30
INFO: iteration 3, average log likelihood -0.950755
WARNING: Variances had to be floored 3 6 13 14 20 30
INFO: iteration 4, average log likelihood -0.983864
WARNING: Variances had to be floored 1 5 11 13 14 28 30
INFO: iteration 5, average log likelihood -0.952833
WARNING: Variances had to be floored 3 4 5 6 7 13 14 20 27 30
INFO: iteration 6, average log likelihood -0.953878
WARNING: Variances had to be floored 5 13 14 29 30
INFO: iteration 7, average log likelihood -0.982759
WARNING: Variances had to be floored 1 3 5 6 13 14 20 28 30
INFO: iteration 8, average log likelihood -0.943858
WARNING: Variances had to be floored 4 5 7 13 14 27 30
INFO: iteration 9, average log likelihood -0.965706
WARNING: Variances had to be floored 3 5 6 13 14 20 29 30
INFO: iteration 10, average log likelihood -0.972256
INFO: EM with 100000 data points 10 iterations avll -0.972256
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.15278     -0.0678911   -0.030003   -0.19789      0.071482     0.0508033    0.23112     -0.0688384    0.0438934    0.0109951   -0.0496562   -0.0750765   -0.151837   -0.261994    -0.0255808   -0.0950425  -0.000202726  -0.104559     0.0518834    0.1811      -0.00851539  -0.00378962  -0.1714      -0.0591005    0.0147305   -0.00380774
  0.0186901   -0.0611247    0.0132737   0.0346025    0.0426844   -0.028698    -0.0688323    0.0924728    0.0502322   -0.0653477    0.0592551    0.0820591   -0.0464989   0.0822332   -0.0265423   -0.142922    0.139869      0.0790065    0.0090566    0.00751078  -0.180674    -0.017091     0.102583     0.13741      0.173723     0.110695  
  0.132902    -0.0269757    0.0616169  -0.0442517   -0.0350436    0.175679    -0.0969119    0.180863    -0.140028    -0.0566733    0.0485109    0.0906574    0.195543   -0.127925     0.101793     0.113639    0.180144     -0.0515751   -0.0870681    0.00818643  -0.0553001   -0.0309022   -0.154315     0.0319861    0.125628    -0.0361655 
 -0.0840905   -0.129525    -0.093536   -0.0508468   -0.0506011   -0.0701909    0.233747     0.0143786   -0.121946     0.0529405   -0.0980919    0.0207966   -0.0144828  -0.0880989    0.0922483    0.102733    0.0667925    -0.148746     0.0746977   -0.0369694    0.179689     0.00598976   0.132954     0.0570597    0.104338    -0.12348   
 -0.0441908   -0.109121    -0.116391   -0.205698    -0.19904      0.0718753    0.0865899    0.0756615   -0.124304     0.0521008    0.0764664   -0.020677     0.0540317   0.157972     0.066489    -0.0952698   0.133678     -0.157571     0.0768579   -0.0474232    0.0227412   -0.00155001   0.211673    -0.0512723    0.0331798   -0.0924542 
 -0.165696     0.0986759    0.102754    0.0410977   -0.111655    -0.262986     0.00616566  -0.0919685   -0.00711258  -0.0156073    0.107257     0.0864205    0.0505007   0.0307562    0.186927    -0.0569826   0.0325064    -0.128357    -0.0119744    0.0400008    0.0617558    0.0621963    0.0837605   -0.119802     0.0925897   -0.168708  
 -0.0771908    0.224415    -0.0310312  -0.0198316    0.01278      0.0275255   -0.0422821   -0.0324978    0.0420602    0.063048    -0.0551909   -0.0382449    0.0401043   0.0389767   -0.184854    -0.111173   -0.188903      0.113744     0.0895327    0.0584403    0.0390506    0.063928     0.0350031   -0.013648     0.184687    -0.16825   
 -0.0515726    0.0100987    0.130948    0.0471374   -0.12086      0.157304     0.109205    -0.076936    -0.102181     0.0237479   -0.0609493   -0.0806676   -0.0929366   0.0161882   -0.0132578   -0.0835904  -0.0644202     0.0334295    0.112255     0.169184     0.217496     0.0280466    0.0190607    0.177281    -0.00302191   0.0184304 
  0.0482882   -0.102307    -0.0595247  -0.10142     -0.0177845    0.039644     0.018163    -0.11937      0.0335577    0.0488676   -0.0770142   -0.100081    -0.0713204   0.0449288   -0.114555     0.0214569  -0.0454309    -0.023734     0.181188     0.14644      0.0399914   -0.0585176    0.0955785   -0.225009     0.0219599   -0.0673806 
 -0.126648    -0.0865268   -0.212781   -0.0422542    0.0473197   -0.176786     0.141185    -0.0250356    0.126213     0.0826658    0.00916622  -0.0459906   -0.0902636  -0.0288274   -0.00935616   0.0121214   0.155768     -0.158311     0.0426319   -0.0285987   -0.0492786   -0.0147172    0.099761     0.149077    -0.135676     0.0652584 
  0.10897      0.00804741   0.0551548   0.0353661   -0.0470735   -0.12825     -0.0658853   -0.102487     0.128783    -0.165432     0.167229     0.115742     0.179698    0.0920037    0.0720215    0.0466683  -0.0100056    -0.103389    -0.0290325    0.156671    -0.00248637  -0.0583702   -0.0697407   -0.00437357  -0.0351149   -0.00717406
 -0.0834763   -0.0312495   -0.117241    0.102174     0.125147    -0.0156657    0.016249    -0.118144    -0.0170245   -0.039332     0.0495861   -0.0253735   -0.0480507  -0.0705038    0.137589     0.0660353   0.034515      0.00144596   0.0979842   -0.0236605    0.147278     0.072763    -0.0583206    0.0714563    0.0655276   -0.150274  
  0.0461908    0.112559     0.144748   -0.0160352   -0.126183    -0.0138      -0.0208391   -0.0260597   -0.20662      0.0498062    0.152295     0.093703     0.0953688  -0.0855599   -0.0224499   -0.101636    0.0346187    -0.0279065    0.00908441  -0.0393952    0.0835597   -0.0105904   -0.0160646   -0.244882    -0.123571    -0.0507393 
 -0.0435253   -0.15778     -0.0651304   0.0453068    0.0714213    0.00156016   0.0729463    0.00436412  -0.143203     0.069963    -0.0972502    0.014356    -0.0526816   0.186146    -0.173868    -0.0958139   0.0708821     0.148131    -0.0237129    0.0403779    0.167982    -0.160678     0.0291952   -0.0746676    0.0257847   -0.0704747 
 -0.0360019   -0.0143866   -0.0444402  -0.00955912   0.0796299    0.00759379  -0.0797802   -0.102592     0.136381     0.0262652   -0.0295464    0.115793     0.0661048   0.147063     0.216435     0.088233   -0.0294963     0.0477339    0.014011    -0.137898    -0.090397     0.0518042   -0.0335054    0.00789222   0.0314651   -0.197257  
  0.0778029    0.156558     0.12477    -0.00645246  -0.0654878    0.128838    -0.0136974    0.119861     0.0662991    0.0534057    0.157466    -0.124197    -0.0058317  -0.0607496   -0.0218257   -0.0508676  -0.105554     -0.111168    -0.0431392    0.0414038   -0.0712556   -0.0403219   -0.00642275  -0.051968     0.143491    -0.101306  
 -0.125453    -0.0838915   -0.126977    0.067388    -0.206868     0.112276     0.0328524    0.0486726    0.0171804   -0.117666    -0.0607811    0.105519    -0.0190224   0.0425386    0.0360778   -0.0425003  -0.0963829    -0.0562787    0.0228731   -0.0901173    0.248074     0.117535    -0.148142    -0.117557    -0.115001     0.100521  
 -0.134886     0.0638274    0.103961    0.0493162    0.0867222   -0.0706455   -0.164362    -0.161145     0.20932      0.183361     0.00724786  -0.0953838   -0.139497   -0.0635385   -0.028485    -0.0353751   0.130794     -0.0606823   -0.0300189    0.0121864    0.0494521    0.014021    -0.0393007   -0.0319901   -0.0852144   -0.0680993 
 -0.0410603   -0.0463103    0.0171063  -0.113055     0.0369819   -0.0724739   -0.111642     0.0530721   -0.0966765   -0.0628722   -0.115025    -0.0399626    0.285753   -0.00512652  -0.165659    -0.0103201   0.0350237     0.0461292    0.262566    -0.0968719    0.0970766    0.016748     0.0392196    0.0428019    0.109373    -0.0718581 
  0.0885556    0.102106    -0.091358   -0.00115174  -0.0896586    0.0524735    0.197786    -0.0165307    0.101097    -0.0406411    0.0668796    0.0871164    0.0147402   0.0399509    0.188036    -0.0139315  -0.0686935     0.0478298   -0.101083    -0.00992916  -0.161816     0.0749026   -0.10833     -0.00561832   0.152376    -0.112831  
 -0.017776     0.158971     0.0326822   0.0575233    0.104073    -0.0797246   -0.0520004    0.0273158    0.0337915    0.0168648   -0.00814159   0.0717996    0.137641   -0.133534    -0.0365081   -0.0727985   0.0562038    -0.145862     0.0587625    0.0017247    0.0527412   -0.0196508   -0.0777878   -0.0927428    0.158446    -0.0709444 
 -0.0662669    0.192816    -0.275531    0.0701339    0.0401691    0.0828348   -0.0118493    0.0282462    0.0888585   -0.106356    -0.0536714   -0.164187    -0.0792353  -0.144342    -0.0477024   -0.0881206  -0.0931922     0.0125837    0.0612427    0.0367179    0.10829      0.00403192   0.0561264   -0.0314317    0.0152654   -0.0647234 
 -0.017344     0.0107026   -0.0143131  -0.0641822    0.00812197  -0.14941     -0.0294434    0.215922     0.0119806    0.0357627    0.196005    -0.0175141   -0.148369   -0.171183    -0.157998     0.068487   -0.120612      0.117334     0.046353    -0.196396     0.0506376    0.0339003   -0.0154281    0.00206725  -0.15339      0.175643  
 -0.0984705    0.0127916    0.0555866  -0.0984964   -0.126375     0.242761    -0.0799409   -0.0833677    0.035649     0.0196757   -0.00546293   0.0876822    0.204093    0.139848    -0.0776357   -0.0611801  -0.0392224     0.0429435   -0.0131302   -0.0194745    0.0194944    0.0930126   -0.10025     -0.00350252  -0.129742     0.148749  
  0.116324    -0.159244    -0.0203312  -0.105221     0.0420742    0.0217659    0.00521983   0.107475    -0.0487047   -0.00830846   0.0116523    0.0312795   -0.123071    0.0363388    0.158396    -0.0900413  -0.0208102     0.00647128  -0.0419445   -0.261323     0.147186     0.10462     -0.0157776    0.025833    -0.0908582   -0.0844711 
 -0.110869    -0.0542101    0.007917   -0.100363     0.0242869   -0.088628    -0.147613    -0.162711    -0.0595557    0.0384149    0.18604      0.0391972    0.0656977  -0.118759    -0.0568228   -0.117374   -0.120999     -0.115909     0.00666493   0.131616     0.109483     0.0535605   -0.0289772    0.0391034   -0.00780289   0.00159641
  0.130269     0.0364454    0.257556    0.0773598    0.104326     0.041539    -0.0634798    0.0206267    0.149585    -0.105278     0.0961989   -0.0336761    0.0706094   0.122756     0.0579518   -0.0667145  -0.141585     -0.0643534    0.17085     -0.10238      0.166343     0.0875542   -0.128261    -0.0386637    0.0190851   -0.0389045 
  0.106678     0.0686874    0.136434    0.036546    -0.128752    -0.0187586    0.147931     0.0373783   -0.0793481    0.101575     0.152435    -0.00107053  -0.0797834   0.109706     0.0518775   -0.051217   -0.000496182  -0.125637     0.0573257    0.0617464   -0.163252     0.226504    -0.0241817   -0.0713278    0.0578755    0.103797  
 -0.091409    -0.0362028    0.087111   -0.0821033    0.0389776   -0.12875     -0.0632689   -0.187706    -0.0576896    0.108385     0.123398     0.0098505    0.0250407  -0.0220011    0.0745852    0.0254499  -0.17555      -0.0276865    0.199872     0.116147     0.14446      0.00198381   0.0517252   -0.0222735   -0.00904217   0.128414  
 -0.00724642   0.0350128    0.0650537   0.156502     0.131904    -0.0208697   -0.173258     0.00857666   0.0158535    0.0727769    0.0204019   -0.133797    -0.119159   -0.065466    -0.06491      0.0304024   0.0625816    -0.162547     0.0779397   -0.0507554    0.0867244   -0.0447011   -0.151027     0.0521571    0.0913336    0.128381  
  0.0997467   -0.0552976    0.0176667   0.0499009    0.0704714   -0.135663    -0.0362939    0.142046     0.0509871   -0.0924577    0.172225    -0.192152     0.119731    0.0131982   -0.0857354   -0.118856   -0.0608839    -0.0884145    0.0487118    0.0369716   -0.181882    -0.0627857   -0.0408767   -0.0906802   -0.0473765   -0.0550246 
 -0.198973    -0.021562     0.0866493  -0.0205259   -0.111839    -0.13833      0.107512     0.0640041    0.166454    -0.0810275   -0.263975    -0.168176    -0.100303   -0.102158     0.0555571    0.0497049  -0.0504371    -0.152526    -0.0524737   -0.140392     0.0258761   -0.178478     0.217826    -0.00203703  -0.0732194   -0.0963633 kind full, method split
0: avll = -1.4243520378425336
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.424372
INFO: iteration 2, average log likelihood -1.424313
INFO: iteration 3, average log likelihood -1.424270
INFO: iteration 4, average log likelihood -1.424217
INFO: iteration 5, average log likelihood -1.424152
INFO: iteration 6, average log likelihood -1.424070
INFO: iteration 7, average log likelihood -1.423977
INFO: iteration 8, average log likelihood -1.423876
INFO: iteration 9, average log likelihood -1.423775
INFO: iteration 10, average log likelihood -1.423669
INFO: iteration 11, average log likelihood -1.423535
INFO: iteration 12, average log likelihood -1.423317
INFO: iteration 13, average log likelihood -1.422917
INFO: iteration 14, average log likelihood -1.422223
INFO: iteration 15, average log likelihood -1.421226
INFO: iteration 16, average log likelihood -1.420161
INFO: iteration 17, average log likelihood -1.419359
INFO: iteration 18, average log likelihood -1.418915
INFO: iteration 19, average log likelihood -1.418711
INFO: iteration 20, average log likelihood -1.418624
INFO: iteration 21, average log likelihood -1.418587
INFO: iteration 22, average log likelihood -1.418572
INFO: iteration 23, average log likelihood -1.418565
INFO: iteration 24, average log likelihood -1.418562
INFO: iteration 25, average log likelihood -1.418560
INFO: iteration 26, average log likelihood -1.418560
INFO: iteration 27, average log likelihood -1.418559
INFO: iteration 28, average log likelihood -1.418559
INFO: iteration 29, average log likelihood -1.418559
INFO: iteration 30, average log likelihood -1.418558
INFO: iteration 31, average log likelihood -1.418558
INFO: iteration 32, average log likelihood -1.418558
INFO: iteration 33, average log likelihood -1.418558
INFO: iteration 34, average log likelihood -1.418558
INFO: iteration 35, average log likelihood -1.418558
INFO: iteration 36, average log likelihood -1.418557
INFO: iteration 37, average log likelihood -1.418557
INFO: iteration 38, average log likelihood -1.418557
INFO: iteration 39, average log likelihood -1.418557
INFO: iteration 40, average log likelihood -1.418557
INFO: iteration 41, average log likelihood -1.418557
INFO: iteration 42, average log likelihood -1.418557
INFO: iteration 43, average log likelihood -1.418557
INFO: iteration 44, average log likelihood -1.418557
INFO: iteration 45, average log likelihood -1.418557
INFO: iteration 46, average log likelihood -1.418557
INFO: iteration 47, average log likelihood -1.418557
INFO: iteration 48, average log likelihood -1.418557
INFO: iteration 49, average log likelihood -1.418557
INFO: iteration 50, average log likelihood -1.418557
INFO: EM with 100000 data points 50 iterations avll -1.418557
952.4 data points per parameter
1: avll = [-1.42437,-1.42431,-1.42427,-1.42422,-1.42415,-1.42407,-1.42398,-1.42388,-1.42378,-1.42367,-1.42354,-1.42332,-1.42292,-1.42222,-1.42123,-1.42016,-1.41936,-1.41892,-1.41871,-1.41862,-1.41859,-1.41857,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.418576
INFO: iteration 2, average log likelihood -1.418515
INFO: iteration 3, average log likelihood -1.418470
INFO: iteration 4, average log likelihood -1.418415
INFO: iteration 5, average log likelihood -1.418345
INFO: iteration 6, average log likelihood -1.418259
INFO: iteration 7, average log likelihood -1.418163
INFO: iteration 8, average log likelihood -1.418066
INFO: iteration 9, average log likelihood -1.417977
INFO: iteration 10, average log likelihood -1.417903
INFO: iteration 11, average log likelihood -1.417844
INFO: iteration 12, average log likelihood -1.417796
INFO: iteration 13, average log likelihood -1.417758
INFO: iteration 14, average log likelihood -1.417724
INFO: iteration 15, average log likelihood -1.417695
INFO: iteration 16, average log likelihood -1.417667
INFO: iteration 17, average log likelihood -1.417642
INFO: iteration 18, average log likelihood -1.417618
INFO: iteration 19, average log likelihood -1.417594
INFO: iteration 20, average log likelihood -1.417572
INFO: iteration 21, average log likelihood -1.417550
INFO: iteration 22, average log likelihood -1.417529
INFO: iteration 23, average log likelihood -1.417509
INFO: iteration 24, average log likelihood -1.417489
INFO: iteration 25, average log likelihood -1.417471
INFO: iteration 26, average log likelihood -1.417453
INFO: iteration 27, average log likelihood -1.417436
INFO: iteration 28, average log likelihood -1.417420
INFO: iteration 29, average log likelihood -1.417405
INFO: iteration 30, average log likelihood -1.417390
INFO: iteration 31, average log likelihood -1.417375
INFO: iteration 32, average log likelihood -1.417361
INFO: iteration 33, average log likelihood -1.417347
INFO: iteration 34, average log likelihood -1.417333
INFO: iteration 35, average log likelihood -1.417319
INFO: iteration 36, average log likelihood -1.417305
INFO: iteration 37, average log likelihood -1.417292
INFO: iteration 38, average log likelihood -1.417278
INFO: iteration 39, average log likelihood -1.417265
INFO: iteration 40, average log likelihood -1.417253
INFO: iteration 41, average log likelihood -1.417240
INFO: iteration 42, average log likelihood -1.417228
INFO: iteration 43, average log likelihood -1.417217
INFO: iteration 44, average log likelihood -1.417207
INFO: iteration 45, average log likelihood -1.417197
INFO: iteration 46, average log likelihood -1.417188
INFO: iteration 47, average log likelihood -1.417180
INFO: iteration 48, average log likelihood -1.417172
INFO: iteration 49, average log likelihood -1.417165
INFO: iteration 50, average log likelihood -1.417159
INFO: EM with 100000 data points 50 iterations avll -1.417159
473.9 data points per parameter
2: avll = [-1.41858,-1.41852,-1.41847,-1.41841,-1.41834,-1.41826,-1.41816,-1.41807,-1.41798,-1.4179,-1.41784,-1.4178,-1.41776,-1.41772,-1.41769,-1.41767,-1.41764,-1.41762,-1.41759,-1.41757,-1.41755,-1.41753,-1.41751,-1.41749,-1.41747,-1.41745,-1.41744,-1.41742,-1.4174,-1.41739,-1.41738,-1.41736,-1.41735,-1.41733,-1.41732,-1.41731,-1.41729,-1.41728,-1.41727,-1.41725,-1.41724,-1.41723,-1.41722,-1.41721,-1.4172,-1.41719,-1.41718,-1.41717,-1.41717,-1.41716]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417168
INFO: iteration 2, average log likelihood -1.417115
INFO: iteration 3, average log likelihood -1.417074
INFO: iteration 4, average log likelihood -1.417031
INFO: iteration 5, average log likelihood -1.416980
INFO: iteration 6, average log likelihood -1.416922
INFO: iteration 7, average log likelihood -1.416855
INFO: iteration 8, average log likelihood -1.416781
INFO: iteration 9, average log likelihood -1.416705
INFO: iteration 10, average log likelihood -1.416629
INFO: iteration 11, average log likelihood -1.416558
INFO: iteration 12, average log likelihood -1.416494
INFO: iteration 13, average log likelihood -1.416438
INFO: iteration 14, average log likelihood -1.416389
INFO: iteration 15, average log likelihood -1.416347
INFO: iteration 16, average log likelihood -1.416309
INFO: iteration 17, average log likelihood -1.416276
INFO: iteration 18, average log likelihood -1.416245
INFO: iteration 19, average log likelihood -1.416216
INFO: iteration 20, average log likelihood -1.416187
INFO: iteration 21, average log likelihood -1.416160
INFO: iteration 22, average log likelihood -1.416132
INFO: iteration 23, average log likelihood -1.416105
INFO: iteration 24, average log likelihood -1.416077
INFO: iteration 25, average log likelihood -1.416049
INFO: iteration 26, average log likelihood -1.416020
INFO: iteration 27, average log likelihood -1.415992
INFO: iteration 28, average log likelihood -1.415964
INFO: iteration 29, average log likelihood -1.415936
INFO: iteration 30, average log likelihood -1.415909
INFO: iteration 31, average log likelihood -1.415883
INFO: iteration 32, average log likelihood -1.415857
INFO: iteration 33, average log likelihood -1.415833
INFO: iteration 34, average log likelihood -1.415810
INFO: iteration 35, average log likelihood -1.415789
INFO: iteration 36, average log likelihood -1.415768
INFO: iteration 37, average log likelihood -1.415749
INFO: iteration 38, average log likelihood -1.415731
INFO: iteration 39, average log likelihood -1.415714
INFO: iteration 40, average log likelihood -1.415697
INFO: iteration 41, average log likelihood -1.415682
INFO: iteration 42, average log likelihood -1.415666
INFO: iteration 43, average log likelihood -1.415652
INFO: iteration 44, average log likelihood -1.415637
INFO: iteration 45, average log likelihood -1.415623
INFO: iteration 46, average log likelihood -1.415610
INFO: iteration 47, average log likelihood -1.415597
INFO: iteration 48, average log likelihood -1.415584
INFO: iteration 49, average log likelihood -1.415571
INFO: iteration 50, average log likelihood -1.415559
INFO: EM with 100000 data points 50 iterations avll -1.415559
236.4 data points per parameter
3: avll = [-1.41717,-1.41711,-1.41707,-1.41703,-1.41698,-1.41692,-1.41685,-1.41678,-1.4167,-1.41663,-1.41656,-1.41649,-1.41644,-1.41639,-1.41635,-1.41631,-1.41628,-1.41624,-1.41622,-1.41619,-1.41616,-1.41613,-1.4161,-1.41608,-1.41605,-1.41602,-1.41599,-1.41596,-1.41594,-1.41591,-1.41588,-1.41586,-1.41583,-1.41581,-1.41579,-1.41577,-1.41575,-1.41573,-1.41571,-1.4157,-1.41568,-1.41567,-1.41565,-1.41564,-1.41562,-1.41561,-1.4156,-1.41558,-1.41557,-1.41556]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.415559
INFO: iteration 2, average log likelihood -1.415497
INFO: iteration 3, average log likelihood -1.415446
INFO: iteration 4, average log likelihood -1.415392
INFO: iteration 5, average log likelihood -1.415332
INFO: iteration 6, average log likelihood -1.415264
INFO: iteration 7, average log likelihood -1.415186
INFO: iteration 8, average log likelihood -1.415101
INFO: iteration 9, average log likelihood -1.415009
INFO: iteration 10, average log likelihood -1.414915
INFO: iteration 11, average log likelihood -1.414821
INFO: iteration 12, average log likelihood -1.414731
INFO: iteration 13, average log likelihood -1.414646
INFO: iteration 14, average log likelihood -1.414568
INFO: iteration 15, average log likelihood -1.414496
INFO: iteration 16, average log likelihood -1.414432
INFO: iteration 17, average log likelihood -1.414374
INFO: iteration 18, average log likelihood -1.414322
INFO: iteration 19, average log likelihood -1.414274
INFO: iteration 20, average log likelihood -1.414231
INFO: iteration 21, average log likelihood -1.414191
INFO: iteration 22, average log likelihood -1.414153
INFO: iteration 23, average log likelihood -1.414118
INFO: iteration 24, average log likelihood -1.414084
INFO: iteration 25, average log likelihood -1.414052
INFO: iteration 26, average log likelihood -1.414022
INFO: iteration 27, average log likelihood -1.413993
INFO: iteration 28, average log likelihood -1.413965
INFO: iteration 29, average log likelihood -1.413939
INFO: iteration 30, average log likelihood -1.413914
INFO: iteration 31, average log likelihood -1.413889
INFO: iteration 32, average log likelihood -1.413866
INFO: iteration 33, average log likelihood -1.413843
INFO: iteration 34, average log likelihood -1.413822
INFO: iteration 35, average log likelihood -1.413802
INFO: iteration 36, average log likelihood -1.413782
INFO: iteration 37, average log likelihood -1.413763
INFO: iteration 38, average log likelihood -1.413746
INFO: iteration 39, average log likelihood -1.413729
INFO: iteration 40, average log likelihood -1.413713
INFO: iteration 41, average log likelihood -1.413698
INFO: iteration 42, average log likelihood -1.413684
INFO: iteration 43, average log likelihood -1.413670
INFO: iteration 44, average log likelihood -1.413657
INFO: iteration 45, average log likelihood -1.413645
INFO: iteration 46, average log likelihood -1.413634
INFO: iteration 47, average log likelihood -1.413623
INFO: iteration 48, average log likelihood -1.413613
INFO: iteration 49, average log likelihood -1.413603
INFO: iteration 50, average log likelihood -1.413594
INFO: EM with 100000 data points 50 iterations avll -1.413594
118.1 data points per parameter
4: avll = [-1.41556,-1.4155,-1.41545,-1.41539,-1.41533,-1.41526,-1.41519,-1.4151,-1.41501,-1.41492,-1.41482,-1.41473,-1.41465,-1.41457,-1.4145,-1.41443,-1.41437,-1.41432,-1.41427,-1.41423,-1.41419,-1.41415,-1.41412,-1.41408,-1.41405,-1.41402,-1.41399,-1.41397,-1.41394,-1.41391,-1.41389,-1.41387,-1.41384,-1.41382,-1.4138,-1.41378,-1.41376,-1.41375,-1.41373,-1.41371,-1.4137,-1.41368,-1.41367,-1.41366,-1.41365,-1.41363,-1.41362,-1.41361,-1.4136,-1.41359]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413593
INFO: iteration 2, average log likelihood -1.413525
INFO: iteration 3, average log likelihood -1.413455
INFO: iteration 4, average log likelihood -1.413368
INFO: iteration 5, average log likelihood -1.413254
INFO: iteration 6, average log likelihood -1.413110
INFO: iteration 7, average log likelihood -1.412939
INFO: iteration 8, average log likelihood -1.412754
INFO: iteration 9, average log likelihood -1.412568
INFO: iteration 10, average log likelihood -1.412390
INFO: iteration 11, average log likelihood -1.412225
INFO: iteration 12, average log likelihood -1.412075
INFO: iteration 13, average log likelihood -1.411942
INFO: iteration 14, average log likelihood -1.411824
INFO: iteration 15, average log likelihood -1.411721
INFO: iteration 16, average log likelihood -1.411630
INFO: iteration 17, average log likelihood -1.411550
INFO: iteration 18, average log likelihood -1.411480
INFO: iteration 19, average log likelihood -1.411418
INFO: iteration 20, average log likelihood -1.411363
INFO: iteration 21, average log likelihood -1.411315
INFO: iteration 22, average log likelihood -1.411272
INFO: iteration 23, average log likelihood -1.411233
INFO: iteration 24, average log likelihood -1.411198
INFO: iteration 25, average log likelihood -1.411166
INFO: iteration 26, average log likelihood -1.411136
INFO: iteration 27, average log likelihood -1.411109
INFO: iteration 28, average log likelihood -1.411084
INFO: iteration 29, average log likelihood -1.411060
INFO: iteration 30, average log likelihood -1.411038
INFO: iteration 31, average log likelihood -1.411017
INFO: iteration 32, average log likelihood -1.410997
INFO: iteration 33, average log likelihood -1.410978
INFO: iteration 34, average log likelihood -1.410960
INFO: iteration 35, average log likelihood -1.410942
INFO: iteration 36, average log likelihood -1.410925
INFO: iteration 37, average log likelihood -1.410909
INFO: iteration 38, average log likelihood -1.410893
INFO: iteration 39, average log likelihood -1.410877
INFO: iteration 40, average log likelihood -1.410862
INFO: iteration 41, average log likelihood -1.410847
INFO: iteration 42, average log likelihood -1.410833
INFO: iteration 43, average log likelihood -1.410819
INFO: iteration 44, average log likelihood -1.410805
INFO: iteration 45, average log likelihood -1.410791
INFO: iteration 46, average log likelihood -1.410778
INFO: iteration 47, average log likelihood -1.410765
INFO: iteration 48, average log likelihood -1.410752
INFO: iteration 49, average log likelihood -1.410740
INFO: iteration 50, average log likelihood -1.410728
INFO: EM with 100000 data points 50 iterations avll -1.410728
59.0 data points per parameter
5: avll = [-1.41359,-1.41352,-1.41346,-1.41337,-1.41325,-1.41311,-1.41294,-1.41275,-1.41257,-1.41239,-1.41222,-1.41208,-1.41194,-1.41182,-1.41172,-1.41163,-1.41155,-1.41148,-1.41142,-1.41136,-1.41131,-1.41127,-1.41123,-1.4112,-1.41117,-1.41114,-1.41111,-1.41108,-1.41106,-1.41104,-1.41102,-1.411,-1.41098,-1.41096,-1.41094,-1.41093,-1.41091,-1.41089,-1.41088,-1.41086,-1.41085,-1.41083,-1.41082,-1.41081,-1.41079,-1.41078,-1.41077,-1.41075,-1.41074,-1.41073]
[-1.42435,-1.42437,-1.42431,-1.42427,-1.42422,-1.42415,-1.42407,-1.42398,-1.42388,-1.42378,-1.42367,-1.42354,-1.42332,-1.42292,-1.42222,-1.42123,-1.42016,-1.41936,-1.41892,-1.41871,-1.41862,-1.41859,-1.41857,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41856,-1.41858,-1.41852,-1.41847,-1.41841,-1.41834,-1.41826,-1.41816,-1.41807,-1.41798,-1.4179,-1.41784,-1.4178,-1.41776,-1.41772,-1.41769,-1.41767,-1.41764,-1.41762,-1.41759,-1.41757,-1.41755,-1.41753,-1.41751,-1.41749,-1.41747,-1.41745,-1.41744,-1.41742,-1.4174,-1.41739,-1.41738,-1.41736,-1.41735,-1.41733,-1.41732,-1.41731,-1.41729,-1.41728,-1.41727,-1.41725,-1.41724,-1.41723,-1.41722,-1.41721,-1.4172,-1.41719,-1.41718,-1.41717,-1.41717,-1.41716,-1.41717,-1.41711,-1.41707,-1.41703,-1.41698,-1.41692,-1.41685,-1.41678,-1.4167,-1.41663,-1.41656,-1.41649,-1.41644,-1.41639,-1.41635,-1.41631,-1.41628,-1.41624,-1.41622,-1.41619,-1.41616,-1.41613,-1.4161,-1.41608,-1.41605,-1.41602,-1.41599,-1.41596,-1.41594,-1.41591,-1.41588,-1.41586,-1.41583,-1.41581,-1.41579,-1.41577,-1.41575,-1.41573,-1.41571,-1.4157,-1.41568,-1.41567,-1.41565,-1.41564,-1.41562,-1.41561,-1.4156,-1.41558,-1.41557,-1.41556,-1.41556,-1.4155,-1.41545,-1.41539,-1.41533,-1.41526,-1.41519,-1.4151,-1.41501,-1.41492,-1.41482,-1.41473,-1.41465,-1.41457,-1.4145,-1.41443,-1.41437,-1.41432,-1.41427,-1.41423,-1.41419,-1.41415,-1.41412,-1.41408,-1.41405,-1.41402,-1.41399,-1.41397,-1.41394,-1.41391,-1.41389,-1.41387,-1.41384,-1.41382,-1.4138,-1.41378,-1.41376,-1.41375,-1.41373,-1.41371,-1.4137,-1.41368,-1.41367,-1.41366,-1.41365,-1.41363,-1.41362,-1.41361,-1.4136,-1.41359,-1.41359,-1.41352,-1.41346,-1.41337,-1.41325,-1.41311,-1.41294,-1.41275,-1.41257,-1.41239,-1.41222,-1.41208,-1.41194,-1.41182,-1.41172,-1.41163,-1.41155,-1.41148,-1.41142,-1.41136,-1.41131,-1.41127,-1.41123,-1.4112,-1.41117,-1.41114,-1.41111,-1.41108,-1.41106,-1.41104,-1.41102,-1.411,-1.41098,-1.41096,-1.41094,-1.41093,-1.41091,-1.41089,-1.41088,-1.41086,-1.41085,-1.41083,-1.41082,-1.41081,-1.41079,-1.41078,-1.41077,-1.41075,-1.41074,-1.41073]
32Ã—26 Array{Float64,2}:
  0.0846664   -0.261711    -0.616358    -0.212955     0.0544936   -0.186818     0.209495   -0.109736   -0.0442582   0.669753   -0.130893    -0.0913157  -0.378845    -0.101454     -0.181305   -0.218413     0.297288    -0.0218313   -0.018362     0.255859     0.233532    -0.403466     0.357338    -0.396635     0.172401    0.406671  
  0.351786    -0.284066     0.915734    -0.469779     0.0961865   -0.558687     0.331836   -0.0614232  -0.151927    0.229508    0.151442    -0.0257791  -0.372751    -0.190339      0.323849   -0.189914    -0.0107956   -0.193615    -0.199683     0.328454    -0.290856    -0.261263     0.213617    -0.0751698    0.380932   -0.141885  
  0.178559     0.386455    -0.195327    -0.367394    -0.0648757   -0.405553     0.457966   -0.243383   -0.294854    0.484121   -0.433942    -0.0138067   0.0163585   -0.401671      0.169252   -0.486181     0.222304    -0.00212412  -0.163967     0.219243    -0.0286058    0.355948    -0.114711    -0.345341    -0.298      -0.520395  
 -0.0498865    1.06478     -0.0196615   -0.00156303   0.126478     0.314467     0.39815     0.272142    0.261988    0.211899    0.576286    -0.0418083  -0.229084    -0.344305     -0.0132105  -0.34088      0.118636    -0.186864    -0.0726883    0.0559092   -0.185301     0.0956882   -0.167954    -0.155083     0.14184    -0.303586  
 -0.00874866  -0.0937952    0.228204    -0.0018504    0.324911    -0.755666     0.275548   -0.624934    0.336822   -0.546017   -0.0420661   -0.132638    0.0272288    0.277182     -0.128843   -0.158508    -0.221114    -0.302832    -0.552736     0.204817     0.145629     0.389836    -0.949048    -0.123506    -0.17533     0.165155  
 -0.555108     0.208144     0.0584809   -0.53324     -0.327893    -0.157003     0.368654   -0.175129   -0.288056   -0.519009   -0.477258    -0.0947326  -0.397546     0.481274      0.216506    0.409637    -0.068438    -0.395317     0.493993     0.214649     0.447328     0.412273    -0.00385342  -0.578301     0.22427     0.125719  
 -0.618214     0.0828879    0.00990657  -0.00420015   0.392547    -0.188713     0.142905   -0.310882   -0.0389292  -0.432007   -0.0669065   -0.25396    -0.015426    -0.0945892     0.272509   -0.0547265   -0.155362    -0.444462    -0.108567    -0.492045     0.116712    -0.11416      0.341114     0.568497     0.11103    -0.00456105
 -0.310346     0.67938      0.231772    -0.256246    -0.0808328    0.0717611    0.166463   -0.365562    0.0791657  -0.214473   -0.0618532    0.0460637   0.518862     1.02039       0.464258   -0.639399    -0.00548699  -0.310345     0.299638    -0.0212008    0.0191085    0.00336174  -0.134695     0.454712    -0.208375   -0.305674  
  0.578195    -0.249492    -0.1169       0.123144    -0.357036    -0.00299698  -0.113325    0.125847    0.324039    0.215821    0.0289239   -0.420214   -0.0764046   -0.427857     -0.555442   -0.0795276   -0.260496     0.250632     0.0439912    0.437721    -0.0488554    0.151996    -0.459621    -0.385231     0.0054178   0.096303  
  0.383486    -0.215482     0.564967     0.182199     0.534151     0.123265     0.217068    0.703866    0.516503   -0.0984038   0.190613     0.0441503  -0.229433     0.0459255    -0.527246    0.471286     0.176304     0.231474     0.00220748  -0.559558    -0.090016     0.260781    -0.485953    -0.453376     0.131493    0.43692   
  0.515734    -0.0464906    0.149612     0.176897    -0.357171     0.505556    -0.422628    0.664718    0.137826    0.19526     0.776634     0.358504    0.287094    -0.207861     -0.0454722   0.200397     0.0627824    0.406066     0.203658    -0.0633911   -0.473637    -0.292391     0.24341      0.419431     0.128924    0.106705  
  0.392242     0.457584     0.135564    -0.0618672   -0.323244     0.0265419    0.175966    0.171929    0.329308    0.482639    0.431077     0.0621558  -0.0697848   -0.222086      0.323185    0.164779     0.466239     0.315782     0.0302296    0.278767     0.777376    -0.00760592   0.233227     0.190772     0.0308367   0.533555  
 -0.0372137    0.0687885    0.0337519   -0.14439      0.0436385   -0.172378     0.0918494  -0.0505583   0.100767   -0.0175808   0.0310219   -0.0637111  -0.0571998    0.000871655   0.0118136  -0.0807293    0.0217683   -0.0979242   -0.167398     0.0189794   -0.0301747    0.0563537    0.0419805   -0.0395417    0.0835276   0.0067359 
 -0.0396052    0.0153058   -0.0535014    0.23233     -0.130674     0.278022    -0.129599    0.0879094  -0.194766   -0.110899   -0.0974283    0.0277871   0.226889     0.0460114    -0.0284878   0.0263273   -0.0477026    0.149656     0.382638    -0.0917996    0.174432    -0.0155675   -0.126558    -0.0100475   -0.15212    -0.0870388 
 -0.154461    -0.405095    -0.195244     0.413803     0.267139    -0.0350865   -0.529782   -0.253647   -0.0890943   0.0495285   0.262548     0.729779    0.101479    -0.147843     -0.0600771   0.161121    -0.0842713   -0.0465093   -0.0302836   -0.196477    -0.0376998    0.292105     0.188391    -0.155821    -0.199137   -0.43291   
 -0.441615    -0.630352     0.0801583    0.424098    -0.0534783    0.0578011   -0.703213   -0.219538    0.0679533  -0.351567    0.0417913   -0.0126492  -0.249388     0.0799203    -0.189111    0.385568    -0.376048    -0.0792082    0.0656896    0.212905     0.14665      0.246894    -0.114858     0.379094     0.284329    0.154956  
 -0.0234602   -1.04803     -0.164287    -0.3432       0.386217    -0.0143245   -0.0904854  -0.0323181  -0.143739   -0.391358   -0.285586     0.190344    0.444572     0.779618     -0.016004    0.00875515  -0.410605     0.205021     0.565324    -0.00660664  -0.0654455   -0.500974    -0.0223237   -0.253379     0.103557    0.0406981 
  0.0215224   -0.118495    -0.196583    -0.18739     -0.425427    -0.0324707   -0.0318135   0.519122   -0.254211   -0.219254   -0.380041    -0.776588    0.949301     0.296715     -0.10897     0.0533727    0.111217     0.131907     0.243958    -0.491781     0.283708    -0.39835      0.346561     0.270276     0.0473486   0.218596  
 -0.720506    -0.361191    -0.629215     0.00661369   0.00322018  -0.772641    -0.357022    0.139357    0.0608259  -0.0958952   0.0247967   -0.69889     0.347377     0.357907      0.0959731  -0.451522    -0.0224546   -0.196424     0.0174533    0.190469    -0.0451678    0.31488     -0.344466    -0.118795     1.11856     0.75078   
  0.58588     -0.0579864   -0.292019     0.730119     0.644224     0.247275    -0.374083   -0.0564058   0.429207   -0.013235    0.329092    -0.751326    0.0611194    0.576646      0.262195   -0.0158267   -0.0396245   -0.371156     1.04394      0.0740966   -0.618878    -1.13988     -0.592559    -0.573955     0.594829   -0.0645711 
  0.124574     0.0622991   -0.174318     0.802412    -0.291794     0.370694    -0.0906982  -0.12619    -0.198575    0.020749    0.277229     0.592274   -0.0995436    0.128001     -0.214196    0.491663    -0.554995     0.429843    -0.00658821   0.533453     0.335434     0.367477    -0.624079    -0.881366    -0.262094   -0.0185678 
 -0.768202     0.655597    -0.457408     0.67226     -0.00464379   0.436786    -0.177362   -0.0885864   0.067904   -0.830595    0.143535     0.530095    0.525269     0.0867064     0.424566    0.230126     0.12527      0.309158    -0.0230623   -0.276935    -0.0124683    0.369895    -0.311096     0.115623    -0.448286    0.246246  
 -0.36558     -0.537823    -0.0753615    0.0500942   -0.0250188    0.427147    -0.682002   -0.0790984  -0.35322    -0.174947   -0.349385     0.16846     0.119014     0.213851      0.04171     0.015646    -0.413409    -0.026577     0.374346    -0.389617    -0.203459     0.0994548    0.175688     0.211987     0.125659   -0.487187  
  0.268046    -0.308811     0.449446    -0.5845      -0.537351    -0.0340005   -0.985256    0.222104   -0.0197124  -0.375388    0.388855    -0.2789      0.35821     -0.231034      0.598473    0.391343    -0.204845    -0.463537     0.145142     0.106777     0.0477852    0.432689    -0.276332     0.320092    -0.247475   -0.432982  
 -0.0702609    0.0693381   -0.0488538   -0.0195641    0.959169    -0.313149     0.699378   -0.158526    0.0452135  -0.0579724  -0.414299     0.153763    0.0121025    0.0456241     0.0323467  -0.300172     0.183905     0.0859176   -0.0333244   -0.171632    -0.0127084   -0.371316     0.214713    -0.161        0.520675    0.212766  
  0.542374     0.0528713   -0.0621209   -0.0301977   -0.351666    -0.242789     0.249379    0.0616553   0.496968    0.543367    0.0719857   -0.704392   -0.0636296   -0.320282     -0.607456   -0.186805     0.0558788   -0.0171703   -0.0504676    0.210721     0.172459    -0.183218    -0.0737734    0.00443498   0.0434781   0.0738417 
 -0.4413       0.170476     0.434449     0.15945      0.0644722   -0.313575    -0.149103   -0.319458    0.143725    0.356036    0.63504      0.654444   -0.895618    -0.383198      0.519123   -0.0762802    0.248108    -0.2137      -0.422282     0.320061    -0.191766     0.151038     0.278848    -0.2043       0.286573   -0.226559  
 -0.107702     0.524326    -0.0367274   -0.378983     0.0905366   -0.344702     0.35851     0.0913111  -0.129897    0.789212    0.192364    -0.579252   -0.349634    -0.318992      0.111255   -0.788897     0.92831     -0.473447     0.639991    -0.426781    -0.00634984  -0.259348     0.761152     0.417331     0.311183    0.0262521 
 -0.0851376    0.0818792    0.736868    -0.794806    -0.147917     0.1121       0.419589    0.297119   -0.38877    -0.689054   -0.785235     0.562658   -0.00294752  -0.347666     -0.593467    0.00473252  -0.069392    -0.0556978   -0.824127    -0.772862    -0.0842695    0.262773     0.91411      0.0161293   -0.926638   -0.883267  
 -0.387188    -0.331526     0.477773    -0.615046    -0.729839    -0.150535     0.117346   -0.139716   -0.570404    0.11075     0.0196105    0.158163    0.0630389   -0.396446     -0.340121   -0.0289223   -0.157533     0.345961    -0.739129     0.617269     0.803964     0.999857     0.226129     0.79457     -0.383314    0.487432  
 -0.169574     0.00947883  -0.558168    -0.0439135   -0.460024     0.631484    -0.256886    0.162601    0.0196112   0.373082    0.00568739   0.217538   -0.24443     -0.0508282    -0.117533    0.146262    -0.0663935   -0.521564    -0.118831    -0.272604    -0.261643    -0.143063     0.0997048    0.262986    -0.328656   -0.901576  
  0.643673     0.426229     0.683169     0.173203     0.103131     0.839615     0.169743   -0.0193145  -0.183076    0.0238191   0.0986392    0.530491   -0.263392    -0.418071      0.0275007   0.27934     -0.210528     0.193433     0.244214    -0.182715     0.189895    -0.201337     0.0521605    0.0821635   -0.968422   -0.527135  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.410715
INFO: iteration 2, average log likelihood -1.410704
INFO: iteration 3, average log likelihood -1.410692
INFO: iteration 4, average log likelihood -1.410681
INFO: iteration 5, average log likelihood -1.410670
INFO: iteration 6, average log likelihood -1.410659
INFO: iteration 7, average log likelihood -1.410648
INFO: iteration 8, average log likelihood -1.410638
INFO: iteration 9, average log likelihood -1.410628
INFO: iteration 10, average log likelihood -1.410618
INFO: EM with 100000 data points 10 iterations avll -1.410618
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.028927e+05
      1       7.032972e+05      -1.995955e+05 |       32
      2       6.914069e+05      -1.189031e+04 |       32
      3       6.863379e+05      -5.069053e+03 |       32
      4       6.838123e+05      -2.525506e+03 |       32
      5       6.822693e+05      -1.543034e+03 |       32
      6       6.811287e+05      -1.140647e+03 |       32
      7       6.802125e+05      -9.161313e+02 |       32
      8       6.794428e+05      -7.697171e+02 |       32
      9       6.788248e+05      -6.180470e+02 |       32
     10       6.783026e+05      -5.221546e+02 |       32
     11       6.778441e+05      -4.585435e+02 |       32
     12       6.774518e+05      -3.922916e+02 |       32
     13       6.771157e+05      -3.361222e+02 |       32
     14       6.768222e+05      -2.934527e+02 |       32
     15       6.765742e+05      -2.479704e+02 |       32
     16       6.763543e+05      -2.199335e+02 |       32
     17       6.761364e+05      -2.178993e+02 |       32
     18       6.759349e+05      -2.014535e+02 |       32
     19       6.757264e+05      -2.085670e+02 |       32
     20       6.755314e+05      -1.949461e+02 |       32
     21       6.753461e+05      -1.853217e+02 |       32
     22       6.751553e+05      -1.908133e+02 |       32
     23       6.749634e+05      -1.918981e+02 |       32
     24       6.747875e+05      -1.758531e+02 |       32
     25       6.746264e+05      -1.611073e+02 |       32
     26       6.744916e+05      -1.348093e+02 |       32
     27       6.743555e+05      -1.360940e+02 |       32
     28       6.742231e+05      -1.324269e+02 |       32
     29       6.741056e+05      -1.175397e+02 |       32
     30       6.740042e+05      -1.014024e+02 |       32
     31       6.739020e+05      -1.021846e+02 |       32
     32       6.738044e+05      -9.753793e+01 |       32
     33       6.737211e+05      -8.335132e+01 |       32
     34       6.736501e+05      -7.102357e+01 |       32
     35       6.735817e+05      -6.832872e+01 |       32
     36       6.735181e+05      -6.360619e+01 |       32
     37       6.734572e+05      -6.090278e+01 |       32
     38       6.734041e+05      -5.317863e+01 |       32
     39       6.733504e+05      -5.365339e+01 |       32
     40       6.732995e+05      -5.087770e+01 |       32
     41       6.732505e+05      -4.897936e+01 |       32
     42       6.731987e+05      -5.188286e+01 |       32
     43       6.731461e+05      -5.252898e+01 |       32
     44       6.731020e+05      -4.412468e+01 |       32
     45       6.730659e+05      -3.607487e+01 |       32
     46       6.730336e+05      -3.233318e+01 |       32
     47       6.730018e+05      -3.178190e+01 |       32
     48       6.729635e+05      -3.834181e+01 |       32
     49       6.729267e+05      -3.682288e+01 |       32
     50       6.728943e+05      -3.233126e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672894.3208838261)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.422913
INFO: iteration 2, average log likelihood -1.417970
INFO: iteration 3, average log likelihood -1.416579
INFO: iteration 4, average log likelihood -1.415468
INFO: iteration 5, average log likelihood -1.414267
INFO: iteration 6, average log likelihood -1.413177
INFO: iteration 7, average log likelihood -1.412441
INFO: iteration 8, average log likelihood -1.412027
INFO: iteration 9, average log likelihood -1.411791
INFO: iteration 10, average log likelihood -1.411640
INFO: iteration 11, average log likelihood -1.411531
INFO: iteration 12, average log likelihood -1.411447
INFO: iteration 13, average log likelihood -1.411379
INFO: iteration 14, average log likelihood -1.411322
INFO: iteration 15, average log likelihood -1.411273
INFO: iteration 16, average log likelihood -1.411230
INFO: iteration 17, average log likelihood -1.411192
INFO: iteration 18, average log likelihood -1.411158
INFO: iteration 19, average log likelihood -1.411127
INFO: iteration 20, average log likelihood -1.411099
INFO: iteration 21, average log likelihood -1.411073
INFO: iteration 22, average log likelihood -1.411050
INFO: iteration 23, average log likelihood -1.411027
INFO: iteration 24, average log likelihood -1.411007
INFO: iteration 25, average log likelihood -1.410987
INFO: iteration 26, average log likelihood -1.410969
INFO: iteration 27, average log likelihood -1.410952
INFO: iteration 28, average log likelihood -1.410935
INFO: iteration 29, average log likelihood -1.410920
INFO: iteration 30, average log likelihood -1.410905
INFO: iteration 31, average log likelihood -1.410891
INFO: iteration 32, average log likelihood -1.410878
INFO: iteration 33, average log likelihood -1.410865
INFO: iteration 34, average log likelihood -1.410853
INFO: iteration 35, average log likelihood -1.410841
INFO: iteration 36, average log likelihood -1.410830
INFO: iteration 37, average log likelihood -1.410819
INFO: iteration 38, average log likelihood -1.410809
INFO: iteration 39, average log likelihood -1.410799
INFO: iteration 40, average log likelihood -1.410789
INFO: iteration 41, average log likelihood -1.410780
INFO: iteration 42, average log likelihood -1.410771
INFO: iteration 43, average log likelihood -1.410762
INFO: iteration 44, average log likelihood -1.410754
INFO: iteration 45, average log likelihood -1.410745
INFO: iteration 46, average log likelihood -1.410737
INFO: iteration 47, average log likelihood -1.410729
INFO: iteration 48, average log likelihood -1.410721
INFO: iteration 49, average log likelihood -1.410713
INFO: iteration 50, average log likelihood -1.410705
INFO: EM with 100000 data points 50 iterations avll -1.410705
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.459469   -0.147519    0.17214     0.138975    0.109021    0.412848    -0.40873     -0.203906    -0.413907   -0.511451    0.181279    0.838675    0.0715483   0.0383319   0.618969      0.221934    -0.289039     0.11768     -0.0020399  -0.0950866  -0.208704     0.220154    0.158695    0.154402   -0.291641    -0.420841 
  0.590736    0.352428    0.638035    0.145255    0.149255    0.721494     0.135921     0.00523866  -0.110284   -0.0157808   0.098342    0.580666   -0.220826   -0.369314   -0.126152      0.269797    -0.143485     0.116004     0.151236   -0.268397    0.175336    -0.217071    0.146821    0.0833771  -1.01723     -0.584215 
  0.208599    0.535805    0.108643    0.26517    -0.176556    0.176714    -0.0233044    0.288803     0.194812    0.484981    0.88145     0.531474    0.0822786  -0.27873     0.291144     -0.0536712    0.469674     0.622865     0.171238    0.180383    0.100535    -0.0710746   0.767888    0.27659     0.320362     0.514797 
 -0.121928   -0.0899333  -0.055132   -0.138021   -0.0478207   0.00465885  -0.0334886   -0.064972    -0.041921   -0.112411   -0.155443    0.202352   -0.0209879   0.331398    0.00152255   -0.0638441   -0.0545183   -0.0334452    0.0499321   0.0741063   0.0493753    0.147547   -0.0429558  -0.0386744  -0.00276944  -0.119588 
  0.185826   -0.432524    0.191739    0.488784   -0.254584    0.177067    -0.34212     -0.0205407   -0.411343   -0.017528   -0.100083    0.280613    0.145551    0.112473    0.0685057     0.191845    -0.300953     0.544934     0.572762    0.25133     0.352975    -0.0395092  -0.319337   -0.247181   -0.147528     0.247796 
 -0.361847   -0.361508    0.160315   -0.343441    0.0872325  -0.0999352    0.240442    -0.24695     -0.571225   -0.431311   -1.14478    -0.0571766  -0.0940882   0.123325   -0.230481     -0.109673    -0.267874    -0.589605    -0.224801   -0.552213   -0.30611      0.265687   -0.0710832  -0.412572   -0.342862    -0.98168  
 -0.306951    0.0121445   0.351297   -0.0864479  -0.184897    0.0579102   -0.778182     0.203788     0.292994   -0.371871    0.607484    0.147202   -0.0631991  -0.0178463   0.547242      0.10889      0.0131439   -0.443716    -0.0230525  -0.165642   -0.132169     0.215788    0.188209    0.629888   -0.0567679   -0.31404  
 -0.0605865  -0.800133   -0.539136   -0.204134   -0.425573    0.415015    -0.580121     0.266654    -0.177631    0.647799   -0.0637831   0.212631   -0.330385   -0.125212   -0.274627      0.17976     -0.248432     0.0636072    0.0473288  -0.114562   -0.0105591   -0.0802347   0.470834   -0.0234858   0.136937    -0.176595 
  0.0890752   0.0933667   0.877222   -0.393719    0.335805   -0.346903     0.593985    -0.172009    -0.32064     0.0389403   0.0966124  -0.0445653  -0.573885   -0.266683    0.496483     -0.210725    -0.0481716   -0.0677664   -0.14489     0.328993   -0.278604    -0.0871389   0.264167   -0.0619934   0.513336    -0.171411 
  0.205305   -0.490658    0.284102    0.123722    0.185648   -0.487118    -0.200575    -0.302946     0.304888   -0.0272756   0.297321    0.416755   -0.183841   -0.163042   -0.105292      0.0545262   -0.359953    -0.00161036  -0.697105    0.464541   -0.279445     0.361902   -0.50622    -0.413671    0.233562    -0.0995983
 -0.0220408   0.175177   -0.556029    0.22793    -0.349737    0.652844    -0.148499     0.384073    -0.292745   -0.709747   -0.537239   -0.111676    0.82784     0.372516   -0.0178275     0.546509    -0.131045     0.243021     0.160536   -0.168712    0.165163     0.112266   -0.444721    0.233051   -0.318954    -0.1948   
  0.604693   -0.370903    0.469296    0.115045    0.325473    0.0786799    0.141195     0.658487     0.482119    0.155208    0.0795598  -0.124367   -0.114786   -0.0140699  -0.69628       0.334864     0.171019     0.387466     0.117531   -0.433901   -0.0814248    0.174599   -0.432716   -0.286469    0.122243     0.459647 
  0.515041    0.0235112  -0.057946   -0.528758   -0.124844   -0.198555     0.429701     0.270874     0.427047    0.278881    0.241236   -0.431994   -0.0284294  -0.0219495  -0.0390864    -0.130258     0.166682    -0.235042    -0.0329669   0.569688    0.394667    -0.713468   -0.28709    -0.0960097   0.082507     0.748802 
  0.376036    0.501767   -0.0999758   0.0407795  -0.529174    0.610373     0.11497      0.541797    -0.0883482   0.777182    0.274285   -0.0314717  -0.418227   -0.445629    0.235325      0.118331     0.288135    -0.593191    -0.110616   -0.42453    -0.192326    -0.275559    0.520573    0.560659   -0.184207    -0.745117 
 -0.649549    0.348308   -0.623214    0.891451   -0.0855796   0.356468    -0.324734    -0.224051     0.235942   -0.0703803   0.581921    0.394798    0.133014   -0.203664   -0.247611      0.215253    -0.031467    -0.0412167    0.0433221  -0.0806827   0.0603755    0.263293   -0.358457   -0.1523     -0.396668    -0.0538933
 -0.14961    -0.0108068  -0.763756    0.391825    0.71565     0.299671     0.182164    -0.0678002   -0.127293   -0.026019   -0.641028    0.165592   -0.306996    0.485822   -0.000849473  -0.410729    -0.0410083    0.0229101    0.4977     -0.177499   -0.281989    -0.672606    0.479002   -0.581909    0.474517    -0.167977 
  0.023505   -0.445207    0.0207985  -0.406472   -0.0277567  -0.338094     0.00253446   0.349709    -0.131954   -0.197403   -0.423934   -0.46762     1.06409     0.347831   -0.00276227   -0.135542     0.149397     0.401291     0.341565   -0.542874    0.167415    -0.519179    0.655048    0.200011    0.270863     0.316771 
  0.533898   -0.669988    0.210973   -0.194104   -0.788229   -0.0481744   -0.518263    -0.304542     0.148289   -0.0366616  -0.020901   -0.829683    0.425023   -0.137866   -0.0863733     0.0105877   -0.665267    -0.246108     0.264688    0.110282   -0.0555629    0.214396   -0.154732    0.557343   -0.0213122   -0.458423 
  0.119729    0.0703768   0.040809    0.161184   -0.0167559   0.0376951   -0.0269271    0.101769     0.124864    0.078687    0.160443   -0.169669   -0.042192   -0.323724   -0.0906303     0.0856541   -0.00368734   0.047879    -0.0274782  -0.0422184   0.0708132    0.0376562  -0.0352404  -0.0808694   0.0709989    0.0895941
 -0.643652   -0.756725   -0.0757339   0.27194     0.431357   -0.264076    -0.411096    -0.363078    -0.0765983  -0.600435   -0.110036   -0.0224604  -0.0888044   0.242205   -0.192004      0.292753    -0.311554    -0.309109     0.101754   -0.0391693   0.155451     0.0675703   0.0491913   0.310813    0.256161     0.193912 
  0.793248   -0.166926   -0.0586937   0.541807    0.599386    0.236209    -0.530306     0.111339     0.295522    0.102681    0.584368   -0.813896    0.11365     0.608917    0.371319      0.115553    -0.0279612   -0.40129      1.03608     0.175045   -0.701234    -0.974769   -0.66385    -0.379647    0.684026    -0.0997972
  0.0120901  -0.0149893  -0.421097   -0.219613    0.0212602  -0.474418     0.484162    -0.400522    -0.270474    0.539209   -0.169246   -0.094268   -0.192418   -0.214126   -0.0439533    -0.309772     0.408426    -0.186942    -0.0581291   0.189615    0.25927     -0.108309    0.22831    -0.285044   -0.196168     0.0605742
 -0.697892   -0.319131   -0.574204   -0.0114516  -0.036952   -0.760359    -0.269011     0.0921866    0.0544139  -0.133077   -0.0593779  -0.76228     0.28223     0.362347    0.0700506    -0.452675    -0.0317519   -0.191507     0.038567    0.211366   -0.00437482   0.321428   -0.370432   -0.147926    1.0727       0.771277 
 -0.663532    0.560479    0.0949175  -0.389005   -0.471639    0.169297     0.443447     0.0502134   -0.112543   -0.394133   -0.241627   -0.661139   -0.249496   -0.183343   -0.0135166     0.0526826   -0.0352538   -0.328608     0.0357148  -0.328011    0.650058     0.200931    0.224645    0.332866   -0.0456088    0.483299 
 -0.175294    0.380687    0.443564   -0.244449   -0.208056   -0.234683     0.0253946    0.0630938    0.240019   -0.793666    0.21153     0.322925   -0.406561    0.631425    0.34341       1.02705      0.0538442   -0.545574     0.491835   -0.16397     0.176507     0.346755   -0.0261395  -1.26855     0.189067    -0.0677556
 -0.194843    0.758744    0.0239034   0.0592381   0.874996   -0.235685     0.618471    -0.259878     0.561453    0.0294083  -0.0699734   0.0683106  -0.184114   -0.162042    0.0271958    -0.301146     0.2989      -0.0892939   -0.423696   -0.307708    0.0831407   -0.0596603   0.0799304   0.223961    0.309715    -0.0238028
 -0.115833    0.0917186   0.234673   -0.445615    0.121906   -0.779762     0.287851    -0.208373    -0.0693557   0.713669    0.108512   -0.41233    -0.512008   -0.240414    0.169669     -0.687796     0.57449     -0.560605     0.248874    0.0664893  -0.0586864   -0.290695    0.599012   -0.0586959   0.447954    -0.0621281
 -0.164781   -0.222597    0.543289   -0.669175   -0.61913    -0.248148     0.172461    -0.121765    -0.362156    0.0618181  -0.06208     0.322571   -0.0222712  -0.362329   -0.210564      0.101068    -0.0214277    0.378195    -0.877176    0.617888    0.8036       1.01579     0.179305    0.5087     -0.517443     0.217763 
  0.339158    0.724352   -0.112695   -0.249099   -0.376178    0.204252     0.170221     0.221134     0.122822    0.492297    0.237314   -0.0323289  -0.203689   -0.435198   -0.0444535    -0.37666      0.1633       0.0765337    0.0166561   0.462885   -0.12245      0.452802   -0.26603    -0.424599   -0.095055    -0.530637 
 -0.280041    0.669785    0.11566    -0.252175    0.368406   -0.222077     0.352257    -0.418755     0.0360916  -0.318555   -0.295136    0.386309    0.445427    0.717387    0.847231     -0.515106     0.0178456   -0.0599984    0.0535748  -0.0607522   0.0975327    0.368159   -0.821811   -0.0611474  -0.353995     0.147188 
  0.268515   -0.0203489  -0.135546    0.252838    0.0122224  -0.0734363    0.0967058   -0.0777937    0.290523    0.19553     0.023915   -0.228521   -0.0361737  -0.0792089  -0.54217       0.00565116  -0.150625     0.0901225    0.0379894   0.22039     0.177621    -0.0401633  -0.361086   -0.218353    0.0420876    0.0685302
 -0.25677     0.258213   -0.0754976  -0.143914   -0.0539694  -0.0206427    0.0477624   -0.0838563   -0.0442774  -0.220447    0.0348497  -0.226084    0.577139    0.284606    0.0282295    -0.334747     0.0195092   -0.252691     0.175111   -0.314021   -0.114861    -0.322324    0.142107    0.386856   -0.0807272   -0.369922 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.410697
INFO: iteration 2, average log likelihood -1.410689
INFO: iteration 3, average log likelihood -1.410681
INFO: iteration 4, average log likelihood -1.410674
INFO: iteration 5, average log likelihood -1.410666
INFO: iteration 6, average log likelihood -1.410657
INFO: iteration 7, average log likelihood -1.410649
INFO: iteration 8, average log likelihood -1.410641
INFO: iteration 9, average log likelihood -1.410633
INFO: iteration 10, average log likelihood -1.410624
INFO: EM with 100000 data points 10 iterations avll -1.410624
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
