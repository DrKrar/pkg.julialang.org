>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.754
Commit ac25c58 (2016-09-23 23:59 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (672.40625 MB free)
Uptime: 24732.0 sec
Load Avg:  1.078125  1.04248046875  1.033203125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1399242 s       1355 s     162136 s     596482 s         86 s
#2  3499 MHz     720544 s       6395 s      95286 s    1493596 s          3 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##749#751{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-2.237672735442889e6,[14303.2,85696.8],
[-2856.0 -4387.62 6387.01; 2746.53 4675.63 -6352.72],

Array{Float64,2}[
[15816.3 417.086 -462.541; 417.086 9046.01 4913.26; -462.541 4913.26 9513.14],

[84065.5 -833.104 375.324; -833.104 91130.0 -4775.92; 375.324 -4775.92 90562.0]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.380448e+03
      1       1.130467e+03      -2.499815e+02 |        6
      2       1.105836e+03      -2.463148e+01 |        0
      3       1.105836e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 1105.8355041319091)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.087248
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.768335
INFO: iteration 2, lowerbound -3.655920
INFO: iteration 3, lowerbound -3.533712
INFO: iteration 4, lowerbound -3.380361
INFO: iteration 5, lowerbound -3.207846
INFO: iteration 6, lowerbound -3.041662
INFO: dropping number of Gaussions to 6
INFO: iteration 7, lowerbound -2.887429
INFO: iteration 8, lowerbound -2.761321
INFO: iteration 9, lowerbound -2.678378
INFO: iteration 10, lowerbound -2.629841
INFO: dropping number of Gaussions to 4
INFO: iteration 11, lowerbound -2.595585
INFO: iteration 12, lowerbound -2.568385
INFO: dropping number of Gaussions to 3
INFO: iteration 13, lowerbound -2.542043
INFO: iteration 14, lowerbound -2.505797
INFO: iteration 15, lowerbound -2.463997
INFO: iteration 16, lowerbound -2.418190
INFO: iteration 17, lowerbound -2.375760
INFO: iteration 18, lowerbound -2.341370
INFO: iteration 19, lowerbound -2.317518
INFO: iteration 20, lowerbound -2.307656
INFO: dropping number of Gaussions to 2
INFO: iteration 21, lowerbound -2.302983
INFO: iteration 22, lowerbound -2.299263
INFO: iteration 23, lowerbound -2.299258
INFO: iteration 24, lowerbound -2.299255
INFO: iteration 25, lowerbound -2.299254
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Sat 24 Sep 2016 11:22:10 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sat 24 Sep 2016 11:22:12 AM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Sat 24 Sep 2016 11:22:14 AM UTC: EM with 272 data points 0 iterations avll -2.087248
5.8 data points per parameter
,Sat 24 Sep 2016 11:22:14 AM UTC: GMM converted to Variational GMM
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 1, lowerbound -3.768335
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 2, lowerbound -3.655920
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 3, lowerbound -3.533712
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 4, lowerbound -3.380361
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 5, lowerbound -3.207846
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 6, lowerbound -3.041662
,Sat 24 Sep 2016 11:22:17 AM UTC: dropping number of Gaussions to 6
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 7, lowerbound -2.887429
,Sat 24 Sep 2016 11:22:17 AM UTC: iteration 8, lowerbound -2.761321
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 9, lowerbound -2.678378
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 10, lowerbound -2.629841
,Sat 24 Sep 2016 11:22:18 AM UTC: dropping number of Gaussions to 4
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 11, lowerbound -2.595585
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 12, lowerbound -2.568385
,Sat 24 Sep 2016 11:22:18 AM UTC: dropping number of Gaussions to 3
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 13, lowerbound -2.542043
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 14, lowerbound -2.505797
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 15, lowerbound -2.463997
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 16, lowerbound -2.418190
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 17, lowerbound -2.375760
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 18, lowerbound -2.341370
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 19, lowerbound -2.317518
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 20, lowerbound -2.307656
,Sat 24 Sep 2016 11:22:18 AM UTC: dropping number of Gaussions to 2
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 21, lowerbound -2.302983
,Sat 24 Sep 2016 11:22:18 AM UTC: iteration 22, lowerbound -2.299263
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 23, lowerbound -2.299258
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 24, lowerbound -2.299255
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 25, lowerbound -2.299254
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 26, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 27, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 28, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 29, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 30, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 31, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 32, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 33, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 34, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 35, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 36, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 37, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 38, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 39, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:19 AM UTC: iteration 40, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 41, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 42, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 43, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 44, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 45, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 46, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 47, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 48, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 49, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: iteration 50, lowerbound -2.299253
,Sat 24 Sep 2016 11:22:20 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.045,95.9549]
Î² = [178.045,95.9549]
m = [4.2503 79.2869; 2.00023 53.852]
Î½ = [180.045,97.9549]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.184042 -0.00764405; 0.0 0.00858171],

[0.375876 -0.00895312; 0.0 0.0127487]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 100000.00000000009
avll from stats: -0.9837883350170574
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -0.9837883350170578
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -0.9837883350170578
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9625187880395747
avll from llpg:  -0.9625187880395749
avll direct:     -0.9625187880395749
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0602357   -0.0556752  -0.0268428   -0.0703245    0.123304     0.0623866   -0.0514002    -0.17576      0.0770073    0.0725469     0.132266     0.0284913    0.13188      0.219171     0.107634     0.0516798    -0.0594516   -0.0238807  -0.0997032    0.18336     -0.00522325   0.0195853   -0.0473484    0.0556106    -0.00101674  -0.0214719
 -0.112081     0.0582704  -0.0446191   -0.0543252    0.0564967    0.0469856    0.0271063     0.0404905    0.0110718    0.212182      0.0688624    0.00290005  -0.0607946   -0.210867    -0.0103113   -0.228915     -0.135592     0.100688   -0.0771992    0.0907501    0.13532     -0.115658     0.055047    -0.120609      0.222586     0.138414 
  0.155748     0.22688    -0.135987    -0.046521     0.0120817   -0.0605715   -0.183247     -0.0188293    0.0653088   -0.0547103     0.0155027    0.137747     0.0139248   -0.0843836   -0.00986075  -0.00486444    0.118309     0.023176   -0.0780379   -0.109635    -0.0465145    0.152606    -0.0130947   -0.0362932     0.0189072    0.209557 
 -0.10842     -0.0784319  -0.151533     0.0651861    0.0189799    0.0765846   -0.0554902    -0.131626    -0.0507659    0.0187244     0.0992125    0.00781034   0.0202809   -0.0156758   -0.0345764    0.0958989    -0.122621     0.0243615  -0.0510966    0.0128213    0.109491    -0.021823    -0.125734     0.121966     -0.11558     -0.0534552
 -0.113498     0.0276025  -0.0590138    0.0908583   -0.0956636    0.122441     0.0178063    -0.0484313   -0.108014    -0.0879347     0.0465683   -0.209028     0.114425    -0.0989546    0.0664506   -0.0471635    -0.0909354   -0.117515    0.0849897   -0.0876448   -0.0967974    0.0521148   -0.0884908   -0.110757      0.114887     0.0712583
 -0.0905023   -0.0269452  -0.00791453   0.0292605    0.0593777    0.263071    -0.151841      0.113373    -0.0147628    0.00459566   -0.0421531   -0.11698      0.049856     0.0461374   -0.0327776    0.0129061    -0.05495      0.0373476  -0.160955     0.053118     0.0332596    0.0197175   -0.00343176  -0.151934     -0.0867524    0.0208607
 -0.048572    -0.0148529   0.0884544   -0.0173966    0.0634315    0.108724     0.0263503    -0.0730767    0.0429247   -0.025464      0.0601005   -0.00388126   0.0260746    0.0315446   -0.0372092    0.0843351     0.00421699  -0.0297608  -0.146393     0.143888    -0.0151632   -0.00347543  -0.0295109   -0.0157801    -0.00154279  -0.0151984
  0.090585    -0.0298892  -0.0408936    0.209748    -0.0239774    0.017063     0.0301334     0.146183    -0.0202516   -0.138406     -0.0282353   -0.0614778    0.106897     0.138577     0.0322425    0.0896764    -0.0584154   -0.265206    0.00681145  -0.109233    -0.0166901   -0.0341062    0.0968079   -0.0539571     0.027825     0.0507136
  0.0249094   -0.0468558  -0.236428    -0.135277     0.0628484   -0.249363    -0.014507     -0.0120315   -0.116016    -0.0887359    -0.00465866  -0.0650677   -0.0255353    0.0612663    0.0922426    0.0547068     0.0652855   -0.137878   -0.286243     0.0638534    0.0166939   -0.0388115   -0.141602     0.106173     -0.204667    -0.0430218
  0.174858     0.0141062   0.126722     0.0687985    0.151428     0.0181369   -0.109279     -0.054647    -0.0828121    0.112967     -0.0444354   -0.0348796    0.07124      0.0614071    0.118052    -0.0359482    -0.0426003   -0.0146918  -0.0898353    0.0102098    0.059501    -0.282047    -0.10584     -0.0227626     0.125998     0.135245 
 -0.153517     0.0278334   0.0959186    0.100157    -0.0242774    0.196611    -0.000118912  -0.0431085   -0.0329675   -0.113626      0.0912038   -0.110786     0.137959     0.0596715   -0.0638156   -0.147476     -0.0602846    0.0699546  -0.0846583    0.071838     0.122685     0.147442     0.0411134    0.0482335     0.135002     0.117067 
 -0.0502532    0.0631404  -0.0930865    0.0332039    0.0826156    0.0981079    0.0116564    -0.110132     0.0840937   -0.00163329   -0.164286     0.0604182   -0.0620956    0.0162674   -0.0696801    0.0889898    -0.254307    -0.0556588  -0.0941531    0.0961055    0.0358674   -0.0853384   -0.075773    -0.227765      0.224446    -0.185123 
 -0.138932     0.0557706  -0.0824762   -0.0959556   -0.0741429   -0.0907864   -0.0239102    -0.145645    -0.0955032   -0.00923641    0.0877226   -0.15663      0.015363    -0.253562    -0.143332    -0.136157     -0.129397    -0.154823    0.0787029    0.131894    -0.138578     0.0468799    0.00642684  -0.0179383    -0.0126499    0.0174906
  0.0353981    0.0915638  -0.0306115   -0.0956699    0.0638316    0.0912782   -0.0479564    -0.019076    -0.123322    -0.0141492    -0.0110748   -0.0390835   -0.0214095   -0.0456963   -0.0614926    0.000973992  -0.00759189  -0.143454   -0.100317    -0.0182627   -0.00669615   0.010796    -0.0966203    0.000383744   0.0969277    0.122301 
  0.0173346    0.0260422  -0.190277     0.0599613   -0.0374961   -0.0525477    0.0617734    -0.15227      0.0724243   -0.0834082     0.0406559   -0.00503578   0.0423454    0.119069     0.0837697    0.0310884     0.00370172   0.178291    0.0299819   -0.0513674   -0.190473     0.0261994    0.0774867   -0.198443     -0.051229     0.0473858
  0.00325144  -0.0461951  -0.139533     0.0616275    0.114539     0.0408505   -0.0326125     0.0134627   -0.0485921   -0.0107002    -0.0916065   -0.0470057    0.0830575   -0.126302     0.0111732    0.119377     -0.15859     -0.0492644  -0.0143207   -0.0846405   -0.113965     0.090808    -0.0616726   -0.148624      0.0673861    0.103885 
 -0.0597181   -0.0336863   0.032448    -0.0409556    0.0704625   -0.00571683  -0.0506634     0.0363245    0.0465621    0.0214444     0.0301714    0.292611    -0.113275     0.00493996  -0.0121535    0.18086      -0.0696193   -0.0591753  -0.306483     0.00979376  -0.157887    -0.217894     0.150922    -0.0328423    -0.0150193   -0.0228272
 -0.0350172   -0.0350549   0.00899664  -0.175585    -0.03016     -0.0316576   -0.0660711     0.0813316    0.0260506    0.0260082     0.0165258   -0.148067     0.0196899    0.0147519   -0.00319648  -0.196007      0.0182642    0.0188089  -0.0544666   -0.0187019    0.127849    -0.0102657   -0.239045     0.0892072     0.124995    -0.122658 
 -0.135201     0.0674792  -0.124442    -0.0727934    0.0154816   -0.0642375   -0.0494479     0.233532     0.0154562   -0.208491     -0.123843    -0.0142454    0.103112    -0.0464678    0.0758803   -0.211959      0.0836202    0.0801291  -0.10263      0.0289679   -0.154039     0.146513     0.0542187   -0.0341679    -0.0309564   -0.0479916
  0.123458    -0.105981    0.00918824  -0.107567    -0.170436    -0.143946    -0.00261307    0.0964617    0.192206     0.127318      0.112023     0.0447366    0.0102763    0.0512854   -0.0403747   -0.1107       -0.0396006    0.073484    0.110697     0.102935    -0.0337963   -0.0214645    0.0626794   -0.0683486    -0.0824556    0.121115 
  0.140807     0.0965717   0.18331      0.0814046   -0.0897596   -0.0357559    0.0362663    -0.0019036   -0.00638426  -0.214777      0.0879143   -0.0626833    0.0288302   -0.0875122   -0.0818815    0.0291503     0.142124    -0.0856334   0.14728      0.079315    -0.0776127    0.0936465   -0.00745769   0.000172448   0.0130382   -0.0247206
 -0.0660655   -0.102244    0.0430673    0.144034     0.00468456   0.0990773    0.239845      0.0111676   -0.0939982   -0.137515      0.114996     0.0898639    0.00160882  -0.218895    -0.0541816    0.0159782     0.105449    -0.15884    -0.0111789    0.0872121   -0.0528333    0.0944998   -0.0644325    0.0838645    -0.0827588    0.0274324
  0.0706328    0.0861303  -0.101986    -0.00778019  -0.0345201    0.296723     0.0896576     0.0284526    0.0163403   -0.05015      -0.0279201    0.105582     0.0799095   -0.134567    -0.10421     -0.00678717   -0.028324    -0.0449551  -0.103792     0.00759203  -0.10019      0.0469144    0.00783256   0.108744     -0.0662947    0.0435258
  0.126696     0.0225832   0.0616244    0.043323     0.20644     -0.264069     0.0701324     0.0866827   -0.0302435   -0.000514874   0.144442     0.00758343  -0.0306168    0.0932594    0.106446     0.018869      0.180698     0.0158892   0.0625643    0.0167663   -0.0783347    0.0376249   -0.1344       0.10635      -0.0672552    0.0217573
  0.0718204   -0.169057    0.0945243    0.153272     0.0541306    0.135024     0.0690823    -0.224333    -0.145059    -0.037651      0.0457512    0.0100189   -0.0755989    0.00215704   0.179313    -0.0422556    -0.10597     -0.0434587  -0.144008    -0.183223    -0.0136002    0.0337587   -0.0407145    0.00971352   -0.0745152   -0.0378145
  0.0525477   -0.0181786  -0.0792516   -0.0229578   -0.0888385    0.163075    -0.260976     -0.00976432  -0.00279614  -0.122991      0.0874506   -0.153107     0.0736195    0.059302    -0.0187252   -0.0767081     0.0966141    0.118813    0.0425209    0.0210647    0.0476445    0.141993     0.0858724    0.02341      -0.0314527    0.0726548
 -0.177239     0.0408073  -0.096342    -0.251432    -0.105893     0.0653814   -0.0927184     0.0770567   -0.214492     0.0805544    -0.0954535    0.096574    -0.148255     0.0417397    0.0883175   -0.238618     -0.145907    -0.0803571   0.0471689   -0.181109     0.011357     0.0254817   -0.118371     0.0567758    -0.0957635    0.142579 
  0.0837627   -0.0861919  -0.166644     0.0845507   -0.0661709   -0.192645     0.132016     -0.00839614   0.0236733    0.0254262     0.0499001    0.102149     0.186409    -0.067141    -0.0357859    0.164266     -0.059324    -0.0313516   0.0879635    0.0636667   -0.111483     0.0769348   -0.0124463    0.107466      0.0628418   -0.0816602
 -0.0625086   -0.0458584  -0.00376368  -0.115322    -0.125957    -0.142032     0.173254      0.0287984   -0.0587115   -0.0909447     0.080615    -0.246501     0.0440691   -0.0650936   -0.131177    -0.0459172    -0.00471919   0.0311144   0.0565338    0.163132    -0.102799    -0.30865      0.122058     0.0176827    -0.0274213    0.121971 
  0.10101     -0.12816    -0.0172635   -0.0434754    0.075408     0.0405888    0.0457703     0.152087    -0.0573908   -0.0342496     0.0238305    0.0785671    0.0397042   -0.00143952  -0.0154642    0.0163078     0.098552    -0.167814    0.189009     0.0457332   -0.137644    -0.322409     0.106659    -0.154816      0.0619072    0.140326 
  0.0088129   -0.0443484   0.0523495    0.0641754   -0.0254189    0.116144     0.00663215   -0.00945088   0.113515    -0.180142      0.0999045    0.0836481    0.0976546   -0.0383985   -0.00721023  -0.0143729     0.0416338   -0.0604099   0.121154     0.0294664   -0.115524     0.0736598    0.0384268   -0.160119     -0.0380142    0.263728 
  0.125553    -0.0829072   0.1054      -0.0729339    0.020368     0.035655     0.202755      0.011873    -0.238993    -0.148142     -0.162208    -0.0496395    0.00951892  -0.0957859    0.0195124   -0.074489     -0.203409    -0.0201417   0.0961735   -0.0316488   -0.0948297    0.0654518    0.00520781   0.00950784    0.120728     0.0984261kind diag, method split
0: avll = -1.3879529681282332
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.388045
INFO: iteration 2, average log likelihood -1.387939
INFO: iteration 3, average log likelihood -1.387157
INFO: iteration 4, average log likelihood -1.379189
INFO: iteration 5, average log likelihood -1.361878
INFO: iteration 6, average log likelihood -1.354914
INFO: iteration 7, average log likelihood -1.352498
INFO: iteration 8, average log likelihood -1.351226
INFO: iteration 9, average log likelihood -1.350570
INFO: iteration 10, average log likelihood -1.350203
INFO: iteration 11, average log likelihood -1.349967
INFO: iteration 12, average log likelihood -1.349801
INFO: iteration 13, average log likelihood -1.349681
INFO: iteration 14, average log likelihood -1.349590
INFO: iteration 15, average log likelihood -1.349515
INFO: iteration 16, average log likelihood -1.349449
INFO: iteration 17, average log likelihood -1.349387
INFO: iteration 18, average log likelihood -1.349327
INFO: iteration 19, average log likelihood -1.349270
INFO: iteration 20, average log likelihood -1.349214
INFO: iteration 21, average log likelihood -1.349162
INFO: iteration 22, average log likelihood -1.349111
INFO: iteration 23, average log likelihood -1.349064
INFO: iteration 24, average log likelihood -1.349020
INFO: iteration 25, average log likelihood -1.348978
INFO: iteration 26, average log likelihood -1.348940
INFO: iteration 27, average log likelihood -1.348905
INFO: iteration 28, average log likelihood -1.348874
INFO: iteration 29, average log likelihood -1.348847
INFO: iteration 30, average log likelihood -1.348824
INFO: iteration 31, average log likelihood -1.348805
INFO: iteration 32, average log likelihood -1.348788
INFO: iteration 33, average log likelihood -1.348774
INFO: iteration 34, average log likelihood -1.348761
INFO: iteration 35, average log likelihood -1.348751
INFO: iteration 36, average log likelihood -1.348742
INFO: iteration 37, average log likelihood -1.348734
INFO: iteration 38, average log likelihood -1.348727
INFO: iteration 39, average log likelihood -1.348721
INFO: iteration 40, average log likelihood -1.348715
INFO: iteration 41, average log likelihood -1.348710
INFO: iteration 42, average log likelihood -1.348705
INFO: iteration 43, average log likelihood -1.348701
INFO: iteration 44, average log likelihood -1.348697
INFO: iteration 45, average log likelihood -1.348692
INFO: iteration 46, average log likelihood -1.348688
INFO: iteration 47, average log likelihood -1.348684
INFO: iteration 48, average log likelihood -1.348680
INFO: iteration 49, average log likelihood -1.348676
INFO: iteration 50, average log likelihood -1.348672
INFO: EM with 100000 data points 50 iterations avll -1.348672
952.4 data points per parameter
1: avll = [-1.38805,-1.38794,-1.38716,-1.37919,-1.36188,-1.35491,-1.3525,-1.35123,-1.35057,-1.3502,-1.34997,-1.3498,-1.34968,-1.34959,-1.34952,-1.34945,-1.34939,-1.34933,-1.34927,-1.34921,-1.34916,-1.34911,-1.34906,-1.34902,-1.34898,-1.34894,-1.3489,-1.34887,-1.34885,-1.34882,-1.3488,-1.34879,-1.34877,-1.34876,-1.34875,-1.34874,-1.34873,-1.34873,-1.34872,-1.34872,-1.34871,-1.34871,-1.3487,-1.3487,-1.34869,-1.34869,-1.34868,-1.34868,-1.34868,-1.34867]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.348812
INFO: iteration 2, average log likelihood -1.348664
INFO: iteration 3, average log likelihood -1.347973
INFO: iteration 4, average log likelihood -1.342627
INFO: iteration 5, average log likelihood -1.329651
INFO: iteration 6, average log likelihood -1.320481
INFO: iteration 7, average log likelihood -1.316991
INFO: iteration 8, average log likelihood -1.315049
INFO: iteration 9, average log likelihood -1.313569
INFO: iteration 10, average log likelihood -1.312208
INFO: iteration 11, average log likelihood -1.310947
INFO: iteration 12, average log likelihood -1.309905
INFO: iteration 13, average log likelihood -1.309044
INFO: iteration 14, average log likelihood -1.308192
INFO: iteration 15, average log likelihood -1.307212
INFO: iteration 16, average log likelihood -1.305730
INFO: iteration 17, average log likelihood -1.303582
INFO: iteration 18, average log likelihood -1.301699
INFO: iteration 19, average log likelihood -1.300779
INFO: iteration 20, average log likelihood -1.300284
INFO: iteration 21, average log likelihood -1.299934
INFO: iteration 22, average log likelihood -1.299644
INFO: iteration 23, average log likelihood -1.299404
INFO: iteration 24, average log likelihood -1.299218
INFO: iteration 25, average log likelihood -1.299074
INFO: iteration 26, average log likelihood -1.298967
INFO: iteration 27, average log likelihood -1.298888
INFO: iteration 28, average log likelihood -1.298830
INFO: iteration 29, average log likelihood -1.298787
INFO: iteration 30, average log likelihood -1.298755
INFO: iteration 31, average log likelihood -1.298730
INFO: iteration 32, average log likelihood -1.298710
INFO: iteration 33, average log likelihood -1.298693
INFO: iteration 34, average log likelihood -1.298680
INFO: iteration 35, average log likelihood -1.298668
INFO: iteration 36, average log likelihood -1.298659
INFO: iteration 37, average log likelihood -1.298651
INFO: iteration 38, average log likelihood -1.298645
INFO: iteration 39, average log likelihood -1.298640
INFO: iteration 40, average log likelihood -1.298635
INFO: iteration 41, average log likelihood -1.298631
INFO: iteration 42, average log likelihood -1.298628
INFO: iteration 43, average log likelihood -1.298626
INFO: iteration 44, average log likelihood -1.298623
INFO: iteration 45, average log likelihood -1.298621
INFO: iteration 46, average log likelihood -1.298620
INFO: iteration 47, average log likelihood -1.298618
INFO: iteration 48, average log likelihood -1.298617
INFO: iteration 49, average log likelihood -1.298616
INFO: iteration 50, average log likelihood -1.298616
INFO: EM with 100000 data points 50 iterations avll -1.298616
473.9 data points per parameter
2: avll = [-1.34881,-1.34866,-1.34797,-1.34263,-1.32965,-1.32048,-1.31699,-1.31505,-1.31357,-1.31221,-1.31095,-1.30991,-1.30904,-1.30819,-1.30721,-1.30573,-1.30358,-1.3017,-1.30078,-1.30028,-1.29993,-1.29964,-1.2994,-1.29922,-1.29907,-1.29897,-1.29889,-1.29883,-1.29879,-1.29875,-1.29873,-1.29871,-1.29869,-1.29868,-1.29867,-1.29866,-1.29865,-1.29865,-1.29864,-1.29864,-1.29863,-1.29863,-1.29863,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.298795
INFO: iteration 2, average log likelihood -1.298629
INFO: iteration 3, average log likelihood -1.298043
INFO: iteration 4, average log likelihood -1.291834
INFO: iteration 5, average log likelihood -1.271829
INFO: iteration 6, average log likelihood -1.256862
INFO: iteration 7, average log likelihood -1.249787
INFO: iteration 8, average log likelihood -1.244946
INFO: iteration 9, average log likelihood -1.241543
INFO: iteration 10, average log likelihood -1.238950
INFO: iteration 11, average log likelihood -1.237159
INFO: iteration 12, average log likelihood -1.236236
INFO: iteration 13, average log likelihood -1.235768
INFO: iteration 14, average log likelihood -1.235525
INFO: iteration 15, average log likelihood -1.235412
INFO: iteration 16, average log likelihood -1.235355
INFO: iteration 17, average log likelihood -1.235318
INFO: iteration 18, average log likelihood -1.235291
INFO: iteration 19, average log likelihood -1.235269
INFO: iteration 20, average log likelihood -1.235252
INFO: iteration 21, average log likelihood -1.235237
INFO: iteration 22, average log likelihood -1.235223
INFO: iteration 23, average log likelihood -1.235210
INFO: iteration 24, average log likelihood -1.235198
INFO: iteration 25, average log likelihood -1.235186
INFO: iteration 26, average log likelihood -1.235175
INFO: iteration 27, average log likelihood -1.235164
INFO: iteration 28, average log likelihood -1.235153
INFO: iteration 29, average log likelihood -1.235142
INFO: iteration 30, average log likelihood -1.235131
INFO: iteration 31, average log likelihood -1.235119
INFO: iteration 32, average log likelihood -1.235107
INFO: iteration 33, average log likelihood -1.235094
INFO: iteration 34, average log likelihood -1.235080
INFO: iteration 35, average log likelihood -1.235065
INFO: iteration 36, average log likelihood -1.235049
INFO: iteration 37, average log likelihood -1.235031
INFO: iteration 38, average log likelihood -1.235011
INFO: iteration 39, average log likelihood -1.234987
INFO: iteration 40, average log likelihood -1.234960
INFO: iteration 41, average log likelihood -1.234930
INFO: iteration 42, average log likelihood -1.234897
INFO: iteration 43, average log likelihood -1.234862
INFO: iteration 44, average log likelihood -1.234824
INFO: iteration 45, average log likelihood -1.234784
INFO: iteration 46, average log likelihood -1.234740
INFO: iteration 47, average log likelihood -1.234690
INFO: iteration 48, average log likelihood -1.234632
INFO: iteration 49, average log likelihood -1.234568
INFO: iteration 50, average log likelihood -1.234499
INFO: EM with 100000 data points 50 iterations avll -1.234499
236.4 data points per parameter
3: avll = [-1.2988,-1.29863,-1.29804,-1.29183,-1.27183,-1.25686,-1.24979,-1.24495,-1.24154,-1.23895,-1.23716,-1.23624,-1.23577,-1.23552,-1.23541,-1.23535,-1.23532,-1.23529,-1.23527,-1.23525,-1.23524,-1.23522,-1.23521,-1.2352,-1.23519,-1.23518,-1.23516,-1.23515,-1.23514,-1.23513,-1.23512,-1.23511,-1.23509,-1.23508,-1.23506,-1.23505,-1.23503,-1.23501,-1.23499,-1.23496,-1.23493,-1.2349,-1.23486,-1.23482,-1.23478,-1.23474,-1.23469,-1.23463,-1.23457,-1.2345]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.234665
INFO: iteration 2, average log likelihood -1.234378
INFO: iteration 3, average log likelihood -1.233837
INFO: iteration 4, average log likelihood -1.228179
WARNING: Variances had to be floored 10
INFO: iteration 5, average log likelihood -1.204862
WARNING: Variances had to be floored 10
INFO: iteration 6, average log likelihood -1.188773
INFO: iteration 7, average log likelihood -1.179365
WARNING: Variances had to be floored 10
INFO: iteration 8, average log likelihood -1.167915
WARNING: Variances had to be floored 10 14
INFO: iteration 9, average log likelihood -1.166875
WARNING: Variances had to be floored 12
INFO: iteration 10, average log likelihood -1.173538
WARNING: Variances had to be floored 10
INFO: iteration 11, average log likelihood -1.170026
WARNING: Variances had to be floored 10
INFO: iteration 12, average log likelihood -1.168673
WARNING: Variances had to be floored 10
INFO: iteration 13, average log likelihood -1.165714
WARNING: Variances had to be floored 10
INFO: iteration 14, average log likelihood -1.162489
WARNING: Variances had to be floored 10 12 14
INFO: iteration 15, average log likelihood -1.159207
INFO: iteration 16, average log likelihood -1.174267
WARNING: Variances had to be floored 10
INFO: iteration 17, average log likelihood -1.161573
WARNING: Variances had to be floored 10
INFO: iteration 18, average log likelihood -1.163831
INFO: iteration 19, average log likelihood -1.162564
WARNING: Variances had to be floored 10 12
INFO: iteration 20, average log likelihood -1.156747
WARNING: Variances had to be floored 10
INFO: iteration 21, average log likelihood -1.166277
WARNING: Variances had to be floored 10 14
INFO: iteration 22, average log likelihood -1.160176
INFO: iteration 23, average log likelihood -1.166246
WARNING: Variances had to be floored 10
INFO: iteration 24, average log likelihood -1.155877
WARNING: Variances had to be floored 10 12 15
INFO: iteration 25, average log likelihood -1.153510
WARNING: Variances had to be floored 10
INFO: iteration 26, average log likelihood -1.167309
WARNING: Variances had to be floored 10 14
INFO: iteration 27, average log likelihood -1.159619
WARNING: Variances had to be floored 15
INFO: iteration 28, average log likelihood -1.163391
WARNING: Variances had to be floored 10
INFO: iteration 29, average log likelihood -1.157951
WARNING: Variances had to be floored 10
INFO: iteration 30, average log likelihood -1.160087
WARNING: Variances had to be floored 10 12 15
INFO: iteration 31, average log likelihood -1.157397
WARNING: Variances had to be floored 10
INFO: iteration 32, average log likelihood -1.164472
WARNING: Variances had to be floored 10 14
INFO: iteration 33, average log likelihood -1.158367
INFO: iteration 34, average log likelihood -1.165297
WARNING: Variances had to be floored 10 15
INFO: iteration 35, average log likelihood -1.149374
WARNING: Variances had to be floored 10
INFO: iteration 36, average log likelihood -1.161249
WARNING: Variances had to be floored 10 12
INFO: iteration 37, average log likelihood -1.156349
WARNING: Variances had to be floored 10 14 15
INFO: iteration 38, average log likelihood -1.157933
INFO: iteration 39, average log likelihood -1.167399
WARNING: Variances had to be floored 10
INFO: iteration 40, average log likelihood -1.157322
INFO: iteration 41, average log likelihood -1.160102
WARNING: Variances had to be floored 10 12
INFO: iteration 42, average log likelihood -1.154460
INFO: iteration 43, average log likelihood -1.164845
WARNING: Variances had to be floored 10 15
INFO: iteration 44, average log likelihood -1.152568
WARNING: Variances had to be floored 10
INFO: iteration 45, average log likelihood -1.163442
INFO: iteration 46, average log likelihood -1.160643
WARNING: Variances had to be floored 10 12
INFO: iteration 47, average log likelihood -1.154215
WARNING: Variances had to be floored 10 15
INFO: iteration 48, average log likelihood -1.157723
WARNING: Variances had to be floored 10
INFO: iteration 49, average log likelihood -1.164236
WARNING: Variances had to be floored 10
INFO: iteration 50, average log likelihood -1.159130
INFO: EM with 100000 data points 50 iterations avll -1.159130
118.1 data points per parameter
4: avll = [-1.23467,-1.23438,-1.23384,-1.22818,-1.20486,-1.18877,-1.17937,-1.16792,-1.16687,-1.17354,-1.17003,-1.16867,-1.16571,-1.16249,-1.15921,-1.17427,-1.16157,-1.16383,-1.16256,-1.15675,-1.16628,-1.16018,-1.16625,-1.15588,-1.15351,-1.16731,-1.15962,-1.16339,-1.15795,-1.16009,-1.1574,-1.16447,-1.15837,-1.1653,-1.14937,-1.16125,-1.15635,-1.15793,-1.1674,-1.15732,-1.1601,-1.15446,-1.16484,-1.15257,-1.16344,-1.16064,-1.15421,-1.15772,-1.16424,-1.15913]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 1, average log likelihood -1.151253
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 2, average log likelihood -1.148945
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 3, average log likelihood -1.148371
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 4, average log likelihood -1.134043
WARNING: Variances had to be floored 7 19 20 22 27 28 29 30
INFO: iteration 5, average log likelihood -1.099561
WARNING: Variances had to be floored 8 19 20 21 23 24 27 28 29 30
INFO: iteration 6, average log likelihood -1.092100
WARNING: Variances had to be floored 7 19 20 22 27 28 29 30
INFO: iteration 7, average log likelihood -1.091840
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 8, average log likelihood -1.086364
WARNING: Variances had to be floored 7 8 10 19 20 21 22 27 28 29 30
INFO: iteration 9, average log likelihood -1.066280
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 10, average log likelihood -1.105964
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 11, average log likelihood -1.092785
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 12, average log likelihood -1.069769
WARNING: Variances had to be floored 8 10 19 20 21 27 28 29 30
INFO: iteration 13, average log likelihood -1.078657
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 14, average log likelihood -1.095099
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 15, average log likelihood -1.091244
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 16, average log likelihood -1.068808
WARNING: Variances had to be floored 10 19 20 27 28 29 30
INFO: iteration 17, average log likelihood -1.095127
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 18, average log likelihood -1.095616
WARNING: Variances had to be floored 7 19 20 22 27 28 29 30
INFO: iteration 19, average log likelihood -1.073604
WARNING: Variances had to be floored 8 19 20 21 23 24 27 28 29 30
INFO: iteration 20, average log likelihood -1.079590
WARNING: Variances had to be floored 7 10 19 20 22 27 28 29 30
INFO: iteration 21, average log likelihood -1.084894
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 22, average log likelihood -1.094565
WARNING: Variances had to be floored 7 8 19 20 21 22 27 28 29 30
INFO: iteration 23, average log likelihood -1.073023
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 24, average log likelihood -1.096569
WARNING: Variances had to be floored 10 19 20 27 28 29 30
INFO: iteration 25, average log likelihood -1.086016
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 26, average log likelihood -1.077622
WARNING: Variances had to be floored 8 19 20 21 27 28 29 30
INFO: iteration 27, average log likelihood -1.083881
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 28, average log likelihood -1.086196
WARNING: Variances had to be floored 10 19 20 27 28 29 30
INFO: iteration 29, average log likelihood -1.084999
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 30, average log likelihood -1.076968
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 31, average log likelihood -1.100712
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 32, average log likelihood -1.087360
WARNING: Variances had to be floored 7 10 19 20 22 27 28 29 30
INFO: iteration 33, average log likelihood -1.067958
WARNING: Variances had to be floored 8 19 20 21 23 24 27 28 29 30
INFO: iteration 34, average log likelihood -1.087296
WARNING: Variances had to be floored 7 19 20 22 27 28 29 30
INFO: iteration 35, average log likelihood -1.087983
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 36, average log likelihood -1.075495
WARNING: Variances had to be floored 7 8 10 19 20 21 22 27 28 29 30
INFO: iteration 37, average log likelihood -1.052771
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 38, average log likelihood -1.090467
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 39, average log likelihood -1.077143
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 40, average log likelihood -1.054384
WARNING: Variances had to be floored 8 10 19 20 21 27 28 29 30
INFO: iteration 41, average log likelihood -1.063745
WARNING: Variances had to be floored 7 19 20 22 23 24 27 28 29 30
INFO: iteration 42, average log likelihood -1.079782
WARNING: Variances had to be floored 19 20 27 28 29 30
INFO: iteration 43, average log likelihood -1.076077
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 44, average log likelihood -1.053803
WARNING: Variances had to be floored 10 19 20 27 28 29 30
INFO: iteration 45, average log likelihood -1.080823
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 46, average log likelihood -1.081138
WARNING: Variances had to be floored 7 19 20 22 27 28 29 30
INFO: iteration 47, average log likelihood -1.058702
WARNING: Variances had to be floored 8 19 20 21 23 24 27 28 29 30
INFO: iteration 48, average log likelihood -1.064942
WARNING: Variances had to be floored 7 10 19 20 22 27 28 29 30
INFO: iteration 49, average log likelihood -1.070133
WARNING: Variances had to be floored 19 20 23 24 27 28 29 30
INFO: iteration 50, average log likelihood -1.080003
INFO: EM with 100000 data points 50 iterations avll -1.080003
59.0 data points per parameter
5: avll = [-1.15125,-1.14894,-1.14837,-1.13404,-1.09956,-1.0921,-1.09184,-1.08636,-1.06628,-1.10596,-1.09279,-1.06977,-1.07866,-1.0951,-1.09124,-1.06881,-1.09513,-1.09562,-1.0736,-1.07959,-1.08489,-1.09456,-1.07302,-1.09657,-1.08602,-1.07762,-1.08388,-1.0862,-1.085,-1.07697,-1.10071,-1.08736,-1.06796,-1.0873,-1.08798,-1.0755,-1.05277,-1.09047,-1.07714,-1.05438,-1.06374,-1.07978,-1.07608,-1.0538,-1.08082,-1.08114,-1.0587,-1.06494,-1.07013,-1.08]
[-1.38795,-1.38805,-1.38794,-1.38716,-1.37919,-1.36188,-1.35491,-1.3525,-1.35123,-1.35057,-1.3502,-1.34997,-1.3498,-1.34968,-1.34959,-1.34952,-1.34945,-1.34939,-1.34933,-1.34927,-1.34921,-1.34916,-1.34911,-1.34906,-1.34902,-1.34898,-1.34894,-1.3489,-1.34887,-1.34885,-1.34882,-1.3488,-1.34879,-1.34877,-1.34876,-1.34875,-1.34874,-1.34873,-1.34873,-1.34872,-1.34872,-1.34871,-1.34871,-1.3487,-1.3487,-1.34869,-1.34869,-1.34868,-1.34868,-1.34868,-1.34867,-1.34881,-1.34866,-1.34797,-1.34263,-1.32965,-1.32048,-1.31699,-1.31505,-1.31357,-1.31221,-1.31095,-1.30991,-1.30904,-1.30819,-1.30721,-1.30573,-1.30358,-1.3017,-1.30078,-1.30028,-1.29993,-1.29964,-1.2994,-1.29922,-1.29907,-1.29897,-1.29889,-1.29883,-1.29879,-1.29875,-1.29873,-1.29871,-1.29869,-1.29868,-1.29867,-1.29866,-1.29865,-1.29865,-1.29864,-1.29864,-1.29863,-1.29863,-1.29863,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862,-1.29862,-1.2988,-1.29863,-1.29804,-1.29183,-1.27183,-1.25686,-1.24979,-1.24495,-1.24154,-1.23895,-1.23716,-1.23624,-1.23577,-1.23552,-1.23541,-1.23535,-1.23532,-1.23529,-1.23527,-1.23525,-1.23524,-1.23522,-1.23521,-1.2352,-1.23519,-1.23518,-1.23516,-1.23515,-1.23514,-1.23513,-1.23512,-1.23511,-1.23509,-1.23508,-1.23506,-1.23505,-1.23503,-1.23501,-1.23499,-1.23496,-1.23493,-1.2349,-1.23486,-1.23482,-1.23478,-1.23474,-1.23469,-1.23463,-1.23457,-1.2345,-1.23467,-1.23438,-1.23384,-1.22818,-1.20486,-1.18877,-1.17937,-1.16792,-1.16687,-1.17354,-1.17003,-1.16867,-1.16571,-1.16249,-1.15921,-1.17427,-1.16157,-1.16383,-1.16256,-1.15675,-1.16628,-1.16018,-1.16625,-1.15588,-1.15351,-1.16731,-1.15962,-1.16339,-1.15795,-1.16009,-1.1574,-1.16447,-1.15837,-1.1653,-1.14937,-1.16125,-1.15635,-1.15793,-1.1674,-1.15732,-1.1601,-1.15446,-1.16484,-1.15257,-1.16344,-1.16064,-1.15421,-1.15772,-1.16424,-1.15913,-1.15125,-1.14894,-1.14837,-1.13404,-1.09956,-1.0921,-1.09184,-1.08636,-1.06628,-1.10596,-1.09279,-1.06977,-1.07866,-1.0951,-1.09124,-1.06881,-1.09513,-1.09562,-1.0736,-1.07959,-1.08489,-1.09456,-1.07302,-1.09657,-1.08602,-1.07762,-1.08388,-1.0862,-1.085,-1.07697,-1.10071,-1.08736,-1.06796,-1.0873,-1.08798,-1.0755,-1.05277,-1.09047,-1.07714,-1.05438,-1.06374,-1.07978,-1.07608,-1.0538,-1.08082,-1.08114,-1.0587,-1.06494,-1.07013,-1.08]
32Ã—26 Array{Float64,2}:
 -0.121402     0.0438177   -0.0406974   -0.0495898    0.0551799    0.0430139    0.0631639    0.0977886     0.0314698    0.212034     0.0736646    0.00498101  -0.0645132   -0.236689     0.0166887   -0.229997    -0.114007     0.0888801   -0.0851209    0.0911094    0.137811    -0.0990018    0.0741689   -0.120815    0.2238        0.139097  
 -0.100058     0.00124997  -0.0449372   -0.084862     0.0301159   -0.00375153  -0.0453658   -0.175615     -0.0246542    0.0320185    0.107179    -0.0529406    0.0741791   -0.0268714   -0.0293169   -0.0187826   -0.0912775   -0.0889623   -0.00961943   0.154443    -0.105222     0.0401587   -0.0224938    0.0224721  -0.00702582   -0.0036965 
  0.0761033    0.046326    -0.0330496    0.165461     0.0195853    0.0160358    0.00647809   0.242082     -0.0703654   -0.00265374  -0.0199473   -0.0830198    0.0930297    0.13671      0.259179    -0.0172681   -0.0316375   -0.264944     0.0162891   -0.0890473    0.0457709   -0.967996     0.100249    -0.0567519   0.0856532     0.0266383 
  0.113516    -0.0860056   -0.0616582    0.22137     -0.0854675    0.00266487  -0.00581726   0.0421258     0.00102956  -0.122389    -0.0393544   -0.0482815    0.187557     0.138871    -0.110455     0.238559    -0.102339    -0.257002    -0.00465944  -0.127031    -0.124111     0.835555     0.0961122   -0.0516832   0.10424       0.0649737 
 -0.0514891    0.029661    -0.0950516    0.00508941   0.0798024    0.0827396   -0.0289493   -0.0756709     0.0780076   -0.012521    -0.168198     0.0573319   -0.0688727    0.0165155   -0.0687712    0.102786    -0.264086    -0.0561762   -0.0916573    0.0918955    0.0372008   -0.0884051   -0.0629609   -0.23398     0.1493       -0.181147  
  0.146181     0.227769    -0.13594     -0.0735131    0.007147    -0.0724472   -0.186213    -0.0177617     0.0591597   -0.0596967    0.0300628    0.130501     0.0177496   -0.0759071   -0.0344286   -0.0239257    0.123693     0.0336995   -0.0745016   -0.120115    -0.0577664    0.151122    -0.0262872   -0.0485264  -0.00450277    0.140359  
 -0.169416     0.0338309   -0.110492    -0.196145    -0.0885974    0.0617654   -0.0839535    0.0886411    -0.253848     0.0559597   -0.0950444    0.0885443   -0.127923     0.0338944    0.0869706   -0.209529    -0.135302    -0.0917223    0.0476069   -0.173103     0.0026072    0.0457572   -0.110873     0.0582678  -0.09291       0.127291  
 -0.0449088   -0.0322761    0.0913098   -0.0162086    0.0789431    0.110206     0.0362827   -0.0410444     0.0441032   -0.032339     0.0889728   -0.0188507    0.0207713    0.0216534   -0.0816181    0.0794028    0.0047369   -0.0299257   -0.147687     0.140288    -0.0073096   -0.0589997   -0.0721605   -0.0157449   0.000525925  -0.0200648 
 -0.0174801    0.0884226   -0.102634    -0.0382086    0.00527104   0.130152     0.0316898    0.118877      0.0213461   -0.137358    -0.0431182    0.0256471    0.0944826   -0.084298    -0.0181498   -0.0930181    0.0288447    0.00997839  -0.111386     0.0365624   -0.122835     0.107732     0.0132151    0.0420971  -0.0514156    -0.0146123 
  0.111856    -0.0750017   -0.00555873  -0.0343296    0.0512048    0.061628     0.0427473    0.136412     -0.0555749   -0.0352649    0.0532741    0.0782249    0.0395704    0.00260679  -0.00349672   0.0168651    0.0916138   -0.125834     0.161871     0.0529048   -0.132827    -0.255974     0.0704896   -0.132368    0.0399629     0.100896  
  0.00666457  -0.0438771   -0.0979468   -0.0345525   -0.130916    -0.139437     0.16793      0.0625616    -0.0788094   -0.049752     0.242271    -0.240366     0.0297678   -0.0860549   -0.138198    -0.113686     0.021448    -0.0321195    0.0805097    0.158605    -0.111671    -1.52241      0.213853    -0.042898    0.00553399    0.130834  
 -0.156912    -0.0962787    0.0772999   -0.147816    -0.105155    -0.123531     0.169469    -0.00224069   -0.0240275   -0.0982837    0.0445992   -0.243617     0.0549739   -0.0755951   -0.12234      0.084019    -0.0908817    0.0648517    0.0556056    0.16111     -0.102356     0.8051       0.0771673    0.0179993  -0.0185447     0.116015  
  0.0962597    0.0562261    0.0434261   -0.0116028    0.10416      0.0551143   -0.0759631   -0.0343073    -0.109685     0.0303039   -0.0426412   -0.0455837    0.024084     0.0419728    0.0226729   -0.0111149   -0.0194991   -0.0750142   -0.092189    -0.00295546   0.0426509   -0.122833    -0.101084    -0.0133951   0.109471      0.125341  
  0.017315    -0.046335    -0.179698    -0.017228     0.0851352   -0.116746    -0.0191197   -0.000130841  -0.0785314   -0.0387953   -0.0540779   -0.0246457    0.03221     -0.00655784   0.0531265    0.0632104   -0.0363287   -0.0848692   -0.150613    -0.00436907  -0.0595566    0.0153747   -0.110059    -0.0162964  -0.0757207     0.0149857 
  0.013368    -0.0125837   -0.0551368    0.0492515    0.0110754   -0.120358     0.0352701    0.0228716    -0.0283067   -0.00572691   0.0656679    0.0445789    0.0424013   -0.0256584    0.022278     0.0629595   -0.00699759  -0.0426557   -0.00299624  -0.0044196   -0.0906197   -0.00609905   0.00377182   0.0248383   0.0319667     0.00614197
  0.0481856    0.0160318    0.0654502   -0.0558997   -0.0531845   -0.0287904   -0.00421641   0.0265146     0.0115725   -0.0819166    0.0482894   -0.0990585    0.00831662  -0.0269626   -0.0625271   -0.073147     0.0665213   -0.0501689    0.0372829    0.0166853    0.0129862    0.0288081   -0.139287     0.0690906   0.060965     -0.0802467 
  0.0808113   -0.172408     0.0804038   -0.185932     0.0302927    0.137603     0.121882    -0.222451     -0.150758    -0.0333333   -0.0256796   -0.00840987  -0.159179     0.0024404    0.169611    -0.0386731   -0.0882129   -0.151763    -0.2559      -0.188967    -0.0207016    0.0265001   -0.0286532    0.015558   -0.0713613    -0.0464208 
  0.0545621   -0.159456     0.106998     0.479162     0.0885282    0.137201    -0.00371169  -0.233038     -0.146682    -0.0400135    0.0428641    0.0194752   -0.0231986    0.00182801   0.2162      -0.0448006   -0.13519      0.0538636   -0.00541686  -0.148282    -0.00591681   0.048241    -0.0301437    0.020136   -0.0772446    -0.0282449 
 -0.0982616    0.0111494   -0.00772813   0.0471215   -0.0233458    0.202356    -0.0154601    0.497463     -0.00721306   0.0746121    0.0150132   -0.090741     0.0230086    0.150346    -0.0135833    0.0253999   -0.0520455    0.00221371  -0.255557     0.0337019    0.0377499    0.0180998   -0.0157437   -0.247476   -0.0870204    -1.27478   
 -0.0952477   -0.0389708   -0.00777729   0.0266868    0.107197     0.295168    -0.209317    -0.17697      -0.0100421   -0.0458725   -0.0919826   -0.154832     0.022828    -0.0600771   -0.0253921   -0.00262408  -0.0534661    0.0292511   -0.173656     0.0624486    0.035087     0.0202211   -0.00686921  -0.0855521  -0.088045      1.01508   
 -0.0632489   -0.111786     0.0439415    0.147546     0.0197165    0.100188     0.229265     0.0443796    -0.119356    -0.118878     0.0981499    0.0915558   -0.0223174   -0.219844    -0.0501295    0.0194348    0.134825    -0.150244    -0.00977985   0.0905381   -0.0543867    0.0923732   -0.0703691    0.0859167  -0.0803966     0.0810691 
 -0.0840041   -0.0762106   -0.154552     0.0786994    0.0131555    0.0629387   -0.0508113   -0.111389     -0.0229861    0.0175018    0.0855127    0.00692432   0.0563874    0.00770242  -0.0270169    0.125264    -0.0980233    0.00886264  -0.0509002    0.0022809    0.0897662   -0.0207608   -0.165067     0.120413   -0.110538     -0.0566333 
  0.0424955   -0.00477642  -0.253403     0.0148241   -0.0799615    0.115927     0.0601828    0.0997269     0.149805    -0.147151     0.176775     0.0949716    0.0948401   -0.0687865    0.0944147   -0.239819     0.0188726   -0.109738     0.124488     0.0440477   -0.0772727    0.0291482    0.145537    -0.301605   -0.0364747    -0.0180885 
 -0.0367329   -0.0740392    0.258491     0.0745979   -0.00055229   0.116569    -0.129018    -0.047069      0.076923    -0.175071     0.019022     0.080836     0.0939763   -0.0428259   -0.0662563    0.182583     0.0559738   -0.0144083    0.119479    -0.0142109   -0.122109     0.0792114   -0.0594698   -0.0866613  -0.0394691     0.482104  
 -0.173317     0.168889     0.129626     0.184191    -0.0138835    0.211104     0.0100679   -0.173077     -0.0758082   -0.155787     0.0870028   -0.109495     0.172355     0.135123    -0.137139    -0.179638    -0.00345629   0.0455948   -0.0862013   -0.537251     0.162757     0.158815    -0.0699578    0.170992    0.107762      0.117502  
 -0.13091     -0.0378143    0.0986245    0.0454878   -0.0226003    0.193708    -0.015014     0.0816254    -0.0220759   -0.0225202    0.0784137   -0.107293     0.0952051    0.00174808  -0.0307462   -0.15565     -0.109773     0.107405    -0.080686     0.634423     0.0970298    0.143044     0.139679    -0.0672009   0.162816      0.116819  
 -0.0475503   -0.105432    -0.119998    -0.0336807   -0.088786     0.191945    -0.179306    -0.0124683    -0.0136132   -0.488651     0.166002    -0.134099     0.0878799    0.00359672  -0.0474861   -0.0722689    0.0942414    0.0678839    0.349953     0.0533115    0.0792667    0.138608    -0.0310898   -0.0454936  -0.0274638     0.0655216 
  0.115196     0.0472481   -0.0140901   -0.0123185   -0.088825     0.0984084   -0.327224    -0.0285059    -0.00927646   0.219238    -0.00148468  -0.159708     0.0678887    0.135167     0.0277528   -0.0754777    0.0874408    0.149425    -0.257864    -0.0335548   -0.00237962   0.14413      0.218261     0.0983524  -0.0258213     0.0813966 
  0.166142    -0.0898419    0.109514    -0.0754932    0.0228288    0.0356442    0.138073    -0.0210094    -0.205944    -0.149011    -0.173371    -0.0462897    0.0238576    0.716097     0.020536    -0.120982    -0.197551    -0.0271198    0.107653    -0.0334543   -0.10052      0.0745641    0.00521465   0.0101958   0.127274      0.0964173 
  0.170246    -0.104087     0.104235    -0.0680362    0.00151022   0.0355146    0.220255     0.017751     -0.282463    -0.146682    -0.13726     -0.053094     0.0135755   -0.993932     0.0186512   -0.0389757   -0.20902      0.0155219    0.106261    -0.0908973   -0.104897     0.0547714    0.00406641   0.0097069   0.164183      0.0987703 
  0.108238    -0.106091     0.0078834   -0.112114    -0.145713    -0.144813    -0.00838172   0.0991439     0.181034     0.122003     0.115412     0.0450215    0.0291568    0.0406504   -0.0356765   -0.115453    -0.0593651    0.0755162    0.124188     0.118935    -0.0288475   -0.0148091    0.0573856   -0.0437673  -0.112722      0.109901  
  0.0105354   -0.00783446  -0.189041     0.0635576   -0.0361833   -0.0538113    0.0593855   -0.12547       0.0816286   -0.0692957    0.0412001   -0.0140749    0.0330102    0.117496     0.0986928    0.0194241   -0.0171753    0.200603     0.0325438   -0.0553359   -0.199841     0.0240806    0.0785333   -0.184333   -0.0674666     0.044692  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 7 8 19 20 21 22 27 28 29 30
INFO: iteration 1, average log likelihood -1.058066
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 2, average log likelihood -1.053685
WARNING: Variances had to be floored 7 8 10 19 20 21 22 27 28 29 30
INFO: iteration 3, average log likelihood -1.052324
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 4, average log likelihood -1.056826
WARNING: Variances had to be floored 7 8 19 20 21 22 27 28 29 30
INFO: iteration 5, average log likelihood -1.054482
WARNING: Variances had to be floored 7 8 10 19 20 21 22 23 24 27 28 29 30
INFO: iteration 6, average log likelihood -1.050486
WARNING: Variances had to be floored 7 8 19 20 21 22 27 28 29 30
INFO: iteration 7, average log likelihood -1.058083
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 8, average log likelihood -1.053198
WARNING: Variances had to be floored 7 8 10 19 20 21 22 27 28 29 30
INFO: iteration 9, average log likelihood -1.051712
WARNING: Variances had to be floored 7 8 19 20 21 22 23 24 27 28 29 30
INFO: iteration 10, average log likelihood -1.056831
INFO: EM with 100000 data points 10 iterations avll -1.056831
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.161806e+05
      1       6.501620e+05      -1.660186e+05 |       32
      2       6.253878e+05      -2.477423e+04 |       32
      3       6.113395e+05      -1.404821e+04 |       32
      4       6.017670e+05      -9.572538e+03 |       32
      5       5.966365e+05      -5.130535e+03 |       32
      6       5.925879e+05      -4.048622e+03 |       32
      7       5.890401e+05      -3.547775e+03 |       32
      8       5.864220e+05      -2.618098e+03 |       32
      9       5.848906e+05      -1.531417e+03 |       32
     10       5.840110e+05      -8.795195e+02 |       32
     11       5.834006e+05      -6.104057e+02 |       32
     12       5.827661e+05      -6.345505e+02 |       32
     13       5.820843e+05      -6.817767e+02 |       32
     14       5.814431e+05      -6.411655e+02 |       32
     15       5.809204e+05      -5.227252e+02 |       32
     16       5.804576e+05      -4.628053e+02 |       32
     17       5.799931e+05      -4.645633e+02 |       32
     18       5.795444e+05      -4.486108e+02 |       32
     19       5.791637e+05      -3.807782e+02 |       32
     20       5.788125e+05      -3.511996e+02 |       32
     21       5.784761e+05      -3.363811e+02 |       32
     22       5.781704e+05      -3.056646e+02 |       32
     23       5.778653e+05      -3.051627e+02 |       32
     24       5.776717e+05      -1.935900e+02 |       32
     25       5.775390e+05      -1.326469e+02 |       32
     26       5.774490e+05      -8.997894e+01 |       32
     27       5.773788e+05      -7.026126e+01 |       32
     28       5.773157e+05      -6.306201e+01 |       32
     29       5.772528e+05      -6.291891e+01 |       32
     30       5.771969e+05      -5.589003e+01 |       31
     31       5.771528e+05      -4.408174e+01 |       32
     32       5.771161e+05      -3.675430e+01 |       31
     33       5.770913e+05      -2.476171e+01 |       31
     34       5.770710e+05      -2.034207e+01 |       31
     35       5.770536e+05      -1.739129e+01 |       31
     36       5.770387e+05      -1.487968e+01 |       27
     37       5.770241e+05      -1.458582e+01 |       27
     38       5.770098e+05      -1.427795e+01 |       28
     39       5.769918e+05      -1.804732e+01 |       28
     40       5.769525e+05      -3.931273e+01 |       31
     41       5.768734e+05      -7.910166e+01 |       32
     42       5.766630e+05      -2.103823e+02 |       32
     43       5.762167e+05      -4.462918e+02 |       32
     44       5.756069e+05      -6.098057e+02 |       32
     45       5.752154e+05      -3.915297e+02 |       32
     46       5.750215e+05      -1.938625e+02 |       32
     47       5.749091e+05      -1.124043e+02 |       32
     48       5.748504e+05      -5.867287e+01 |       32
     49       5.748137e+05      -3.673176e+01 |       31
     50       5.747915e+05      -2.222292e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 574791.4657370195)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.297244
INFO: iteration 2, average log likelihood -1.267068
INFO: iteration 3, average log likelihood -1.230995
INFO: iteration 4, average log likelihood -1.193454
INFO: iteration 5, average log likelihood -1.155963
WARNING: Variances had to be floored 4 13 16 23 30
INFO: iteration 6, average log likelihood -1.104504
WARNING: Variances had to be floored 10 19 32
INFO: iteration 7, average log likelihood -1.113478
WARNING: Variances had to be floored 6
INFO: iteration 8, average log likelihood -1.098123
WARNING: Variances had to be floored 2 4 16 30
INFO: iteration 9, average log likelihood -1.060895
WARNING: Variances had to be floored 15 29 32
INFO: iteration 10, average log likelihood -1.083391
WARNING: Variances had to be floored 10 23
INFO: iteration 11, average log likelihood -1.082396
WARNING: Variances had to be floored 4 6 13 16 31
INFO: iteration 12, average log likelihood -1.062816
WARNING: Variances had to be floored 2 30
INFO: iteration 13, average log likelihood -1.095822
WARNING: Variances had to be floored 32
INFO: iteration 14, average log likelihood -1.079775
WARNING: Variances had to be floored 4 10 15 16 23 29
INFO: iteration 15, average log likelihood -1.040188
WARNING: Variances had to be floored 6
INFO: iteration 16, average log likelihood -1.091051
WARNING: Variances had to be floored 2 30 31 32
INFO: iteration 17, average log likelihood -1.039156
WARNING: Variances had to be floored 4 10 13 16
INFO: iteration 18, average log likelihood -1.055304
WARNING: Variances had to be floored 23 29
INFO: iteration 19, average log likelihood -1.072310
WARNING: Variances had to be floored 2 15
INFO: iteration 20, average log likelihood -1.051625
WARNING: Variances had to be floored 4 6 10 16 30 31 32
INFO: iteration 21, average log likelihood -1.023549
INFO: iteration 22, average log likelihood -1.080182
WARNING: Variances had to be floored 2 13 23 29
INFO: iteration 23, average log likelihood -1.028568
WARNING: Variances had to be floored 4 10 16 32
INFO: iteration 24, average log likelihood -1.053171
WARNING: Variances had to be floored 30 31
INFO: iteration 25, average log likelihood -1.065352
WARNING: Variances had to be floored 2
INFO: iteration 26, average log likelihood -1.042273
WARNING: Variances had to be floored 4 10 13 16 23 29 32
INFO: iteration 27, average log likelihood -1.010554
WARNING: Variances had to be floored 14
INFO: iteration 28, average log likelihood -1.080664
WARNING: Variances had to be floored 2 30 31
INFO: iteration 29, average log likelihood -1.040597
WARNING: Variances had to be floored 10 16
INFO: iteration 30, average log likelihood -1.046481
WARNING: Variances had to be floored 4 6 13 23 32
INFO: iteration 31, average log likelihood -1.039711
WARNING: Variances had to be floored 2 14 29
INFO: iteration 32, average log likelihood -1.048232
WARNING: Variances had to be floored 10 16 30 31
INFO: iteration 33, average log likelihood -1.039530
WARNING: Variances had to be floored 32
INFO: iteration 34, average log likelihood -1.069280
WARNING: Variances had to be floored 4 13 23
INFO: iteration 35, average log likelihood -1.033581
WARNING: Variances had to be floored 2 6 10 14 16 32
INFO: iteration 36, average log likelihood -1.021623
WARNING: Variances had to be floored 30 31
INFO: iteration 37, average log likelihood -1.070779
WARNING: Variances had to be floored 29
INFO: iteration 38, average log likelihood -1.051249
WARNING: Variances had to be floored 4 10 13 16 32
INFO: iteration 39, average log likelihood -1.020548
WARNING: Variances had to be floored 2 14 23 30
INFO: iteration 40, average log likelihood -1.052754
WARNING: Variances had to be floored 6 31
INFO: iteration 41, average log likelihood -1.063141
WARNING: Variances had to be floored 10 16 32
INFO: iteration 42, average log likelihood -1.035139
WARNING: Variances had to be floored 4 13 29
INFO: iteration 43, average log likelihood -1.040050
WARNING: Variances had to be floored 2 23 30
INFO: iteration 44, average log likelihood -1.040203
WARNING: Variances had to be floored 10 14 16 31 32
INFO: iteration 45, average log likelihood -1.042243
WARNING: Variances had to be floored 4 6
INFO: iteration 46, average log likelihood -1.068045
WARNING: Variances had to be floored 13 29
INFO: iteration 47, average log likelihood -1.034431
WARNING: Variances had to be floored 2 10 16 23 30
INFO: iteration 48, average log likelihood -1.019526
WARNING: Variances had to be floored 4 32
INFO: iteration 49, average log likelihood -1.062619
WARNING: Variances had to be floored 6 14 31
INFO: iteration 50, average log likelihood -1.049230
INFO: EM with 100000 data points 50 iterations avll -1.049230
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.12777      0.0255802    0.0967294    0.0588936   -0.026542     0.180027     0.00403508   0.0448068   -0.0243027   -0.0278356    0.0859299  -0.111481     0.1067      0.0205653   -0.0299245   -0.163922     -0.10667      0.0949489    -0.0825871    1.24835      0.113168     0.145126     0.0814356   -0.0383759   0.145967     0.11906   
 -0.0946879   -0.019673    -0.00843794   0.0380151    0.0510054    0.263925    -0.12718      0.129159    -0.00857278   0.0067534   -0.0484985  -0.128669     0.0258566   0.0294323   -0.0265008    0.00947317   -0.0532134    0.0156546    -0.227094     0.0575939    0.0342636    0.0205283   -0.0103251   -0.176786   -0.086861     0.0299869 
 -0.0517247   -0.0511866   -0.0142903   -0.0689243    0.112398     0.0723229   -0.0625569   -0.174852     0.0370948    0.066455     0.125795    0.030503     0.116323    0.170173     0.080041     0.0405875    -0.0584017   -0.02344      -0.0940107    0.168527    -0.0716767    0.0244754   -0.0477129    0.0541879  -0.00205572  -0.0188645 
 -0.0367414   -0.0780025   -0.024755    -0.173291    -0.0345223   -0.0283049   -0.045821     0.0836876    0.0289509    0.0307442    0.0240046  -0.142624     0.0164547  -0.0106156    0.00532068  -0.186775      0.0142065    0.0052286    -0.0376046   -0.00443424   0.0961027   -0.0224831   -0.267786     0.126786    0.111728    -0.125809  
  0.105049    -0.0589817   -0.157368     0.0804166   -0.0725079   -0.190174     0.100324     0.0315402    0.0183536    0.0365294    0.0685124   0.103837     0.19638    -0.0832963   -0.0482525    0.124199     -0.0595928   -0.0332396     0.130914     0.0978284   -0.112014     0.0744302    0.0380387    0.123045    0.0531599   -0.0743367 
 -0.0369562   -0.117621     0.0438417    0.147397     0.0347171    0.0987099    0.162765     0.00987354  -0.0766423   -0.117059     0.0887539   0.0903607    0.0315024  -0.22935     -0.0745713   -0.000561333   0.0469995   -0.146964     -0.0110484    0.0845658   -0.0672872    0.0897861   -0.0707056    0.0862495  -0.0836712    0.193843  
 -0.110242     0.0300882   -0.113388     0.0827466   -0.0795345    0.130119     0.0186582   -0.0444944   -0.123225    -0.0709433    0.0344362  -0.20712      0.0963981  -0.11709      0.062295    -0.070372     -0.0340873   -0.0924048     0.0938425   -0.0957971   -0.02281      0.079798    -0.0874573   -0.0777038   0.116702     0.0680078 
  0.141404     0.102111     0.185302     0.0765311   -0.0879957   -0.0228745    0.0342706   -0.0306124   -0.00845428  -0.224172     0.0928073  -0.0582313    0.0111212  -0.0549252   -0.116347     0.0429545     0.121716    -0.106614      0.143902     0.0493854   -0.0676061    0.0858385   -0.0108559    0.013026    0.0126364   -0.0234625 
  0.171511     0.0218886    0.132535     0.0716552    0.156612     0.0172381   -0.0991984   -0.0417429   -0.102093     0.0946015   -0.0442745  -0.0436361    0.0696889   0.109151     0.0995205   -0.0363485    -0.00730818  -0.00653179   -0.110368     0.0147555    0.0980794   -0.262317    -0.113809    -0.0281738   0.120576     0.135982  
  0.19027     -0.0906354    0.112288    -0.0676626    0.0209893    0.0451393    0.223576     0.00245982  -0.295854    -0.150952    -0.156072   -0.0423648    0.0122482  -0.102636     0.0221824   -0.183639     -0.201933     0.000488101   0.130159    -0.0796724   -0.106153     0.0677604    0.00644856   0.0130735   0.141962     0.0876041 
 -0.00190904  -0.0885969   -0.0113285   -0.0742443   -0.0297558   -0.0202629    0.111173     0.0847857   -0.0516052   -0.0558138    0.0940793  -0.0899425    0.0432228  -0.0494302   -0.0772028    0.0125562     0.0125199   -0.0601004     0.124389     0.109767    -0.120723    -0.296565     0.118909    -0.0957792   0.0235479    0.119531  
  0.0380005    0.0863015   -0.0318271   -0.0965881    0.0492841    0.090216    -0.0500316   -0.0214843   -0.124557    -0.0183406   -0.0347829  -0.0380435   -0.0225654  -0.0343943   -0.0545206   -0.00036459   -0.025059    -0.141093     -0.0877799   -0.0180982   -0.0148714    0.00601363  -0.0947376    0.0113469   0.092934     0.118732  
  0.151193     0.027435     0.0560863    0.0421015    0.184402    -0.26182      0.0591547    0.086724    -0.0247459   -0.00718189   0.138609    0.016922    -0.0310651   0.100439     0.10673      0.0171144     0.188139     0.0153397     0.0660205   -0.0141533   -0.0802391    0.0273395   -0.116165     0.114755   -0.0645706    0.0229641 
  0.0784111    0.0920493   -0.091231    -0.0104522   -0.00955848   0.296604     0.0898152    0.0265154    0.0210767   -0.0581885    0.0258655   0.107462     0.0860316  -0.116329    -0.11014     -0.0066492    -0.0247241   -0.0447323    -0.104648     0.0162465   -0.0970056    0.0475256   -0.0049097    0.1141     -0.0843463    0.0569164 
 -0.121154     0.0747837   -0.108251    -0.0733435    0.0138493   -0.0745887   -0.0427671    0.235561     0.00727964  -0.212085    -0.141255   -0.0359474    0.101648   -0.0410718    0.0761272   -0.195041      0.0741901    0.0537653    -0.0933562    0.0588717   -0.159455     0.137382     0.0621576   -0.068507   -0.00486789  -0.0800607 
  0.0282955   -0.0252018   -0.0656575   -0.0248251   -0.0843113    0.145188    -0.260717    -0.0194915   -0.00928506  -0.125364     0.0823777  -0.150198     0.0729512   0.0680417   -0.0106678   -0.0705627     0.0836219    0.114928      0.0433212    0.0139533    0.0385167    0.138662     0.100291     0.0316537  -0.0271081    0.0744026 
  0.0646446   -0.160813     0.0917589    0.154836     0.0605346    0.137497     0.0533795   -0.225997    -0.145549    -0.0368577    0.0120462   0.00438053  -0.0846111   0.00240064   0.189411    -0.0409752    -0.110255    -0.0431627    -0.134119    -0.162008    -0.0123518    0.0372998   -0.0280598    0.0171884  -0.0747793   -0.0361922 
  0.0927342   -0.0194659   -0.0468138    0.190419    -0.0330198    0.00932314   0.0041182    0.142027    -0.0344031   -0.0644877   -0.0297523  -0.0654907    0.138689    0.137594     0.0765334    0.112498     -0.0681511   -0.262158      0.00695479  -0.10781     -0.0354818   -0.0748085    0.0972797   -0.0539547   0.0988631    0.0455081 
  0.107688    -0.106563     0.00786923  -0.11073     -0.147623    -0.143907    -0.00648916   0.0991302    0.180387     0.119803     0.115925    0.0448569    0.0269573   0.0392044   -0.0360542   -0.115699     -0.0584722    0.07543       0.122846     0.116443    -0.0303783   -0.014737     0.0585145   -0.0428587  -0.110711     0.109804  
 -0.0538388    0.0332018   -0.0952386    0.00125065   0.0787859    0.0852816   -0.0332068   -0.0786671    0.0770743   -0.0104786   -0.169003    0.0563664   -0.0729349   0.0167765   -0.0681249    0.100887     -0.267853    -0.056913     -0.0914689    0.0905816    0.0345146   -0.0874493   -0.0645718   -0.232054    0.146879    -0.179527  
  0.0147666   -0.0471144   -0.222725    -0.121743     0.0727069   -0.24175     -0.0103981   -0.0348228   -0.110162    -0.0762411   -0.016072   -0.0434726   -0.0233223   0.0600979    0.0941804    0.0345406     0.0688316   -0.132104     -0.301569     0.0671392   -0.0042793   -0.0207393   -0.167273     0.0968796  -0.196901    -0.0580444 
 -0.0636967    0.00377561  -0.115287    -0.00838477   0.023888    -0.0231544   -0.030245    -0.0676114   -0.0685293   -0.00493137  -0.0186984  -0.0858753    0.0552973  -0.143279    -0.0713374    0.0191794    -0.139512    -0.0992941     0.0365428    0.00668546  -0.118525     0.0412988   -0.0216402   -0.0840456   0.0201095    0.0630232 
 -0.00887567  -0.0579219    0.0746488    0.0925714   -0.0272806    0.106423    -0.0753705   -0.00126094   0.150372    -0.164954     0.0783688   0.066864     0.113135   -0.0617002   -0.00712193   0.0937757     0.0544784   -0.0561567     0.119584     0.0144011   -0.104762     0.0708315    0.0274424   -0.209265   -0.037668     0.318361  
 -0.176169     0.0911364    0.127184     0.149956    -0.012187     0.217576    -0.00934469  -0.116019    -0.0718425   -0.149448     0.0815075  -0.107023     0.148337    0.0998771   -0.122227    -0.167865     -0.0208232    0.0618264    -0.083019    -0.976531     0.141158     0.155258    -0.00727983   0.123666    0.131075     0.114951  
  0.0146345   -0.00983532  -0.183249     0.0586327   -0.036465    -0.0515725    0.0598346   -0.124243     0.080953    -0.0690415    0.0390025  -0.0164046    0.0358905   0.118209     0.102078     0.0119341    -0.0222829    0.192133      0.0282594   -0.057005    -0.19775      0.02503      0.0764625   -0.180653   -0.0641304    0.0468202 
 -0.0520271   -0.0471532   -0.0124439   -0.0209971    0.0442222   -0.104283    -0.0414331    0.0288546    0.0331978    0.0201281    0.0255311   0.293694    -0.106127    0.0425183   -0.0207824    0.177979     -0.0715675   -0.0404961    -0.276987     0.0110442   -0.155289    -0.229069     0.157339    -0.0369293  -0.0233688    0.0178534 
 -0.125157     0.0465629   -0.0416237   -0.0538391    0.0528381    0.0451574    0.0616516    0.0987629    0.0265271    0.212523     0.0740078   0.00296093  -0.0634797  -0.24511      0.0180136   -0.231724     -0.114127     0.0869927    -0.0832102    0.0912744    0.133909    -0.0956573    0.0693137   -0.12225     0.225404     0.13857   
  0.148327     0.22901     -0.140956    -0.0833317    0.00732185  -0.072065    -0.192558    -0.0190107    0.0635512   -0.0599488    0.0312845   0.130634     0.0145288  -0.0765539   -0.0351772   -0.0239863     0.118946     0.0305918    -0.0747959   -0.120983    -0.0536814    0.152698    -0.0325928   -0.0486807  -0.00789272   0.147102  
 -0.0916209   -0.104105     0.0442108    0.139573    -0.00862899   0.0987595    0.253755     0.0558639   -0.15958     -0.113829     0.104027    0.0850796   -0.0861     -0.208576    -0.0315499    0.0289479     0.163387    -0.142229     -0.00579808   0.0848618   -0.0425022    0.0877063   -0.0753887    0.0828969  -0.0779811    0.00543642
 -0.177537     0.0307954   -0.120213    -0.214401    -0.0977993    0.0679657   -0.0929565    0.0691867   -0.269758     0.0610166   -0.102407    0.0929749   -0.131579    0.0328872    0.0832297   -0.215209     -0.134683    -0.099232      0.0491299   -0.17956      0.00383837   0.0481084   -0.112932     0.0545245  -0.0921608    0.14579   
 -0.0497868   -0.0296157    0.0909595   -0.0192427    0.0659815    0.108124     0.0415336   -0.0400312    0.0362739   -0.0302469    0.086743   -0.0222908    0.0183104   0.0190951   -0.0900066    0.0691049    -0.00399154  -0.0364463    -0.146117     0.140196    -0.00716381  -0.0443937   -0.0676017   -0.0157506  -0.00119348  -0.0175104 
 -0.0982767   -0.076616    -0.156265     0.0568535    0.0155261    0.0594432   -0.0503119   -0.11841     -0.0346313    0.0116513    0.0748796  -0.00632848   0.0608053  -0.00507663  -0.0260976    0.12286      -0.120098     0.00350323   -0.0528527    0.00859003   0.0928362   -0.0190397   -0.159774     0.117875   -0.0998741   -0.0596284 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 2 10 13 16 29
INFO: iteration 1, average log likelihood -1.019845
WARNING: Variances had to be floored 2 4 10 13 16 23 29 30 32
INFO: iteration 2, average log likelihood -0.998233
WARNING: Variances had to be floored 2 4 10 13 16 23 29
INFO: iteration 3, average log likelihood -1.001227
WARNING: Variances had to be floored 2 4 6 10 13 14 16 23 29 30 31 32
INFO: iteration 4, average log likelihood -0.988624
WARNING: Variances had to be floored 2 10 13 16 29
INFO: iteration 5, average log likelihood -1.019298
WARNING: Variances had to be floored 2 4 10 13 16 23 29 30 32
INFO: iteration 6, average log likelihood -0.998110
WARNING: Variances had to be floored 2 4 10 13 16 23 29
INFO: iteration 7, average log likelihood -1.000832
WARNING: Variances had to be floored 2 4 6 10 13 14 16 23 29 30 31 32
INFO: iteration 8, average log likelihood -0.988458
WARNING: Variances had to be floored 2 10 13 16 29
INFO: iteration 9, average log likelihood -1.019388
WARNING: Variances had to be floored 2 4 10 13 16 23 29 30 32
INFO: iteration 10, average log likelihood -0.998066
INFO: EM with 100000 data points 10 iterations avll -0.998066
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0834124   -0.11643       0.167512     0.107983     0.0500654     0.164885     0.149478      0.0922598    -0.164174     0.125945     -0.109163    -0.0418302    0.0656083     0.0571022   -0.0183049   0.00704867  -0.00755153  -0.0873211   -0.000859731   0.147887   -0.084851    0.0143321    0.039859    -0.0191115  -0.111608    -0.022356 
 -0.0697061    0.01802      -0.0134753    0.182863    -0.191368      0.105713     0.151798      0.0678196    -0.118295     0.0319887    -0.00946671  -0.143523     0.0688666    -0.00611347   0.100067    0.100795    -0.0499285    0.0491014    0.00818718    0.103333    0.0162889   0.0852971    0.130182    -0.13058     0.0371879   -0.122798 
  0.0482504   -0.114018     -0.0942745   -0.126458     0.0137329     0.0206047    0.00127714    0.0783476    -0.00884598  -0.0907867     0.104162    -0.0654223   -0.00881371    0.0731936    0.0463198   0.151709     0.105968    -0.205201    -0.0298148     0.0986215  -0.165913    0.104689     0.0728516    0.0689851   0.0955853   -0.118371 
 -0.0884817    0.0697972     0.0248459    0.200734    -0.0803364     0.0673232    0.00610189   -0.0867847    -0.125187     0.0680563     0.122816    -0.0767626    0.0363531    -0.0255819    0.134082    0.0144202   -0.191775    -0.0366471   -0.104001     -0.0409524  -0.0899056   0.00760005  -0.115978    -0.20359    -0.143979    -0.0111753
 -0.0521515   -0.0859712    -0.0164063   -0.0121992    0.0381787    -0.0478478    0.0357533     0.114718     -0.136797    -0.0843203     0.0131329    0.10686      0.00861218    0.105402    -0.0581027   0.128115    -0.0406065    0.11457      0.123403      0.0542197  -0.184456    0.0061866    0.019811    -0.068712    0.195868     0.0987396
  0.026318    -0.000984589  -0.144963    -0.143647     0.1586        0.0062964   -0.0762125     0.0221583     0.0426606   -0.00877721   -0.0717923    0.0589937   -0.151115     -0.148539     0.0618213  -0.0173406    0.110829     0.0857553    0.134087     -0.129829    0.197769   -0.0400508   -0.122284     0.0662537  -0.0957373    0.111778 
 -0.00974627  -0.0927405     0.148733    -0.167564     0.0358141     0.00799842   0.13128      -0.155365     -0.0890282   -0.00298439    0.0596255    0.0761253    0.0256711    -0.061922     0.0859737   0.0140705   -0.0368757   -0.18056     -0.0507753    -0.0691082  -0.0267831   0.107141     0.0542526    0.131687   -0.0235429    0.12973  
 -0.194137    -0.154605     -0.0168156   -0.0410522    0.0487869    -0.0944154   -0.0362413     0.00532187    0.0365163    0.0945264    -0.0120124   -0.132414     0.191278      0.00503641   0.0370092  -0.084505     0.0185007   -0.0220516   -0.156229      0.110409   -0.0386924  -0.00646864   0.0272501   -0.0756026  -0.0101862    0.128392 
  0.0255617    0.122722     -0.0813594   -0.140524     0.0234248     0.165642    -0.280604      0.0774122     0.0583626   -0.0498186     0.172185    -0.162252    -0.12815       0.150747    -0.0347655   0.176945     0.232039     0.0252815    0.133288     -0.0498061  -0.0228564  -0.0668259    0.0960715    0.143083   -0.118307     0.0844634
  0.0196498    0.037977      0.0124286   -0.0356603   -0.25223       0.0669099    0.0576228    -0.0983521    -0.12753     -0.0731243    -0.0825252   -0.0219564   -0.0785108    -0.0888668    0.0877051  -0.156761     0.0620973   -0.0103314   -0.121093     -0.145824    0.150296    0.107511    -0.200764     0.0315729  -0.118391    -0.0280443
 -0.179388     0.0394976     0.184317    -0.206686     0.000430958   0.119054     0.223803     -0.0842711    -0.092754    -0.0195255     0.0777386    0.132275    -0.123469      0.0778146   -0.032482    0.0379302    0.0157643    0.120475    -0.128152     -0.054441   -0.140488   -0.0576211   -0.103627     0.164295    0.204902     0.0105242
 -0.0143927    0.0172746    -0.0786789    0.047607    -0.150558     -0.195393    -0.0220198     0.0469515    -0.0634921    0.00528179   -0.25754      0.13918      0.0358843     0.00931603  -0.107202   -0.0957396    0.199726    -0.00485525   0.0289191     0.0812776   0.123934    0.150991     0.0680057    0.030612   -0.00358947   0.116142 
  0.030953     0.00351903   -0.0378091   -0.0942249    0.00155964   -0.0185139    0.0859752    -0.00237842   -0.102193     0.108905      0.271958     0.0960096    0.0390364    -0.0675092    0.0245213   0.0126058    0.0686197   -0.00850514  -0.0459785    -0.17165    -0.198741    0.0963314   -0.00351291  -0.086959    0.0846558    0.0423863
  0.0983942    0.0916515    -0.0894886    0.108069    -0.120192     -0.17242      0.0594288    -0.128959      0.00573787   0.0969873    -0.153975     0.215723    -0.114747     -0.197566     0.09898    -0.0882434   -0.0131422   -0.125662    -0.114776      0.0939806  -0.0877385   0.19006     -0.0722903   -0.0062729  -0.0121743   -0.0915078
 -0.00556385   0.246357      0.11982      0.128948    -0.0366248     0.148185     0.0326816    -0.0987424     0.0766101   -0.0284905    -0.0910891    0.149168    -0.000377872  -0.0862967   -0.0401896  -0.0592446   -0.0394731   -0.118986    -0.0603181    -0.0588508   0.0231365  -0.0574888   -0.0793435   -0.0019203  -0.0292622    0.0581754
  0.138441    -0.00788959    0.204238    -0.0535624   -0.0970353     0.0607424   -0.114551     -0.0375432    -0.0164066    0.116684      0.0696401   -0.149029     0.192611     -0.106452     0.0656042  -0.0455037    0.288511     0.0935725   -0.127627      0.112972   -0.0329883   0.0768868   -0.00817802  -0.132324   -0.0181183   -0.12575  
 -0.123726    -0.144498      0.0327206    0.0564663   -0.0800284     0.0362842   -0.0446856     0.0615286    -0.132861    -0.0751661    -0.0468434    0.00640946   0.16187      -0.0170146    0.0785618  -0.09006      0.098109    -0.0854809    0.0345746    -0.182508    0.0686172   0.128797     0.054692    -0.121901   -0.0113438    0.0212888
 -0.0582902   -0.0179935    -0.207338     0.110086    -0.0635613     0.114834     0.0149182    -0.128448     -0.0391034   -0.000646159  -0.0922823   -0.117348    -0.0138711     0.0462789   -0.100589    0.029748    -0.31648      0.0089444   -0.149024      0.165232    0.161401    0.0376439   -0.105518     0.11673    -0.0307308    0.208687 
  0.0792024   -0.02366      -0.00346437  -0.0289676   -0.0243094    -0.142591     0.0592393     0.070492      0.162727    -0.0509422     0.0173912   -0.00393906   0.141074      0.0300068    0.0348417  -0.0550346    0.066226     0.0460676    0.11286      -0.142759   -0.0219941  -0.178495    -0.0924126    0.138418   -0.0482717   -0.0722113
 -0.035287    -0.024809      0.00343864  -0.131035    -0.121532      0.0337434    0.000890073  -0.0819377     0.037441    -0.0503381    -0.0933361    0.145587     0.0247398    -0.110003     0.132454    0.0475675    0.0177076   -0.156602     0.0408754     0.0199229   0.0368195  -0.0815482    0.00518991   0.0176729   0.00366541   0.0371371
 -0.077211     0.00594742   -0.00890153   0.0319157    0.0167389    -0.0245706    0.0671546    -0.0432143    -0.173623     0.0882508     0.0375052    0.0154326    0.0585963     0.0329542   -0.052839   -0.276332    -0.071088    -0.0928568   -0.129684      0.0668476   0.0329582  -0.00771915   0.158186     0.0201018   0.195767    -0.064611 
  0.037164    -0.103268      0.180134     0.157839     0.0973294     0.0919802    0.0220183    -0.0174036    -0.0441014   -0.157531     -0.0428091    0.0309028    0.136405      0.058524    -0.136958   -0.0697765    0.0894323    0.029309     0.0282057    -0.117678    0.0341676  -0.0361286    0.089003     0.0117587  -0.0842889    0.0323409
  0.0194966   -0.0161285     0.136586    -0.0784764    0.031023      0.0719353    0.140027      0.182206     -0.0253391    0.0365856    -0.0473253   -0.021716    -0.0735998    -0.0352555    0.121551   -0.0525813    0.155762    -0.0434834    0.0314849    -0.102164    0.159676    0.10286      0.0576525   -0.107539   -0.0342185    0.136293 
  0.0627775    0.077391      0.00487863   0.135611     0.0528337    -0.0728486   -0.00152368    0.0807417    -0.114776    -0.341867     -0.101598     0.0504622    0.109463      0.0558786   -0.0952235   0.17814      0.0279816   -0.0919233    0.0260284    -0.151662    0.144982   -0.0472661    0.0242971    0.077166    0.0450949   -0.12723  
 -0.063862     0.167131     -0.17561     -0.0301534   -0.00193339    0.0787128    0.114591     -0.0438717     0.126166    -0.145318      0.0337941   -0.180895    -0.0321106    -0.150099     0.115612    0.122044    -0.111133    -0.0465049   -0.0461181    -0.0250231  -0.07041    -0.0295248    0.0377134    0.161123    0.10745     -0.107461 
 -0.0683783   -0.147166     -0.0688052    0.11517     -0.0828671     0.0489245   -0.0870225    -0.0355166     0.00167719  -0.016491      0.0349872    0.0559479   -0.093688      0.0575954    0.0442002  -0.0614624    0.00348076   0.0601579   -0.0953808    -0.0680769   0.0700903   0.114695     0.0932584    0.227916    0.0918726    0.110124 
  0.0333945   -0.0667945    -0.0528028    0.120116     0.102955      0.0170845   -0.00247381   -0.000103896  -0.0986879    0.039148      0.0819503    0.109547    -0.044518     -0.097553    -0.165392   -0.195622     0.123177     0.171632     0.0371394     0.19662    -0.0606968  -0.0576259    0.0478352    0.024534    0.0320484   -0.0844247
 -0.114673     0.109836      0.0260841    0.00333464  -0.0960761    -0.0701354    0.217198      0.0214105    -0.0159259    0.221908     -0.113073    -0.0423144   -0.242225      0.190934    -0.072167   -0.053246     0.0679974   -0.0523352   -0.0584532     0.0448717  -0.165407    0.0612582    0.0149457   -0.0109308  -0.130968     0.0460375
  0.0282516    0.0736657    -0.0685091   -0.0151006   -0.0985003     0.211845     0.0249758     0.168453      0.096365    -0.0281057     0.104538    -0.00346381  -0.0442919    -0.074121     0.0672758   0.0873894    0.14508      0.0121939   -0.0622307    -0.207943    0.114816    0.0701229   -0.123988     0.151907   -0.0220986   -0.1665   
  0.0661768   -0.101251      0.0443523    0.162604     0.100609      0.0150926    0.16505      -0.0593841    -0.0180415    0.15434      -0.0956859   -0.0773481   -0.062917      0.068059    -0.0412296   0.0287823   -0.0823772   -0.00131513  -0.00371523   -0.20821    -0.0628999  -0.050588     0.11095     -0.132779   -0.0230091    0.0856806
 -0.0400989    0.0919915    -0.105306    -0.0952763   -0.149719      0.0315964    0.184338      0.116889     -0.249005     0.0981787    -0.087007     0.0366798    0.032279     -0.0330684   -0.119831    0.0142533    0.0974292   -0.0616122    0.0659044     0.0124025  -0.0926586  -0.108645     0.0304185   -0.0276662  -0.0952302    0.141496 
  0.0125543    0.06513       0.024449    -0.0247154    0.12184       0.0897421   -0.139889      0.0171149     0.118893    -0.0258016     0.0453932   -0.125104    -0.227753     -0.213395    -0.109068   -0.295062    -0.0510831   -0.110872    -0.152681      0.113247   -0.0516858   0.111563     0.0704121    0.139257   -0.0111618    0.0264061kind full, method split
0: avll = -1.4163719490486362
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.416391
INFO: iteration 2, average log likelihood -1.416314
INFO: iteration 3, average log likelihood -1.416253
INFO: iteration 4, average log likelihood -1.416182
INFO: iteration 5, average log likelihood -1.416093
INFO: iteration 6, average log likelihood -1.415986
INFO: iteration 7, average log likelihood -1.415861
INFO: iteration 8, average log likelihood -1.415717
INFO: iteration 9, average log likelihood -1.415531
INFO: iteration 10, average log likelihood -1.415251
INFO: iteration 11, average log likelihood -1.414795
INFO: iteration 12, average log likelihood -1.414091
INFO: iteration 13, average log likelihood -1.413182
INFO: iteration 14, average log likelihood -1.412292
INFO: iteration 15, average log likelihood -1.411660
INFO: iteration 16, average log likelihood -1.411319
INFO: iteration 17, average log likelihood -1.411162
INFO: iteration 18, average log likelihood -1.411094
INFO: iteration 19, average log likelihood -1.411065
INFO: iteration 20, average log likelihood -1.411052
INFO: iteration 21, average log likelihood -1.411046
INFO: iteration 22, average log likelihood -1.411044
INFO: iteration 23, average log likelihood -1.411042
INFO: iteration 24, average log likelihood -1.411041
INFO: iteration 25, average log likelihood -1.411041
INFO: iteration 26, average log likelihood -1.411040
INFO: iteration 27, average log likelihood -1.411040
INFO: iteration 28, average log likelihood -1.411040
INFO: iteration 29, average log likelihood -1.411039
INFO: iteration 30, average log likelihood -1.411039
INFO: iteration 31, average log likelihood -1.411039
INFO: iteration 32, average log likelihood -1.411039
INFO: iteration 33, average log likelihood -1.411039
INFO: iteration 34, average log likelihood -1.411038
INFO: iteration 35, average log likelihood -1.411038
INFO: iteration 36, average log likelihood -1.411038
INFO: iteration 37, average log likelihood -1.411038
INFO: iteration 38, average log likelihood -1.411038
INFO: iteration 39, average log likelihood -1.411038
INFO: iteration 40, average log likelihood -1.411038
INFO: iteration 41, average log likelihood -1.411038
INFO: iteration 42, average log likelihood -1.411038
INFO: iteration 43, average log likelihood -1.411038
INFO: iteration 44, average log likelihood -1.411037
INFO: iteration 45, average log likelihood -1.411037
INFO: iteration 46, average log likelihood -1.411037
INFO: iteration 47, average log likelihood -1.411037
INFO: iteration 48, average log likelihood -1.411037
INFO: iteration 49, average log likelihood -1.411037
INFO: iteration 50, average log likelihood -1.411037
INFO: EM with 100000 data points 50 iterations avll -1.411037
952.4 data points per parameter
1: avll = [-1.41639,-1.41631,-1.41625,-1.41618,-1.41609,-1.41599,-1.41586,-1.41572,-1.41553,-1.41525,-1.41479,-1.41409,-1.41318,-1.41229,-1.41166,-1.41132,-1.41116,-1.41109,-1.41106,-1.41105,-1.41105,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411052
INFO: iteration 2, average log likelihood -1.410973
INFO: iteration 3, average log likelihood -1.410905
INFO: iteration 4, average log likelihood -1.410824
INFO: iteration 5, average log likelihood -1.410722
INFO: iteration 6, average log likelihood -1.410600
INFO: iteration 7, average log likelihood -1.410469
INFO: iteration 8, average log likelihood -1.410342
INFO: iteration 9, average log likelihood -1.410230
INFO: iteration 10, average log likelihood -1.410139
INFO: iteration 11, average log likelihood -1.410067
INFO: iteration 12, average log likelihood -1.410014
INFO: iteration 13, average log likelihood -1.409975
INFO: iteration 14, average log likelihood -1.409947
INFO: iteration 15, average log likelihood -1.409927
INFO: iteration 16, average log likelihood -1.409912
INFO: iteration 17, average log likelihood -1.409901
INFO: iteration 18, average log likelihood -1.409892
INFO: iteration 19, average log likelihood -1.409885
INFO: iteration 20, average log likelihood -1.409879
INFO: iteration 21, average log likelihood -1.409874
INFO: iteration 22, average log likelihood -1.409869
INFO: iteration 23, average log likelihood -1.409864
INFO: iteration 24, average log likelihood -1.409860
INFO: iteration 25, average log likelihood -1.409856
INFO: iteration 26, average log likelihood -1.409852
INFO: iteration 27, average log likelihood -1.409849
INFO: iteration 28, average log likelihood -1.409845
INFO: iteration 29, average log likelihood -1.409842
INFO: iteration 30, average log likelihood -1.409838
INFO: iteration 31, average log likelihood -1.409835
INFO: iteration 32, average log likelihood -1.409832
INFO: iteration 33, average log likelihood -1.409828
INFO: iteration 34, average log likelihood -1.409825
INFO: iteration 35, average log likelihood -1.409822
INFO: iteration 36, average log likelihood -1.409818
INFO: iteration 37, average log likelihood -1.409815
INFO: iteration 38, average log likelihood -1.409812
INFO: iteration 39, average log likelihood -1.409809
INFO: iteration 40, average log likelihood -1.409805
INFO: iteration 41, average log likelihood -1.409802
INFO: iteration 42, average log likelihood -1.409799
INFO: iteration 43, average log likelihood -1.409796
INFO: iteration 44, average log likelihood -1.409793
INFO: iteration 45, average log likelihood -1.409791
INFO: iteration 46, average log likelihood -1.409788
INFO: iteration 47, average log likelihood -1.409785
INFO: iteration 48, average log likelihood -1.409783
INFO: iteration 49, average log likelihood -1.409781
INFO: iteration 50, average log likelihood -1.409779
INFO: EM with 100000 data points 50 iterations avll -1.409779
473.9 data points per parameter
2: avll = [-1.41105,-1.41097,-1.41091,-1.41082,-1.41072,-1.4106,-1.41047,-1.41034,-1.41023,-1.41014,-1.41007,-1.41001,-1.40997,-1.40995,-1.40993,-1.40991,-1.4099,-1.40989,-1.40989,-1.40988,-1.40987,-1.40987,-1.40986,-1.40986,-1.40986,-1.40985,-1.40985,-1.40985,-1.40984,-1.40984,-1.40983,-1.40983,-1.40983,-1.40982,-1.40982,-1.40982,-1.40981,-1.40981,-1.40981,-1.40981,-1.4098,-1.4098,-1.4098,-1.40979,-1.40979,-1.40979,-1.40979,-1.40978,-1.40978,-1.40978]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409786
INFO: iteration 2, average log likelihood -1.409725
INFO: iteration 3, average log likelihood -1.409670
INFO: iteration 4, average log likelihood -1.409608
INFO: iteration 5, average log likelihood -1.409533
INFO: iteration 6, average log likelihood -1.409445
INFO: iteration 7, average log likelihood -1.409345
INFO: iteration 8, average log likelihood -1.409241
INFO: iteration 9, average log likelihood -1.409140
INFO: iteration 10, average log likelihood -1.409048
INFO: iteration 11, average log likelihood -1.408967
INFO: iteration 12, average log likelihood -1.408896
INFO: iteration 13, average log likelihood -1.408836
INFO: iteration 14, average log likelihood -1.408784
INFO: iteration 15, average log likelihood -1.408741
INFO: iteration 16, average log likelihood -1.408705
INFO: iteration 17, average log likelihood -1.408675
INFO: iteration 18, average log likelihood -1.408650
INFO: iteration 19, average log likelihood -1.408630
INFO: iteration 20, average log likelihood -1.408614
INFO: iteration 21, average log likelihood -1.408600
INFO: iteration 22, average log likelihood -1.408588
INFO: iteration 23, average log likelihood -1.408577
INFO: iteration 24, average log likelihood -1.408568
INFO: iteration 25, average log likelihood -1.408559
INFO: iteration 26, average log likelihood -1.408551
INFO: iteration 27, average log likelihood -1.408544
INFO: iteration 28, average log likelihood -1.408537
INFO: iteration 29, average log likelihood -1.408531
INFO: iteration 30, average log likelihood -1.408524
INFO: iteration 31, average log likelihood -1.408518
INFO: iteration 32, average log likelihood -1.408513
INFO: iteration 33, average log likelihood -1.408507
INFO: iteration 34, average log likelihood -1.408502
INFO: iteration 35, average log likelihood -1.408496
INFO: iteration 36, average log likelihood -1.408491
INFO: iteration 37, average log likelihood -1.408486
INFO: iteration 38, average log likelihood -1.408481
INFO: iteration 39, average log likelihood -1.408476
INFO: iteration 40, average log likelihood -1.408471
INFO: iteration 41, average log likelihood -1.408466
INFO: iteration 42, average log likelihood -1.408462
INFO: iteration 43, average log likelihood -1.408457
INFO: iteration 44, average log likelihood -1.408452
INFO: iteration 45, average log likelihood -1.408447
INFO: iteration 46, average log likelihood -1.408443
INFO: iteration 47, average log likelihood -1.408438
INFO: iteration 48, average log likelihood -1.408433
INFO: iteration 49, average log likelihood -1.408428
INFO: iteration 50, average log likelihood -1.408423
INFO: EM with 100000 data points 50 iterations avll -1.408423
236.4 data points per parameter
3: avll = [-1.40979,-1.40972,-1.40967,-1.40961,-1.40953,-1.40944,-1.40935,-1.40924,-1.40914,-1.40905,-1.40897,-1.4089,-1.40884,-1.40878,-1.40874,-1.4087,-1.40867,-1.40865,-1.40863,-1.40861,-1.4086,-1.40859,-1.40858,-1.40857,-1.40856,-1.40855,-1.40854,-1.40854,-1.40853,-1.40852,-1.40852,-1.40851,-1.40851,-1.4085,-1.4085,-1.40849,-1.40849,-1.40848,-1.40848,-1.40847,-1.40847,-1.40846,-1.40846,-1.40845,-1.40845,-1.40844,-1.40844,-1.40843,-1.40843,-1.40842]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.408427
INFO: iteration 2, average log likelihood -1.408368
INFO: iteration 3, average log likelihood -1.408313
INFO: iteration 4, average log likelihood -1.408250
INFO: iteration 5, average log likelihood -1.408172
INFO: iteration 6, average log likelihood -1.408075
INFO: iteration 7, average log likelihood -1.407960
INFO: iteration 8, average log likelihood -1.407831
INFO: iteration 9, average log likelihood -1.407698
INFO: iteration 10, average log likelihood -1.407568
INFO: iteration 11, average log likelihood -1.407447
INFO: iteration 12, average log likelihood -1.407337
INFO: iteration 13, average log likelihood -1.407238
INFO: iteration 14, average log likelihood -1.407150
INFO: iteration 15, average log likelihood -1.407071
INFO: iteration 16, average log likelihood -1.407002
INFO: iteration 17, average log likelihood -1.406941
INFO: iteration 18, average log likelihood -1.406888
INFO: iteration 19, average log likelihood -1.406842
INFO: iteration 20, average log likelihood -1.406802
INFO: iteration 21, average log likelihood -1.406766
INFO: iteration 22, average log likelihood -1.406735
INFO: iteration 23, average log likelihood -1.406707
INFO: iteration 24, average log likelihood -1.406681
INFO: iteration 25, average log likelihood -1.406656
INFO: iteration 26, average log likelihood -1.406634
INFO: iteration 27, average log likelihood -1.406612
INFO: iteration 28, average log likelihood -1.406592
INFO: iteration 29, average log likelihood -1.406573
INFO: iteration 30, average log likelihood -1.406554
INFO: iteration 31, average log likelihood -1.406536
INFO: iteration 32, average log likelihood -1.406519
INFO: iteration 33, average log likelihood -1.406502
INFO: iteration 34, average log likelihood -1.406486
INFO: iteration 35, average log likelihood -1.406470
INFO: iteration 36, average log likelihood -1.406455
INFO: iteration 37, average log likelihood -1.406440
INFO: iteration 38, average log likelihood -1.406426
INFO: iteration 39, average log likelihood -1.406412
INFO: iteration 40, average log likelihood -1.406399
INFO: iteration 41, average log likelihood -1.406386
INFO: iteration 42, average log likelihood -1.406373
INFO: iteration 43, average log likelihood -1.406361
INFO: iteration 44, average log likelihood -1.406349
INFO: iteration 45, average log likelihood -1.406337
INFO: iteration 46, average log likelihood -1.406326
INFO: iteration 47, average log likelihood -1.406315
INFO: iteration 48, average log likelihood -1.406304
INFO: iteration 49, average log likelihood -1.406294
INFO: iteration 50, average log likelihood -1.406284
INFO: EM with 100000 data points 50 iterations avll -1.406284
118.1 data points per parameter
4: avll = [-1.40843,-1.40837,-1.40831,-1.40825,-1.40817,-1.40807,-1.40796,-1.40783,-1.4077,-1.40757,-1.40745,-1.40734,-1.40724,-1.40715,-1.40707,-1.407,-1.40694,-1.40689,-1.40684,-1.4068,-1.40677,-1.40673,-1.40671,-1.40668,-1.40666,-1.40663,-1.40661,-1.40659,-1.40657,-1.40655,-1.40654,-1.40652,-1.4065,-1.40649,-1.40647,-1.40645,-1.40644,-1.40643,-1.40641,-1.4064,-1.40639,-1.40637,-1.40636,-1.40635,-1.40634,-1.40633,-1.40631,-1.4063,-1.40629,-1.40628]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.406281
INFO: iteration 2, average log likelihood -1.406215
INFO: iteration 3, average log likelihood -1.406149
INFO: iteration 4, average log likelihood -1.406070
INFO: iteration 5, average log likelihood -1.405967
INFO: iteration 6, average log likelihood -1.405835
INFO: iteration 7, average log likelihood -1.405672
INFO: iteration 8, average log likelihood -1.405486
INFO: iteration 9, average log likelihood -1.405290
INFO: iteration 10, average log likelihood -1.405098
INFO: iteration 11, average log likelihood -1.404921
INFO: iteration 12, average log likelihood -1.404761
INFO: iteration 13, average log likelihood -1.404621
INFO: iteration 14, average log likelihood -1.404498
INFO: iteration 15, average log likelihood -1.404391
INFO: iteration 16, average log likelihood -1.404298
INFO: iteration 17, average log likelihood -1.404216
INFO: iteration 18, average log likelihood -1.404144
INFO: iteration 19, average log likelihood -1.404080
INFO: iteration 20, average log likelihood -1.404023
INFO: iteration 21, average log likelihood -1.403973
INFO: iteration 22, average log likelihood -1.403926
INFO: iteration 23, average log likelihood -1.403884
INFO: iteration 24, average log likelihood -1.403845
INFO: iteration 25, average log likelihood -1.403809
INFO: iteration 26, average log likelihood -1.403775
INFO: iteration 27, average log likelihood -1.403743
INFO: iteration 28, average log likelihood -1.403712
INFO: iteration 29, average log likelihood -1.403683
INFO: iteration 30, average log likelihood -1.403655
INFO: iteration 31, average log likelihood -1.403629
INFO: iteration 32, average log likelihood -1.403603
INFO: iteration 33, average log likelihood -1.403578
INFO: iteration 34, average log likelihood -1.403554
INFO: iteration 35, average log likelihood -1.403530
INFO: iteration 36, average log likelihood -1.403508
INFO: iteration 37, average log likelihood -1.403486
INFO: iteration 38, average log likelihood -1.403465
INFO: iteration 39, average log likelihood -1.403445
INFO: iteration 40, average log likelihood -1.403425
INFO: iteration 41, average log likelihood -1.403406
INFO: iteration 42, average log likelihood -1.403389
INFO: iteration 43, average log likelihood -1.403372
INFO: iteration 44, average log likelihood -1.403355
INFO: iteration 45, average log likelihood -1.403340
INFO: iteration 46, average log likelihood -1.403325
INFO: iteration 47, average log likelihood -1.403311
INFO: iteration 48, average log likelihood -1.403297
INFO: iteration 49, average log likelihood -1.403285
INFO: iteration 50, average log likelihood -1.403272
INFO: EM with 100000 data points 50 iterations avll -1.403272
59.0 data points per parameter
5: avll = [-1.40628,-1.40621,-1.40615,-1.40607,-1.40597,-1.40583,-1.40567,-1.40549,-1.40529,-1.4051,-1.40492,-1.40476,-1.40462,-1.4045,-1.40439,-1.4043,-1.40422,-1.40414,-1.40408,-1.40402,-1.40397,-1.40393,-1.40388,-1.40385,-1.40381,-1.40378,-1.40374,-1.40371,-1.40368,-1.40366,-1.40363,-1.4036,-1.40358,-1.40355,-1.40353,-1.40351,-1.40349,-1.40346,-1.40344,-1.40343,-1.40341,-1.40339,-1.40337,-1.40336,-1.40334,-1.40332,-1.40331,-1.4033,-1.40328,-1.40327]
[-1.41637,-1.41639,-1.41631,-1.41625,-1.41618,-1.41609,-1.41599,-1.41586,-1.41572,-1.41553,-1.41525,-1.41479,-1.41409,-1.41318,-1.41229,-1.41166,-1.41132,-1.41116,-1.41109,-1.41106,-1.41105,-1.41105,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41104,-1.41105,-1.41097,-1.41091,-1.41082,-1.41072,-1.4106,-1.41047,-1.41034,-1.41023,-1.41014,-1.41007,-1.41001,-1.40997,-1.40995,-1.40993,-1.40991,-1.4099,-1.40989,-1.40989,-1.40988,-1.40987,-1.40987,-1.40986,-1.40986,-1.40986,-1.40985,-1.40985,-1.40985,-1.40984,-1.40984,-1.40983,-1.40983,-1.40983,-1.40982,-1.40982,-1.40982,-1.40981,-1.40981,-1.40981,-1.40981,-1.4098,-1.4098,-1.4098,-1.40979,-1.40979,-1.40979,-1.40979,-1.40978,-1.40978,-1.40978,-1.40979,-1.40972,-1.40967,-1.40961,-1.40953,-1.40944,-1.40935,-1.40924,-1.40914,-1.40905,-1.40897,-1.4089,-1.40884,-1.40878,-1.40874,-1.4087,-1.40867,-1.40865,-1.40863,-1.40861,-1.4086,-1.40859,-1.40858,-1.40857,-1.40856,-1.40855,-1.40854,-1.40854,-1.40853,-1.40852,-1.40852,-1.40851,-1.40851,-1.4085,-1.4085,-1.40849,-1.40849,-1.40848,-1.40848,-1.40847,-1.40847,-1.40846,-1.40846,-1.40845,-1.40845,-1.40844,-1.40844,-1.40843,-1.40843,-1.40842,-1.40843,-1.40837,-1.40831,-1.40825,-1.40817,-1.40807,-1.40796,-1.40783,-1.4077,-1.40757,-1.40745,-1.40734,-1.40724,-1.40715,-1.40707,-1.407,-1.40694,-1.40689,-1.40684,-1.4068,-1.40677,-1.40673,-1.40671,-1.40668,-1.40666,-1.40663,-1.40661,-1.40659,-1.40657,-1.40655,-1.40654,-1.40652,-1.4065,-1.40649,-1.40647,-1.40645,-1.40644,-1.40643,-1.40641,-1.4064,-1.40639,-1.40637,-1.40636,-1.40635,-1.40634,-1.40633,-1.40631,-1.4063,-1.40629,-1.40628,-1.40628,-1.40621,-1.40615,-1.40607,-1.40597,-1.40583,-1.40567,-1.40549,-1.40529,-1.4051,-1.40492,-1.40476,-1.40462,-1.4045,-1.40439,-1.4043,-1.40422,-1.40414,-1.40408,-1.40402,-1.40397,-1.40393,-1.40388,-1.40385,-1.40381,-1.40378,-1.40374,-1.40371,-1.40368,-1.40366,-1.40363,-1.4036,-1.40358,-1.40355,-1.40353,-1.40351,-1.40349,-1.40346,-1.40344,-1.40343,-1.40341,-1.40339,-1.40337,-1.40336,-1.40334,-1.40332,-1.40331,-1.4033,-1.40328,-1.40327]
32Ã—26 Array{Float64,2}:
  0.21411    -0.970056    -0.0811999    0.210224   -0.51283    -0.103546     0.18893     0.509836   -0.328041   -0.118713   -0.660579    0.229067    -0.66963     0.475148      0.0487523    0.233396    0.142861    0.0504975    0.0703468   -0.240631    0.305448    -0.115246   -0.0475563  -0.685259    -1.07623    -0.463091 
 -0.481207   -0.348389     0.103966    -0.198748   -0.0158713  -0.227044    -0.0922939   0.030313   -0.496739    0.302716   -0.243078    0.632134     0.0264794  -0.125119     -0.448988     0.359614    0.0839692  -0.279316    -0.0208277    0.569299    0.167002    -0.425925    0.202248   -0.220051     0.0835361  -0.223225 
  0.21756    -0.0400501    0.231634     0.0703759  -0.140593    0.0486011    0.262506   -0.0678029  -0.0663447  -0.518394   -0.0102501  -0.231999    -0.139167   -0.0711644     0.466939    -0.181319    0.140695    0.0386905   -0.0339878   -0.320589    0.07579      0.169803    0.103483    0.231616     0.187865    0.279947 
  0.126757    0.623362    -0.0503261   -0.157621    0.0868497   0.258188    -0.120918   -0.0668408   0.084845    0.382145    0.634392   -0.0478947    0.154204   -0.114439     -0.242217    -0.158578   -0.0742559  -0.258644     0.0339012    0.138804   -0.082283     0.310089   -0.389785    0.105285    -0.126094   -0.158917 
  0.0885092   0.00902854  -0.570179    -0.886324    0.0133594  -0.30856     -0.191654    0.261057    0.222626    0.266704   -0.180504   -0.0220399   -0.660133   -0.118081      0.115548    -0.755457    0.388919   -0.12168     -0.766394    -0.106882    0.485549     0.465959    0.750043    0.530858    -0.364903    0.182696 
 -0.0792532   0.179732    -0.347647     0.719645   -0.192124    0.0673987   -0.382114    0.108377    0.672224    0.199691    0.0902257  -0.0649625   -0.634227    0.304368      0.00658738  -0.39499     0.0482064  -0.382219    -0.457875     0.318109    0.278307     0.0198606   0.0337774   0.790772     0.054428    0.784112 
  0.574442   -1.18376     -0.404504    -0.068851   -0.206812   -0.233974     0.263758    0.231927    0.381982   -0.643675   -0.0318806   0.102343    -0.212404    0.327629      0.0379598   -0.296179   -0.161293   -0.614154     0.0966499   -0.362902    0.279882    -0.297868    0.0793019   0.0546238    0.738123   -0.807365 
  0.163945    0.335913    -0.800086    -0.0769022  -0.41683    -0.645442    -0.243934    0.27313     0.302306    0.301816    0.0586549   0.373783    -0.0334536  -0.224706      0.0833532    0.642659   -0.291525   -0.546418    -0.0518328   -0.754031   -0.027471     0.0619857   0.510028   -0.449762     0.109529    0.1121   
 -0.0463285   0.152454    -0.316325     0.0680925   0.195423    0.222766     0.408404   -0.489355   -0.2515     -0.250973   -0.390652   -0.67592     -0.0592522  -0.360713     -0.419437     0.404461   -0.105988    0.488401     0.0370687   -0.248236   -0.0336163   -0.922031   -0.193766   -0.208359    -0.0711371  -0.386936 
  0.19898     0.0141834   -0.103548     0.28769     0.351212   -0.329055     0.338833   -0.899423    0.0270162  -0.425752   -0.588943    0.191032    -0.0320575   0.130546     -0.194925     0.212929   -0.154364    0.193342     0.110597    -0.67524    -1.03682      0.0716453  -0.270086   -0.574709     0.117012   -0.0767507
  0.23277     0.131212    -0.363657    -0.241445   -0.33465    -0.0802649   -0.0442982  -0.0204528   0.924861   -0.448127   -0.921066   -0.366015     0.402086   -0.162766      0.304393     0.194319   -0.130455    0.220639    -0.28541     -0.617204   -0.304787    -0.196909   -0.0171954   0.814575     0.147681   -0.0558317
 -0.439941   -0.0111702   -0.477763    -0.218126   -0.353457   -0.241844    -0.122063    0.408369    0.152663   -0.321334   -1.23106    -0.318131     0.223598   -0.395456     -0.463413     0.204787    0.211164    0.492268     0.265257     0.319608   -0.0115725   -0.240635    0.784563   -0.0071611    0.101981    0.203856 
 -0.326893    0.120536    -0.170206     0.474606    0.534938    0.0948348   -0.0508467   0.372781    0.593346    1.01544     0.311402    0.17682      0.464428    0.593202     -0.329048    -0.660836   -0.428881   -0.380578     0.516412     0.101512   -0.109183    -0.317223    0.527765   -0.369906     0.0997317   0.591492 
  0.343204    0.0462364    0.230558     0.587255   -0.482456    0.464789     0.143514   -0.114128   -0.189554   -0.189042    0.33781    -0.0925185    0.998513    0.240914     -0.163969     0.766618   -0.389284    0.00288807   0.670284    -0.190683   -0.648215    -0.49695    -0.0354999  -0.399375     0.473189    0.686013 
 -0.473714   -0.266051    -0.174793     0.269864    0.212309    0.429896    -0.149986    0.276652   -0.0974614   0.197354    0.142885   -0.0624199    0.21124     0.352512     -0.291217    -0.151239   -0.0978139   0.758396    -0.543847     0.736871   -0.30632      0.836653   -0.303313   -0.267702     0.179832   -0.390228 
 -0.284465    0.0525741   -0.0565388   -0.698539    0.425233    0.123103     0.106895    0.238512   -0.179579   -0.054046    0.135341   -0.190631     0.618169   -0.388455      0.0543865    0.0925951   0.0942854   0.414159     0.464835    -0.238872   -0.388911     0.342711    0.225815   -0.567273     0.0608181  -0.282424 
  0.271448    0.55305      0.10591      0.313812   -0.269426   -0.250856     0.411623    0.156498   -0.571431    0.250996   -0.148318   -0.380423    -0.162416   -0.178444      0.11816     -0.189558    0.0733702   0.0321005   -0.18758      0.0512448   0.143945    -0.486306    0.0476516   0.150281    -0.659748    0.853261 
 -0.744835    1.40174      0.498622     0.181613    0.0794586   0.702016    -0.213224    0.0103113  -0.188852    0.540828    0.296614   -0.0973774   -0.0502048  -0.650379      0.304944     0.533129    0.608778    0.786175    -0.162621     0.127248   -0.130218     0.601745   -0.195886    0.174194    -0.807992    0.712015 
  0.0617656  -0.382709     0.24267     -0.167943    0.179727   -0.283617    -0.112122    0.0253292   0.161551   -0.0688055  -0.427539   -0.0347032   -0.514222   -0.131458      0.637709    -0.13909     0.129553    0.0821993   -0.300863     0.143701    0.678003     0.0383965  -0.0897617   0.680227    -0.351084   -0.223262 
 -0.108607   -0.15878      0.317103     0.380223    0.0988788  -0.536728     0.185925    0.327685    0.108877    0.335817    0.653803   -0.354697     0.875148    0.0802204     0.418356    -0.326172    0.420709    0.215539    -0.305428    -0.783658    0.271593     0.107394   -0.0924462  -0.0974114   -0.144504   -0.0611487
  0.242896    0.360384     0.203518     0.570695   -0.736557    0.0199793    0.0495979  -0.289442    0.221002    0.102185    0.147432   -0.230306    -0.161761    0.326408      0.165333    -0.309854   -0.264049   -0.302687     0.040278    -0.151474   -0.00137039   0.444453   -0.497262    0.0458073    0.116154    0.076982 
  0.0388659   0.133441     0.494211     0.360584    0.256789    0.389203     0.204304   -0.305135   -0.240274   -0.148823    1.02065     0.35332     -0.253634    0.229779      0.511018    -0.211719   -0.202744   -0.629508     0.0938458   -0.453755    0.0264529    0.331948   -0.628569   -0.0234534    0.144764    0.141507 
  0.0137895  -0.514032     0.520042     0.484495   -0.120623    0.185423     0.0593843  -0.0900635  -0.438421   -0.3769     -0.339864   -0.283762     0.253531   -0.0719266     0.305757    -0.223578   -0.0748371   0.621851    -0.185635     0.129211   -0.093385     0.358036   -0.227854   -0.0504085    0.20259    -0.0859096
  0.0945016   0.0584936    0.721743    -0.220745    0.250658    0.58826      0.393326   -0.474774   -0.361323   -0.330536    0.265785   -0.0464191   -0.0737948   0.0632733    -0.0858812   -0.694866    0.728983    0.416711     0.302415     0.282673   -0.126382    -0.220027   -0.28147     0.560041    -0.0601405   0.0957819
 -0.0459155   0.115168    -0.0247201   -0.186839    0.0437949   0.739834    -0.602003    0.123062   -0.0640902  -0.101801   -0.146158    0.19861     -0.0709304  -0.174739     -0.356138     0.386419   -0.0348876  -0.240001    -0.0111748    0.664249   -0.114028    -0.440287   -0.0821864   0.165745     0.145138    0.163204 
 -0.149454   -0.32193     -0.14652     -0.384172    0.0522604   0.752752    -0.458229   -0.16638     0.120456   -0.506612   -0.2879      0.394344    -0.439713   -0.198175     -0.163511     0.226119   -0.614128   -0.261569     0.145925     0.240676   -0.493148     0.871017    0.030032    0.137709     0.832681   -0.373035 
 -0.113377   -0.0540404   -0.0943581    0.014073   -0.197999   -0.519058     0.523407   -0.230451   -0.394655    0.215836    0.379527    0.344541    -0.667415    0.0297624    -0.261156    -0.145774    0.594071   -0.448157    -0.00863971   0.324668    0.379229     0.159387    0.112856   -0.0222581   -0.263439   -0.513356 
  0.344564    0.219707     0.0309929   -0.333048   -0.0295009   0.00919074   0.111041    0.184312   -0.14753     0.059585    0.161218    0.478256    -0.258697    0.149382      0.0323332   -0.0299212   0.23496    -0.577628     0.113693     0.0856423   0.0257956    0.0168154   0.531286    0.0694506   -0.188835    0.627024 
 -0.0623633   0.177314    -0.141092    -0.0224677   0.151582    0.0721166    0.03123    -0.0469459   0.128029   -0.175753    0.079229   -0.111879     0.0960278  -0.18799       0.130576    -0.426126    0.0354806   0.269508    -0.148938    -0.270351   -0.0916591    0.192646   -0.0870892   0.177195     0.213371    0.119497 
 -0.0350267  -0.0162242   -0.0271894    0.0042951  -0.0946057   0.0364562    0.0444035   0.108953   -0.004939   -0.0395312  -0.0751175  -7.65714e-6  -0.0804011  -0.0108304     0.0964711    0.183924    0.0550973  -0.149669    -0.0113591   -0.058262    0.0210317   -0.0234079   0.119941    0.00471859  -0.0505922   0.126066 
  0.0616573   0.187027     0.00327818  -0.177228    0.0270846   0.00299674   0.0589605   0.0678135  -0.0892148   0.647444    0.122642   -0.0384623    0.0429914   0.142806     -0.339136     0.0737651   0.023782    0.0756386   -0.161697     0.144711    0.00429159  -0.245162   -0.338654   -0.0974808   -0.661987   -0.308739 
 -0.430391   -0.350873     0.158444     0.0115512  -0.0346069  -0.121477     0.0324089  -0.171953   -0.318669    0.27229     0.0647637   0.228064     0.371006   -0.000240373  -0.349866     0.333075   -0.15801    -0.217631     0.194685     0.258723    0.0255173   -0.139844    0.248613   -0.275664     0.289441   -0.471318 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.403261
INFO: iteration 2, average log likelihood -1.403250
INFO: iteration 3, average log likelihood -1.403239
INFO: iteration 4, average log likelihood -1.403229
INFO: iteration 5, average log likelihood -1.403219
INFO: iteration 6, average log likelihood -1.403210
INFO: iteration 7, average log likelihood -1.403201
INFO: iteration 8, average log likelihood -1.403192
INFO: iteration 9, average log likelihood -1.403184
INFO: iteration 10, average log likelihood -1.403176
INFO: EM with 100000 data points 10 iterations avll -1.403176
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.760076e+05
      1       6.956531e+05      -1.803546e+05 |       32
      2       6.825542e+05      -1.309890e+04 |       32
      3       6.772071e+05      -5.347026e+03 |       32
      4       6.743882e+05      -2.818951e+03 |       32
      5       6.726900e+05      -1.698210e+03 |       32
      6       6.714671e+05      -1.222842e+03 |       32
      7       6.705680e+05      -8.991795e+02 |       32
      8       6.698587e+05      -7.092734e+02 |       32
      9       6.692771e+05      -5.816234e+02 |       32
     10       6.688026e+05      -4.744091e+02 |       32
     11       6.683910e+05      -4.116281e+02 |       32
     12       6.680347e+05      -3.563687e+02 |       32
     13       6.677164e+05      -3.182863e+02 |       32
     14       6.674418e+05      -2.745897e+02 |       32
     15       6.672155e+05      -2.262523e+02 |       32
     16       6.669952e+05      -2.203534e+02 |       32
     17       6.668198e+05      -1.754025e+02 |       32
     18       6.666713e+05      -1.484626e+02 |       32
     19       6.665305e+05      -1.408166e+02 |       32
     20       6.663977e+05      -1.328359e+02 |       32
     21       6.662658e+05      -1.318842e+02 |       32
     22       6.661452e+05      -1.205962e+02 |       32
     23       6.660256e+05      -1.195998e+02 |       32
     24       6.659040e+05      -1.215888e+02 |       32
     25       6.657807e+05      -1.233020e+02 |       32
     26       6.656571e+05      -1.236144e+02 |       32
     27       6.655628e+05      -9.426226e+01 |       32
     28       6.654752e+05      -8.761163e+01 |       32
     29       6.653832e+05      -9.202707e+01 |       32
     30       6.652950e+05      -8.812213e+01 |       32
     31       6.652108e+05      -8.426881e+01 |       32
     32       6.651257e+05      -8.508882e+01 |       32
     33       6.650461e+05      -7.956200e+01 |       32
     34       6.649764e+05      -6.970028e+01 |       32
     35       6.649078e+05      -6.858726e+01 |       32
     36       6.648398e+05      -6.807992e+01 |       32
     37       6.647760e+05      -6.379051e+01 |       32
     38       6.647170e+05      -5.898708e+01 |       32
     39       6.646613e+05      -5.568864e+01 |       32
     40       6.646049e+05      -5.642753e+01 |       32
     41       6.645418e+05      -6.305993e+01 |       32
     42       6.644770e+05      -6.476496e+01 |       32
     43       6.644095e+05      -6.755142e+01 |       32
     44       6.643427e+05      -6.675565e+01 |       32
     45       6.642841e+05      -5.862648e+01 |       32
     46       6.642308e+05      -5.326496e+01 |       32
     47       6.641809e+05      -4.995591e+01 |       32
     48       6.641290e+05      -5.191134e+01 |       32
     49       6.640750e+05      -5.399550e+01 |       32
     50       6.640263e+05      -4.864950e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 664026.3282559634)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414984
INFO: iteration 2, average log likelihood -1.410055
INFO: iteration 3, average log likelihood -1.408765
INFO: iteration 4, average log likelihood -1.407828
INFO: iteration 5, average log likelihood -1.406832
INFO: iteration 6, average log likelihood -1.405871
INFO: iteration 7, average log likelihood -1.405163
INFO: iteration 8, average log likelihood -1.404743
INFO: iteration 9, average log likelihood -1.404502
INFO: iteration 10, average log likelihood -1.404349
INFO: iteration 11, average log likelihood -1.404239
INFO: iteration 12, average log likelihood -1.404151
INFO: iteration 13, average log likelihood -1.404077
INFO: iteration 14, average log likelihood -1.404013
INFO: iteration 15, average log likelihood -1.403956
INFO: iteration 16, average log likelihood -1.403904
INFO: iteration 17, average log likelihood -1.403857
INFO: iteration 18, average log likelihood -1.403814
INFO: iteration 19, average log likelihood -1.403774
INFO: iteration 20, average log likelihood -1.403736
INFO: iteration 21, average log likelihood -1.403700
INFO: iteration 22, average log likelihood -1.403667
INFO: iteration 23, average log likelihood -1.403635
INFO: iteration 24, average log likelihood -1.403605
INFO: iteration 25, average log likelihood -1.403577
INFO: iteration 26, average log likelihood -1.403550
INFO: iteration 27, average log likelihood -1.403524
INFO: iteration 28, average log likelihood -1.403500
INFO: iteration 29, average log likelihood -1.403477
INFO: iteration 30, average log likelihood -1.403454
INFO: iteration 31, average log likelihood -1.403433
INFO: iteration 32, average log likelihood -1.403413
INFO: iteration 33, average log likelihood -1.403394
INFO: iteration 34, average log likelihood -1.403376
INFO: iteration 35, average log likelihood -1.403359
INFO: iteration 36, average log likelihood -1.403343
INFO: iteration 37, average log likelihood -1.403327
INFO: iteration 38, average log likelihood -1.403313
INFO: iteration 39, average log likelihood -1.403299
INFO: iteration 40, average log likelihood -1.403285
INFO: iteration 41, average log likelihood -1.403272
INFO: iteration 42, average log likelihood -1.403260
INFO: iteration 43, average log likelihood -1.403249
INFO: iteration 44, average log likelihood -1.403237
INFO: iteration 45, average log likelihood -1.403227
INFO: iteration 46, average log likelihood -1.403216
INFO: iteration 47, average log likelihood -1.403206
INFO: iteration 48, average log likelihood -1.403196
INFO: iteration 49, average log likelihood -1.403187
INFO: iteration 50, average log likelihood -1.403178
INFO: EM with 100000 data points 50 iterations avll -1.403178
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.333209    -0.425829     0.0691031  -0.00839834  -0.000339003  -0.123282    0.0752868   -0.0786911  -0.493368     0.148607    -0.0233335    0.0812931   0.300902   -0.11683     -0.205313     0.315853   -0.119172   -0.0669691    0.0817631     0.26514     0.0290458   -0.103771     0.330716    -0.327134      0.0840218  -0.468145   
  0.290756     0.0762119    0.0114091  -0.0236524   -0.129629      0.159977    0.646125    -0.529407   -0.935668    -0.444372     0.0965104   -0.196953   -0.604799   -0.878588     0.373481     0.238606   -0.214311   -0.00217576  -0.0701731    -0.287244    0.197104    -0.487712     0.013526     0.0954998    -0.2305     -0.0417171  
  0.0316903    0.675122    -0.568097    0.0223408   -0.212114     -0.132652   -0.0911223   -0.109522    0.0681591    0.13573      0.295267     0.169441    0.281236   -0.0854651   -0.0315393    0.118      -0.281416   -0.430936     0.0588419    -0.590889   -0.456339     0.132322     0.527769    -0.297425      0.553369    0.867821   
  0.132615    -0.131034    -0.430125   -0.404535    -0.143811     -0.16142     0.0420549    0.317786    0.358474     0.0383557   -0.087479     0.157897   -0.026558    0.0129212    0.127813     0.473584   -0.0666381  -0.292294     0.387742     -0.607732   -0.0781399   -0.0552417    0.294854    -0.491774     -0.322256   -0.390701   
 -0.01659     -0.221857    -0.0623268  -0.193145    -0.0729168    -0.139948    0.127567    -0.111056   -0.0423653   -0.207692    -0.328305     0.110825    0.0186391  -0.137571     0.0462602    0.270029    0.0767219   0.0324997    0.0487775    -0.362662   -0.221663     0.0200054    0.147152    -0.322641      0.034899   -0.297413   
  0.119785    -0.280173     0.636012    0.725082    -0.370326      0.132576    0.261057    -0.212325   -0.744514    -0.0666069   -0.552438     0.24045    -0.175912    0.45237     -0.0351683   -0.520094    0.37794     0.463067    -0.419376      0.32771    -0.211848     0.533992    -0.117507    -0.032373     -0.07454     0.355163   
  0.104622     0.16368      0.468225    0.383277     0.0430955     0.211975    0.19048     -0.288326   -0.238181     0.0194485    1.13764      0.309279   -0.142425    0.300959     0.374314    -0.212785   -0.103384   -0.7081       0.181181     -0.289831    0.0572581    0.406868    -0.495002    -0.0894513     0.146617    0.0623545  
  0.0465243    0.781303     0.0329491   0.130946    -0.0303044     0.387986   -0.252105     0.108193    0.16814      0.200755     0.312351    -0.157657   -0.0150991  -0.0257442   -0.11053     -0.311694    0.105378   -0.205134    -0.227007      0.464916    0.12368      0.240062    -0.303294     0.58956      -0.0435178   0.404057   
 -0.0785618   -0.0493424   -0.415004   -0.318961    -0.239153     -0.133188   -0.208052     0.135619    0.352133    -0.351129    -1.23449     -0.466362    0.188866   -0.397816    -0.170629     0.293959   -0.0308357   0.43205     -0.24422       0.0190671  -0.0713883   -0.292339     0.366249     0.445791      0.0444829  -0.0994683  
 -0.259412     0.100628    -0.139814   -0.641232     0.0400703     0.0210172  -0.137059     0.49202    -0.288188    -0.454416    -0.165323     0.13408    -0.324417   -0.390475    -0.334516    -0.110072    0.445263   -0.0193139    0.563094      0.422453    0.407349    -0.00222116   0.980826    -0.119787      0.26173     0.534968   
  0.0858163    0.398887    -0.255093    0.379956    -0.26817       0.168439   -0.00777585   0.548512    0.383862    -0.514324    -0.339003    -0.14139    -0.165003   -0.199099     0.627134    -0.194867    0.037994   -0.152926    -0.0905555    -0.231086   -0.0899887    0.295478    -0.0681315    0.427952     -0.0866009   0.640268   
  0.174258    -0.281139    -0.391704   -0.119086    -0.180342     -0.715827    0.0864932    0.275755    0.18564      0.271329    -0.0801332   -0.0381692  -0.622098    0.135249     0.402826    -0.612756    0.232788   -0.187446    -0.762711     -0.203107    0.604036     0.41664      0.876074     0.475309     -0.405241    0.287791   
 -0.0426387    0.172999     0.11044     0.0862019   -0.154247     -0.292458    0.289745    -0.032628   -0.02641      0.121047     0.0592015   -0.0477126   0.0206095   0.0574807    0.123712    -0.0840509   0.273938   -0.0999448   -0.108256     -0.374735    0.161233    -0.0921208    0.0743383    0.0665531    -0.129754    0.225018   
 -0.341131    -0.12384      0.145622    0.269754     0.330363     -0.218476   -0.0598084    0.510756    0.480424     1.12292      0.370715     0.309858    0.562885    0.594756    -0.327711    -0.349715   -0.0406177  -0.429643     0.270932      0.16999     0.101824    -0.25015      0.416346    -0.230136     -0.0943712   0.29295    
  0.819845    -0.341708     0.66126     0.564002    -0.54096       0.0842804   0.314584     0.36246     0.00302572  -0.926444     0.12499     -0.837497    0.707507    0.343466     0.45168      0.1065     -0.335205    0.276108     0.551767     -0.438349   -0.0730247   -0.244713     0.0978879   -0.0228297     0.0927924   0.568472   
  0.210913    -0.174807    -0.259349    0.271363    -0.517878      0.109519   -0.229409    -0.132714    0.111826     0.206253    -0.196657    -0.158833   -0.0965756   0.0811483   -0.474422     0.238877   -0.437734   -0.0010033   -0.323457      0.0753275   0.184883     0.0915359   -1.05759     -0.21348      -0.455468   -0.9733     
  0.12818     -0.251453     0.824034   -0.420383     0.325232      0.505301    0.516989    -0.27864    -0.304037    -0.414124     0.269195    -0.171792   -0.223589    0.151864    -0.107134    -0.758365    0.708305    0.330741     0.426194      0.243009   -0.0453411   -0.153846    -0.364666     0.53674      -0.421898   -0.293486   
 -0.595613     0.963261     0.512878   -0.21948      0.306586      0.504319    0.00574821  -0.197531   -0.0886451    0.302922     0.16228     -0.0354657   0.223718   -0.546826     0.241825     0.410852    0.540664    0.856622     0.130516      0.0656396  -0.343345     0.293316    -0.253821     0.0837714    -0.372913    0.185722   
 -0.139707    -0.743603     0.219836    0.153777    -0.288984     -0.379413   -0.0151295    0.377293   -0.345045     0.0195243   -0.50444      0.472527   -0.640739    0.0511736    0.249892     0.0497251   0.465001   -0.252957     0.0490082     0.477818    0.886969    -0.424034    -0.126428     0.219296     -0.614632   -0.458725   
 -0.397642    -0.424947    -0.143426   -0.0978077    0.264352      0.48682    -0.295528     0.518903   -0.118028    -0.156092     0.0819176   -0.138102    0.31735     0.106567    -0.00560732  -0.0829904  -0.37151     0.638578    -0.0851781     0.496112   -0.325185     0.727749    -0.10186     -0.373733      0.45582    -0.364152   
 -0.0791996   -0.00275529   0.0526206   0.0393991    0.0884439     0.324276   -0.0593901   -0.0178514  -0.0318855   -0.0785888    0.00973186  -0.0340554   0.0337244  -0.0458735   -0.0416387   -0.0769695  -0.0822569   0.135685     0.000852131   0.155764   -0.125163     0.0870504   -0.163063     0.0248149     0.174338   -0.000653236
  0.685822    -1.37792     -0.520997    0.0031474   -0.218163     -0.306251    0.34244      0.250432    0.355128    -0.768386    -0.0404173    0.182642   -0.236495    0.417584    -0.00879809  -0.356386   -0.164732   -0.742355     0.0565169    -0.299153    0.335667    -0.349567     0.118475     0.113553      1.0644     -0.998243   
  0.0998227    0.169501    -0.656425    0.0855459   -0.0247535     0.135569   -0.390955     0.068105    0.650248     0.162158     0.213953     0.106523   -0.701802    0.208391    -0.350258    -0.116348   -0.0179621  -0.412575    -0.338204      0.214772    0.237965    -0.416001     0.0845645    0.554157     -0.0156685   0.478124   
 -0.215641     0.233222    -0.538691   -0.405387     0.199104     -0.422729    0.535964    -0.137738   -0.500062     0.618097     0.154387     0.123181   -0.179206    0.114789    -0.822636    -0.146326    0.596841    0.173167    -0.418137      0.206476   -0.00739799  -0.258891     0.14889     -0.4049       -0.632772   -0.204742   
  0.226607    -0.0680499   -0.0332075  -0.416303     0.192806     -0.161621   -0.256108     0.228521   -0.175153     0.00712724   0.0815067    0.255451   -0.415428   -0.0869722    0.384931    -0.27775     0.165227   -0.177664    -0.503799      0.120968    0.306055     0.406693    -0.00834474   0.402991     -0.325425    0.0303414  
 -0.00341648   0.162194    -0.252359   -0.308103    -0.00641502   -0.142289    0.0532383   -0.428224    0.43153     -0.227214     0.269916    -0.355589    0.32259    -0.340612    -0.0305512   -0.475983    0.194623    0.453893    -0.187465     -0.550938   -0.00486239   0.253055    -0.222017     0.302421      0.541215   -0.526554   
 -0.0136343   -0.181377     0.602165    0.108718     0.214122      0.267491   -0.00170101  -0.486133    0.473085    -0.0634546   -0.399918    -0.161483   -0.374674    0.140638     0.924089    -0.126694   -0.0904399  -0.0117191   -0.127053     -0.256886    0.344346     0.0831415   -0.0386251    0.598763      0.230061    0.281117   
 -0.0795613   -0.16051      0.298027    0.450852     0.146587     -0.288764    0.279106     0.241835   -0.0845056    0.232236     0.416651    -0.494052    0.810899   -0.0820473    0.435018    -0.421114    0.251474    0.570946    -0.375213     -0.670015    0.0762628    0.196811    -0.284314    -0.143268     -0.245109   -0.0915063  
  0.170868     0.143379    -0.218978    0.617057     0.403089     -0.124667    0.464158    -0.773694    0.0130743   -0.399732    -0.454616    -0.288425    0.0391625   0.188147    -0.418607     0.105811   -0.52002     0.224895     0.28906      -0.405828   -0.947018    -0.260173    -0.390277    -0.366656      0.337394    0.118061   
 -0.256144    -0.257484     0.0594141  -0.379109     0.108619      0.360198   -0.382478    -0.503482   -0.100414    -0.169064    -0.154974     0.808856   -0.200413   -0.107562    -0.568576     0.229006   -0.218105   -0.5818       0.11908       0.480909   -0.459366     0.334041    -0.0274092   -0.0120629     0.695233   -0.429063   
 -0.235939    -0.139724     0.220017    0.37712     -0.276064      0.451079   -0.0715333   -0.137555   -0.38548      0.134511    -0.120979     0.302336    0.871923    0.0524465   -0.495663     1.06955    -0.279291    0.120301     0.471975      0.386449   -0.409154    -0.788674    -0.129044    -0.286422      0.454417    0.348942   
  0.298384     0.426474     0.221204    0.00438853  -0.202147      0.23671     0.0460597    0.183041   -0.342836     0.484811     0.0502165    0.0126379  -0.118535   -0.00290296  -0.320372     0.130681    0.101824   -0.335202     0.166316      0.544144   -0.107494    -0.385222     0.0606988    0.000715538  -0.584654    0.402229   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.403169
INFO: iteration 2, average log likelihood -1.403160
INFO: iteration 3, average log likelihood -1.403151
INFO: iteration 4, average log likelihood -1.403143
INFO: iteration 5, average log likelihood -1.403135
INFO: iteration 6, average log likelihood -1.403127
INFO: iteration 7, average log likelihood -1.403119
INFO: iteration 8, average log likelihood -1.403112
INFO: iteration 9, average log likelihood -1.403105
INFO: iteration 10, average log likelihood -1.403097
INFO: EM with 100000 data points 10 iterations avll -1.403097
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
