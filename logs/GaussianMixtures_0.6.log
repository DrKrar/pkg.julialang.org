>>> 'Pkg.add("GaussianMixtures")' log
INFO: Cloning cache of GaussianMixtures from https://github.com/davidavdav/GaussianMixtures.jl.git
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.1.0
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StaticArrays v0.0.5
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.6.0-dev.787
Commit c71f205 (2016-09-26 16:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (655.17578125 MB free)
Uptime: 23773.0 sec
Load Avg:  0.93896484375  0.97314453125  1.029296875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1337278 s         93 s     139254 s     602671 s         49 s
#2  3500 MHz     697859 s         54 s      83792 s    1459104 s          1 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
20 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.1.0
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StaticArrays                  0.0.5
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: isdefined(a::Array, i::Int) is deprecated, use isassigned(a, i) instead
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in h5convert_array(::JLD.JldFile, ::Array{Any,1}, ::JLD.JldDatatype, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:614
 in #_write#15(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:579
 in #write#12(::Array{Any,1}, ::Function, ::JLD.JldFile, ::String, ::Array{Any,1}, ::JLD.JldWriteSession) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:529
 in #jldopen#7(::Bool, ::Bool, ::Bool, ::Function, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:198
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::Bool, ::Bool, ::Bool, ::Bool, ::Bool) at ./<missing>:0
 in #jldopen#8(::Bool, ::Bool, ::Bool, ::Function, ::String, ::String) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:253
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::String, ::String) at ./<missing>:0
 in #jldopen#9(::Array{Any,1}, ::Function, ::JLD.##32#33{String,Array{Float64,2},Tuple{}}, ::String, ::Vararg{String,N}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:263
 in (::JLD.#kw##jldopen)(::Array{Any,1}, ::JLD.#jldopen, ::Function, ::String, ::String) at ./<missing>:0
 in #save#31(::Bool, ::Bool, ::Function, ::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1208
 in save(::FileIO.File{FileIO.DataFormat{:JLD}}, ::String, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/JLD/src/JLD.jl:1205
 in #save#14(::Array{Any,1}, ::Function, ::String, ::String, ::Vararg{Any,N}) at /home/vagrant/.julia/v0.6/FileIO/src/loadsave.jl:54
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:8 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:345
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in #15 at ./<missing>:0 [inlined]
 in next at ./generator.jl:26 [inlined]
 in collect_to!(::Array{Float64,1}, ::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}, ::Int64, ::Int64) at ./array.jl:378
 in collect(::Base.Generator{UnitRange{Int64},GaussianMixtures.##15#16{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}}}) at ./array.jl:346
 in llpg(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:324
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:354
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexp(::Array{Float64,1}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/compat.jl:21
 in mapslices(::GaussianMixtures.#logsumexp, ::Array{Float64,2}, ::Array{Int64,1}) at ./abstractarray.jl:1739
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:356
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:85
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:86
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in (::##9#10{GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}})(::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl:23
 in macro expansion at ./asyncmap.jl:63 [inlined]
 in (::Base.##748#750{Base.AsyncCollector,Base.AsyncCollectorState})() at ./task.jl:363
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/data.jl, in expression starting on line 26
(100000,-803999.0807526843,[45440.3,54559.7],
[-12834.2 -16924.6 24881.9; 12470.2 16330.7 -24865.5],

Array{Float64,2}[
[61207.8 1382.57 -7304.73; 1382.57 43509.3 -6541.78; -7304.73 -6541.78 45206.2],

[38647.4 -1629.32 7441.4; -1629.32 56779.8 6338.99; 7441.4 6338.99 54319.4]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.477435e+03
      1       1.029334e+03      -4.481011e+02 |        7
      2       9.832935e+02      -4.604059e+01 |        2
      3       9.360004e+02      -4.729308e+01 |        2
      4       9.105296e+02      -2.547081e+01 |        0
      5       9.105296e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 910.5295878546776)
INFO: K-means with 272 data points using 5 iterations
11.3 data points per parameter
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::UpperTriangular{Float64,Array{Float64,2}}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:56
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:131
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:270
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{UpperTriangular{Float64,Array{Float64,2}},1}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMMk#9(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:132
 in (::GaussianMixtures.#kw##GMMk)(::Array{Any,1}, ::GaussianMixtures.#GMMk, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:34
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 4
INFO: EM with 272 data points 0 iterations avll -2.079138
5.8 data points per parameter
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:90
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: digamma{T <: Number}(x::AbstractArray{T}) is deprecated, use digamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in digamma(::Array{Float64,1}) at ./deprecated.jl:50
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in expectations(::GaussianMixtures.VGMM{Float64}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:93
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:243
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::Array{Float64,2}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:217
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:225
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in mylogdet at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:44 [inlined]
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
WARNING: lgamma{T <: Number}(x::AbstractArray{T}) is deprecated, use lgamma.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in lgamma(::Array{Float64,1}) at ./deprecated.jl:50
 in (::GaussianMixtures.#logB#24{Int64})(::UpperTriangular{Float64,Array{Float64,2}}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:206
 in lowerbound(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:229
 in emstep!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:261
 in #em!#29(::Int64, ::Function, ::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:272
 in em!(::GaussianMixtures.VGMM{Float64}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/bayes.jl:269
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/bayes.jl, in expression starting on line 7
INFO: iteration 1, lowerbound -3.840020
INFO: iteration 2, lowerbound -3.703048
INFO: iteration 3, lowerbound -3.540930
INFO: iteration 4, lowerbound -3.343086
INFO: iteration 5, lowerbound -3.138884
INFO: iteration 6, lowerbound -2.966539
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.846540
INFO: dropping number of Gaussions to 6
INFO: iteration 8, lowerbound -2.774298
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.730408
INFO: dropping number of Gaussions to 3
INFO: iteration 10, lowerbound -2.689032
INFO: iteration 11, lowerbound -2.644733
INFO: iteration 12, lowerbound -2.602356
INFO: iteration 13, lowerbound -2.556776
INFO: iteration 14, lowerbound -2.510891
INFO: iteration 15, lowerbound -2.467440
INFO: iteration 16, lowerbound -2.428006
INFO: iteration 17, lowerbound -2.392638
INFO: iteration 18, lowerbound -2.360711
INFO: iteration 19, lowerbound -2.333061
INFO: iteration 20, lowerbound -2.313717
INFO: iteration 21, lowerbound -2.307431
INFO: dropping number of Gaussions to 2
INFO: iteration 22, lowerbound -2.302931
INFO: iteration 23, lowerbound -2.299260
INFO: iteration 24, lowerbound -2.299256
INFO: iteration 25, lowerbound -2.299254
INFO: iteration 26, lowerbound -2.299254
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Wed 28 Sep 2016 09:52:50 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Wed 28 Sep 2016 09:52:52 PM UTC: K-means with 272 data points using 5 iterations
11.3 data points per parameter
,Wed 28 Sep 2016 09:52:53 PM UTC: EM with 272 data points 0 iterations avll -2.079138
5.8 data points per parameter
,Wed 28 Sep 2016 09:52:54 PM UTC: GMM converted to Variational GMM
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 1, lowerbound -3.840020
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 2, lowerbound -3.703048
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 3, lowerbound -3.540930
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 4, lowerbound -3.343086
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 5, lowerbound -3.138884
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 6, lowerbound -2.966539
,Wed 28 Sep 2016 09:52:57 PM UTC: dropping number of Gaussions to 7
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 7, lowerbound -2.846540
,Wed 28 Sep 2016 09:52:57 PM UTC: dropping number of Gaussions to 6
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 8, lowerbound -2.774298
,Wed 28 Sep 2016 09:52:57 PM UTC: dropping number of Gaussions to 5
,Wed 28 Sep 2016 09:52:57 PM UTC: iteration 9, lowerbound -2.730408
,Wed 28 Sep 2016 09:52:58 PM UTC: dropping number of Gaussions to 3
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 10, lowerbound -2.689032
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 11, lowerbound -2.644733
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 12, lowerbound -2.602356
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 13, lowerbound -2.556776
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 14, lowerbound -2.510891
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 15, lowerbound -2.467440
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 16, lowerbound -2.428006
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 17, lowerbound -2.392638
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 18, lowerbound -2.360711
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 19, lowerbound -2.333061
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 20, lowerbound -2.313717
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 21, lowerbound -2.307431
,Wed 28 Sep 2016 09:52:58 PM UTC: dropping number of Gaussions to 2
,Wed 28 Sep 2016 09:52:58 PM UTC: iteration 22, lowerbound -2.302931
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 23, lowerbound -2.299260
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 24, lowerbound -2.299256
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 25, lowerbound -2.299254
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 26, lowerbound -2.299254
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 27, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 28, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 29, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 30, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 31, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 32, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 33, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 34, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 35, lowerbound -2.299253
,Wed 28 Sep 2016 09:52:59 PM UTC: iteration 36, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 37, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 38, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 39, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 40, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 41, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 42, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 43, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 44, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 45, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 46, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 47, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 48, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 49, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: iteration 50, lowerbound -2.299253
,Wed 28 Sep 2016 09:53:00 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.9549,178.045]
Î² = [95.9549,178.045]
m = [2.00023 53.852; 4.2503 79.2869]
Î½ = [97.9549,180.045]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.375876 -0.00895312; 0.0 0.0127487],

[0.184042 -0.00764405; 0.0 0.00858171]]
Kind: diag, size256
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,1}) at ./deprecated.jl:50
 in rand(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/rand.jl:58
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:7 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: sqrt{T <: Number}(x::AbstractArray{T}) is deprecated, use sqrt.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sqrt(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:48
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}, ::Int64) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:67
 in #stats#35(::Int64, ::Bool, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:141
 in stats(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/stats.jl:123
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:10 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9878585559220004
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:290
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:14 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll from llpg:  -0.9878585559220003
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,1}) at ./deprecated.jl:50
 in logsumexpw at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:157 [inlined]
 in avll(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:336
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:15 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
avll direct:     -0.9878585559220003
WARNING: log{T <: Number}(x::AbstractArray{T}) is deprecated, use log.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in log(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:355
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
WARNING: exp{T <: Number}(x::AbstractArray{T}) is deprecated, use exp.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in exp(::Array{Float64,2}) at ./deprecated.jl:50
 in gmmposterior(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:358
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:17 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 2
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9995755686010761
avll from llpg:  -0.9995755686010757
avll direct:     -0.9995755686010757
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0944018   -0.122562      0.127797     0.0131817    0.0140578    -0.0355912   -0.0486801   -0.0671776  -0.0181627    0.13746     -0.0494377  -0.0641874  -0.0213438    0.223201     -0.106426    -0.0586765  -0.0666265    0.11917     -0.032238     0.186454    -0.0560527    0.0959893   0.112258     0.0645306   -0.134221    -0.0514826  
  0.0467527   -0.0953274    -0.0768941    0.0661636   -0.0542771    -0.06768     -0.0748157    0.0386768   0.116169     0.0705936    0.135541   -0.012074   -0.0424234   -0.00776863   -0.00492371  -0.0185007  -0.143827    -0.0808784   -0.0367351   -0.0909294    0.0898313   -0.115402   -0.189317    -0.00746347  -0.0581609   -0.0680145  
 -0.0131005    0.0531899    -0.0346318    0.148912     0.172706      0.0375758   -0.195612    -0.0417402   0.0896139   -0.0653507    0.0298772   0.0390411   0.155615    -0.0957436     0.204418     0.0544899   0.147101    -0.115434    -0.0256311   -0.10587     -0.177591    -0.103313   -0.107048    -0.0492723   -0.0896825   -0.0169327  
  0.107525    -0.0173256     0.184793     0.0415754    0.0221993     0.0176984   -0.173725     0.0879688  -0.123675     0.102256    -0.233372   -0.0217725   0.0440073    0.0284335     0.0766913   -0.0317256  -0.00181408  -0.0571725    0.0658585   -0.0109007   -0.0992829   -0.0856628  -0.0160091    0.0233849    0.0208773    0.00589496 
  0.0304473    0.0754361    -0.0537636   -0.024313     0.147657     -0.119422     0.0357676    0.0333547   0.0483233   -0.0268057   -0.0190746   0.0137713   0.084303    -0.0673771    -0.0243312    0.0368938   0.212763    -0.00874242   0.12299      0.100538     0.0552207   -0.192561    0.205895     0.0436033   -0.0431365    0.0242559  
 -0.0457751    0.0084264    -0.0811932    0.00966443  -0.0685384     0.112611    -0.0526025   -0.0751476   0.134576     0.0463424   -0.0605285   0.0164006   0.083421     0.0962006    -0.0835753   -0.117011    0.108581     0.102426    -0.0506459   -0.167467     0.0334072   -0.021531   -0.056239    -0.0487586   -0.0687264    0.12392    
 -0.0406532    0.219672     -0.0207586    0.021848     0.0106051     0.041215     0.0367618    0.211385    0.146862     0.00884843   0.160152   -0.136626    0.0283647   -0.0194744    -0.00697358   0.0365438   0.029552     0.138347    -0.0603443    0.0843804   -0.0415847   -0.0268265   0.0653305    0.0316169    0.0272945   -0.126648   
 -0.158113    -0.0825216    -0.0586481   -0.0261971   -0.000220917   0.246685     0.019464     0.145707   -0.0237816   -0.186861     0.0179483  -0.0389865  -0.0427774   -0.127444     -0.0197311   -0.0360959   0.00542292  -0.0501437   -0.00178672  -0.145514    -0.0827766    0.0460019  -0.0551753   -0.133609     0.0993253   -0.0282282  
  0.150798     0.119841      0.216531     0.0525478    0.074371      0.162969    -0.128315     0.0588805   0.0226689    0.092717    -0.0772328  -0.0236669  -0.0236564   -0.0222292    -0.116914    -0.0438172   0.278537     0.0906224    0.105052    -0.0206297   -0.0602978    0.0682202  -0.0658914    0.018801    -0.267072     0.0521664  
 -0.0234733   -0.0591802    -0.0651375    0.202693     0.0528284    -0.111539     0.0451467    0.0422249   0.0525422   -0.0288304   -0.134227    0.0277861   0.0225121   -0.217582     -0.0606677    0.0619369  -0.12952      0.0990398    0.0956864    0.0532516    0.0895703    0.017347    0.118867     0.117371     0.00312582   0.0543055  
 -0.102448    -0.01484       0.226813    -0.0127348   -0.103972      0.17092     -0.0455774    0.0579912   0.0418413    0.0655333   -0.12442    -0.0915005   0.0101818    0.248271      0.00956071  -0.155514   -0.102951     0.0341105   -0.0994794    0.0210713   -0.0198177   -0.0479814  -0.0529919    0.0504482   -0.133416    -0.0132501  
  0.00605008   0.262811      0.0454127    0.153162     0.0143025     0.128028    -0.046788     0.193336    0.00123515   0.100813    -0.127848   -0.0537463   0.119114    -0.000411366   0.127892    -0.0707792   0.00362449   0.0255626    0.0370197    0.00746     -0.134132     0.0529703  -0.0746844    0.00534057  -0.00203288   0.0782906  
  0.0580424   -0.198008     -0.0413799   -0.0227589    0.102513      0.0544067    0.00328995   0.104936    0.0573546    0.0644694   -0.0602879   0.0270655  -0.0711964    0.0150044     0.166226    -0.0482505  -0.0575356   -0.136998     0.00659413   0.0654197   -0.0944656   -0.048978    0.100618    -0.100099    -0.086588    -0.0407502  
 -0.0373402   -0.05313       0.124336    -0.0946663   -0.0936559     0.0134811    0.0232862   -0.0521021  -0.134162     0.161945    -0.0466452   0.0309732   0.0214585   -0.101085      0.0418404   -0.0919912  -0.0161583    0.032699     0.0703689   -0.0355497   -0.0128014    0.0355449   0.101874     0.0321044   -0.0716466   -0.0510923  
 -0.00935341  -0.134513      0.103156     0.17919      0.101563      0.00201322   0.076186    -0.130477    0.0250006   -0.0335897   -0.162158    0.102818   -0.13567     -0.127002      0.00910066   0.0318648   0.0702188    0.150555     0.0975621    0.039375     0.0883272    0.0454153   0.055063     0.00278928   0.0973735    0.119518   
 -0.0512783   -0.0172829    -0.0841861    0.0376164    0.0931807     0.102239    -0.181684    -0.0125596  -0.0776224   -0.081201    -0.29131     0.143691   -0.0816183    0.0740955     0.0746781    0.133797   -0.0121724   -0.121682    -0.0391169    0.12799      0.125122     0.0525955  -0.120976     0.164824    -0.0985357   -0.132751   
 -0.010262    -0.000634588  -0.0247972    0.0465004    0.0188826     0.162413     0.0563856    0.245728   -0.0780597    0.0236462    0.14559    -0.240479    0.0631288    0.057081     -0.108297    -0.0218422   0.126175    -0.00886182   0.0141722   -0.00900134  -0.153451    -0.0881822  -0.00698246   0.0592621   -0.021365    -0.0513988  
  0.0201222    0.0921346     0.111216    -0.0908448   -0.0178734    -0.0370087    0.0106095   -0.122459   -0.0860636    0.117611    -0.147064    0.149729   -0.143485     0.0546908     0.0241275    0.0708517   0.0456376   -0.161025    -0.224252     0.00197142  -0.0349345   -0.0469721   0.0985866    0.0752201    0.0854859   -0.111509   
 -0.0577119    0.0347954     0.128714    -0.0872825   -0.0708154     0.0562892    0.0466353   -0.0303416  -0.161981    -0.073496     0.0801075   0.0756671  -0.0164626    0.128765      0.131298    -0.0542706  -0.00906721   0.0274342    0.00555483   0.0331388    0.0252003    0.0533605   0.00802216  -0.00365203  -0.110852     0.0890902  
  0.0864427    0.0238598    -0.0377586   -0.159093     0.061671     -0.0950642   -0.291192     0.0217969   0.152764    -0.0501769    0.203445    0.0286368  -0.068212    -0.0993326    -0.0980882   -0.021304    0.0444414   -0.017563     0.12478      0.148235     0.0488867   -0.018339   -0.0122241   -0.00556347   0.0893925   -0.052319   
  0.0368814   -0.19806      -0.109285    -0.148107    -0.121435      0.0696914    0.249385     0.0567284  -0.316254     0.0214571    0.100312   -0.138121    0.0616265   -0.0166213     0.0571502   -0.052048   -0.0833      -0.00210191   0.0966921   -0.0661207   -0.00847818  -0.0223762   0.0847077    0.093961    -0.0274399    0.109017   
 -0.01945     -0.0496225    -0.0253852    0.0828921   -0.103982     -0.064257     0.0366327   -0.0212988   0.0536516    0.0982475    0.138285    0.0256765   0.104647     0.0471243     0.0681347    0.0920973  -0.0113146   -0.0788812    0.0646726   -0.060951     0.00967809   0.0445712   0.0476873   -0.121581     0.107274    -0.0545142  
  0.123973     0.103296      0.0546931   -0.112823    -0.106348     -0.0109221   -0.173406    -0.131087   -0.0988613    0.0510619    0.164084    0.139217    0.0410584   -0.335052      0.0743976   -0.0522569   0.0278348    0.0768102   -0.0385938   -0.110513    -0.0724064    0.0678783   0.0923406    0.0604344   -0.0665263   -0.158388   
 -0.0717183    0.0654531     0.00907988  -0.122559     0.0617253     0.105307     0.103735    -0.0865511  -0.031616     0.03681     -0.192525    0.239093    0.0204796    0.0115833     0.0644008   -0.0203824   0.247104    -0.00318682  -0.0552968   -0.0200296   -0.0479109   -0.0374196   0.095681    -0.0531457   -0.0560717    0.2462     
  0.0589353   -0.129123      0.0611177   -0.00575883   0.0474765     0.065543     0.0169708    0.153144    0.00131969  -0.0143619    0.155384    0.0620547   0.0557333   -0.017561      0.102446     0.0341717  -0.125157    -0.0073082   -0.0527686    0.0606573    0.00501555  -0.126532    0.163458     0.0072119    0.0290097   -0.12183    
 -0.0406075   -0.0598411     0.0348862   -0.0714526   -0.175867      0.0772941   -0.00236877  -0.0367611  -0.137409    -0.0306381   -0.298527   -0.120444   -0.196242     0.0171694    -0.00216415   0.0117759   0.0301485   -0.0784524    0.0180887    0.0673158    0.0562572   -0.0419246  -0.0250428   -0.0345589    0.016992     0.114796   
 -0.031499     0.000494861  -0.229359    -0.0953041   -0.0449813    -0.00650702   0.141816    -0.0312701   0.178149    -0.0349661    0.134153   -0.0226444  -0.162869    -0.0847802     0.0216411    0.26589    -0.032852    -0.0573858    0.0103149   -0.117069    -0.041625     0.158761   -0.0548125   -0.0852541   -0.140905    -0.179763   
  0.0677931   -0.0212561     0.0934849   -0.0792143    0.13688       0.0261981   -0.0502492   -0.0649538  -0.0574284    0.0495724    0.0109047  -0.102892   -0.157655    -0.0689432    -0.0175482    0.177913    0.00157848   0.0888881    0.0243139    0.0115004    0.111231    -0.0819874   0.0865199   -0.0278398   -0.193998     0.187851   
  0.186223     0.122309      0.00443992   0.0894255    0.000976582  -0.0162646    0.025476    -0.115281    0.113122     0.19349     -0.149452   -0.105215    0.00219975   0.0014239     0.00222873   0.0360858   0.182972     0.10343      0.103165    -0.0575531   -0.235631     0.123101   -0.0295481    0.0868007    0.235596     0.0108273  
  0.0624624    0.119188      0.181725    -0.13725     -0.0215117     0.0216503    0.167362    -0.0430667  -0.260835    -0.0291818    0.0514473  -0.0264097  -0.125118     0.0174576    -0.0360317    0.0602423   0.0113171    0.0026781    0.131156     0.0201637    0.156832    -0.170816    0.0683493    0.0151098   -0.0657091   -0.000786684
 -0.120504     0.0617735     0.0164641   -0.0535331   -0.0369592     0.0863109   -0.00464068  -0.111177   -0.104763    -0.131672    -0.0868499   0.0844156   0.0398954   -0.150165     -0.00685448   0.111171    0.0169512    0.0722605    0.102407    -0.00667483  -0.122558     0.145998    0.0268625    0.0170011    0.00241769   0.00879236 
  0.132489    -0.0716175     0.111185    -0.0261807   -0.172282     -0.0598971   -0.0407289   -0.187874   -0.0430858   -0.0783689    0.0159938   0.175392    0.120016    -0.0960802     0.0546455    0.061744    0.0162348   -0.0821541   -0.105879    -0.0733094   -0.0235292    0.15928     0.031985    -0.0437016    0.0799163    0.0984938  kind diag, method split
0: avll = -1.4674617638373446
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:45
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isnan{T <: Number}(x::AbstractArray{T}) is deprecated, use isnan.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isnan(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
WARNING: isinf{T <: Number}(x::AbstractArray{T}) is deprecated, use isinf.(x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in isinf(::Array{Float64,2}) at ./deprecated.jl:50
 in sanitycheck!(::GaussianMixtures.GMM{Float64,Array{Float64,2}}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:50
 in #em!#14(::Int64, ::Float64, ::Int64, ::Int64, ::Function, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:261
 in (::GaussianMixtures.#kw##em!)(::Array{Any,1}, ::GaussianMixtures.#em!, ::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at ./<missing>:0
 in #GMM2#12(::Symbol, ::Int64, ::Int64, ::Int64, ::Function, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:147
 in (::GaussianMixtures.#kw##GMM2)(::Array{Any,1}, ::GaussianMixtures.#GMM2, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in #GMM#7(::Symbol, ::Symbol, ::Int64, ::Int64, ::Int64, ::Int64, ::Type{T}, ::Int64, ::Array{Float64,2}) at /home/vagrant/.julia/v0.6/GaussianMixtures/src/train.jl:32
 in (::Core.#kw#Type)(::Array{Any,1}, ::Type{GaussianMixtures.GMM}, ::Int64, ::Array{Float64,2}) at ./<missing>:0
 in macro expansion; at /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl:29 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:268
 in _start() at ./client.jl:332
while loading /home/vagrant/.julia/v0.6/GaussianMixtures/test/train.jl, in expression starting on line 22
INFO: iteration 1, average log likelihood -1.467606
INFO: iteration 2, average log likelihood -1.467497
INFO: iteration 3, average log likelihood -1.467206
INFO: iteration 4, average log likelihood -1.464384
INFO: iteration 5, average log likelihood -1.453540
INFO: iteration 6, average log likelihood -1.444984
INFO: iteration 7, average log likelihood -1.442751
INFO: iteration 8, average log likelihood -1.441797
INFO: iteration 9, average log likelihood -1.441163
INFO: iteration 10, average log likelihood -1.440630
INFO: iteration 11, average log likelihood -1.440105
INFO: iteration 12, average log likelihood -1.439548
INFO: iteration 13, average log likelihood -1.438930
INFO: iteration 14, average log likelihood -1.438248
INFO: iteration 15, average log likelihood -1.437594
INFO: iteration 16, average log likelihood -1.437023
INFO: iteration 17, average log likelihood -1.436506
INFO: iteration 18, average log likelihood -1.436033
INFO: iteration 19, average log likelihood -1.435614
INFO: iteration 20, average log likelihood -1.435235
INFO: iteration 21, average log likelihood -1.434896
INFO: iteration 22, average log likelihood -1.434598
INFO: iteration 23, average log likelihood -1.434336
INFO: iteration 24, average log likelihood -1.434104
INFO: iteration 25, average log likelihood -1.433893
INFO: iteration 26, average log likelihood -1.433682
INFO: iteration 27, average log likelihood -1.433443
INFO: iteration 28, average log likelihood -1.433135
INFO: iteration 29, average log likelihood -1.432766
INFO: iteration 30, average log likelihood -1.432450
INFO: iteration 31, average log likelihood -1.432236
INFO: iteration 32, average log likelihood -1.432094
INFO: iteration 33, average log likelihood -1.431991
INFO: iteration 34, average log likelihood -1.431911
INFO: iteration 35, average log likelihood -1.431844
INFO: iteration 36, average log likelihood -1.431787
INFO: iteration 37, average log likelihood -1.431736
INFO: iteration 38, average log likelihood -1.431691
INFO: iteration 39, average log likelihood -1.431648
INFO: iteration 40, average log likelihood -1.431606
INFO: iteration 41, average log likelihood -1.431564
INFO: iteration 42, average log likelihood -1.431520
INFO: iteration 43, average log likelihood -1.431477
INFO: iteration 44, average log likelihood -1.431437
INFO: iteration 45, average log likelihood -1.431403
INFO: iteration 46, average log likelihood -1.431375
INFO: iteration 47, average log likelihood -1.431353
INFO: iteration 48, average log likelihood -1.431336
INFO: iteration 49, average log likelihood -1.431322
INFO: iteration 50, average log likelihood -1.431311
INFO: EM with 100000 data points 50 iterations avll -1.431311
952.4 data points per parameter
1: avll = [-1.46761,-1.4675,-1.46721,-1.46438,-1.45354,-1.44498,-1.44275,-1.4418,-1.44116,-1.44063,-1.44011,-1.43955,-1.43893,-1.43825,-1.43759,-1.43702,-1.43651,-1.43603,-1.43561,-1.43524,-1.4349,-1.4346,-1.43434,-1.4341,-1.43389,-1.43368,-1.43344,-1.43314,-1.43277,-1.43245,-1.43224,-1.43209,-1.43199,-1.43191,-1.43184,-1.43179,-1.43174,-1.43169,-1.43165,-1.43161,-1.43156,-1.43152,-1.43148,-1.43144,-1.4314,-1.43138,-1.43135,-1.43134,-1.43132,-1.43131]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.431421
INFO: iteration 2, average log likelihood -1.431282
INFO: iteration 3, average log likelihood -1.430357
INFO: iteration 4, average log likelihood -1.422519
INFO: iteration 5, average log likelihood -1.405007
INFO: iteration 6, average log likelihood -1.395037
INFO: iteration 7, average log likelihood -1.390661
INFO: iteration 8, average log likelihood -1.387649
INFO: iteration 9, average log likelihood -1.385678
INFO: iteration 10, average log likelihood -1.384534
INFO: iteration 11, average log likelihood -1.383808
INFO: iteration 12, average log likelihood -1.383271
INFO: iteration 13, average log likelihood -1.382859
INFO: iteration 14, average log likelihood -1.382551
INFO: iteration 15, average log likelihood -1.382320
INFO: iteration 16, average log likelihood -1.382155
INFO: iteration 17, average log likelihood -1.382040
INFO: iteration 18, average log likelihood -1.381957
INFO: iteration 19, average log likelihood -1.381897
INFO: iteration 20, average log likelihood -1.381851
INFO: iteration 21, average log likelihood -1.381816
INFO: iteration 22, average log likelihood -1.381788
INFO: iteration 23, average log likelihood -1.381765
INFO: iteration 24, average log likelihood -1.381746
INFO: iteration 25, average log likelihood -1.381730
INFO: iteration 26, average log likelihood -1.381717
INFO: iteration 27, average log likelihood -1.381705
INFO: iteration 28, average log likelihood -1.381694
INFO: iteration 29, average log likelihood -1.381685
INFO: iteration 30, average log likelihood -1.381677
INFO: iteration 31, average log likelihood -1.381670
INFO: iteration 32, average log likelihood -1.381664
INFO: iteration 33, average log likelihood -1.381659
INFO: iteration 34, average log likelihood -1.381654
INFO: iteration 35, average log likelihood -1.381650
INFO: iteration 36, average log likelihood -1.381646
INFO: iteration 37, average log likelihood -1.381642
INFO: iteration 38, average log likelihood -1.381639
INFO: iteration 39, average log likelihood -1.381637
INFO: iteration 40, average log likelihood -1.381634
INFO: iteration 41, average log likelihood -1.381632
INFO: iteration 42, average log likelihood -1.381630
INFO: iteration 43, average log likelihood -1.381628
INFO: iteration 44, average log likelihood -1.381626
INFO: iteration 45, average log likelihood -1.381625
INFO: iteration 46, average log likelihood -1.381623
INFO: iteration 47, average log likelihood -1.381622
INFO: iteration 48, average log likelihood -1.381621
INFO: iteration 49, average log likelihood -1.381620
INFO: iteration 50, average log likelihood -1.381619
INFO: EM with 100000 data points 50 iterations avll -1.381619
473.9 data points per parameter
2: avll = [-1.43142,-1.43128,-1.43036,-1.42252,-1.40501,-1.39504,-1.39066,-1.38765,-1.38568,-1.38453,-1.38381,-1.38327,-1.38286,-1.38255,-1.38232,-1.38216,-1.38204,-1.38196,-1.3819,-1.38185,-1.38182,-1.38179,-1.38177,-1.38175,-1.38173,-1.38172,-1.3817,-1.38169,-1.38169,-1.38168,-1.38167,-1.38166,-1.38166,-1.38165,-1.38165,-1.38165,-1.38164,-1.38164,-1.38164,-1.38163,-1.38163,-1.38163,-1.38163,-1.38163,-1.38162,-1.38162,-1.38162,-1.38162,-1.38162,-1.38162]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.381826
INFO: iteration 2, average log likelihood -1.381636
INFO: iteration 3, average log likelihood -1.381102
INFO: iteration 4, average log likelihood -1.375852
INFO: iteration 5, average log likelihood -1.355677
INFO: iteration 6, average log likelihood -1.334891
INFO: iteration 7, average log likelihood -1.322995
INFO: iteration 8, average log likelihood -1.317816
INFO: iteration 9, average log likelihood -1.315798
INFO: iteration 10, average log likelihood -1.314889
INFO: iteration 11, average log likelihood -1.314400
INFO: iteration 12, average log likelihood -1.314117
INFO: iteration 13, average log likelihood -1.313951
INFO: iteration 14, average log likelihood -1.313849
INFO: iteration 15, average log likelihood -1.313781
INFO: iteration 16, average log likelihood -1.313733
INFO: iteration 17, average log likelihood -1.313694
INFO: iteration 18, average log likelihood -1.313661
INFO: iteration 19, average log likelihood -1.313629
INFO: iteration 20, average log likelihood -1.313594
INFO: iteration 21, average log likelihood -1.313551
INFO: iteration 22, average log likelihood -1.313494
INFO: iteration 23, average log likelihood -1.313421
INFO: iteration 24, average log likelihood -1.313327
INFO: iteration 25, average log likelihood -1.313211
INFO: iteration 26, average log likelihood -1.313073
INFO: iteration 27, average log likelihood -1.312923
INFO: iteration 28, average log likelihood -1.312779
INFO: iteration 29, average log likelihood -1.312648
INFO: iteration 30, average log likelihood -1.312524
INFO: iteration 31, average log likelihood -1.312403
INFO: iteration 32, average log likelihood -1.312278
INFO: iteration 33, average log likelihood -1.312147
INFO: iteration 34, average log likelihood -1.312014
INFO: iteration 35, average log likelihood -1.311888
INFO: iteration 36, average log likelihood -1.311777
INFO: iteration 37, average log likelihood -1.311690
INFO: iteration 38, average log likelihood -1.311628
INFO: iteration 39, average log likelihood -1.311584
INFO: iteration 40, average log likelihood -1.311553
INFO: iteration 41, average log likelihood -1.311530
INFO: iteration 42, average log likelihood -1.311511
INFO: iteration 43, average log likelihood -1.311493
INFO: iteration 44, average log likelihood -1.311476
INFO: iteration 45, average log likelihood -1.311457
INFO: iteration 46, average log likelihood -1.311437
INFO: iteration 47, average log likelihood -1.311415
INFO: iteration 48, average log likelihood -1.311389
INFO: iteration 49, average log likelihood -1.311361
INFO: iteration 50, average log likelihood -1.311329
INFO: EM with 100000 data points 50 iterations avll -1.311329
236.4 data points per parameter
3: avll = [-1.38183,-1.38164,-1.3811,-1.37585,-1.35568,-1.33489,-1.32299,-1.31782,-1.3158,-1.31489,-1.3144,-1.31412,-1.31395,-1.31385,-1.31378,-1.31373,-1.31369,-1.31366,-1.31363,-1.31359,-1.31355,-1.31349,-1.31342,-1.31333,-1.31321,-1.31307,-1.31292,-1.31278,-1.31265,-1.31252,-1.3124,-1.31228,-1.31215,-1.31201,-1.31189,-1.31178,-1.31169,-1.31163,-1.31158,-1.31155,-1.31153,-1.31151,-1.31149,-1.31148,-1.31146,-1.31144,-1.31141,-1.31139,-1.31136,-1.31133]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.311595
INFO: iteration 2, average log likelihood -1.311205
INFO: iteration 3, average log likelihood -1.308530
WARNING: Variances had to be floored 9 10
INFO: iteration 4, average log likelihood -1.289424
INFO: iteration 5, average log likelihood -1.272565
WARNING: Variances had to be floored 9 10 12
INFO: iteration 6, average log likelihood -1.237672
INFO: iteration 7, average log likelihood -1.248243
WARNING: Variances had to be floored 3 9 10
INFO: iteration 8, average log likelihood -1.224523
WARNING: Variances had to be floored 12
INFO: iteration 9, average log likelihood -1.237842
WARNING: Variances had to be floored 9 10
INFO: iteration 10, average log likelihood -1.223971
INFO: iteration 11, average log likelihood -1.225429
WARNING: Variances had to be floored 3 9 10 12
INFO: iteration 12, average log likelihood -1.207606
INFO: iteration 13, average log likelihood -1.235422
WARNING: Variances had to be floored 9 10
INFO: iteration 14, average log likelihood -1.213711
WARNING: Variances had to be floored 12
INFO: iteration 15, average log likelihood -1.219853
WARNING: Variances had to be floored 9 10
INFO: iteration 16, average log likelihood -1.214715
WARNING: Variances had to be floored 3
INFO: iteration 17, average log likelihood -1.218559
WARNING: Variances had to be floored 9 10 12
INFO: iteration 18, average log likelihood -1.214909
INFO: iteration 19, average log likelihood -1.229325
WARNING: Variances had to be floored 9 10
INFO: iteration 20, average log likelihood -1.210879
WARNING: Variances had to be floored 3 12
INFO: iteration 21, average log likelihood -1.216520
WARNING: Variances had to be floored 9 10
INFO: iteration 22, average log likelihood -1.222864
INFO: iteration 23, average log likelihood -1.223797
WARNING: Variances had to be floored 9 10 12
INFO: iteration 24, average log likelihood -1.206915
WARNING: Variances had to be floored 3
INFO: iteration 25, average log likelihood -1.224711
WARNING: Variances had to be floored 9 10
INFO: iteration 26, average log likelihood -1.217480
WARNING: Variances had to be floored 12
INFO: iteration 27, average log likelihood -1.220080
WARNING: Variances had to be floored 9 10
INFO: iteration 28, average log likelihood -1.215367
WARNING: Variances had to be floored 3
INFO: iteration 29, average log likelihood -1.219411
WARNING: Variances had to be floored 9 10 12
INFO: iteration 30, average log likelihood -1.213909
INFO: iteration 31, average log likelihood -1.228690
WARNING: Variances had to be floored 9 10
INFO: iteration 32, average log likelihood -1.210210
WARNING: Variances had to be floored 3 12
INFO: iteration 33, average log likelihood -1.215786
WARNING: Variances had to be floored 9 10
INFO: iteration 34, average log likelihood -1.222540
INFO: iteration 35, average log likelihood -1.223613
WARNING: Variances had to be floored 9 10 12
INFO: iteration 36, average log likelihood -1.206632
WARNING: Variances had to be floored 3
INFO: iteration 37, average log likelihood -1.224369
WARNING: Variances had to be floored 9 10
INFO: iteration 38, average log likelihood -1.217452
WARNING: Variances had to be floored 12
INFO: iteration 39, average log likelihood -1.220068
WARNING: Variances had to be floored 9 10
INFO: iteration 40, average log likelihood -1.215270
WARNING: Variances had to be floored 3
INFO: iteration 41, average log likelihood -1.219299
WARNING: Variances had to be floored 9 10 12
INFO: iteration 42, average log likelihood -1.213903
INFO: iteration 43, average log likelihood -1.228685
WARNING: Variances had to be floored 9 10
INFO: iteration 44, average log likelihood -1.210183
WARNING: Variances had to be floored 3 12
INFO: iteration 45, average log likelihood -1.215747
WARNING: Variances had to be floored 9 10
INFO: iteration 46, average log likelihood -1.222538
INFO: iteration 47, average log likelihood -1.223612
WARNING: Variances had to be floored 9 10 12
INFO: iteration 48, average log likelihood -1.206621
WARNING: Variances had to be floored 3
INFO: iteration 49, average log likelihood -1.224358
WARNING: Variances had to be floored 9 10
INFO: iteration 50, average log likelihood -1.217451
INFO: EM with 100000 data points 50 iterations avll -1.217451
118.1 data points per parameter
4: avll = [-1.3116,-1.31121,-1.30853,-1.28942,-1.27256,-1.23767,-1.24824,-1.22452,-1.23784,-1.22397,-1.22543,-1.20761,-1.23542,-1.21371,-1.21985,-1.21471,-1.21856,-1.21491,-1.22932,-1.21088,-1.21652,-1.22286,-1.2238,-1.20691,-1.22471,-1.21748,-1.22008,-1.21537,-1.21941,-1.21391,-1.22869,-1.21021,-1.21579,-1.22254,-1.22361,-1.20663,-1.22437,-1.21745,-1.22007,-1.21527,-1.2193,-1.2139,-1.22869,-1.21018,-1.21575,-1.22254,-1.22361,-1.20662,-1.22436,-1.21745]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 23 24
INFO: iteration 1, average log likelihood -1.220401
WARNING: Variances had to be floored 1 17 18 19 20 23 24
INFO: iteration 2, average log likelihood -1.206509
WARNING: Variances had to be floored 1 5 6 23 24
INFO: iteration 3, average log likelihood -1.214491
WARNING: Variances had to be floored 1 17 18 19 20 23 24
INFO: iteration 4, average log likelihood -1.196003
WARNING: Variances had to be floored 1 5 6 9 10 23 24
INFO: iteration 5, average log likelihood -1.166340
WARNING: Variances had to be floored 3 8 17 18 19 20 23 24
INFO: iteration 6, average log likelihood -1.142315
WARNING: Variances had to be floored 1 5 6 9 23 24 31
INFO: iteration 7, average log likelihood -1.155029
WARNING: Variances had to be floored 1 9 10 17 18 19 20 23 24
INFO: iteration 8, average log likelihood -1.137585
WARNING: Variances had to be floored 3 5 6 8 16 23 24
INFO: iteration 9, average log likelihood -1.134575
WARNING: Variances had to be floored 9 17 18 19 20 23 24 31
INFO: iteration 10, average log likelihood -1.146335
WARNING: Variances had to be floored 1 5 6 9 10 23 24
INFO: iteration 11, average log likelihood -1.142051
WARNING: Variances had to be floored 8 17 18 19 20 23 24
INFO: iteration 12, average log likelihood -1.127297
WARNING: Variances had to be floored 1 3 5 6 9 23 24 31
INFO: iteration 13, average log likelihood -1.131103
WARNING: Variances had to be floored 9 10 17 18 19 20 23 24
INFO: iteration 14, average log likelihood -1.133865
WARNING: Variances had to be floored 1 5 6 8 23 24
INFO: iteration 15, average log likelihood -1.131863
WARNING: Variances had to be floored 3 9 17 18 19 20 23 24 31
INFO: iteration 16, average log likelihood -1.123590
WARNING: Variances had to be floored 1 5 6 9 10 23 24
INFO: iteration 17, average log likelihood -1.139241
WARNING: Variances had to be floored 8 17 18 19 20 23 24
INFO: iteration 18, average log likelihood -1.123021
WARNING: Variances had to be floored 1 3 5 6 9 16 23 24 31
INFO: iteration 19, average log likelihood -1.127678
WARNING: Variances had to be floored 9 10 17 18 19 20 23 24
INFO: iteration 20, average log likelihood -1.138543
WARNING: Variances had to be floored 1 5 6 8 23 24
INFO: iteration 21, average log likelihood -1.134913
WARNING: Variances had to be floored 9 17 18 19 20 23 24 31
INFO: iteration 22, average log likelihood -1.125492
WARNING: Variances had to be floored 1 3 5 6 9 10 23 24
INFO: iteration 23, average log likelihood -1.129879
WARNING: Variances had to be floored 8 17 18 19 20 23 24
INFO: iteration 24, average log likelihood -1.131533
WARNING: Variances had to be floored 1 5 6 9 23 24 31
INFO: iteration 25, average log likelihood -1.133417
WARNING: Variances had to be floored 3 9 10 17 18 19 20 23 24
INFO: iteration 26, average log likelihood -1.123803
WARNING: Variances had to be floored 1 5 6 8 23 24
INFO: iteration 27, average log likelihood -1.137889
WARNING: Variances had to be floored 1 9 17 18 19 20 23 24 31
INFO: iteration 28, average log likelihood -1.125156
WARNING: Variances had to be floored 3 5 6 9 10 23 24
INFO: iteration 29, average log likelihood -1.128691
WARNING: Variances had to be floored 1 8 16 17 18 19 20 23 24
INFO: iteration 30, average log likelihood -1.127486
WARNING: Variances had to be floored 5 6 9 23 24 31
INFO: iteration 31, average log likelihood -1.138979
WARNING: Variances had to be floored 1 9 10 17 18 19 20 23 24
INFO: iteration 32, average log likelihood -1.125980
WARNING: Variances had to be floored 3 5 6 8 23 24
INFO: iteration 33, average log likelihood -1.127773
WARNING: Variances had to be floored 1 9 17 18 19 20 23 24 31
INFO: iteration 34, average log likelihood -1.133130
WARNING: Variances had to be floored 5 6 9 10 23 24
INFO: iteration 35, average log likelihood -1.133538
WARNING: Variances had to be floored 1 3 8 17 18 19 20 23 24
INFO: iteration 36, average log likelihood -1.121664
WARNING: Variances had to be floored 5 6 9 23 24 31
INFO: iteration 37, average log likelihood -1.138792
WARNING: Variances had to be floored 1 9 10 17 18 19 20 23 24
INFO: iteration 38, average log likelihood -1.124205
WARNING: Variances had to be floored 3 5 6 8 16 23 24
INFO: iteration 39, average log likelihood -1.125475
WARNING: Variances had to be floored 1 9 17 18 19 20 23 24 31
INFO: iteration 40, average log likelihood -1.138399
WARNING: Variances had to be floored 5 6 9 10 23 24
INFO: iteration 41, average log likelihood -1.136207
WARNING: Variances had to be floored 1 8 17 18 19 20 23 24
INFO: iteration 42, average log likelihood -1.123350
WARNING: Variances had to be floored 1 3 5 6 9 23 24 31
INFO: iteration 43, average log likelihood -1.129415
WARNING: Variances had to be floored 9 10 17 18 19 20 23 24
INFO: iteration 44, average log likelihood -1.133022
WARNING: Variances had to be floored 5 6 8 23 24
INFO: iteration 45, average log likelihood -1.131691
WARNING: Variances had to be floored 1 3 9 17 18 19 20 23 24 31
INFO: iteration 46, average log likelihood -1.122848
WARNING: Variances had to be floored 5 6 9 10 23 24
INFO: iteration 47, average log likelihood -1.138136
WARNING: Variances had to be floored 1 8 16 17 18 19 20 23 24
INFO: iteration 48, average log likelihood -1.121449
WARNING: Variances had to be floored 5 6 9 23 24 31
INFO: iteration 49, average log likelihood -1.136603
WARNING: Variances had to be floored 1 3 9 10 17 18 19 20 23 24
INFO: iteration 50, average log likelihood -1.122914
INFO: EM with 100000 data points 50 iterations avll -1.122914
59.0 data points per parameter
5: avll = [-1.2204,-1.20651,-1.21449,-1.196,-1.16634,-1.14231,-1.15503,-1.13758,-1.13458,-1.14634,-1.14205,-1.1273,-1.1311,-1.13386,-1.13186,-1.12359,-1.13924,-1.12302,-1.12768,-1.13854,-1.13491,-1.12549,-1.12988,-1.13153,-1.13342,-1.1238,-1.13789,-1.12516,-1.12869,-1.12749,-1.13898,-1.12598,-1.12777,-1.13313,-1.13354,-1.12166,-1.13879,-1.1242,-1.12548,-1.1384,-1.13621,-1.12335,-1.12942,-1.13302,-1.13169,-1.12285,-1.13814,-1.12145,-1.1366,-1.12291]
[-1.46746,-1.46761,-1.4675,-1.46721,-1.46438,-1.45354,-1.44498,-1.44275,-1.4418,-1.44116,-1.44063,-1.44011,-1.43955,-1.43893,-1.43825,-1.43759,-1.43702,-1.43651,-1.43603,-1.43561,-1.43524,-1.4349,-1.4346,-1.43434,-1.4341,-1.43389,-1.43368,-1.43344,-1.43314,-1.43277,-1.43245,-1.43224,-1.43209,-1.43199,-1.43191,-1.43184,-1.43179,-1.43174,-1.43169,-1.43165,-1.43161,-1.43156,-1.43152,-1.43148,-1.43144,-1.4314,-1.43138,-1.43135,-1.43134,-1.43132,-1.43131,-1.43142,-1.43128,-1.43036,-1.42252,-1.40501,-1.39504,-1.39066,-1.38765,-1.38568,-1.38453,-1.38381,-1.38327,-1.38286,-1.38255,-1.38232,-1.38216,-1.38204,-1.38196,-1.3819,-1.38185,-1.38182,-1.38179,-1.38177,-1.38175,-1.38173,-1.38172,-1.3817,-1.38169,-1.38169,-1.38168,-1.38167,-1.38166,-1.38166,-1.38165,-1.38165,-1.38165,-1.38164,-1.38164,-1.38164,-1.38163,-1.38163,-1.38163,-1.38163,-1.38163,-1.38162,-1.38162,-1.38162,-1.38162,-1.38162,-1.38162,-1.38183,-1.38164,-1.3811,-1.37585,-1.35568,-1.33489,-1.32299,-1.31782,-1.3158,-1.31489,-1.3144,-1.31412,-1.31395,-1.31385,-1.31378,-1.31373,-1.31369,-1.31366,-1.31363,-1.31359,-1.31355,-1.31349,-1.31342,-1.31333,-1.31321,-1.31307,-1.31292,-1.31278,-1.31265,-1.31252,-1.3124,-1.31228,-1.31215,-1.31201,-1.31189,-1.31178,-1.31169,-1.31163,-1.31158,-1.31155,-1.31153,-1.31151,-1.31149,-1.31148,-1.31146,-1.31144,-1.31141,-1.31139,-1.31136,-1.31133,-1.3116,-1.31121,-1.30853,-1.28942,-1.27256,-1.23767,-1.24824,-1.22452,-1.23784,-1.22397,-1.22543,-1.20761,-1.23542,-1.21371,-1.21985,-1.21471,-1.21856,-1.21491,-1.22932,-1.21088,-1.21652,-1.22286,-1.2238,-1.20691,-1.22471,-1.21748,-1.22008,-1.21537,-1.21941,-1.21391,-1.22869,-1.21021,-1.21579,-1.22254,-1.22361,-1.20663,-1.22437,-1.21745,-1.22007,-1.21527,-1.2193,-1.2139,-1.22869,-1.21018,-1.21575,-1.22254,-1.22361,-1.20662,-1.22436,-1.21745,-1.2204,-1.20651,-1.21449,-1.196,-1.16634,-1.14231,-1.15503,-1.13758,-1.13458,-1.14634,-1.14205,-1.1273,-1.1311,-1.13386,-1.13186,-1.12359,-1.13924,-1.12302,-1.12768,-1.13854,-1.13491,-1.12549,-1.12988,-1.13153,-1.13342,-1.1238,-1.13789,-1.12516,-1.12869,-1.12749,-1.13898,-1.12598,-1.12777,-1.13313,-1.13354,-1.12166,-1.13879,-1.1242,-1.12548,-1.1384,-1.13621,-1.12335,-1.12942,-1.13302,-1.13169,-1.12285,-1.13814,-1.12145,-1.1366,-1.12291]
32Ã—26 Array{Float64,2}:
 -0.139908      0.166387     0.00445236  -0.00991828   0.0266785   0.444624    -0.0535133   -0.234739     -0.107798    -0.112363    -0.129499     0.110268     -0.00523925  -0.128776    -0.0803848    0.104131     0.00489344   0.0767687     0.0882113   -0.0178532   -0.121185      0.272821     0.0338868    0.0159391    0.00300439  -0.781889  
 -0.0950051     0.0166544    0.0447642   -0.0807324   -0.112236   -0.231635     0.0544338   -0.0307032    -0.101835    -0.176857    -0.0506682    0.0714643     0.034369    -0.165242     0.048051     0.105336     0.0439739    0.0867891     0.140933    -0.00425514  -0.123949      0.103456     0.0216101    0.0140319    0.00300384   0.726583  
  0.123256      0.0964941    0.0573412   -0.103252    -0.105073    0.00016605  -0.173665    -0.130466     -0.0960545    0.0548209    0.17572      0.119352      0.0528311   -0.327836     0.0717224   -0.0381746    0.0373109    0.0705945    -0.0479851   -0.10929     -0.0483317     0.0716495    0.107326     0.0605908   -0.0666166   -0.155876  
 -0.0651574    -0.0675346   -0.0621888    0.0844603    0.0203369   0.062266     0.0312834    0.0912006     0.00729796  -0.113173    -0.0657093   -0.0334542    -0.00872294  -0.160889    -0.0404052    0.0125889   -0.090529     0.0112837     0.0381317   -0.0482156   -0.00113357    0.0314617    0.032314    -0.00550933   0.0520877    0.010365  
  0.0313732     0.119854    -0.0461329   -0.155511     0.145773   -0.158188     0.0331439    0.289063      0.20051     -0.109564    -0.774073     0.0105235     0.0910094   -0.0764695   -0.0278516    0.0554552    0.158483    -0.0158858     0.120092     0.0958917    0.167886     -0.189272     0.20607      0.100471    -0.0439752    0.205389  
  0.0358716     0.0213052   -0.0409754    0.0709265    0.145702   -0.0799055    0.0319287   -0.228878     -0.119711     0.00722588   0.696596     0.000183696   0.104715    -0.0859166   -0.0316833    0.0480768    0.25208     -0.0153301     0.114671     0.0990534    0.0106063    -0.189982     0.204472     0.0387781   -0.0447552   -0.263601  
  0.0406523    -0.19831     -0.126044    -0.126864    -0.122379    0.00113099   0.261698     0.0512083    -0.323159     0.0262797    0.138251    -0.141308      0.0619725    0.0110492    0.0575923   -0.0526838   -0.113458    -0.00598323    0.097247    -0.0723457    0.000680289  -0.0243894    0.0806126    0.104888    -0.0278894    0.0922651 
  0.039565      0.115574     0.178776    -0.13352     -0.0231473   0.0188435    0.168498    -0.0355121    -0.211417    -0.0294818    0.0508436   -0.047314     -0.109364     0.0113999   -0.0536361    0.0595918    0.00672068   0.000510306   0.121251     0.0138014    0.11007      -0.164265     0.0698882   -0.0137402   -0.0657651    0.0310679 
 -0.00244056    0.0556553   -0.0161786    0.17883      0.162308    0.0580375   -0.194804    -0.0326903     0.0542172   -0.0698014    0.0407348    0.0603246     0.158734    -0.0455352    0.190626     0.0583504    0.131198    -0.0874644    -0.0295995   -0.122826    -0.177434     -0.0988247   -0.0954298   -0.0525774   -0.0806265   -0.0176085 
  0.00656288    0.256121     0.0549254    0.147095     0.0140141   0.123313    -0.0648741    0.201326     -0.0103143    0.112991    -0.128738     0.00522338    0.114603     0.00595275   0.113081    -0.0805569    0.00563657  -0.014587      0.0233242    0.046168    -0.120524      0.063679    -0.0642933    0.00862625  -0.0242627    0.0758617 
 -0.00884789   -0.0592742   -0.0555824    0.0999075   -0.106791   -0.0623234    0.0315784   -0.0413642     0.0538115    0.0630608    0.107614     0.0346302     0.101751     0.0385172    0.0729721    0.0889998   -0.0334021   -0.107296      0.0420418   -0.0945283    0.0293574     0.0136851    0.00818073  -0.12053      0.107296    -0.0467795 
 -0.0734097    -0.00966711   0.103675     0.00825535  -0.0849541   0.138655    -0.0575867   -0.0269742     0.0887608    0.0474733   -0.0864191   -0.0539462     0.0466095    0.163893    -0.032542    -0.13539      0.00298786   0.0666153    -0.0756696   -0.0734668    0.0323032    -0.00589377  -0.0402226    0.00136513  -0.101722     0.0546491 
  0.0525625    -0.255405     0.145821     0.179289     0.123808   -0.0148915   -0.0121122   -0.318656      0.0208138   -0.0274689   -0.673001     0.111966     -0.115761    -0.0843031    0.0952677    0.0405457    0.148644     0.168035      0.102457     0.141845     0.0642887     0.0582685   -0.00653394   0.0197775    0.0814728    0.193445  
 -0.0592244    -0.0720201    0.147903     0.177662     0.0595113  -0.0252584    0.222097     0.0991989    -0.052377    -0.032205     0.51419      0.0920114    -0.163235    -0.0571701   -0.11169      0.0279956   -0.0108071    0.165828      0.059796    -0.195892     0.0909218     0.066058     0.0835635   -0.0118467    0.114393     0.0701182 
  0.110959      0.0651518    0.038812    -0.0951274    0.0642965   0.00744067  -0.230099     0.0691766     0.110288    -0.0130063    0.0986888    0.0131685    -0.0581213   -0.057846    -0.110866    -0.0457438    0.133129     0.0165191     0.125051     0.0664783    0.0127395     0.0160086   -0.0594065    0.013743    -0.0549375   -0.0336831 
  0.0832528    -0.00843253   0.107185    -0.0548094    0.131509    0.0604646   -0.0622963   -0.0322171    -0.0766249    0.0879059   -0.0128394   -0.0473362    -0.125444    -0.0386591   -0.0312695    0.14761      0.0760011    0.063541      0.0127741   -0.00449955   0.0932929    -0.0715685    0.0873976   -0.0202737   -0.197377     0.21315   
  0.0316717    -0.044272     1.47049      0.0690075   -0.0158777  -0.0655022   -0.0470908   -0.0372714     0.100529     0.0751028    0.119907    -0.0432571    -0.134029    -0.00286692  -0.0044367   -0.045105    -0.143712    -0.10353      -0.0439119   -0.0855865    0.00674671   -0.115499    -0.260434    -0.0274382   -0.0401613   -0.0781597 
  0.0521936    -0.110342    -1.40574      0.0733178   -0.0486769  -0.0675189   -0.0803698    0.0398149     0.11941      0.0741432    0.0920105    0.0270898    -0.0335242   -0.00141036  -0.00476699   0.00298015  -0.143482    -0.0628577    -0.0436338   -0.0883247    0.144959     -0.118442    -0.212213     0.0493644   -0.059799    -0.0368605 
  0.132507     -0.0517732    0.104165     0.0133306   -0.248365   -0.026637    -0.0177084   -0.194095     -0.0155476   -0.055941    -0.00266732   0.175448      0.120155    -0.096754     0.0568495    0.0531099    0.0163117   -0.0830571    -0.0895753   -0.0676285   -0.0361123     0.15936     -2.01106     -0.0447622    0.0928899    0.10715   
  0.13466      -0.0900687    0.107512    -0.0329447   -0.144544   -0.0935503   -0.0938219   -0.158298     -0.0425535   -0.10201      0.0540286    0.179674      0.119963    -0.0951568    0.0563538    0.0871484    0.0152212   -0.083982     -0.104589    -0.0754186   -0.00776827    0.159252     1.5963      -0.0443511    0.0762295    0.0972975 
 -0.0886683    -0.0491765   -0.0941238   -0.0281575    0.145581    0.0673258   -0.637968    -0.000466746  -0.125279    -0.144988    -0.400597     0.17871      -0.0298479    0.060424     0.0986584    0.18379     -0.0131062   -0.0624379    -0.0845679    0.113105     0.109392      0.0558221   -0.130905     0.166475    -0.146305    -0.131694  
 -0.0638963     0.0222274   -0.0885194    0.0719627    0.0255145   0.198449     0.291304    -0.0261702    -0.0746243   -0.0443355   -0.187866     0.0536663    -0.203062     0.0869741    0.0403661    0.0864309   -0.00650115  -0.226269     -0.0550308    0.128184     0.129903      0.0476953   -0.08688      0.162664    -0.0566705   -0.128206  
  0.0993121    -0.010343     0.159035    -0.00984433   0.0219419   0.0177626   -0.170124     0.0735093     0.134019     0.119375    -0.231862    -0.158298      0.132176     0.0289969    0.0592194    0.305354    -0.00768062  -0.0612356     0.0652572    0.0391914   -0.0988441    -0.0850323   -0.823721     0.0261842    0.115842     0.00523457
  0.0976536    -0.0338655    0.208413     0.0503628    0.05054     0.0164541   -0.169833     0.110161     -0.422428     0.0597802   -0.231254     0.075162     -0.0702527    0.0292289    0.0619875   -0.390263     0.00595472  -0.0559208    -0.016383    -0.0572878   -0.0917495    -0.084912     0.909206     0.0226102   -0.0650582    0.00520864
  0.0452013    -1.15905e-5   0.0420956   -0.0102034   -0.0348187   0.0376656    0.00543109  -0.0284727    -0.0190911    0.0834948   -0.0486665   -0.0193623    -0.0700638    0.00533226   0.0359613    0.0467378    0.0142325   -0.0132192    -0.0123431    0.0129305   -0.0640082    -0.0328487    0.0551633    0.0357301    0.0891705   -0.0306604 
 -0.0508226     0.0176727   -0.0532979   -0.0883986   -0.0372283   0.0193406    0.105623    -0.0307682    -0.00249885  -0.0425334    0.0486138    0.03587      -0.0731415    0.0222233    0.0837037    0.111419    -0.0243846   -0.0192245    -0.0102523   -0.0471708   -0.00611015    0.10507     -0.0178438   -0.0323007   -0.0957911   -0.0487651 
 -0.0414221    -0.0418597    0.0925053   -0.0992225   -0.0936683   0.00513698  -0.0113505   -0.0771398    -0.132001     0.16576     -0.0525255    0.0275273     0.0295708   -0.106129     0.0361687   -0.0519484    0.00269807   0.0439851     0.015039    -0.00889107  -0.00331826    0.0707089    0.0723975    0.0324414   -0.0849662   -0.0204154 
 -0.000442242   0.0469729   -0.0150668   -0.040479     0.0695187   0.125315     0.0828074    0.0694031    -0.0630643    0.0363424   -0.0410156   -0.000670835   0.0330331    0.0311024   -0.0484415   -0.0139218    0.182936    -0.0283397    -0.0223594   -0.0189293   -0.0903299    -0.0641983    0.0473724   -0.00396141  -0.0153098    0.120413  
  0.171406     -0.203101    -0.0583817    0.0464852    0.102271    0.0630351    0.0597472    0.227671      0.0639074    0.0574221   -0.0517744    0.0373614    -0.0792747    0.0322742    0.185053    -0.0467808   -0.33035     -0.147765      0.00239438   0.0367043   -0.092177      0.041176     0.107149     0.00516911  -0.108308    -0.0377918 
  0.105482     -0.122445    -0.0237982   -0.0692357    0.102555    0.0396352   -0.019191    -0.129151      0.0331038    0.027657    -0.121536    -0.00138854   -0.0788362   -0.0308092    0.139043    -0.0676555    0.236744    -0.201621     -0.0140792    0.122557    -0.138236     -0.200037     0.0886489   -0.166852    -0.062039    -0.0150112 
 -0.0338431     0.192171    -0.0180598    0.00911107   0.0327362   0.0381673    0.0203527    0.208635      0.1624       0.0251862    0.151312    -0.133577      0.0123212    0.0216834   -0.0137967    0.0540363    0.0422782    0.150018     -0.0592887    0.0881723   -0.0497554    -0.026191     0.0754718    0.0342396    0.0348907   -0.12108   
 -0.0942413    -0.137904     0.141422     0.0309603   -0.0671624  -0.0382679   -0.039907    -0.0772557    -0.0156518    0.158275    -0.0867309   -0.105493     -0.0265096    0.205563    -0.0956146   -0.0583768   -0.0963946    0.131208     -0.0361033    0.184874    -0.0560588     0.0996197    0.105327     0.138968    -0.156038    -0.0418477 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 5 6 8 23 24
INFO: iteration 1, average log likelihood -1.138900
WARNING: Variances had to be floored 1 5 6 8 9 17 18 19 20 23 24 31
INFO: iteration 2, average log likelihood -1.112428
WARNING: Variances had to be floored 3 5 6 8 9 10 23 24
INFO: iteration 3, average log likelihood -1.123583
WARNING: Variances had to be floored 5 6 8 17 18 19 20 23 24 31
INFO: iteration 4, average log likelihood -1.124373
WARNING: Variances had to be floored 1 5 6 8 9 23 24
INFO: iteration 5, average log likelihood -1.125893
WARNING: Variances had to be floored 3 5 6 8 9 10 17 18 19 20 23 24 31
INFO: iteration 6, average log likelihood -1.108366
WARNING: Variances had to be floored 5 6 8 23 24
INFO: iteration 7, average log likelihood -1.135596
WARNING: Variances had to be floored 1 5 6 8 9 16 17 18 19 20 23 24 31
INFO: iteration 8, average log likelihood -1.108515
WARNING: Variances had to be floored 3 5 6 8 9 10 23 24
INFO: iteration 9, average log likelihood -1.124955
WARNING: Variances had to be floored 5 6 8 17 18 19 20 23 24 31
INFO: iteration 10, average log likelihood -1.123765
INFO: EM with 100000 data points 10 iterations avll -1.123765
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.020735e+06
      1       7.646462e+05      -2.560889e+05 |       32
      2       7.315389e+05      -3.310730e+04 |       32
      3       7.134167e+05      -1.812215e+04 |       32
      4       7.031989e+05      -1.021779e+04 |       32
      5       6.978673e+05      -5.331619e+03 |       32
      6       6.946712e+05      -3.196116e+03 |       32
      7       6.918468e+05      -2.824440e+03 |       32
      8       6.894135e+05      -2.433308e+03 |       32
      9       6.882520e+05      -1.161429e+03 |       32
     10       6.877233e+05      -5.287568e+02 |       32
     11       6.873805e+05      -3.427790e+02 |       32
     12       6.870758e+05      -3.046897e+02 |       32
     13       6.867174e+05      -3.583547e+02 |       32
     14       6.862824e+05      -4.350565e+02 |       32
     15       6.857865e+05      -4.959075e+02 |       32
     16       6.854385e+05      -3.479666e+02 |       32
     17       6.852907e+05      -1.478548e+02 |       32
     18       6.852176e+05      -7.301480e+01 |       32
     19       6.851806e+05      -3.708144e+01 |       32
     20       6.851574e+05      -2.318746e+01 |       32
     21       6.851422e+05      -1.512811e+01 |       30
     22       6.851332e+05      -9.068885e+00 |       31
     23       6.851282e+05      -4.997212e+00 |       27
     24       6.851242e+05      -3.978053e+00 |       24
     25       6.851208e+05      -3.451057e+00 |       23
     26       6.851175e+05      -3.292212e+00 |       26
     27       6.851149e+05      -2.568939e+00 |       24
     28       6.851124e+05      -2.440893e+00 |       22
     29       6.851108e+05      -1.694366e+00 |       20
     30       6.851092e+05      -1.555003e+00 |       20
     31       6.851079e+05      -1.299376e+00 |       14
     32       6.851070e+05      -9.473218e-01 |       13
     33       6.851064e+05      -5.582910e-01 |       10
     34       6.851059e+05      -4.984777e-01 |       12
     35       6.851055e+05      -4.054251e-01 |        9
     36       6.851049e+05      -5.446977e-01 |        8
     37       6.851041e+05      -8.230017e-01 |        7
     38       6.851037e+05      -3.838173e-01 |        5
     39       6.851034e+05      -3.008101e-01 |        5
     40       6.851032e+05      -2.731938e-01 |        3
     41       6.851030e+05      -1.200871e-01 |        2
     42       6.851030e+05      -2.242680e-02 |        0
     43       6.851030e+05       0.000000e+00 |        0
K-means converged with 43 iterations (objv = 685103.0217029821)
INFO: K-means with 32000 data points using 43 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.382165
INFO: iteration 2, average log likelihood -1.349368
INFO: iteration 3, average log likelihood -1.313483
INFO: iteration 4, average log likelihood -1.267868
WARNING: Variances had to be floored 32
INFO: iteration 5, average log likelihood -1.213227
WARNING: Variances had to be floored 31
INFO: iteration 6, average log likelihood -1.172981
WARNING: Variances had to be floored 1 7
INFO: iteration 7, average log likelihood -1.124398
WARNING: Variances had to be floored 6 22 26 30 32
INFO: iteration 8, average log likelihood -1.101289
WARNING: Variances had to be floored 4 11 31
INFO: iteration 9, average log likelihood -1.125641
INFO: iteration 10, average log likelihood -1.134359
WARNING: Variances had to be floored 1 7 26 30 32
INFO: iteration 11, average log likelihood -1.086901
WARNING: Variances had to be floored 11
INFO: iteration 12, average log likelihood -1.117807
WARNING: Variances had to be floored 4 6 22 31
INFO: iteration 13, average log likelihood -1.085153
WARNING: Variances had to be floored 27 32
INFO: iteration 14, average log likelihood -1.112730
WARNING: Variances had to be floored 7 26 30
INFO: iteration 15, average log likelihood -1.108182
WARNING: Variances had to be floored 1 11
INFO: iteration 16, average log likelihood -1.098341
WARNING: Variances had to be floored 22 31 32
INFO: iteration 17, average log likelihood -1.080940
WARNING: Variances had to be floored 6 27 30
INFO: iteration 18, average log likelihood -1.102173
WARNING: Variances had to be floored 1 4 7 11 26
INFO: iteration 19, average log likelihood -1.093116
WARNING: Variances had to be floored 22 32
INFO: iteration 20, average log likelihood -1.111846
WARNING: Variances had to be floored 31
INFO: iteration 21, average log likelihood -1.117042
WARNING: Variances had to be floored 6 27 30
INFO: iteration 22, average log likelihood -1.084523
WARNING: Variances had to be floored 7 11 22 26 32
INFO: iteration 23, average log likelihood -1.084383
WARNING: Variances had to be floored 1 31
INFO: iteration 24, average log likelihood -1.126553
WARNING: Variances had to be floored 4
INFO: iteration 25, average log likelihood -1.109700
WARNING: Variances had to be floored 6 22 27 30 32
INFO: iteration 26, average log likelihood -1.062564
WARNING: Variances had to be floored 7 11 31
INFO: iteration 27, average log likelihood -1.113566
WARNING: Variances had to be floored 1 26
INFO: iteration 28, average log likelihood -1.121201
WARNING: Variances had to be floored 4 30 32
INFO: iteration 29, average log likelihood -1.099559
WARNING: Variances had to be floored 11 22 31
INFO: iteration 30, average log likelihood -1.090582
WARNING: Variances had to be floored 6 7 27
INFO: iteration 31, average log likelihood -1.099842
WARNING: Variances had to be floored 26 32
INFO: iteration 32, average log likelihood -1.114962
WARNING: Variances had to be floored 1 11 22 30 31
INFO: iteration 33, average log likelihood -1.077831
WARNING: Variances had to be floored 4 7
INFO: iteration 34, average log likelihood -1.113194
WARNING: Variances had to be floored 26 27 32
INFO: iteration 35, average log likelihood -1.099922
WARNING: Variances had to be floored 6 22 30
INFO: iteration 36, average log likelihood -1.100639
WARNING: Variances had to be floored 11 31
INFO: iteration 37, average log likelihood -1.104561
WARNING: Variances had to be floored 1 7
INFO: iteration 38, average log likelihood -1.093435
WARNING: Variances had to be floored 4 22 26 27 30 32
INFO: iteration 39, average log likelihood -1.073718
WARNING: Variances had to be floored 11 31
INFO: iteration 40, average log likelihood -1.134590
WARNING: Variances had to be floored 6
INFO: iteration 41, average log likelihood -1.135895
INFO: iteration 42, average log likelihood -1.110879
WARNING: Variances had to be floored 1 7 11 22 32
INFO: iteration 43, average log likelihood -1.058768
WARNING: Variances had to be floored 4 27 30 31
INFO: iteration 44, average log likelihood -1.109640
WARNING: Variances had to be floored 6 26
INFO: iteration 45, average log likelihood -1.129437
WARNING: Variances had to be floored 32
INFO: iteration 46, average log likelihood -1.111183
WARNING: Variances had to be floored 11 22 27
INFO: iteration 47, average log likelihood -1.074447
WARNING: Variances had to be floored 1 7 26 30
INFO: iteration 48, average log likelihood -1.094635
WARNING: Variances had to be floored 4 6 31 32
INFO: iteration 49, average log likelihood -1.113296
INFO: iteration 50, average log likelihood -1.137401
INFO: EM with 100000 data points 50 iterations avll -1.137401
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0525819   -0.0270429    0.0470306    -0.0809564    0.142097    -0.014939    -0.0125925   -0.0252258    -0.0946492    0.0311597   -0.0341383  -0.0666985  -0.0592345   -0.0467403   -0.0283049    0.145198     0.027769      0.0389722    0.0466879    0.0394248    0.139306    -0.126179    0.126117    -0.0269366   -0.130147     0.219251  
 -0.0747685   -0.0115154   -0.0896274     0.0201183    0.0875191    0.128447    -0.169626    -0.0113976    -0.108854    -0.0917954   -0.292704    0.117405   -0.117211     0.0725534    0.0720493    0.133097    -0.00987417   -0.132909    -0.0660358    0.120724     0.115073     0.0482869  -0.110827     0.16447     -0.102429    -0.126389  
  0.0467471    0.0124422   -0.0405046     0.0578481    0.0599135    0.166374     0.048573     0.242615     -0.0833731    0.029753     0.141162   -0.248746    0.0554444    0.0486615   -0.102503    -0.0122603    0.129673     -0.0684271    0.00985478  -0.0114642   -0.140983    -0.102919   -0.00525117   0.0702679   -0.050566    -0.0508408 
 -0.0686468   -0.0240451    0.362821      0.00563736  -0.10443      0.132511    -0.044244    -0.0107834     0.142588     0.0484111   -0.0948579  -0.104307    0.0494413    0.365121    -0.0195704   -0.182558    -0.0694796     0.0663186   -0.0782033   -0.0441616    0.0488455   -0.0476139  -0.0312323    0.0295154   -0.1088       0.0221911 
  0.0904384   -0.07494      0.0214447     0.0278226   -0.11452     -0.0655081   -0.0625563   -0.086086      0.0377267   -0.00448604   0.0708399   0.090168    0.0288368   -0.0506281    0.0268616    0.0273183   -0.0621634    -0.0829432   -0.0700096   -0.0796644    0.0280704    0.0260495  -0.0837376   -0.0191001    0.0210766    0.0253428 
 -0.0298732    0.173379     0.0519883     0.108378    -0.0238216    0.139062    -0.080323     0.12869       0.0197476    0.0854568   -0.145224   -0.0177845   0.109435     0.0130853    0.124569    -0.105269    -0.00948432    0.00320073  -0.01603      0.0566172   -0.147655     0.117096   -0.0966174    0.00899151  -0.0603424    0.0905553 
  0.0185727    0.0674334   -0.00290517   -0.0375665    0.12339     -0.113875     0.032144     0.0697375     0.130987    -0.0738132   -0.0522434   0.0211076   0.073023    -0.0630782   -0.0269426    0.00501598   0.25087      -0.00592437   0.102493     0.0928197    0.0495916   -0.17144     0.192437     0.103026    -0.0732595   -0.151196  
  0.170739     0.110892     0.00777136    0.109098     0.0137171   -0.00169422   0.0162201   -0.115752      0.119215     0.204265    -0.0846704  -0.099873   -0.0128845   -0.0109984    0.024767     0.0283975    0.15308       0.115743     0.0807483   -0.0621531   -0.245059     0.114855   -0.0170698    0.085623     0.226961     0.0078779 
  0.151478     0.136454     0.142667      0.0599109    0.0753308    0.164349    -0.109082     0.121328      0.04611      0.077136    -0.0411812  -0.0338208  -0.0675613   -0.0210686   -0.108907    -0.0311791    0.275331      0.0856481    0.0988383   -0.0288098    0.00332835   0.063722   -0.0646855    0.0383694   -0.237848     0.0574669 
 -0.0437391   -0.0422272    0.0926501    -0.0990054   -0.0935317    0.00547446  -0.0135318   -0.0771702    -0.13258      0.16649     -0.0504702   0.0283307   0.0303227   -0.106789     0.0369335   -0.0460552    0.00393834    0.047295     0.0127542   -0.00705323  -0.00306125   0.0671428   0.0722292    0.0322762   -0.0845686   -0.0201759 
  0.11955      0.0942763    0.0583283    -0.104019    -0.104311     0.00667239  -0.171002    -0.129699     -0.0967472    0.0533148    0.166832    0.117363    0.0569552   -0.323221     0.0719091   -0.038849     0.0395043     0.0634198   -0.0441814   -0.107768    -0.0534755    0.0682817   0.104952     0.0585527   -0.0672288   -0.148391  
 -0.127776    -0.172149    -0.0638522     0.0589946   -0.00470435  -0.024428     0.145814    -0.0322493     0.0379221    0.0192367   -0.0834882   0.0713667  -0.106236     0.0145678    0.00056862   0.039465    -0.0263791     0.0766021    0.0474672    0.171346    -0.104391     0.0418521   0.134546    -0.0116087    0.0144772    0.0329754 
 -0.0670907    0.119587     0.0214121    -0.121979     0.118324     0.102505     0.100244    -0.100221     -0.0276876    0.0360726   -0.20215     0.218626    0.0156179    0.0218636    0.0440727    0.0152851    0.220391      0.0117297   -0.0354624   -0.0498623   -0.0681221   -0.0312959   0.101987    -0.0770601    0.0722163    0.344359  
  0.144394    -0.188588    -0.0280291    -0.122915    -0.0278507   -0.0427056    0.138392     0.0130568    -0.0893231    0.0341618   -0.105567    0.320105    0.046792    -0.0361858   -0.254943    -0.241646     0.287111     -0.0405517   -0.155426     0.102269     0.0767187   -0.0627845   0.0748027    0.0206579   -0.351133    -0.177275  
 -0.0952482   -0.134869     0.140578      0.0430416   -0.0638129   -0.0309493   -0.0379699   -0.0749044    -0.0124892    0.154284    -0.0845282  -0.103533   -0.0169718    0.210119    -0.0912113   -0.0594587   -0.0919602     0.131597    -0.0376316    0.181415    -0.0565058    0.0999005   0.101339     0.143095    -0.151931    -0.0400125 
 -0.036331    -0.00068498  -0.245571     -0.0777395   -0.0101105   -0.0121421    0.129764    -0.0281482     0.178854    -0.0357489    0.121786   -0.0208943  -0.165473    -0.0899009    0.0305973    0.266173    -0.0743385    -0.0527456    0.010987    -0.149503    -0.0423625    0.154905   -0.0397967   -0.0772288   -0.13537     -0.168275  
  0.0808914    0.0272596   -0.0397355    -0.194752     0.0634107   -0.0905069   -0.295163     0.00860092    0.14302     -0.0453317    0.200101    0.0232025  -0.0286454   -0.0858714   -0.100246    -0.0214961    0.0439521    -0.0284392    0.151873     0.128039     0.01795     -0.0384415  -0.0177119   -0.0170716    0.0667268   -0.0557009 
 -0.00963584  -0.0593136   -0.0622858     0.0962685   -0.107214    -0.0585615    0.0285514   -0.0396355     0.0536015    0.0616141    0.110638    0.0319254   0.0994274    0.0392552    0.0754917    0.0878387   -0.0343128    -0.109049     0.0432614   -0.0964028    0.0276295    0.0151012   0.011745    -0.121015     0.106993    -0.0529319 
 -0.00199167  -0.0494944   -0.0638706     0.19801      0.0545371   -0.121228     0.0350462    0.036258      0.0442864   -0.0298295   -0.148406   -0.0332695   0.0256656   -0.212932    -0.0628589    0.0650342   -0.134502      0.0839026    0.0985062    0.0530727    0.0893879    0.0206335   0.121731     0.119839     3.30487e-5   0.0435612 
  0.0134497   -0.169914     0.162979      0.178483     0.100064    -0.0157894    0.0933612   -0.134324     -0.024627    -0.032201    -0.128969    0.105021   -0.128279    -0.0776887    0.00154137   0.0348633    0.0806793     0.16685      0.0803326   -0.0251887    0.0949705    0.0608767   0.0339923    0.00517408   0.0927738    0.13826   
 -0.12092      0.00767305  -0.0150557    -0.0350884   -0.0258339    0.187619     0.0174854    0.000152726  -0.0657591   -0.162747    -0.0317033   0.0276917  -0.0187216   -0.132382    -0.0226338    0.0347128   -0.00283421    0.00914735   0.0469848   -0.0807655   -0.110087     0.110529   -0.0115899   -0.0562663    0.0497786   -0.0537505 
  0.0669697   -0.0122036    0.175765      0.0119326    0.0113081    0.0192513   -0.145433     0.0738712    -0.177304     0.0958696   -0.252973   -0.0298641   0.0418285    0.0378171    0.0616418   -0.0388976    0.000822742  -0.0507793    0.00702068  -0.0348528   -0.077368    -0.0833656  -0.00706907   0.0140939    0.00664589   0.00578671
  0.149267    -0.168647    -0.0428914    -0.00657288   0.103139     0.0504625    0.024932     0.0628185     0.0506056    0.0451663   -0.077122    0.0222457  -0.0753353    0.00241194   0.167154    -0.056618    -0.0673445    -0.171464    -0.00582467   0.07515     -0.12357     -0.0689827   0.106239    -0.0768397   -0.0888168   -0.0301086 
 -0.0596808   -0.0369639    0.0114012    -0.0713967   -0.175495     0.0813897   -0.00485461  -0.0630086    -0.156405    -0.0211745   -0.307569   -0.11873    -0.1784       0.00820311  -0.00224015  -0.0103997    0.0350291    -0.0760952    0.0608328    0.0539531    0.0557323   -0.06383    -0.0248436   -0.031848     0.0190991    0.112704  
  0.036624    -0.196005    -0.122768     -0.126228    -0.122028     0.0015707    0.260132     0.0492729    -0.335372     0.0252344    0.135485   -0.141087    0.0611827    0.0123265    0.0554108   -0.0532237   -0.111275     -0.00613204   0.0965063   -0.076839    -0.00306449  -0.025858    0.0801449    0.0999334   -0.0282015    0.0965655 
 -0.0285708    0.217665    -0.0187703    -0.0179253    0.0379635    0.0501443    0.0340454    0.248597      0.17227      0.0359202    0.148161   -0.141089   -0.0134933    0.0383249   -0.0280847    0.0408713    0.0234569     0.269843    -0.0619391    0.105638    -0.0368343   -0.030055    0.101574     0.0356766    0.0640647   -0.125368  
 -0.0685591    0.0310286    0.125258     -0.12028     -0.0671304    0.0533009    0.056647    -0.0303407    -0.164145    -0.0622396    0.0426327   0.0699543   0.00303321   0.119087     0.125517    -0.0417025    0.0107061     0.0234439    0.00849933   0.0679123    0.0212047    0.0615974  -0.0199354   -0.0129723   -0.0826161    0.0684346 
  0.0457309   -0.0815403    0.0448248    -0.010432     0.0282229    0.0564614   -0.0266632    0.15844       0.00808825   0.00868316   0.146545    0.0255996   0.0462992   -0.0148956    0.0900004    0.0700543   -0.110732     -0.00282271  -0.0433548    0.0625237   -0.0118921   -0.114727    0.166095     0.0151486    0.0109865   -0.0985388 
  0.0187723    0.0855881    0.119777     -0.0805104   -0.0118424   -0.00807552  -0.0150212   -0.151147     -0.0813778    0.151774    -0.14804     0.166981   -0.173718     0.0584892    0.0138421    0.0703403    0.0452831    -0.159623    -0.223658    -0.0141348   -0.0344302   -0.0691173   0.0985243    0.0819495    0.0792527   -0.109571  
 -0.0104845    0.10407     -0.000266222   0.173734     0.131853     0.0801754   -0.195145     0.0290013     0.0620196   -0.0210744    0.0292477   0.0402632   0.146965    -0.0368638    0.175194     0.0271357    0.0956773    -0.0861229   -0.01603     -0.123726    -0.168928    -0.078593   -0.0930206   -0.0288543   -0.0820395    0.00205818
  0.0178612    0.11958      0.181607     -0.104212    -0.0336116    0.0453331    0.197921    -0.0123414    -0.258481    -0.00952404   0.0423032  -0.0636007  -0.0968442    0.0139682   -0.0768802    0.0405877   -0.00176481    0.0109682    0.10586      0.0191013    0.186624    -0.156221    0.0652114   -0.0026749   -0.0696174    0.0210582 
 -0.0515081   -0.00214296  -0.220937      0.00548851  -0.0869286    0.110912    -0.01965     -0.0480268     0.197317     0.0321917   -0.0602453   0.0318327   0.0573016    0.0206297   -0.161036    -0.142379     0.165363      0.119438    -0.0544843   -0.15892      0.0820924    0.0664175  -0.103106    -0.0718662   -0.0719826    0.133746  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 11 22
INFO: iteration 1, average log likelihood -1.088150
WARNING: Variances had to be floored 1 7 11 22 26 27 32
INFO: iteration 2, average log likelihood -1.053597
WARNING: Variances had to be floored 6 11 22 30 31
INFO: iteration 3, average log likelihood -1.061120
WARNING: Variances had to be floored 1 4 7 11 22 26 27 32
INFO: iteration 4, average log likelihood -1.052603
WARNING: Variances had to be floored 6 11 22 30 31
INFO: iteration 5, average log likelihood -1.073665
WARNING: Variances had to be floored 1 7 11 22 26 27 32
INFO: iteration 6, average log likelihood -1.062303
WARNING: Variances had to be floored 4 6 11 22 30 31
INFO: iteration 7, average log likelihood -1.064996
WARNING: Variances had to be floored 1 7 11 22 26 27 32
INFO: iteration 8, average log likelihood -1.063722
WARNING: Variances had to be floored 6 11 22 31
INFO: iteration 9, average log likelihood -1.068076
WARNING: Variances had to be floored 1 4 7 11 22 26 27 30 32
INFO: iteration 10, average log likelihood -1.049613
INFO: EM with 100000 data points 10 iterations avll -1.049613
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0179594   -0.113953     0.0472505   -0.0797438    0.0268151    0.0923751    0.20032       0.0615971    -0.13615       0.0631078   -0.0582288   -0.0308388    0.0552187    0.158152    -0.0420906   -0.0609926   -0.0464121    0.0423296    0.156604   -0.0378819     0.123972     0.0431922    -0.123052      0.0489576   -0.145007    -0.036887  
  0.0902636    0.0242584    0.03434     -0.0191648   -0.0760263    0.0483172   -0.0810751    -0.0248003     0.144827      0.0128847   -0.061795     0.082885    -0.19247      0.0407719    0.0451164    0.0748096   -0.0669089    0.134365     0.0328891   0.010661      0.0777435    0.0492098    -0.0975988    -0.0631801   -0.0292649    0.0108717 
 -0.0630218    0.0104725   -0.011636     0.0438849   -0.0796504    0.0198736   -0.0730742    -0.190636     -0.1011        0.0349497    0.0741356   -0.110952     0.0343221   -0.19864     -0.0915957    0.00872315   0.0935134   -0.0540119   -0.0194139  -0.0145218    -0.234454    -0.159058     -0.110683      0.059463     0.0846012    0.0631689 
 -0.0482891    0.148355    -0.0557126    0.062636     0.00633627   0.105793    -0.113322     -0.0593566    -0.0179065     0.0990511    0.00559314   0.0206886   -0.00352806  -0.042534    -0.0285146    0.027245    -0.0841087    0.141539     0.0928086  -0.251208      0.0733716   -0.122038     -0.00707841    0.0959656    0.213341    -0.104305  
 -0.141689     0.0321268    0.0429239   -0.0299003   -0.134564    -0.00135408   0.0530301     0.0348578     0.113579     -0.0400216    0.152241    -0.0843225   -0.0894172   -0.142302     0.0742551    0.0968089   -0.049271    -0.0374779    0.0924037   0.121446     -0.130199    -0.0920212     0.0345389     0.271242    -0.0911415    0.0767009 
  0.115731    -0.0795667   -0.0690514    0.0869291   -0.130155    -0.190047    -0.0256313     0.0238223    -0.110706     -0.0498698    0.0503248    0.0425001    0.147062    -0.116155     0.0848248    0.0212701   -0.128762     0.0552925    0.0084452  -9.45478e-6    0.0122011   -0.0669795    -0.098567      0.101732    -0.028161     0.00307937
  0.0442172   -0.106831     0.168028     0.00217519   0.0437533   -0.0640503   -0.143862     -0.204012     -0.118171     -0.0758688    0.293941    -0.115372    -0.0485914    0.00912533   0.0289588   -0.0162196    0.00109297   0.00572699  -0.0569929  -0.000885713  -0.00972447  -0.145583      0.042044     -0.17171     -0.00552585   0.114069  
 -0.139477     0.0313864   -0.00343784   0.117268    -0.197494    -0.0426225   -0.0436269    -0.0193688     0.0219275     0.0616169    0.135278     0.0035572   -0.0664685    0.0813972    0.0307607    0.0541512   -0.0145936    0.0440246    0.0297675  -0.0461617    -0.216024    -0.0924327     0.187849      0.0825952   -0.00911356   0.00975667
  0.00336244  -0.116688     0.0847549    0.145899    -0.10787     -0.0389197   -0.00711093   -0.171812     -0.0593068    -0.0273149   -0.147988    -0.0837079   -0.0220598    0.22437     -0.0325574   -0.0793621    0.0344363    0.0035827    0.0683028  -0.106629      0.115013     0.0671468     0.0781073     0.144416    -0.0045704   -0.0901447 
  0.104872     0.186576    -0.00463439   0.113836    -0.0277701   -0.0558244   -0.0252936     0.0612446     0.0985006    -0.0179057    0.178722     0.059841    -0.103956     0.0258419   -0.0622555   -0.0136988    0.0355438   -0.0705323    0.0522425  -0.0808477     0.167695     0.082822      0.069133     -0.0717579    0.095506     0.01327   
  0.040479     0.0959639    0.0467137    0.137114    -0.0297595    0.0965272   -0.0432893     0.00661774    0.00692782    0.0861033   -0.0292411    0.0431824   -0.105423     0.067144    -0.197492     0.0106614   -0.0392038    0.0776975    0.104508    0.00569272   -0.0792703   -0.0284296     0.113916      0.0567197    0.018423     0.0441072 
  0.101897     0.0044273   -0.0737402   -0.0424364    0.13294      0.0942126    0.0123412    -0.121925     -0.0429179     0.115586     0.0720149    0.109492     0.111785    -0.161118    -0.0254644   -0.0850832    0.0623284   -0.241487    -0.0310345   0.0131284    -0.0249053    0.0646558     0.013395      0.0258366    0.0987856   -0.00812049
 -0.107536    -0.0833054    0.204628    -0.0717127   -0.0314194    0.0775837    0.023181      0.00671654   -0.040633     -0.0604956   -0.11336      0.0655084    0.119676    -0.0119393    0.100282    -0.0453272    0.0707362    0.0439283   -0.141027   -0.0369779     0.0779732    0.0904409    -0.0553156    -0.0819595   -0.00102402  -0.119856  
  0.0387482    0.10408      0.229669     0.108245    -0.0229973    0.095582    -0.0447707     0.163815     -0.281199     -0.0139474    0.0279727   -0.257429     0.105733     0.0577462    0.0468545   -0.128631     0.0822648   -0.0230515   -0.107759   -0.148972      0.0213954    0.0587613    -0.0463218     0.0221146    0.101544     0.00718004
 -0.0911766   -0.00762323  -0.0966232   -0.0126288    0.137271    -0.0453957   -0.122789     -0.0944488     0.0540445     0.0403081   -0.028289     0.0942065   -0.151121    -0.0242164    0.0897194   -0.188606     0.0402274    0.00521452   0.129804    0.0344569    -0.011383     0.0867892    -0.0373161    -0.0935035    0.142982     0.0100151 
 -0.0185127    0.0199066    0.0838805   -0.102463    -0.124219     0.0319208   -0.0225547    -0.0824067     0.00361986    0.0357279    0.183404     0.0639609   -0.0969005   -0.0205265   -0.0789903   -0.00173005  -0.0701379   -0.0235483   -0.034156    0.00469452    0.0280591    0.00537146    0.032884     -0.00609913  -0.082727    -0.00859796
  0.16165      0.0228291    0.0300579    0.0334333   -0.0119092   -0.00615453  -0.0650612    -0.0532142     0.0276468     0.0169613   -0.147751    -0.0757261    0.0453794    0.0211666    0.0588874   -0.0275107   -0.044037     0.0280461   -0.0065322  -0.0101068     0.0389034   -0.1199       -0.201891     -0.00336679  -0.155271    -0.0413712 
 -0.047961    -0.0686417    0.0112492   -0.0974439   -0.00116598   0.142281    -0.0158437     0.215542      0.0877898    -0.283642    -0.124875    -0.179738     0.0151362    0.0266574   -0.0546855   -0.0982886   -0.108387    -0.00152147   0.0019293   0.0237339     0.215129    -0.0469317     0.0936484     0.0451024   -0.0132225   -0.0027071 
 -0.0612131   -0.0481837    0.134277     0.133433     0.134448     0.023505     0.0579565    -0.0401972    -0.0459568     0.0825558    0.128762    -0.111102    -0.0192717   -0.177933    -0.0885447    0.0024899   -0.106056     0.0839313   -0.0786729  -0.15853      -0.192534    -0.00592568    0.000338025  -0.0814575    0.0277045    0.0832278 
  0.0160939    0.00251996  -0.128722    -0.111583     0.0673185    0.0701351   -0.126296      0.0991355    -0.0945774    -0.112246     0.0403526   -0.196565    -0.0190709    0.0207284   -0.0297883    0.0179786   -0.0734752   -0.141462    -0.0858816   0.0350105    -0.0202585    0.010496      0.0281924    -0.0806515    0.0303247   -0.0522961 
  0.0754087    0.0217298   -0.0890155   -0.0679643   -0.0498572   -0.1131       0.0313498     0.050755     -0.132159     -0.0688692   -0.0780448   -0.0787214   -0.147847    -0.10252      0.24755     -0.0216443    0.0819976    0.155027     0.0229431  -0.101382      0.0643157   -0.140353     -0.0789145    -0.245903    -0.0185595    0.0519401 
 -0.0489153    0.0660696   -0.02438     -4.9126e-5   -0.122298     0.0814074   -0.0426731    -0.000131897   0.129111     -0.00296184   0.131576     0.111009    -0.0214842   -0.344506     0.0814806    0.0918151    0.205776    -0.0615715    0.134922    0.0891329    -0.0911089    0.10689       0.116631      0.105103     0.144184     0.00720806
 -0.00496325   0.135881     0.120227     0.0790779   -0.0383367    0.0371874   -0.209905     -0.0850967     0.0988468    -0.105035    -0.0779442   -0.0777235   -0.0926122    0.105079    -0.182483     0.0942492    0.0958743    0.0632051    0.0924787  -0.19503      -0.159891    -0.0102318     0.134883      0.0657089    0.0586594    0.0445233 
  0.0745845   -0.112858     0.1158      -0.0634632    0.132981    -0.124308     0.0445699     0.024091     -0.261915     -0.120509     0.0385192   -0.015575     0.0419394   -0.0699246    0.00720265  -0.10359     -0.0810933   -0.081502    -0.0383258  -0.0210989    -0.0869103    0.113894      0.00584936    0.0638392    0.176975    -0.0458185 
  0.0780261    0.0520786   -0.1011      -0.0627087    0.0372603    0.0503771    0.0195097     0.0444344    -0.0353878     0.107614     0.0053961   -0.0461927   -0.0967891   -0.0199006    0.0176157   -0.00700958  -0.212256    -0.0765061   -0.0867016   0.0404942    -0.0557016   -0.0180068     0.0379996    -0.00344823  -0.199739     0.0845539 
 -0.047755    -0.00221772   0.0511904   -0.0177204   -0.0505774    0.0447682   -0.102082      0.00155061    0.137627      0.209242     0.0873187   -0.0903306    0.0312945    0.138186     0.0581787   -0.053619    -0.105294    -0.0534384   -0.0715051   0.0269879     0.00651244   0.0803063     0.047919     -0.304045     0.0778238   -0.124435  
  0.231014     0.222062    -0.0124968    0.0878959   -0.0750628   -0.0746677    0.0423937     0.0426896     0.0360408     0.0441423    0.0997203    0.00732844   0.0484332   -0.00679221  -0.031066     0.0793882    0.0849706   -0.0118748   -0.0232057  -0.0742784    -0.0525837   -0.025943     -0.224104      0.148858     0.0856983   -0.0717401 
 -0.00464581  -0.219178     0.0650604   -0.0127327   -0.117023     0.0795107   -0.000359227  -0.0337371     0.0781916    -0.0804761    0.0398744   -0.158622    -0.0456692    0.0109781    0.0444877   -0.00126688  -0.105557     0.133799    -0.263267   -0.198769      0.127394     6.83799e-5   -0.0625254    -0.122627     0.0896677    0.136179  
 -0.0236216   -0.119012     0.0313552   -0.0426573   -0.102351    -0.0159722    0.0779622    -0.0808834     0.079912      0.12519      0.0763127   -0.186618     0.0503444   -0.0660441    0.0351165   -0.0717904    0.010014    -0.0200233   -0.0706758  -0.0941001     0.0380815    0.0183961    -0.0572123     0.0296792    0.188564     0.235245  
  0.0332512    0.147792    -0.211833    -0.00864516  -0.0199077    0.223902     0.142967     -0.149092     -0.0397387     0.157011    -0.222344    -0.0486958    0.0342393    0.156057    -0.00601752   0.200829     0.104562    -0.00409936  -0.0893897  -0.0707581    -0.0835147   -0.107897      0.00247526    0.0099995   -0.0137431   -0.0625425 
  0.0012155    0.0469358    0.0114493    0.0256437    0.0135023   -0.146022     0.00811762    0.0184438     0.000485161  -0.115647     0.0892524   -0.126645     0.0497414    0.0666163   -0.132319     0.0842852   -0.140807     0.00438141   0.0770572  -0.0768179    -0.0805028   -0.000844009  -0.0348563     0.134216     0.00319188  -0.137378  
  0.0271476    0.0903661   -0.0472265   -0.166078     0.0827141   -0.0628398    0.0879289     0.0259795     0.0229883     0.0854703   -0.0831495    0.125249     0.193176    -0.0262926   -0.0826029   -0.0503589   -0.0459629   -0.140899    -0.0228945   0.0182865     0.0261867    0.17784      -0.156054     -0.102115    -0.173477     0.0138406 kind full, method split
0: avll = -1.420198640225544
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.420219
INFO: iteration 2, average log likelihood -1.420124
INFO: iteration 3, average log likelihood -1.420046
INFO: iteration 4, average log likelihood -1.419955
INFO: iteration 5, average log likelihood -1.419847
INFO: iteration 6, average log likelihood -1.419727
INFO: iteration 7, average log likelihood -1.419602
INFO: iteration 8, average log likelihood -1.419471
INFO: iteration 9, average log likelihood -1.419317
INFO: iteration 10, average log likelihood -1.419094
INFO: iteration 11, average log likelihood -1.418727
INFO: iteration 12, average log likelihood -1.418127
INFO: iteration 13, average log likelihood -1.417272
INFO: iteration 14, average log likelihood -1.416325
INFO: iteration 15, average log likelihood -1.415571
INFO: iteration 16, average log likelihood -1.415134
INFO: iteration 17, average log likelihood -1.414929
INFO: iteration 18, average log likelihood -1.414843
INFO: iteration 19, average log likelihood -1.414807
INFO: iteration 20, average log likelihood -1.414793
INFO: iteration 21, average log likelihood -1.414786
INFO: iteration 22, average log likelihood -1.414783
INFO: iteration 23, average log likelihood -1.414782
INFO: iteration 24, average log likelihood -1.414781
INFO: iteration 25, average log likelihood -1.414781
INFO: iteration 26, average log likelihood -1.414780
INFO: iteration 27, average log likelihood -1.414780
INFO: iteration 28, average log likelihood -1.414780
INFO: iteration 29, average log likelihood -1.414780
INFO: iteration 30, average log likelihood -1.414779
INFO: iteration 31, average log likelihood -1.414779
INFO: iteration 32, average log likelihood -1.414779
INFO: iteration 33, average log likelihood -1.414779
INFO: iteration 34, average log likelihood -1.414779
INFO: iteration 35, average log likelihood -1.414779
INFO: iteration 36, average log likelihood -1.414779
INFO: iteration 37, average log likelihood -1.414779
INFO: iteration 38, average log likelihood -1.414778
INFO: iteration 39, average log likelihood -1.414778
INFO: iteration 40, average log likelihood -1.414778
INFO: iteration 41, average log likelihood -1.414778
INFO: iteration 42, average log likelihood -1.414778
INFO: iteration 43, average log likelihood -1.414778
INFO: iteration 44, average log likelihood -1.414778
INFO: iteration 45, average log likelihood -1.414778
INFO: iteration 46, average log likelihood -1.414778
INFO: iteration 47, average log likelihood -1.414778
INFO: iteration 48, average log likelihood -1.414778
INFO: iteration 49, average log likelihood -1.414778
INFO: iteration 50, average log likelihood -1.414778
INFO: EM with 100000 data points 50 iterations avll -1.414778
952.4 data points per parameter
1: avll = [-1.42022,-1.42012,-1.42005,-1.41995,-1.41985,-1.41973,-1.4196,-1.41947,-1.41932,-1.41909,-1.41873,-1.41813,-1.41727,-1.41633,-1.41557,-1.41513,-1.41493,-1.41484,-1.41481,-1.41479,-1.41479,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414795
INFO: iteration 2, average log likelihood -1.414701
INFO: iteration 3, average log likelihood -1.414616
INFO: iteration 4, average log likelihood -1.414512
INFO: iteration 5, average log likelihood -1.414388
INFO: iteration 6, average log likelihood -1.414249
INFO: iteration 7, average log likelihood -1.414111
INFO: iteration 8, average log likelihood -1.413987
INFO: iteration 9, average log likelihood -1.413883
INFO: iteration 10, average log likelihood -1.413802
INFO: iteration 11, average log likelihood -1.413740
INFO: iteration 12, average log likelihood -1.413697
INFO: iteration 13, average log likelihood -1.413667
INFO: iteration 14, average log likelihood -1.413648
INFO: iteration 15, average log likelihood -1.413635
INFO: iteration 16, average log likelihood -1.413627
INFO: iteration 17, average log likelihood -1.413622
INFO: iteration 18, average log likelihood -1.413618
INFO: iteration 19, average log likelihood -1.413616
INFO: iteration 20, average log likelihood -1.413614
INFO: iteration 21, average log likelihood -1.413612
INFO: iteration 22, average log likelihood -1.413611
INFO: iteration 23, average log likelihood -1.413609
INFO: iteration 24, average log likelihood -1.413608
INFO: iteration 25, average log likelihood -1.413607
INFO: iteration 26, average log likelihood -1.413606
INFO: iteration 27, average log likelihood -1.413605
INFO: iteration 28, average log likelihood -1.413604
INFO: iteration 29, average log likelihood -1.413603
INFO: iteration 30, average log likelihood -1.413603
INFO: iteration 31, average log likelihood -1.413602
INFO: iteration 32, average log likelihood -1.413601
INFO: iteration 33, average log likelihood -1.413601
INFO: iteration 34, average log likelihood -1.413600
INFO: iteration 35, average log likelihood -1.413599
INFO: iteration 36, average log likelihood -1.413599
INFO: iteration 37, average log likelihood -1.413598
INFO: iteration 38, average log likelihood -1.413598
INFO: iteration 39, average log likelihood -1.413597
INFO: iteration 40, average log likelihood -1.413597
INFO: iteration 41, average log likelihood -1.413596
INFO: iteration 42, average log likelihood -1.413596
INFO: iteration 43, average log likelihood -1.413595
INFO: iteration 44, average log likelihood -1.413595
INFO: iteration 45, average log likelihood -1.413595
INFO: iteration 46, average log likelihood -1.413594
INFO: iteration 47, average log likelihood -1.413594
INFO: iteration 48, average log likelihood -1.413593
INFO: iteration 49, average log likelihood -1.413593
INFO: iteration 50, average log likelihood -1.413593
INFO: EM with 100000 data points 50 iterations avll -1.413593
473.9 data points per parameter
2: avll = [-1.41479,-1.4147,-1.41462,-1.41451,-1.41439,-1.41425,-1.41411,-1.41399,-1.41388,-1.4138,-1.41374,-1.4137,-1.41367,-1.41365,-1.41364,-1.41363,-1.41362,-1.41362,-1.41362,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413609
INFO: iteration 2, average log likelihood -1.413491
INFO: iteration 3, average log likelihood -1.413383
INFO: iteration 4, average log likelihood -1.413252
INFO: iteration 5, average log likelihood -1.413098
INFO: iteration 6, average log likelihood -1.412935
INFO: iteration 7, average log likelihood -1.412782
INFO: iteration 8, average log likelihood -1.412650
INFO: iteration 9, average log likelihood -1.412541
INFO: iteration 10, average log likelihood -1.412449
INFO: iteration 11, average log likelihood -1.412369
INFO: iteration 12, average log likelihood -1.412300
INFO: iteration 13, average log likelihood -1.412240
INFO: iteration 14, average log likelihood -1.412188
INFO: iteration 15, average log likelihood -1.412145
INFO: iteration 16, average log likelihood -1.412107
INFO: iteration 17, average log likelihood -1.412076
INFO: iteration 18, average log likelihood -1.412048
INFO: iteration 19, average log likelihood -1.412024
INFO: iteration 20, average log likelihood -1.412003
INFO: iteration 21, average log likelihood -1.411984
INFO: iteration 22, average log likelihood -1.411966
INFO: iteration 23, average log likelihood -1.411949
INFO: iteration 24, average log likelihood -1.411934
INFO: iteration 25, average log likelihood -1.411920
INFO: iteration 26, average log likelihood -1.411907
INFO: iteration 27, average log likelihood -1.411894
INFO: iteration 28, average log likelihood -1.411883
INFO: iteration 29, average log likelihood -1.411872
INFO: iteration 30, average log likelihood -1.411861
INFO: iteration 31, average log likelihood -1.411852
INFO: iteration 32, average log likelihood -1.411843
INFO: iteration 33, average log likelihood -1.411834
INFO: iteration 34, average log likelihood -1.411826
INFO: iteration 35, average log likelihood -1.411819
INFO: iteration 36, average log likelihood -1.411811
INFO: iteration 37, average log likelihood -1.411805
INFO: iteration 38, average log likelihood -1.411798
INFO: iteration 39, average log likelihood -1.411792
INFO: iteration 40, average log likelihood -1.411786
INFO: iteration 41, average log likelihood -1.411781
INFO: iteration 42, average log likelihood -1.411775
INFO: iteration 43, average log likelihood -1.411770
INFO: iteration 44, average log likelihood -1.411765
INFO: iteration 45, average log likelihood -1.411760
INFO: iteration 46, average log likelihood -1.411755
INFO: iteration 47, average log likelihood -1.411751
INFO: iteration 48, average log likelihood -1.411747
INFO: iteration 49, average log likelihood -1.411742
INFO: iteration 50, average log likelihood -1.411738
INFO: EM with 100000 data points 50 iterations avll -1.411738
236.4 data points per parameter
3: avll = [-1.41361,-1.41349,-1.41338,-1.41325,-1.4131,-1.41293,-1.41278,-1.41265,-1.41254,-1.41245,-1.41237,-1.4123,-1.41224,-1.41219,-1.41214,-1.41211,-1.41208,-1.41205,-1.41202,-1.412,-1.41198,-1.41197,-1.41195,-1.41193,-1.41192,-1.41191,-1.41189,-1.41188,-1.41187,-1.41186,-1.41185,-1.41184,-1.41183,-1.41183,-1.41182,-1.41181,-1.4118,-1.4118,-1.41179,-1.41179,-1.41178,-1.41178,-1.41177,-1.41176,-1.41176,-1.41176,-1.41175,-1.41175,-1.41174,-1.41174]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411745
INFO: iteration 2, average log likelihood -1.411675
INFO: iteration 3, average log likelihood -1.411611
INFO: iteration 4, average log likelihood -1.411533
INFO: iteration 5, average log likelihood -1.411436
INFO: iteration 6, average log likelihood -1.411317
INFO: iteration 7, average log likelihood -1.411178
INFO: iteration 8, average log likelihood -1.411027
INFO: iteration 9, average log likelihood -1.410873
INFO: iteration 10, average log likelihood -1.410727
INFO: iteration 11, average log likelihood -1.410595
INFO: iteration 12, average log likelihood -1.410479
INFO: iteration 13, average log likelihood -1.410379
INFO: iteration 14, average log likelihood -1.410293
INFO: iteration 15, average log likelihood -1.410218
INFO: iteration 16, average log likelihood -1.410152
INFO: iteration 17, average log likelihood -1.410095
INFO: iteration 18, average log likelihood -1.410045
INFO: iteration 19, average log likelihood -1.410000
INFO: iteration 20, average log likelihood -1.409960
INFO: iteration 21, average log likelihood -1.409925
INFO: iteration 22, average log likelihood -1.409892
INFO: iteration 23, average log likelihood -1.409863
INFO: iteration 24, average log likelihood -1.409836
INFO: iteration 25, average log likelihood -1.409811
INFO: iteration 26, average log likelihood -1.409787
INFO: iteration 27, average log likelihood -1.409765
INFO: iteration 28, average log likelihood -1.409744
INFO: iteration 29, average log likelihood -1.409724
INFO: iteration 30, average log likelihood -1.409704
INFO: iteration 31, average log likelihood -1.409686
INFO: iteration 32, average log likelihood -1.409668
INFO: iteration 33, average log likelihood -1.409651
INFO: iteration 34, average log likelihood -1.409635
INFO: iteration 35, average log likelihood -1.409619
INFO: iteration 36, average log likelihood -1.409604
INFO: iteration 37, average log likelihood -1.409589
INFO: iteration 38, average log likelihood -1.409575
INFO: iteration 39, average log likelihood -1.409562
INFO: iteration 40, average log likelihood -1.409549
INFO: iteration 41, average log likelihood -1.409536
INFO: iteration 42, average log likelihood -1.409525
INFO: iteration 43, average log likelihood -1.409513
INFO: iteration 44, average log likelihood -1.409502
INFO: iteration 45, average log likelihood -1.409492
INFO: iteration 46, average log likelihood -1.409481
INFO: iteration 47, average log likelihood -1.409472
INFO: iteration 48, average log likelihood -1.409462
INFO: iteration 49, average log likelihood -1.409453
INFO: iteration 50, average log likelihood -1.409444
INFO: EM with 100000 data points 50 iterations avll -1.409444
118.1 data points per parameter
4: avll = [-1.41174,-1.41168,-1.41161,-1.41153,-1.41144,-1.41132,-1.41118,-1.41103,-1.41087,-1.41073,-1.4106,-1.41048,-1.41038,-1.41029,-1.41022,-1.41015,-1.4101,-1.41004,-1.41,-1.40996,-1.40992,-1.40989,-1.40986,-1.40984,-1.40981,-1.40979,-1.40977,-1.40974,-1.40972,-1.4097,-1.40969,-1.40967,-1.40965,-1.40963,-1.40962,-1.4096,-1.40959,-1.40958,-1.40956,-1.40955,-1.40954,-1.40952,-1.40951,-1.4095,-1.40949,-1.40948,-1.40947,-1.40946,-1.40945,-1.40944]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409444
INFO: iteration 2, average log likelihood -1.409366
INFO: iteration 3, average log likelihood -1.409290
INFO: iteration 4, average log likelihood -1.409199
INFO: iteration 5, average log likelihood -1.409084
INFO: iteration 6, average log likelihood -1.408942
INFO: iteration 7, average log likelihood -1.408778
INFO: iteration 8, average log likelihood -1.408600
INFO: iteration 9, average log likelihood -1.408420
INFO: iteration 10, average log likelihood -1.408249
INFO: iteration 11, average log likelihood -1.408093
INFO: iteration 12, average log likelihood -1.407954
INFO: iteration 13, average log likelihood -1.407832
INFO: iteration 14, average log likelihood -1.407725
INFO: iteration 15, average log likelihood -1.407631
INFO: iteration 16, average log likelihood -1.407548
INFO: iteration 17, average log likelihood -1.407476
INFO: iteration 18, average log likelihood -1.407413
INFO: iteration 19, average log likelihood -1.407358
INFO: iteration 20, average log likelihood -1.407309
INFO: iteration 21, average log likelihood -1.407266
INFO: iteration 22, average log likelihood -1.407227
INFO: iteration 23, average log likelihood -1.407193
INFO: iteration 24, average log likelihood -1.407162
INFO: iteration 25, average log likelihood -1.407134
INFO: iteration 26, average log likelihood -1.407108
INFO: iteration 27, average log likelihood -1.407084
INFO: iteration 28, average log likelihood -1.407061
INFO: iteration 29, average log likelihood -1.407040
INFO: iteration 30, average log likelihood -1.407019
INFO: iteration 31, average log likelihood -1.407000
INFO: iteration 32, average log likelihood -1.406981
INFO: iteration 33, average log likelihood -1.406963
INFO: iteration 34, average log likelihood -1.406946
INFO: iteration 35, average log likelihood -1.406929
INFO: iteration 36, average log likelihood -1.406912
INFO: iteration 37, average log likelihood -1.406896
INFO: iteration 38, average log likelihood -1.406880
INFO: iteration 39, average log likelihood -1.406865
INFO: iteration 40, average log likelihood -1.406849
INFO: iteration 41, average log likelihood -1.406835
INFO: iteration 42, average log likelihood -1.406820
INFO: iteration 43, average log likelihood -1.406806
INFO: iteration 44, average log likelihood -1.406792
INFO: iteration 45, average log likelihood -1.406779
INFO: iteration 46, average log likelihood -1.406766
INFO: iteration 47, average log likelihood -1.406753
INFO: iteration 48, average log likelihood -1.406741
INFO: iteration 49, average log likelihood -1.406729
INFO: iteration 50, average log likelihood -1.406717
INFO: EM with 100000 data points 50 iterations avll -1.406717
59.0 data points per parameter
5: avll = [-1.40944,-1.40937,-1.40929,-1.4092,-1.40908,-1.40894,-1.40878,-1.4086,-1.40842,-1.40825,-1.40809,-1.40795,-1.40783,-1.40772,-1.40763,-1.40755,-1.40748,-1.40741,-1.40736,-1.40731,-1.40727,-1.40723,-1.40719,-1.40716,-1.40713,-1.40711,-1.40708,-1.40706,-1.40704,-1.40702,-1.407,-1.40698,-1.40696,-1.40695,-1.40693,-1.40691,-1.4069,-1.40688,-1.40686,-1.40685,-1.40683,-1.40682,-1.40681,-1.40679,-1.40678,-1.40677,-1.40675,-1.40674,-1.40673,-1.40672]
[-1.4202,-1.42022,-1.42012,-1.42005,-1.41995,-1.41985,-1.41973,-1.4196,-1.41947,-1.41932,-1.41909,-1.41873,-1.41813,-1.41727,-1.41633,-1.41557,-1.41513,-1.41493,-1.41484,-1.41481,-1.41479,-1.41479,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41478,-1.41479,-1.4147,-1.41462,-1.41451,-1.41439,-1.41425,-1.41411,-1.41399,-1.41388,-1.4138,-1.41374,-1.4137,-1.41367,-1.41365,-1.41364,-1.41363,-1.41362,-1.41362,-1.41362,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.41361,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.4136,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359,-1.41359,-1.41361,-1.41349,-1.41338,-1.41325,-1.4131,-1.41293,-1.41278,-1.41265,-1.41254,-1.41245,-1.41237,-1.4123,-1.41224,-1.41219,-1.41214,-1.41211,-1.41208,-1.41205,-1.41202,-1.412,-1.41198,-1.41197,-1.41195,-1.41193,-1.41192,-1.41191,-1.41189,-1.41188,-1.41187,-1.41186,-1.41185,-1.41184,-1.41183,-1.41183,-1.41182,-1.41181,-1.4118,-1.4118,-1.41179,-1.41179,-1.41178,-1.41178,-1.41177,-1.41176,-1.41176,-1.41176,-1.41175,-1.41175,-1.41174,-1.41174,-1.41174,-1.41168,-1.41161,-1.41153,-1.41144,-1.41132,-1.41118,-1.41103,-1.41087,-1.41073,-1.4106,-1.41048,-1.41038,-1.41029,-1.41022,-1.41015,-1.4101,-1.41004,-1.41,-1.40996,-1.40992,-1.40989,-1.40986,-1.40984,-1.40981,-1.40979,-1.40977,-1.40974,-1.40972,-1.4097,-1.40969,-1.40967,-1.40965,-1.40963,-1.40962,-1.4096,-1.40959,-1.40958,-1.40956,-1.40955,-1.40954,-1.40952,-1.40951,-1.4095,-1.40949,-1.40948,-1.40947,-1.40946,-1.40945,-1.40944,-1.40944,-1.40937,-1.40929,-1.4092,-1.40908,-1.40894,-1.40878,-1.4086,-1.40842,-1.40825,-1.40809,-1.40795,-1.40783,-1.40772,-1.40763,-1.40755,-1.40748,-1.40741,-1.40736,-1.40731,-1.40727,-1.40723,-1.40719,-1.40716,-1.40713,-1.40711,-1.40708,-1.40706,-1.40704,-1.40702,-1.407,-1.40698,-1.40696,-1.40695,-1.40693,-1.40691,-1.4069,-1.40688,-1.40686,-1.40685,-1.40683,-1.40682,-1.40681,-1.40679,-1.40678,-1.40677,-1.40675,-1.40674,-1.40673,-1.40672]
32Ã—26 Array{Float64,2}:
  0.235916   -0.0628501   0.0765861   0.153967    0.0203076  -0.136207   -0.213262   -0.128085     0.091606    0.0748241   0.116878   -0.207      -0.071124    0.0552693  -0.0135511    0.0543861  -0.103839    -0.454275   -0.142514    0.12648      0.0124653   -0.0277917    0.127854    0.105725    -0.0607563   -0.00669365
 -0.109739    0.0267546  -0.0165739  -0.0341631  -0.183406    0.178958   -0.0359861  -0.04191     -0.0307281   0.0725002  -0.0225771  -0.106833   -0.0382971   0.079458    0.183086     0.0527193   0.0905978    0.240056    0.0132294  -0.0437152    0.0621929    0.108319    -0.338979    0.0401336    0.0354512   -0.0516231 
 -0.212798    0.165518    0.370918    0.339751    0.111951   -0.418839   -0.174175   -0.33716     -0.355315   -0.448632    0.253437   -0.571377   -0.591253    0.280051   -0.401128     0.0972302  -0.131818    -0.458735    0.293557    0.0601015   -0.31827     -0.0537034   -0.203352   -0.147121    -0.0590306   -0.135542  
 -0.352505   -0.234369    0.0582121  -0.0219807  -0.155717   -0.269764   -0.0503648  -0.983116     0.0302677  -0.1546      0.31751    -0.222892   -0.0648975  -0.0464791   0.0987988    0.243059   -0.00401242  -0.249238    0.107506    0.0520699    0.491315    -0.0634104   -0.142335   -0.708362    -0.275192     0.766096  
  0.066477    0.0312802   0.0943737  -0.375001    0.173546   -0.0728627   0.0944792   0.0694611   -0.458231   -0.114852    0.0357179  -0.803597    0.622146   -0.111308   -0.00185364  -0.282443    0.155296     0.123124   -0.714122    0.375481     0.0164087    0.392787    -0.308066    0.154748    -0.0612172    0.231315  
 -0.0583218   0.646232    0.157201   -0.586216    0.270257   -0.187861    0.0822568   0.428316    -0.271687    0.143548   -0.0422826  -0.2345      0.114619   -0.479828    0.078846     0.776179   -0.0977775    0.51266    -0.80648    -0.0301697   -0.134617     0.226792    -0.207239    0.126241     0.499076    -0.215514  
 -0.603658    0.125757    0.0010925  -0.24588     0.0668937  -0.0885263   0.353305    0.0614177   -0.114131    0.125892    0.143297   -0.0546283   0.141248   -0.0791985   0.0168549   -0.419685   -0.359022     0.512404    0.151119   -0.0758593    0.0579181   -0.206483     0.3719     -0.10693      0.187362     0.158188  
  0.367111    0.106222   -0.0381075  -0.139704    0.0133327  -0.287811   -0.0703913   0.348235    -0.172627    0.0131886  -0.402839    0.428457    0.187136   -0.257142   -0.152639    -0.0244865   0.0907199    0.47924     0.162769   -0.0307845   -0.218805    -0.0794334    0.163528   -0.144524    -0.0465614    0.0601731 
 -0.303171   -0.14191    -0.137345    0.15882     0.0808521   0.336474   -0.298864    0.0711105   -0.274753    0.0121315   0.0719023   0.631277   -0.144498    0.289239   -0.205121    -0.0559461  -0.254063     0.126592    0.0760555  -0.953592    -0.156014    -0.159836    -0.11152    -0.462553     0.235589     0.202051  
 -0.315288    0.290599   -0.0233101   0.12653    -0.199186    0.199924   -0.262806   -0.0121717    0.819845    0.0864896  -0.0827954   0.473794   -0.651572    0.270002    0.295625     0.082741   -0.424871    -0.0807459   0.434052   -0.158863     0.222494    -0.225614     0.342388   -0.0199374   -0.143893    -0.138585  
 -0.144466   -0.318491   -0.0267826   0.096859    0.220433   -0.227969    0.527893   -0.0759736    0.30724     0.0742007  -0.0628227   0.216098    0.67049     0.16513     0.12138     -0.965855    0.140988     0.0877328  -0.0738958   0.111737    -0.179572    -0.107394     0.413034    0.418234    -0.207193    -0.462716  
 -0.186132   -0.10199    -0.0734478   0.130202   -0.332823    0.924364    0.379148   -0.255556     0.582968   -0.329464    0.229063   -0.0933489   0.246112    0.525901    0.363237    -0.723937   -0.22306     -0.610315    0.0920033  -0.0741887    0.00357374   0.202335    -0.0177471   0.0338006   -0.550742    -0.275559  
 -0.318521   -0.381922    0.426473   -0.233141   -0.214781   -0.549702    0.354222   -0.215412    -0.0240214   0.238073   -0.30548    -0.410578    0.292051   -0.351767   -0.802387     0.0396877   0.289804    -0.269632    0.409826    0.115726    -0.259941    -0.49394      0.603879   -0.0938913    0.504219     0.577936  
 -0.139344    0.112456   -0.298098   -0.140776   -0.162468    0.562899    0.0875893  -0.177381     0.527654    0.731488   -0.52154     0.205701    0.283529   -0.568981   -0.207392     0.498209    0.650946     0.0989922   0.195424    0.00988334  -0.110275    -0.317776    -0.163639   -0.161495     0.871629     0.208081  
  0.548422   -0.482254   -0.0973002   0.0788084  -0.050073    0.360812    0.282363   -0.0178227    0.0546541  -0.0841415   0.716007    0.329406    0.221757   -0.468078   -0.121691     0.181803    0.321731    -0.336671   -0.159046   -0.448686    -0.100513     0.06442     -0.198872   -0.00505429   0.399562    -0.0586413 
 -0.414118    0.794494   -0.54268    -0.101462    0.488176    0.177357    0.634974   -0.332154     0.386087   -0.24967     0.357131    0.146817    0.425366   -1.14338    -0.21955      0.13784     0.799529    -0.121711    0.254919   -0.591053    -0.346675     0.043246    -0.118332   -0.206837    -0.141109     0.149024  
  0.0892037   0.103828   -0.171591   -0.102738   -0.198069    0.185694    0.206769    0.043099     0.173416   -0.296984    0.0679724   0.673777    0.103974   -0.0443308   0.120634    -0.354443   -0.0872368    0.377754    0.237791   -0.70677     -0.0981313   -0.294595     0.391567   -0.0809867   -0.130527    -0.0988878 
 -0.835049    0.618399    0.0472922  -0.347543    0.270709   -0.109851   -0.121273   -0.110556    -0.249917   -0.012997   -0.145346   -0.135144   -0.256484   -0.235364   -0.00416599  -0.364992   -0.345366     0.52069     0.224497    0.475385    -0.139643     0.0154994    0.717199   -0.236335    -0.349417     0.0805754 
  0.465303   -0.379076    0.222958   -0.495831    0.286324    0.245343   -0.20962     1.15236      0.0491936   0.011158   -0.435516    0.56548    -0.585338   -0.27195    -0.136132    -0.478331   -0.783313    -0.0330354   0.429117    0.314935     0.422209     0.301746     0.336671   -0.0624928   -0.191785     0.109358  
  0.404735   -0.332029   -0.195672   -0.671902    0.0253072   0.720467    0.272401    0.928826     0.194472    0.110188   -0.0683092   0.605992    1.05953     0.283989    0.0252088   -0.876776   -0.328394     0.538988   -0.189628   -0.292156     0.130992     0.477824    -0.360615    0.57912     -0.390633     0.189456  
  0.0270533   0.332035    0.240777    0.228518   -0.508349   -0.252233    0.27202    -1.15651     -0.0504456   0.156869    0.255721   -0.962501    0.657688    0.145893    0.00516588   0.437494    0.64681     -0.089506   -0.470649    0.1083      -0.193996    -0.0764246   -0.27626     0.296398     0.0509892   -0.544153  
  0.199829   -0.0963308   0.214595    0.174768    0.101225   -0.153641   -0.146959   -0.113135    -0.169499    0.0619073   0.127404   -0.555089   -0.0799648  -0.0061874  -0.326461     0.227281   -0.0472308   -0.446072   -0.220681    0.315054     0.112047     0.0487353   -0.241377   -0.00856525   0.19553      0.165545  
 -0.884819   -0.453204    0.332195    0.133878    0.327405   -0.170535    0.30015    -0.00708884  -0.116712    0.354624   -0.160905   -0.286028    0.108748    0.0624607   0.358916     0.107943   -0.0460029    0.421995    0.334562    0.0272991    0.140947     0.303003    -1.07301    -0.513299     0.455632     0.20792   
 -0.18734    -0.162538    0.299683   -0.531858   -0.772112   -0.152023   -0.200053    0.145793    -0.307053    0.0676102  -0.342782   -0.369712   -0.0524948   0.647309    0.379108     0.305182    0.00439876   0.481025    0.0371614   0.05762      0.177423     0.06573     -0.693239    0.222742    -0.0202579    0.235712  
  0.732062    0.479984    0.0125529  -0.101238    0.0563393  -0.135935   -0.101705    0.100211    -0.221815   -0.414147    0.303608   -0.121532    0.0706372  -0.39267    -0.642622    -0.167279   -0.0769356   -0.353149   -0.405251   -0.0909082   -0.373247    -0.492757     0.997041    0.560091    -0.00301497  -0.207061  
  0.561171   -0.0684296   0.105919    0.357335   -0.0524514  -0.23995    -0.369849    0.382137    -0.41045    -0.160267    0.179082   -0.188868   -0.564336    0.461826    0.187168    -0.261865   -0.512581     0.0265479  -0.214415    0.116356    -0.0189109   -0.00478447   0.317532    0.696341    -0.240831    -0.32821   
 -0.149765   -0.14743    -0.0473337   1.04181    -0.0102262   0.299953   -0.310914   -0.0894282   -0.105791   -0.136652   -0.466233    0.111233    0.016481    0.586266   -0.428903    -0.337012    0.830549    -0.48123     0.784674    0.00133113  -0.285036     0.0525252    0.24972    -0.362845     0.112999     0.198682  
  0.411843   -0.553663   -0.477746    1.14642     0.581335    0.14346    -0.107436    0.260947     0.153361    0.814619    0.366543    0.0409805  -0.278209   -0.139626    0.180864    -0.294261    0.136481    -0.699914    0.139365    0.161658    -0.116931     0.137032     0.223435   -0.422344     0.433433    -0.0270646 
  1.30003     0.0531189  -0.242843    0.415874   -0.242875   -0.14548    -0.104705    0.13883      0.249318   -0.103014   -0.419359   -0.305159   -0.0724706   0.708573    0.0558415    1.20961     0.175666    -0.809847   -0.381942   -0.752136    -0.100378     0.0265126   -0.616187    0.281081    -0.209248     0.0756447 
  0.777533    0.140667    0.088908    0.0894566  -0.0232416   0.0539067  -0.495517   -0.211958     0.592228   -0.0904841  -0.624041   -0.104822   -0.162033   -0.393792   -0.111767     0.630667    0.285584    -0.592236   -0.136777    0.437553     0.473562     0.101727    -0.113598    0.228641    -0.147586    -0.343351  
  0.184564    0.156548    0.397749   -0.0790637  -0.354627    0.185966   -0.247926    0.0338455   -0.374979    0.12234     0.590266    0.332895   -1.25467    -0.719917   -0.172663     0.881411   -0.166142    -0.35236     0.438737    0.069222     0.493704    -0.037777    -0.317123   -0.245362     0.591081     0.0187815 
  0.188002    0.219126   -0.712126    0.343696   -0.0837068   0.463644   -0.441338   -0.248089    -0.084074   -0.0716678   0.464801    0.215663   -0.608812    0.0313381   0.673635     0.309919    0.0437147    0.413196   -0.597732   -0.40367      0.0354191    0.210652    -0.553496    0.236371    -0.242167    -0.312735  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.406706
INFO: iteration 2, average log likelihood -1.406694
INFO: iteration 3, average log likelihood -1.406684
INFO: iteration 4, average log likelihood -1.406673
INFO: iteration 5, average log likelihood -1.406663
INFO: iteration 6, average log likelihood -1.406653
INFO: iteration 7, average log likelihood -1.406643
INFO: iteration 8, average log likelihood -1.406633
INFO: iteration 9, average log likelihood -1.406624
INFO: iteration 10, average log likelihood -1.406615
INFO: EM with 100000 data points 10 iterations avll -1.406615
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.861083e+05
      1       6.957160e+05      -1.903923e+05 |       32
      2       6.840924e+05      -1.162357e+04 |       32
      3       6.797123e+05      -4.380052e+03 |       32
      4       6.772686e+05      -2.443717e+03 |       32
      5       6.756442e+05      -1.624429e+03 |       32
      6       6.744406e+05      -1.203568e+03 |       32
      7       6.734955e+05      -9.451761e+02 |       32
      8       6.727306e+05      -7.648314e+02 |       32
      9       6.720544e+05      -6.762083e+02 |       32
     10       6.714729e+05      -5.815362e+02 |       32
     11       6.710031e+05      -4.697521e+02 |       32
     12       6.706117e+05      -3.914757e+02 |       32
     13       6.702927e+05      -3.189360e+02 |       32
     14       6.700105e+05      -2.822259e+02 |       32
     15       6.697196e+05      -2.908932e+02 |       32
     16       6.694370e+05      -2.825542e+02 |       32
     17       6.691947e+05      -2.423420e+02 |       32
     18       6.689695e+05      -2.252218e+02 |       32
     19       6.687729e+05      -1.965799e+02 |       32
     20       6.686034e+05      -1.694598e+02 |       32
     21       6.684426e+05      -1.608115e+02 |       32
     22       6.682826e+05      -1.600785e+02 |       32
     23       6.681227e+05      -1.598996e+02 |       32
     24       6.679719e+05      -1.507182e+02 |       32
     25       6.678407e+05      -1.311973e+02 |       32
     26       6.677290e+05      -1.117150e+02 |       32
     27       6.676324e+05      -9.659949e+01 |       32
     28       6.675343e+05      -9.810600e+01 |       32
     29       6.674443e+05      -9.006007e+01 |       32
     30       6.673645e+05      -7.976257e+01 |       32
     31       6.672932e+05      -7.134159e+01 |       32
     32       6.672216e+05      -7.156715e+01 |       32
     33       6.671543e+05      -6.732767e+01 |       32
     34       6.670879e+05      -6.637411e+01 |       32
     35       6.670136e+05      -7.424101e+01 |       32
     36       6.669396e+05      -7.405274e+01 |       32
     37       6.668669e+05      -7.266579e+01 |       32
     38       6.667989e+05      -6.804698e+01 |       32
     39       6.667400e+05      -5.890739e+01 |       32
     40       6.666847e+05      -5.525357e+01 |       32
     41       6.666365e+05      -4.825110e+01 |       32
     42       6.665873e+05      -4.917274e+01 |       32
     43       6.665447e+05      -4.260135e+01 |       32
     44       6.665071e+05      -3.756629e+01 |       32
     45       6.664703e+05      -3.682230e+01 |       32
     46       6.664355e+05      -3.480233e+01 |       32
     47       6.664006e+05      -3.488107e+01 |       32
     48       6.663667e+05      -3.394264e+01 |       32
     49       6.663400e+05      -2.665662e+01 |       32
     50       6.663159e+05      -2.408747e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 666315.9299484813)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417899
INFO: iteration 2, average log likelihood -1.412899
INFO: iteration 3, average log likelihood -1.411421
INFO: iteration 4, average log likelihood -1.410277
INFO: iteration 5, average log likelihood -1.409242
INFO: iteration 6, average log likelihood -1.408478
INFO: iteration 7, average log likelihood -1.408026
INFO: iteration 8, average log likelihood -1.407774
INFO: iteration 9, average log likelihood -1.407619
INFO: iteration 10, average log likelihood -1.407511
INFO: iteration 11, average log likelihood -1.407428
INFO: iteration 12, average log likelihood -1.407358
INFO: iteration 13, average log likelihood -1.407299
INFO: iteration 14, average log likelihood -1.407246
INFO: iteration 15, average log likelihood -1.407198
INFO: iteration 16, average log likelihood -1.407154
INFO: iteration 17, average log likelihood -1.407113
INFO: iteration 18, average log likelihood -1.407075
INFO: iteration 19, average log likelihood -1.407039
INFO: iteration 20, average log likelihood -1.407004
INFO: iteration 21, average log likelihood -1.406972
INFO: iteration 22, average log likelihood -1.406941
INFO: iteration 23, average log likelihood -1.406911
INFO: iteration 24, average log likelihood -1.406883
INFO: iteration 25, average log likelihood -1.406856
INFO: iteration 26, average log likelihood -1.406830
INFO: iteration 27, average log likelihood -1.406805
INFO: iteration 28, average log likelihood -1.406781
INFO: iteration 29, average log likelihood -1.406758
INFO: iteration 30, average log likelihood -1.406736
INFO: iteration 31, average log likelihood -1.406715
INFO: iteration 32, average log likelihood -1.406695
INFO: iteration 33, average log likelihood -1.406675
INFO: iteration 34, average log likelihood -1.406655
INFO: iteration 35, average log likelihood -1.406637
INFO: iteration 36, average log likelihood -1.406618
INFO: iteration 37, average log likelihood -1.406601
INFO: iteration 38, average log likelihood -1.406584
INFO: iteration 39, average log likelihood -1.406567
INFO: iteration 40, average log likelihood -1.406551
INFO: iteration 41, average log likelihood -1.406535
INFO: iteration 42, average log likelihood -1.406520
INFO: iteration 43, average log likelihood -1.406506
INFO: iteration 44, average log likelihood -1.406492
INFO: iteration 45, average log likelihood -1.406479
INFO: iteration 46, average log likelihood -1.406466
INFO: iteration 47, average log likelihood -1.406454
INFO: iteration 48, average log likelihood -1.406443
INFO: iteration 49, average log likelihood -1.406432
INFO: iteration 50, average log likelihood -1.406421
INFO: EM with 100000 data points 50 iterations avll -1.406421
59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.151296   -0.00718595   0.0154377    0.0190018   -0.0790423    0.112444   -0.058216   -0.0946055   -0.0143245   0.0884618    0.0485801  -0.120356   -0.0356939    0.0964503   0.0930762  -0.0147122  -0.0330172    0.0707496    0.0310955  -0.109396    0.0652479    0.055167    -0.22195     -0.0755415   0.0273543   0.0153039
  0.417073   -0.525768    -0.195464    -0.688498     0.0396782    0.515118    0.151424    0.95716      0.185052    0.0518526   -0.276179    0.685147    0.829726     0.239433   -0.0354276  -0.819895   -0.343242     0.547037    -0.0534342  -0.184915    0.153552     0.448313    -0.182595     0.580276   -0.504592    0.251692 
 -0.261834    0.356864    -0.0587414    0.213209     0.242956    -0.533868   -0.370473    0.282116    -0.307766    0.00638959   0.10509    -0.923      -0.545941     0.635772   -0.432573    0.268646   -0.490743    -0.252149    -0.0990093   0.158328   -0.508269    -0.1481       0.00105639   0.0589176   0.142776    0.388289 
  0.180544   -0.420157    -0.337055     1.32948      0.359703     0.157128   -0.261251   -0.0137254    0.11794     0.454405    -0.0262134  -0.145053   -0.142443     0.301697   -0.167963   -0.367101    0.423831    -0.797391     0.325598    0.3003     -0.18267      0.116891     0.149343    -0.361876    0.2034     -0.043574 
  0.24458    -0.0981969    0.459414     0.410702     0.0567577   -0.175149   -0.0842364  -0.287296    -0.243524   -0.629359     0.472888   -0.179229   -0.520986     0.110578   -0.317852   -0.0248153  -0.141863    -0.692461     0.260226   -0.0811702  -0.258381     0.0582414   -0.162978    -0.0459107  -0.254407   -0.356493 
  0.296534    0.0520717   -0.810205     0.581278    -0.140488     0.387326   -0.512652   -0.150339    -0.0401307   0.0914499    0.396497    0.368487   -0.48344      0.0602848   0.543671    0.145951    0.174071     0.224821    -0.306063   -0.327985   -0.230039     0.107791    -0.271762     0.234218   -0.300456   -0.367039 
  0.19575     0.477771     0.303745     0.075031     0.00852807  -0.531731    0.228692   -0.617806    -0.415815    0.0556126    0.483851   -0.721879    0.33531     -0.372504   -0.201325    0.927101    0.576884    -0.35859     -0.750829    0.186127   -0.465712     0.0589842   -0.243993     0.113767    0.586834   -0.362324 
  0.117045    0.0643021    0.492531    -0.0976314    0.0497662   -0.0856478  -0.370353    0.756628    -0.714967    0.093184    -0.133721   -0.117625   -0.228184     0.442378    0.118836   -0.436476   -0.580131     0.460348     0.0255376   0.170784   -0.0396605    0.260873     0.00635272   0.0403577   0.270666   -0.269417 
 -0.122201   -0.205847     0.00908903   0.0420158   -0.12642      0.194994   -0.104813    0.258624     0.302064    0.152907    -0.130676    0.378969   -0.576032     0.0391773   0.33507    -0.557158   -0.452642     0.126853     0.850317    0.196666    0.496635    -0.153442     0.227284    -0.11527    -0.262047    0.199818 
  1.25844    -0.160747     0.131669     0.353906    -0.49671     -0.136908   -0.114214    0.244061    -0.0748547  -0.0480673   -0.150702   -0.492222    0.00324483   0.967348    0.0701041   0.863243    0.0173817   -0.505208    -0.435935   -0.510188    0.160305     0.223121    -0.633089     0.333446   -0.163786    0.085333 
 -0.128535    0.380515    -0.451616    -0.312598     0.0256831    0.448068    0.292904   -0.613619     0.536936    0.305812    -0.122409    0.152116    0.650321    -0.752402   -0.236708    0.686031    0.937518    -0.224778     0.0801267  -0.427155   -0.20748     -0.13789     -0.292438    -0.340889    0.298103    0.405916 
  0.832087    0.308706     0.0509522    0.00325007   0.0622276   -0.125516   -0.150645    0.176365    -0.243791   -0.410726     0.317937   -0.229874   -0.127001    -0.351182   -0.461704   -0.392128   -0.234663    -0.313031    -0.364132    0.0524587  -0.288314    -0.24599      0.883106     0.663121   -0.26179    -0.179857 
 -0.199774    0.0463679   -0.0894881    0.0333971    0.178949     0.184298    0.68469     0.00531975   0.28086    -0.0588814   -0.0939896   0.488666    0.535296    -0.177535    0.218593   -0.900486    0.102782     0.377205     0.217838   -0.313681   -0.130366    -0.156324     0.456445     0.157309   -0.133445   -0.569776 
 -0.57276    -0.0801539    0.197209     0.402284     0.565037     0.169495    0.350719    0.384352    -0.245772    0.376354    -0.292814   -0.572596   -0.284895    -0.96136    -0.150993    0.397785    0.0492254    0.465852     0.600707    0.0143091  -0.146804     0.64675     -0.935668    -0.36548     0.67957    -0.0402456
 -0.436518   -0.0825016    0.12491      0.23067     -0.20318     -0.206631   -0.0300108  -0.989974     0.171709   -0.0578232    0.25066    -0.48072    -0.33007      0.0869419   0.137803    0.558374   -0.00469003  -0.410485     0.163039    0.0973096   0.53937     -0.0212951   -0.226962    -0.591451   -0.14494     0.298312 
 -0.0545562  -0.268278     0.0401731    0.310128    -0.235693     0.182784   -0.0869931  -0.116458     0.1832     -0.139039    -0.252215    0.273555    0.17507      0.28901    -0.515012   -0.509143    0.386589    -0.357634     0.522458   -0.279183   -0.412282    -0.400628     0.237771    -0.11359     0.183978    0.16003  
  0.469859    0.0718468    0.20095     -0.103289    -0.0279288   -0.115862   -0.401379   -0.0814227    0.058908    0.095993    -0.0648163  -0.394698   -0.00383642  -0.125648    0.0694367   0.283524   -0.0470429   -0.333574    -0.437692    0.566662    0.322826     0.227441    -0.0461847    0.319215   -0.0658193  -0.0648587
  0.861591    0.103753    -0.234327     0.210293    -0.0250353    0.15788    -0.327388   -0.0979191    0.871893   -0.0879272   -0.975475    0.138436   -0.283476    -0.220768    0.0825582   0.917858    0.400883    -0.710043    -0.0630847  -0.0391795   0.216761    -0.0780419   -0.428753     0.302016   -0.0515883  -0.413    
 -0.469625   -0.129106     0.244777    -0.327888     0.230336    -0.367716    0.371951   -0.269027    -0.11855     0.171686     0.144502   -0.621015    1.03209      0.215713   -0.0274923  -0.880412   -0.099072     0.224957    -0.173528    0.378293    0.0827776    0.0896201   -0.144027    -0.285233    0.0209086   0.488928 
 -0.255456    0.579773    -0.00543097  -0.673401    -0.0760287    0.12252     0.29369     0.203265    -0.174709   -0.165261     0.124951   -0.386793    0.120412    -0.177725    0.444998    0.357339   -0.144714     0.757688    -0.788998   -0.241119    0.112739     0.21624     -0.445221     0.378371    0.160551   -0.29903  
 -0.727602    0.762225    -0.148484    -0.133379     0.617182    -0.128383    0.114011   -0.260999     0.220621   -0.1307       0.0962823   0.297801   -0.248369    -0.799078   -0.1985     -0.22067    -0.190711     0.171983     0.247335    0.214612   -0.0554977   -0.107798     0.878584    -0.353872   -0.0513123  -0.105904 
  0.46173    -0.416035    -0.182396     0.205593     0.068833     0.544896    0.296237    0.138278     0.188335    0.16685      0.765424    0.415269    0.0551685   -0.523081   -0.142782    0.153055    0.00353669  -0.333781    -0.17833    -0.615323    0.114407    -0.0084936   -0.0105355   -0.0260878   0.634504   -0.114312 
 -0.899652   -0.765106     0.423499    -0.00730379  -0.309657    -0.285572    0.124236   -0.274646    -0.100981    0.440199    -0.159852   -0.149137    0.230138     0.753651    0.550959    0.402601    0.189541     0.401398     0.118618   -0.156184    0.266877    -0.00856846  -0.941051    -0.101912    0.55985     0.294352 
  0.333516   -0.812006     0.152689    -0.344348     0.119359    -0.0825344  -0.161554   -0.295888    -1.02968    -0.280617     0.157537   -0.187004    0.140536    -0.695051   -0.457306   -0.0588762   0.715093    -0.0634319   -0.343832    0.389003    0.357875    -0.105832    -0.611445    -0.239625   -0.0209951   0.663569 
  0.0540885   0.105902     0.124947    -0.145039    -0.122238     0.121826   -0.390338    0.230483    -0.110322    0.128567     0.0784082   0.214987   -0.707951    -0.331521   -0.0440775   0.486305   -0.358011     0.00287601   0.244377    0.0579388   0.336535    -0.0289386   -0.0552707   -0.237405    0.242729    0.185162 
  0.156427    0.174849     0.072269    -0.31757      0.0188587   -0.126199   -0.0734562   0.252109    -0.184354    0.132154    -0.428511    0.438234    0.203936    -0.507948   -0.252351    0.2734      0.130559     0.460269     0.0922199  -0.157288   -0.0467311   -0.0489172   -0.0310503   -0.475075    0.288545    0.235344 
 -0.460078   -0.177373    -0.413502    -0.0554838    0.142075    -0.267393    0.331692   -0.355376    -0.30482    -0.154041     0.644718    0.448375   -0.0816416    0.270057    0.398717   -0.231597   -0.319785     0.49597      0.0548334  -0.718432   -0.29203     -0.0981407   -0.115967    -0.57057     0.0245244   0.926101 
  0.21566     0.0663056   -0.187439    -0.0225022    0.119957    -0.212929    0.164529    0.196235    -0.0138746   0.0303996    0.0542787   0.0206831   0.265368    -0.147772    0.0366363  -0.177784    0.101618     0.106388    -0.311739    0.0518923  -0.306229    -0.109622     0.376041     0.361509   -0.0373569  -0.0800273
 -0.718393    0.549234     0.263834    -0.521465    -0.400569    -0.247885   -0.384334   -0.272096    -0.250004   -0.21901     -0.808415   -0.389371   -0.216625     0.510375    0.247881    0.171855    0.144379     0.40504      0.251074    0.367022   -0.23926      0.115635    -0.00346796   0.0332746  -0.808095    0.120744 
 -0.261735   -0.0578795   -0.101243     0.0338446   -0.223785     0.749521    0.465901   -0.215404     0.461966   -0.285484     0.273165   -0.150398    0.315781     0.526376    0.43846    -0.78783    -0.211822    -0.443852    -0.0711694  -0.0128268  -0.00711518   0.270335     0.0305655    0.137434   -0.591647   -0.281833 
  0.128366    0.325768     0.147637     0.0546743   -0.358254     0.0249341  -0.554656    0.105386     0.218743   -0.23903     -0.0176805   0.647073   -0.397751     0.672462   -0.132674    0.246738   -0.472831     0.129783    -0.0770573  -0.801121    0.0636409   -0.556432     0.521589     0.0229319  -0.139553   -0.276279 
 -0.478169   -0.197596     0.348631    -0.362182    -0.200157    -0.411824    0.546805   -0.110826    -0.0403453   0.156972    -0.182473   -0.600559    0.161201    -0.379002   -0.608724    0.0644837   0.0585694    0.0428405    0.381599    0.251354   -0.112803    -0.3535       0.471576     0.138686    0.470577    0.192725 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.406411
INFO: iteration 2, average log likelihood -1.406401
INFO: iteration 3, average log likelihood -1.406391
INFO: iteration 4, average log likelihood -1.406382
INFO: iteration 5, average log likelihood -1.406374
INFO: iteration 6, average log likelihood -1.406365
INFO: iteration 7, average log likelihood -1.406357
INFO: iteration 8, average log likelihood -1.406349
INFO: iteration 9, average log likelihood -1.406341
INFO: iteration 10, average log likelihood -1.406334
INFO: EM with 100000 data points 10 iterations avll -1.406334
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
