>>> 'Pkg.add("Optim")' log
INFO: No packages to install, update or remove
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of Optim
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("Optim")' log
Julia Version 0.4.5
Commit 2ac304d (2016-03-18 00:58 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing Optim
Running tests:
 * types.jl
 * bfgs.jl
 * gradient_descent.jl
 * momentum_gradient_descent.jl
 * grid_search.jl
 * l_bfgs.jl
 * levenberg_marquardt.jl
WARNING: Problem solving for delta_x: predicted residual increase.
18.95337979630715 (predicted_residual) >
3.6729087897253905 (residual) + 3.552713678800501e-15 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.83860477635018 (predicted_residual) >
2.9812894464055533 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.5347148551516008 (predicted_residual) >
2.1895906529240503 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.4662071702097417 (predicted_residual) >
2.0497617658979004 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.402223943602616 (predicted_residual) >
1.9102621894841052 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
1.9548243717543228 (predicted_residual) >
1.8272637677633554 (residual) + 2.220446049250313e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.289097004965162 (predicted_residual) >
1.7676814916153436 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.5282850316144354 (predicted_residual) >
0.43569220875204495 (residual) + 1.1102230246251565e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.38479244475307006 (predicted_residual) >
0.3191560404065722 (residual) + 5.551115123125783e-17 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.0867292689898465 (predicted_residual) >
0.07825577278289107 (residual) + 1.3877787807814457e-17 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.05060004314422784 (predicted_residual) >
0.04864792336713843 (residual) + 6.938893903907228e-18 (eps)
 * newton.jl
 * cg.jl
 * nelder_mead.jl
 * optimize.jl
 * simulated_annealing.jl
 * interpolating_line_search.jl
 * api.jl
Iter     Function value   Gradient norm 
     0    -1.033256e-01              NaN
 * x_minimum: -0.8541019662496847
 * x_lower: -2.0
 * x_upper: 1.0
     1    -1.033256e-01              NaN
 * x_minimum: -0.8541019662496847
 * x_lower: -2.0
 * x_upper: -0.14589803375031563
     2    -1.033256e-01              NaN
 * x_minimum: -0.8541019662496847
 * x_lower: -1.291796067500631
 * x_upper: -0.14589803375031563
     3    -1.033256e-01              NaN
 * x_minimum: -0.8541019662496847
 * x_lower: -1.291796067500631
 * x_upper: -0.5835921350012621
     4    -1.033256e-01              NaN
 * x_minimum: -0.8541019662496847
 * x_lower: -1.0212862362522084
 * x_upper: -0.5835921350012621
     5    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.8541019662496847
 * x_upper: -0.5835921350012621
     6    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.8541019662496847
 * x_upper: -0.6869176962471611
     7    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7902432574930602
 * x_upper: -0.6869176962471611
     8    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7902432574930602
 * x_upper: -0.7263845487364357
     9    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7658514012257102
 * x_upper: -0.7263845487364357
    10    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7658514012257102
 * x_upper: -0.7414595449583602
    11    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7565345411802846
 * x_upper: -0.7414595449583602
    12    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.7565345411802846
 * x_upper: -0.7472176811348591
    13    -1.249988e-01              NaN
 * x_minimum: -0.7507764050037857
 * x_lower: -0.752975817311358
 * x_upper: -0.7472176811348591
    14    -1.249993e-01              NaN
 * x_minimum: -0.7494170934424312
 * x_lower: -0.7507764050037857
 * x_upper: -0.7472176811348591
    15    -1.249993e-01              NaN
 * x_minimum: -0.7494170934424312
 * x_lower: -0.7507764050037857
 * x_upper: -0.7485769926962135
    16    -1.250000e-01              NaN
 * x_minimum: -0.749936304257568
 * x_lower: -0.7507764050037857
 * x_upper: -0.7494170934424312
    17    -1.250000e-01              NaN
 * x_minimum: -0.749936304257568
 * x_lower: -0.750257194188649
 * x_upper: -0.7494170934424312
    18    -1.250000e-01              NaN
 * x_minimum: -0.749936304257568
 * x_lower: -0.750257194188649
 * x_upper: -0.7497379833735123
    19    -1.250000e-01              NaN
 * x_minimum: -0.7500588733045933
 * x_lower: -0.750257194188649
 * x_upper: -0.749936304257568
    20    -1.250000e-01              NaN
 * x_minimum: -0.7500588733045933
 * x_lower: -0.7501346251416237
 * x_upper: -0.749936304257568
    21    -1.250000e-01              NaN
 * x_minimum: -0.7500120560945983
 * x_lower: -0.7500588733045933
 * x_upper: -0.749936304257568
    22    -1.250000e-01              NaN
 * x_minimum: -0.7500120560945983
 * x_lower: -0.7500588733045933
 * x_upper: -0.749983121467563
    23    -1.250000e-01              NaN
 * x_minimum: -0.7500120560945983
 * x_lower: -0.750029938677558
 * x_upper: -0.749983121467563
    24    -1.250000e-01              NaN
 * x_minimum: -0.7500010040505226
 * x_lower: -0.7500120560945983
 * x_upper: -0.749983121467563
    25    -1.250000e-01              NaN
 * x_minimum: -0.7500010040505226
 * x_lower: -0.7500120560945983
 * x_upper: -0.7499941735116387
    26    -1.250000e-01              NaN
 * x_minimum: -0.7500010040505226
 * x_lower: -0.7500052255557144
 * x_upper: -0.7499941735116387
    27    -1.250000e-01              NaN
 * x_minimum: -0.7500010040505226
 * x_lower: -0.7500052255557144
 * x_upper: -0.7499983950168304
    28    -1.250000e-01              NaN
 * x_minimum: -0.7500010040505226
 * x_lower: -0.7500026165220222
 * x_upper: -0.7499983950168304
    29    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500010040505226
 * x_upper: -0.7499983950168304
    30    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500010040505226
 * x_upper: -0.7499993915790231
    31    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500003881412156
 * x_upper: -0.7499993915790231
    32    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500003881412156
 * x_upper: -0.7499997722319087
    33    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500001528847944
 * x_upper: -0.7499997722319087
    34    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500001528847944
 * x_upper: -0.7499999176283731
    35    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500000630248376
 * x_upper: -0.7499999176283731
    36    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500000630248376
 * x_upper: -0.7499999731648807
    37    -1.250000e-01              NaN
 * x_minimum: -0.75000000748833
 * x_lower: -0.7500000287013883
 * x_upper: -0.7499999731648807
    38    -1.250000e-01              NaN
 * x_minimum: -0.749999994377939
 * x_lower: -0.75000000748833
 * x_upper: -0.7499999731648807
 * golden_section.jl
 * brent.jl
 * type_stability.jl
 * array.jl
 * constrained.jl
WARNING: could not attach metadata for @simd loop.
 * callbacks.jl
 * deprecate.jl
WARNING: accelerated_gradient_descent{T}(df::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Array{T}; linesearch!::Function=hz_linesearch!,nargs...) is deprecated, use optimize(df,initial_x,AcceleratedGradientDescent(linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in accelerated_gradient_descent at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 15
Iter     Function value   Gradient norm 
     0     1.000000e+00     4.000000e+00
     1     5.397751e-01     2.518950e+00
     2     3.066394e-02     2.931102e-01
     3     1.227162e-01     8.293471e-01
WARNING: momentum_gradient_descent{T}(df::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Array{T}; linesearch!::Function=hz_linesearch!,mu::Real=0.01,nargs...) is deprecated, use optimize(df,initial_x,MomentumGradientDescent(mu=mu,linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in momentum_gradient_descent at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 16
WARNING: gradient_descent{T}(df::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Array{T}; linesearch!::Function=hz_linesearch!,nargs...) is deprecated, use optimize(df,initial_x,GradientDescent(linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in gradient_descent at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 32
WARNING: bfgs{T}(d::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Vector{T}; initial_invH::Matrix=eye(length(initial_x)),linesearch!::Function=hz_linesearch!,nargs...) is deprecated, use optimize(d,initial_x,BFGS(linesearch!=linesearch!),OptimizationOptions(; nargs...),initial_invH=initial_invH) instead.
 in depwarn at deprecated.jl:73
 in bfgs at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 49
WARNING: brent{T <: AbstractFloat}(f::Function,x_lower::T,x_upper::T; nargs...) is deprecated, use optimize(f,x_lower,x_upper,Brent(); nargs...) instead.
 in depwarn at deprecated.jl:73
 in brent at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 64
WARNING: golden_section{T <: AbstractFloat}(f::Function,x_lower::T,x_upper::T; nargs...) is deprecated, use optimize(f,x_lower,x_upper,GoldenSection(); nargs...) instead.
 in depwarn at deprecated.jl:73
 in golden_section at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 71
WARNING: cg{T}(df::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Array{T}; linesearch!::Function=hz_linesearch!,eta::Real=convert(T,0.4),P::Any=nothing,precondprep::Function=((P,x)->begin  # /home/vagrant/.julia/v0.4/Optim/src/deprecate.jl, line 38:
                nothing
            end),nargs...) is deprecated, use optimize(df,initial_x,ConjugateGradient(eta=eta,precondprep=precondprep,P=P,linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in cg at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 89
WARNING: l_bfgs{T}(d::Union{DifferentiableFunction,TwiceDifferentiableFunction},initial_x::Vector{T}; m::Integer=10,linesearch!::Function=hz_linesearch!,nargs...) is deprecated, use optimize(d,initial_x,LBFGS(m=m,linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in l_bfgs at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 109
WARNING: nelder_mead{T}(f::Function,initial_x::Vector{T}; a::Real=1.0,g::Real=2.0,b::Real=0.5,initial_step::Vector{T}=ones(T,length(initial_x)),nargs...) is deprecated, use optimize(f,initial_x,NelderMead(a=a,b=b,g=g),OptimizationOptions(nargs...),initial_step=initial_step) instead.
 in depwarn at deprecated.jl:73
 in nelder_mead at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 122
WARNING: newton{T}(df::TwiceDifferentiableFunction,initial_x::Array{T}; linesearch!::Function=hz_linesearch!,nargs...) is deprecated, use optimize(df,initial_x,Newton(linesearch!=linesearch!),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in newton at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 144
WARNING: simulated_annealing{T}(cost::Function,initial_x::Array{T}; neighbor!::Function=default_neighbor!,temperature::Function=log_temperature,keep_best::Bool=true,nargs...) is deprecated, use optimize(cost,initial_x,SimulatedAnnealing(neighbor!=neighbor!,temperature=temperature,keep_best=keep_best),OptimizationOptions(; nargs...)) instead.
 in depwarn at deprecated.jl:73
 in simulated_annealing at deprecated.jl:50
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 [inlined code] from /home/vagrant/.julia/v0.4/Optim/test/runtests.jl:36
 in anonymous at no file:0
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Optim/test/deprecate.jl, in expression starting on line 155
INFO: Optim tests passed

>>> End of log
