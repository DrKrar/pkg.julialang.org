>>> 'Pkg.add("LLLplus")' log
INFO: Cloning cache of LLLplus from git://github.com/christianpeel/LLLplus.jl.git
INFO: Installing LLLplus v0.1.1
INFO: Package database updated

>>> 'Pkg.test("LLLplus")' log
Julia Version 0.4.0-dev+6477
Commit dce9d18* (2015-08-02 23:54 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing LLLplus
tests with small matrices...
...done

In all the following tests, the first time includes the JIT compilation; 
for the second execution the compilation is already done and the time
should be faster.

Testing LLL on 1000x1000 real matrix...
  0.812268 seconds (3.03 M allocations: 859.673 MB, 6.26% gc time)
  0.629794 seconds (2.83 M allocations: 850.454 MB, 7.31% gc time)

Testing LLL on 10x10 complex matrix...
  1.016840 seconds (1.40 M allocations: 63.893 MB, 1.05% gc time)
  0.000384 seconds (2.99 k allocations: 252.172 KB)
Testing VBLAST on same 10x10 complex matrix...
  0.431109 seconds (734.45 k allocations: 33.048 MB, 0.89% gc time)
  0.000621 seconds (463 allocations: 89.375 KB)

Testing sphere decoder on 100000 samples of 2x2 BPSK system...
  0.598778 seconds (4.22 M allocations: 220.214 MB, 3.87% gc time)
  0.201123 seconds (3.70 M allocations: 196.817 MB, 7.41% gc time)
Error Rate is 0.0. It should be zero or very small.

Testing now with 200x200 matrix from latticechallenge.org.
All the column norms should be 30.
max col-norm of input is 233.24879420910193
  0.066016 seconds (191.90 k allocations: 89.220 MB, 12.47% gc time)
max col-norm of lll-reduced basis is 30.0
  4.338796 seconds (27.74 M allocations: 3.987 GB, 5.45% gc time)
max column norm of seysen-reduced basis is 30.0
INFO: LLLplus tests passed

>>> End of log
