>>> 'Pkg.add("Spark")' log
INFO: Cloning cache of JavaCall from git://github.com/aviks/JavaCall.jl.git
INFO: Cloning cache of Spark from git://github.com/dfdx/Spark.jl.git
INFO: Installing Dates v0.4.4
INFO: Installing Iterators v0.1.9
INFO: Installing JavaCall v0.3.5
INFO: Installing Memoize v0.0.1
INFO: Installing Spark v0.1.0
INFO: Building Spark
================================[ ERROR: Spark ]================================

LoadError: Cannot find maven. Is it installed?
while loading /home/vagrant/.julia/v0.4/Spark/deps/build.jl, in expression starting on line 3

================================================================================

================================[ BUILD ERRORS ]================================

WARNING: Spark had build errors.

 - packages with build errors remain installed in /home/vagrant/.julia/v0.4
 - build the package(s) and all dependencies with `Pkg.build("Spark")`
 - build a single package by running its `deps/build.jl` script

================================================================================
INFO: Package database updated

>>> 'Pkg.test("Spark")' log
Julia Version 0.4.6
Commit 2e358ce (2016-06-19 17:16 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing Spark
Loaded /usr/lib/jvm/java-7-oracle/jre/lib/amd64/server/libjvm.so
ERROR: LoadError: Class Not Found org/apache/spark/SparkConf
 in metaclass_unmemoized at /home/vagrant/.julia/v0.4/JavaCall/src/core.jl:243
 in metaclass at /home/vagrant/.julia/v0.4/Memoize/src/Memoize.jl:103
 in jnew at /home/vagrant/.julia/v0.4/JavaCall/src/core.jl:119
 in call at /home/vagrant/.julia/v0.4/JavaCall/src/core.jl:35
 in SparkConf at /home/vagrant/.julia/v0.4/Spark/src/config.jl:7
 in SparkContext at /home/vagrant/.julia/v0.4/Spark/src/context.jl:17
 in include at ./boot.jl:261
 in include_from_node1 at ./loading.jl:320
 in process_options at ./client.jl:280
 in _start at ./client.jl:378
while loading /home/vagrant/.julia/v0.4/Spark/test/runtests.jl, in expression starting on line 5
================================[ ERROR: Spark ]================================

failed process: Process(`/home/vagrant/julia/bin/julia --check-bounds=yes --code-coverage=none --color=no /home/vagrant/.julia/v0.4/Spark/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Spark had test errors
 in error at ./error.jl:21
 in test at pkg/entry.jl:803
 in anonymous at pkg/dir.jl:31
 in cd at file.jl:22
 in cd at pkg/dir.jl:31
 in test at pkg.jl:71
 in process_options at ./client.jl:257
 in _start at ./client.jl:378

>>> End of log
