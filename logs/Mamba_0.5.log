>>> 'Pkg.add("Mamba")' log
INFO: Cloning cache of Cairo from https://github.com/JuliaGraphics/Cairo.jl.git
INFO: Cloning cache of Graphics from https://github.com/JuliaGraphics/Graphics.jl.git
INFO: Cloning cache of Mamba from https://github.com/brian-j-smith/Mamba.jl.git
INFO: Installing AxisAlgorithms v0.1.5
INFO: Installing BinDeps v0.4.3
INFO: Installing Cairo v0.2.34
INFO: Installing Calculus v0.1.15
INFO: Installing Codecs v0.2.0
INFO: Installing ColorTypes v0.2.6
INFO: Installing Colors v0.6.6
INFO: Installing Compose v0.4.4
INFO: Installing Contour v0.2.0
INFO: Installing DataArrays v0.3.8
INFO: Installing DataFrames v0.7.8
INFO: Installing DataStructures v0.4.5
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FixedPointNumbers v0.1.4
INFO: Installing FixedSizeArrays v0.2.3
INFO: Installing ForwardDiff v0.2.4
INFO: Installing GZip v0.2.20
INFO: Installing Gadfly v0.4.3
INFO: Installing Graphics v0.1.3
INFO: Installing Graphs v0.7.0
INFO: Installing Hexagons v0.0.4
INFO: Installing Interpolations v0.3.6
INFO: Installing Iterators v0.1.10
INFO: Installing KernelDensity v0.3.0
INFO: Installing Loess v0.0.7
INFO: Installing Mamba v0.10.0
INFO: Installing Measures v0.0.3
INFO: Installing NaNMath v0.2.1
INFO: Installing Optim v0.6.1
INFO: Installing PDMats v0.4.2
INFO: Installing PositiveFactorizations v0.0.2
INFO: Installing Ratios v0.0.4
INFO: Installing Reexport v0.0.3
INFO: Installing Rmath v0.1.2
INFO: Installing SHA v0.2.1
INFO: Installing Showoff v0.0.7
INFO: Installing SortingAlgorithms v0.1.0
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.0
INFO: Installing URIParser v0.1.6
INFO: Installing WoodburyMatrices v0.2.0
INFO: Building Cairo
INFO: Building Rmath
INFO: Package database updated

>>> 'Pkg.test("Mamba")' log
Julia Version 0.5.0-rc3+0
Commit e6f843b (2016-08-22 23:43 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-93-generic #140-Ubuntu SMP Mon Jul 18 21:21:05 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (899.98046875 MB free)
Uptime: 1439.0 sec
Load Avg:  0.927734375  0.8291015625  0.5244140625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz      45661 s         56 s       5871 s      76449 s          1 s
#2  3500 MHz       7488 s         96 s       2855 s     130247 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - JSON                          0.7.0
 - Mamba                         0.10.0
42 additional packages:
 - AxisAlgorithms                0.1.5
 - BinDeps                       0.4.3
 - Cairo                         0.2.34
 - Calculus                      0.1.15
 - Codecs                        0.2.0
 - ColorTypes                    0.2.6
 - Colors                        0.6.6
 - Compat                        0.8.8
 - Compose                       0.4.4
 - Contour                       0.2.0
 - DataArrays                    0.3.8
 - DataFrames                    0.7.8
 - DataStructures                0.4.5
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FixedPointNumbers             0.1.4
 - FixedSizeArrays               0.2.3
 - ForwardDiff                   0.2.4
 - GZip                          0.2.20
 - Gadfly                        0.4.3
 - Graphics                      0.1.3
 - Graphs                        0.7.0
 - Hexagons                      0.0.4
 - Interpolations                0.3.6
 - Iterators                     0.1.10
 - KernelDensity                 0.3.0
 - Loess                         0.0.7
 - Measures                      0.0.3
 - NaNMath                       0.2.1
 - Optim                         0.6.1
 - PDMats                        0.4.2
 - PositiveFactorizations        0.0.2
 - Ratios                        0.0.4
 - Reexport                      0.0.3
 - Rmath                         0.1.2
 - SHA                           0.2.1
 - Showoff                       0.0.7
 - SortingAlgorithms             0.1.0
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.0
 - URIParser                     0.1.6
 - WoodburyMatrices              0.2.0
INFO: Testing Mamba
Running tests:

>>> Testing ../doc/tutorial/line.jl

INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/Rmath.ji for module Rmath.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/StatsFuns.ji for module StatsFuns.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/Distributions.ji for module Distributions.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/StatsBase.ji for module StatsBase.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/Gadfly.ji for module Gadfly.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/DataArrays.ji for module DataArrays.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/DataFrames.ji for module DataFrames.
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.5/KernelDensity.ji for module KernelDensity.
WARNING: Method definition (::Type{Graphs.KeyVertex})(Int64, #K<:Any) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:12 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:16.
WARNING: Method definition (::Type{Graphs.Edge})(Int64, #V<:Any, #V<:Any) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:54 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:60.
WARNING: Method definition (::Type{Graphs.ExEdge})(Int64, #V<:Any, #V<:Any, Base.Dict{String, Any}) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:72 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:83.
WARNING: Method definition (::Type{Graphs.TargetIterator})(#G<:Graphs.AbstractGraph, #EList<:Any) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:123 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:127.
WARNING: Method definition (::Type{Graphs.SourceIterator})(#G<:Graphs.AbstractGraph, #EList<:Any) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:141 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:145.
WARNING: Method definition edge_property_requirement(Graphs.AbstractEdgePropertyInspector{#T<:Any}, Graphs.AbstractGraph{#V<:Any, E<:Any}) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:164 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/common.jl:179.
WARNING: Method definition vertex_index(#V<:Union{Graphs.ExVertex, Graphs.KeyVertex}, Graphs.GenericGraph{#V<:Union{Graphs.ExVertex, Graphs.KeyVertex}, E<:Any, VList<:Any, EList<:Any, IncList<:Any}) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/graph.jl:65 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/graph.jl:67.
WARNING: Method definition (::Type{Graphs.GDistanceVisitor})(#G<:Graphs.AbstractGraph, #DMap<:Any) in module Graphs at /home/vagrant/.julia/v0.5/Graphs/src/breadth_first_visit.jl:107 overwritten at /home/vagrant/.julia/v0.5/Graphs/src/breadth_first_visit.jl:111.
digraph Mamba.Model {
	"y" [shape="ellipse", style="filled", fillcolor="gray85"];
	"mu" [shape="diamond", style="filled", fillcolor="gray85"];
		"mu" -> "y";
	"s2" [shape="ellipse"];
		"s2" -> "y";
	"beta" [shape="ellipse"];
		"beta" -> "mu";
	"xmat" [shape="box", style="filled", fillcolor="gray85"];
		"xmat" -> "mu";
}
MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:31:45 of 0:31:47 remaining]
Chain 1:  10% [0:00:41 of 0:00:46 remaining]
Chain 1:  20% [0:00:26 of 0:00:32 remaining]
Chain 1:  30% [0:00:19 of 0:00:27 remaining]
Chain 1:  40% [0:00:15 of 0:00:25 remaining]
Chain 1:  50% [0:00:12 of 0:00:23 remaining]
Chain 1:  60% [0:00:09 of 0:00:21 remaining]
Chain 1:  70% [0:00:06 of 0:00:20 remaining]
Chain 1:  80% [0:00:04 of 0:00:20 remaining]
Chain 1:  90% [0:00:02 of 0:00:19 remaining]
Chain 1: 100% [0:00:00 of 0:00:18 remaining]

Chain 2:   0% [0:00:25 of 0:00:25 remaining]
Chain 2:  10% [0:00:12 of 0:00:14 remaining]
Chain 2:  20% [0:00:11 of 0:00:14 remaining]
Chain 2:  30% [0:00:09 of 0:00:13 remaining]
Chain 2:  40% [0:00:09 of 0:00:15 remaining]
Chain 2:  50% [0:00:08 of 0:00:15 remaining]
Chain 2:  60% [0:00:06 of 0:00:15 remaining]
Chain 2:  70% [0:00:05 of 0:00:15 remaining]
Chain 2:  80% [0:00:03 of 0:00:15 remaining]
Chain 2:  90% [0:00:02 of 0:00:15 remaining]
Chain 2: 100% [0:00:00 of 0:00:15 remaining]

Chain 3:   0% [0:00:11 of 0:00:11 remaining]
Chain 3:  10% [0:00:14 of 0:00:16 remaining]
Chain 3:  20% [0:00:12 of 0:00:16 remaining]
Chain 3:  30% [0:00:10 of 0:00:15 remaining]
Chain 3:  40% [0:00:10 of 0:00:16 remaining]
Chain 3:  50% [0:00:08 of 0:00:15 remaining]
Chain 3:  60% [0:00:06 of 0:00:15 remaining]
Chain 3:  70% [0:00:04 of 0:00:14 remaining]
Chain 3:  80% [0:00:03 of 0:00:14 remaining]
Chain 3:  90% [0:00:01 of 0:00:14 remaining]
Chain 3: 100% [0:00:00 of 0:00:14 remaining]

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:43 of 0:00:43 remaining]
Chain 1:  10% [0:00:18 of 0:00:20 remaining]
Chain 1:  20% [0:00:16 of 0:00:19 remaining]
Chain 1:  30% [0:00:14 of 0:00:20 remaining]
Chain 1:  40% [0:00:12 of 0:00:21 remaining]
Chain 1:  50% [0:00:10 of 0:00:21 remaining]
Chain 1:  60% [0:00:08 of 0:00:21 remaining]
Chain 1:  70% [0:00:06 of 0:00:21 remaining]
Chain 1:  80% [0:00:04 of 0:00:21 remaining]
Chain 1:  90% [0:00:02 of 0:00:21 remaining]
Chain 1: 100% [0:00:00 of 0:00:21 remaining]

Chain 2:   0% [0:00:34 of 0:00:34 remaining]
Chain 2:  10% [0:00:27 of 0:00:30 remaining]
Chain 2:  20% [0:00:23 of 0:00:29 remaining]
Chain 2:  30% [0:00:19 of 0:00:27 remaining]
Chain 2:  40% [0:00:17 of 0:00:28 remaining]
Chain 2:  50% [0:00:14 of 0:00:28 remaining]
Chain 2:  60% [0:00:11 of 0:00:27 remaining]
Chain 2:  70% [0:00:08 of 0:00:27 remaining]
Chain 2:  80% [0:00:05 of 0:00:26 remaining]
Chain 2:  90% [0:00:03 of 0:00:27 remaining]
Chain 2: 100% [0:00:00 of 0:00:27 remaining]

Chain 3:   0% [0:00:18 of 0:00:18 remaining]
Chain 3:  10% [0:00:19 of 0:00:21 remaining]
Chain 3:  20% [0:00:16 of 0:00:20 remaining]
Chain 3:  30% [0:00:14 of 0:00:19 remaining]
Chain 3:  40% [0:00:12 of 0:00:21 remaining]
Chain 3:  50% [0:00:09 of 0:00:19 remaining]
Chain 3:  60% [0:00:07 of 0:00:18 remaining]
Chain 3:  70% [0:00:05 of 0:00:18 remaining]
Chain 3:  80% [0:00:04 of 0:00:18 remaining]
Chain 3:  90% [0:00:02 of 0:00:18 remaining]
Chain 3: 100% [0:00:00 of 0:00:17 remaining]

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:26:10 of 0:26:12 remaining]
Chain 1:  10% [0:00:16 of 0:00:18 remaining]
Chain 1:  20% [0:00:08 of 0:00:10 remaining]
Chain 1:  30% [0:00:05 of 0:00:07 remaining]
Chain 1:  40% [0:00:04 of 0:00:06 remaining]
Chain 1:  50% [0:00:03 of 0:00:05 remaining]
Chain 1:  60% [0:00:02 of 0:00:05 remaining]
Chain 1:  70% [0:00:01 of 0:00:04 remaining]
Chain 1:  80% [0:00:01 of 0:00:04 remaining]
Chain 1:  90% [0:00:00 of 0:00:04 remaining]
Chain 1: 100% [0:00:00 of 0:00:04 remaining]

Chain 2:   0% [0:00:02 of 0:00:02 remaining]
Chain 2:  10% [0:00:02 of 0:00:02 remaining]
Chain 2:  20% [0:00:01 of 0:00:02 remaining]
Chain 2:  30% [0:00:01 of 0:00:02 remaining]
Chain 2:  40% [0:00:01 of 0:00:02 remaining]
Chain 2:  50% [0:00:01 of 0:00:02 remaining]
Chain 2:  60% [0:00:01 of 0:00:02 remaining]
Chain 2:  70% [0:00:01 of 0:00:02 remaining]
Chain 2:  80% [0:00:00 of 0:00:02 remaining]
Chain 2:  90% [0:00:00 of 0:00:02 remaining]
Chain 2: 100% [0:00:00 of 0:00:02 remaining]

Chain 3:   0% [0:00:01 of 0:00:01 remaining]
Chain 3:  10% [0:00:02 of 0:00:02 remaining]
Chain 3:  20% [0:00:02 of 0:00:02 remaining]
Chain 3:  30% [0:00:01 of 0:00:02 remaining]
Chain 3:  40% [0:00:01 of 0:00:02 remaining]
Chain 3:  50% [0:00:01 of 0:00:02 remaining]
Chain 3:  60% [0:00:01 of 0:00:02 remaining]
Chain 3:  70% [0:00:01 of 0:00:02 remaining]
Chain 3:  80% [0:00:00 of 0:00:02 remaining]
Chain 3:  90% [0:00:00 of 0:00:02 remaining]
Chain 3: 100% [0:00:00 of 0:00:02 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Gelman, Rubin, and Brooks Diagnostic:
              PSRF 97.5%
     beta[1] 1.016 1.017
     beta[2] 1.012 1.012
          s2 1.017 1.028
Multivariate 1.008   NaN

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Geweke Diagnostic:
First Window Fraction = 0.1
Second Window Fraction = 0.5

        Z-score p-value
beta[1]   0.385  0.7006
beta[2]  -0.763  0.4454
     s2   0.799  0.4242

        Z-score p-value
beta[1]  -0.760  0.4474
beta[2]   0.758  0.4487
     s2   0.919  0.3581

        Z-score p-value
beta[1]  -0.057  0.9543
beta[2]   0.115  0.9085
     s2   0.270  0.7869

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Heidelberger and Welch Diagnostic:
Target Halfwidth Ratio = 0.1
Alpha = 0.05

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
beta[1]     251            1  0.8250  0.6382145 0.055479968    1
beta[2]     251            1  0.7329  0.7914259 0.016036396    1
     s2     251            1  0.9378  1.1115542 0.129042031    0

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
beta[1]     251            1  0.2341 0.65307629 0.083061655    0
beta[2]     251            1  0.5445 0.78645075 0.022150712    1
     s2    2199            1  0.4497 1.20071185 0.282790256    0

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
beta[1]     251            1  0.8416 0.60478079 0.058901220    1
beta[2]     251            1  0.7588 0.80047219 0.016705963    1
     s2    1712            1  0.3774 0.95887818 0.102879572    0

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Raftery and Lewis Diagnostic:
Quantile (q) = 0.025
Accuracy (r) = 0.005
Probability (s) = 0.95

        Thinning Burn-in    Total   Nmin Dependence Factor
beta[1]        2     271 2.1549×10⁴ 3746         5.7525360
beta[2]        4     271 2.3235×10⁴ 3746         6.2026161
     s2        2     257 8.4090×10³ 3746         2.2447944

        Thinning Burn-in    Total   Nmin Dependence Factor
beta[1]        2     269 1.9399×10⁴ 3746         5.1785905
beta[2]        6     275 2.8961×10⁴ 3746         7.7311799
     s2        2     257 8.4090×10³ 3746         2.2447944

        Thinning Burn-in    Total   Nmin Dependence Factor
beta[1]        2     271 2.1549×10⁴ 3746         5.7525360
beta[2]        4     267 2.1139×10⁴ 3746         5.6430860
     s2        2     257 8.6890×10³ 3746         2.3195408

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean        SD       Naive SE       MCSE         ESS   
beta[1] 0.63202387 1.22346884 0.0101168422 0.0171332958 4875.00000
beta[2] 0.79278294 0.36278449 0.0029998585 0.0046723726 4875.00000
     s2 1.30825253 2.22693295 0.0184144691 0.1330447541  280.16816

Quantiles:
            2.5%       25.0%      50.0%      75.0%     97.5%  
beta[1] -1.71941903 0.04729730 0.62969121 1.19275864 3.0869371
beta[2]  0.06863583 0.61940292 0.79471015 0.97090184 1.5023734
     s2  0.17401158 0.38850920 0.66980654 1.28020252 6.9221371

          95% Lower  95% Upper
beta[1] -1.832163566 2.9644512
beta[2]  0.069314061 1.5027416
     s2  0.090890593 4.3484379

          beta[1]      beta[2]        s2     
beta[1]  1.00000000 -0.908473924  0.068730010
beta[2] -0.90847392  1.000000000 -0.038443997
     s2  0.06873001 -0.038443997  1.000000000

           Lag 2      Lag 10        Lag 20       Lag 100   
beta[1] 0.29226178 -0.007948082  -0.008357209 -0.0088907146
beta[2] 0.25163239  0.009849072  -0.005716837 -0.0124545001
     s2 0.72006286  0.201142350   0.045112661  0.0066591124

           Lag 2      Lag 10        Lag 20       Lag 100   
beta[1] 0.36515695  0.016582519 -0.0120655209  -0.023458328
beta[2] 0.29207491  0.015755533 -0.0182661112  -0.025425471
     s2 0.95244356  0.813535063  0.6937875238   0.203112345

           Lag 2      Lag 10        Lag 20       Lag 100   
beta[1] 0.30691365 -0.019464717 -0.0171207932  -0.021431384
beta[2] 0.25589717 -0.023048972 -0.0050008727  -0.018572788
     s2 0.68257462  0.291817972  0.0635169753   0.037528268

             Change Rate
     beta[1]        0.82
     beta[2]        0.82
          s2        1.00
Multivariate        1.00

MCMC Processing of 4875 Iterations x 3 Chains...

Chain 1:   0% [0:01:19 of 0:01:19 remaining]
Chain 1:  10% [0:00:02 of 0:00:02 remaining]
Chain 1:  20% [0:00:01 of 0:00:01 remaining]
Chain 1:  30% [0:00:00 of 0:00:01 remaining]
Chain 1:  40% [0:00:00 of 0:00:01 remaining]
Chain 1:  50% [0:00:00 of 0:00:00 remaining]
Chain 1:  60% [0:00:00 of 0:00:00 remaining]
Chain 1:  70% [0:00:00 of 0:00:00 remaining]
Chain 1:  80% [0:00:00 of 0:00:00 remaining]
Chain 1:  90% [0:00:00 of 0:00:00 remaining]
Chain 1: 100% [0:00:00 of 0:00:00 remaining]

Chain 2:   0% [0:02:21 of 0:02:21 remaining]
Chain 2:  10% [0:00:03 of 0:00:03 remaining]
Chain 2:  20% [0:00:01 of 0:00:02 remaining]
Chain 2:  30% [0:00:01 of 0:00:01 remaining]
Chain 2:  40% [0:00:01 of 0:00:01 remaining]
Chain 2:  50% [0:00:00 of 0:00:01 remaining]
Chain 2:  60% [0:00:00 of 0:00:01 remaining]
Chain 2:  70% [0:00:00 of 0:00:01 remaining]
Chain 2:  80% [0:00:00 of 0:00:01 remaining]
Chain 2:  90% [0:00:00 of 0:00:00 remaining]
Chain 2: 100% [0:00:00 of 0:00:00 remaining]

Chain 3:   0% [0:03:29 of 0:03:30 remaining]
Chain 3:  10% [0:00:04 of 0:00:04 remaining]
Chain 3:  20% [0:00:02 of 0:00:02 remaining]
Chain 3:  30% [0:00:01 of 0:00:02 remaining]
Chain 3:  40% [0:00:01 of 0:00:01 remaining]
Chain 3:  50% [0:00:00 of 0:00:01 remaining]
Chain 3:  60% [0:00:00 of 0:00:01 remaining]
Chain 3:  70% [0:00:00 of 0:00:01 remaining]
Chain 3:  80% [0:00:00 of 0:00:01 remaining]
Chain 3:  90% [0:00:00 of 0:00:01 remaining]
Chain 3: 100% [0:00:00 of 0:00:01 remaining]

      DIC    Effective Parameters
pD 13.779476             1.011407
pV 24.049516             6.146427

Iterations = 1000:5000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 2001

Empirical Posterior Estimates:
           Mean       SD       Naive SE      MCSE       ESS   
beta[1] 0.6590508 1.35840176 0.017532509 0.039086287 1207.8351
beta[2] 0.7875778 0.39504357 0.005098716 0.009695904 1660.0202

Quantiles:
            2.5%        25.0%      50.0%      75.0%     97.5%  
beta[1] -1.777240824 0.06442916 0.65929876 1.22212698 3.2581019
beta[2]  0.025511644 0.61319426 0.78878106 0.97199495 1.5230851

MCMC Simulation of 5000 Iterations x 3 Chains...

Chain 1:   0% [0:00:24 of 0:00:24 remaining]
Chain 1:  10% [0:00:07 of 0:00:08 remaining]
Chain 1:  20% [0:00:07 of 0:00:09 remaining]
Chain 1:  30% [0:00:06 of 0:00:09 remaining]
Chain 1:  40% [0:00:05 of 0:00:09 remaining]
Chain 1:  50% [0:00:05 of 0:00:09 remaining]
Chain 1:  60% [0:00:04 of 0:00:09 remaining]
Chain 1:  70% [0:00:03 of 0:00:09 remaining]
Chain 1:  80% [0:00:02 of 0:00:09 remaining]
Chain 1:  90% [0:00:01 of 0:00:09 remaining]
Chain 1: 100% [0:00:00 of 0:00:09 remaining]

Chain 2:   0% [0:00:17 of 0:00:17 remaining]
Chain 2:  10% [0:00:05 of 0:00:06 remaining]
Chain 2:  20% [0:00:05 of 0:00:07 remaining]
Chain 2:  30% [0:00:04 of 0:00:06 remaining]
Chain 2:  40% [0:00:04 of 0:00:07 remaining]
Chain 2:  50% [0:00:04 of 0:00:07 remaining]
Chain 2:  60% [0:00:03 of 0:00:08 remaining]
Chain 2:  70% [0:00:02 of 0:00:07 remaining]
Chain 2:  80% [0:00:01 of 0:00:07 remaining]
Chain 2:  90% [0:00:01 of 0:00:07 remaining]
Chain 2: 100% [0:00:00 of 0:00:07 remaining]

Chain 3:   0% [0:00:09 of 0:00:09 remaining]
Chain 3:  10% [0:00:11 of 0:00:12 remaining]
Chain 3:  20% [0:00:10 of 0:00:12 remaining]
Chain 3:  30% [0:00:08 of 0:00:11 remaining]
Chain 3:  40% [0:00:07 of 0:00:11 remaining]
Chain 3:  50% [0:00:05 of 0:00:10 remaining]
Chain 3:  60% [0:00:04 of 0:00:10 remaining]
Chain 3:  70% [0:00:03 of 0:00:10 remaining]
Chain 3:  80% [0:00:02 of 0:00:09 remaining]
Chain 3:  90% [0:00:01 of 0:00:09 remaining]
Chain 3: 100% [0:00:00 of 0:00:09 remaining]

Iterations = 252:15000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 7375

Empirical Posterior Estimates:
           Mean       SD       Naive SE       MCSE        ESS   
beta[1] 0.6350429 1.21410071 0.0081623098 0.014135970 7375.00000
beta[2] 0.7914827 0.36058507 0.0024241869 0.003832962 7375.00000
     s2 1.2873151 2.09642409 0.0140941050 0.094704724  490.02134

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
beta[1] -1.75261093 0.048604084 0.62587021 1.2084223 3.0714092
beta[2]  0.07135896 0.616872526 0.79412201 0.9711961 1.4972112
     s2  0.17463572 0.390558697 0.67228308 1.2854779 6.7026585

Object of type "Mamba.Model"
-------------------------------------------------------------------------------
y:
An unmonitored node of type "5-element Mamba.ArrayStochastic{1}"
[1.0,3.0,3.0,3.0,5.0]

Distribution:
IsoNormal(
dim: 5
μ: [3.23845,5.28663,7.33481,9.38299,11.4312]
Σ: [0.392048 0.0 0.0 0.0 0.0; 0.0 0.392048 0.0 0.0 0.0; 0.0 0.0 0.392048 0.0 0.0; 0.0 0.0 0.0 0.392048 0.0; 0.0 0.0 0.0 0.0 0.392048]
)

Function:
LambdaInfo for (::Mamba.##298#299)(::Mamba.Model)
:(begin 
        f = #5
        SSAValue(1) = $(Expr(:invoke, LambdaInfo for getindex(::Mamba.Model, ::Symbol), :(Mamba.getindex), :(model), :(:mu)))
        SSAValue(0) = $(Expr(:invoke, LambdaInfo for getindex(::Mamba.Model, ::Symbol), :(Mamba.getindex), :(model), :(:s2)))
        return (Main.MvNormal)(SSAValue(1),(Main.sqrt)(SSAValue(0)))
    end)

Source Nodes:
Symbol[:mu,:s2]

Target Nodes:
Symbol[]
-------------------------------------------------------------------------------
s2:
A monitored node of type "Mamba.ScalarStochastic"
0.3920476295762887

Distribution:
Distributions.InverseGamma{Float64}(
invd: Distributions.Gamma{Float64}(α=0.001, θ=1000.0)
θ: 0.001
)

Function:
LambdaInfo for (::Mamba.##304#305)(::Mamba.Model)
:(begin 
        f = #8
        return $(Expr(:invoke, LambdaInfo for Distributions.InverseGamma{Float64}(::Float64, ::Float64), Distributions.InverseGamma{Float64}, 0.001, 0.001))
    end::Distributions.InverseGamma{Float64})

Source Nodes:
Symbol[]

Target Nodes:
Symbol[:y]
-------------------------------------------------------------------------------
xmat:
[1.0 1.0; 1.0 2.0; 1.0 3.0; 1.0 4.0; 1.0 5.0]
-------------------------------------------------------------------------------
beta:
A monitored node of type "2-element Mamba.ArrayStochastic{1}"
[1.19027,2.04818]

Distribution:
ZeroMeanIsoNormal(
dim: 2
μ: [0.0,0.0]
Σ: [1000.0 0.0; 0.0 1000.0]
)

Function:
LambdaInfo for (::Mamba.##302#303)(::Mamba.Model)
:(begin 
        f = #7
        return $(Expr(:invoke, LambdaInfo for Distributions.MvNormal{T<:Real,Cov<:PDMats.AbstractPDMat,Mean<:Union{Array{T,1},Distributions.ZeroVector}}(::Int64, ::Float64), :(Main.MvNormal), 2, :((Base.Math.box)(Base.Math.Float64,(Base.Math.sqrt_llvm)((Base.box)(Float64,(Base.sitofp)(Float64,1000))))::Float64)))
    end::Distributions.MvNormal{Float64,PDMats.ScalMat{Float64},Distributions.ZeroVector{Float64}})

Source Nodes:
Symbol[]

Target Nodes:
Symbol[:mu,:y]
-------------------------------------------------------------------------------
mu:
An unmonitored node of type "5-element Mamba.ArrayLogical{1}"
[3.23845,5.28663,7.33481,9.38299,11.4312]
Function:
LambdaInfo for (::Mamba.##300#301)(::Mamba.Model)
:(begin 
        f = #6
        SSAValue(1) = $(Expr(:invoke, LambdaInfo for getindex(::Mamba.Model, ::Symbol), :(Mamba.getindex), :(model), :(:xmat)))
        SSAValue(0) = $(Expr(:invoke, LambdaInfo for getindex(::Mamba.Model, ::Symbol), :(Mamba.getindex), :(model), :(:beta)))
        return SSAValue(1) * SSAValue(0)
    end)

Source Nodes:
Symbol[:xmat,:beta]

Target Nodes:
Symbol[:y]

>>> Testing ../doc/samplers/amm.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE       ESS   
b0 0.67372957 1.07776604 0.0152419136 0.064652461 277.89381
b1 0.77112512 0.32135034 0.0045445801 0.017982404 319.34640
s2 1.29658296 2.18979550 0.0309683849 0.139974432 244.74267

Quantiles:
       2.5%        25.0%       50.0%      75.0%     97.5%  
b0 -1.451022943 0.069490369 0.65978541 1.19631191 3.1685322
b1  0.050258268 0.611291896 0.79094107 0.94652458 1.4132212
s2  0.174653274 0.389575233 0.65132492 1.31853897 6.8337311


>>> Testing ../doc/samplers/amwg.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean       SD      Naive SE       MCSE        ESS   
b0 0.5983881 1.5898262 0.0224835377 0.162560986  95.645964
b1 0.8006155 0.4358909 0.0061644284 0.042038394 107.513597
s2 2.2710644 9.1262030 0.1290640007 0.686946293 176.495925

Quantiles:
       2.5%       25.0%      50.0%      75.0%      97.5%  
b0 -2.17471713 0.03038741 0.67912808 1.30557650  3.3496859
b1  0.03755749 0.60096712 0.77599921 0.96011511  1.7513752
s2  0.16901125 0.39945048 0.70340929 1.47274298 13.3376638


>>> Testing ../doc/samplers/bhmc.jl

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean      SD       Naive SE       MCSE         ESS   
 gamma[1] 0.5425 0.49821539 0.0049821539 0.0043794170 10000.0000
 gamma[2] 1.0000 0.00000000 0.0000000000 0.0000000000 10000.0000
 gamma[3] 0.3125 0.46353558 0.0046353558 0.0052442850  7812.5639
 gamma[4] 1.0000 0.00000000 0.0000000000 0.0000000000 10000.0000
 gamma[5] 0.7132 0.45228997 0.0045228997 0.0056726884  6357.0562
 gamma[6] 0.7342 0.44178035 0.0044178035 0.0055526497  6330.1242
 gamma[7] 1.0000 0.00000000 0.0000000000 0.0000000000 10000.0000
 gamma[8] 0.5202 0.49961677 0.0049961677 0.0030648875 10000.0000
 gamma[9] 0.4972 0.50001716 0.0050001716 0.0063230858  6253.3346
gamma[10] 0.7768 0.41641218 0.0041641218 0.0044537579  8741.6542

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     1     1
 gamma[4]    1     1     1     1     1
 gamma[5]    0     0     1     1     1
 gamma[6]    0     0     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     1     1
gamma[10]    0     1     1     1     1


>>> Testing ../doc/samplers/bia.jl

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean       SD        Naive SE       MCSE         ESS    
 gamma[1] 0.6803 0.466383599 0.00466383599 0.0130286824  1281.40243
 gamma[2] 0.9996 0.019996999 0.00019996999 0.0004000000  2499.24992
 gamma[3] 0.0012 0.034621956 0.00034621956 0.0009458041  1339.98766
 gamma[4] 0.9973 0.051893924 0.00051893924 0.0027000000   369.40731
 gamma[5] 0.9978 0.046854877 0.00046854877 0.0022000000   453.59081
 gamma[6] 0.9997 0.017318776 0.00017318776 0.0003000000  3332.66660
 gamma[7] 0.9982 0.042390325 0.00042390325 0.0018000000   554.61102
 gamma[8] 0.6932 0.461188714 0.00461188714 0.0113109226  1662.49857
 gamma[9] 0.0000 0.000000000 0.00000000000 0.0000000000 10000.00000
gamma[10] 0.9986 0.037392243 0.00037392243 0.0014000000   713.35705

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     0     0
 gamma[4]    1     1     1     1     1
 gamma[5]    1     1     1     1     1
 gamma[6]    1     1     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     0     0
gamma[10]    1     1     1     1     1


>>> Testing ../doc/samplers/bmc3.jl

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean       SD        Naive SE       MCSE          ESS    
 gamma[1] 0.6859 0.464179638 0.00464179638 0.0159190471   850.233153
 gamma[2] 0.9992 0.028274369 0.00028274369 0.0008000000  1249.124912
 gamma[3] 0.0125 0.111107986 0.00111107986 0.0073887370   226.125809
 gamma[4] 0.9988 0.034621956 0.00034621956 0.0012000000   832.416575
 gamma[5] 0.9570 0.202867236 0.00202867236 0.0194803709   108.449957
 gamma[6] 0.9997 0.017318776 0.00017318776 0.0002227015  6047.669940
 gamma[7] 1.0000 0.000000000 0.00000000000 0.0000000000 10000.000000
 gamma[8] 0.6883 0.463211147 0.00463211147 0.0185983897   620.307903
 gamma[9] 0.0440 0.205105355 0.00205105355 0.0196884830   108.524924
gamma[10] 0.9635 0.187540041 0.00187540041 0.0178083938   110.901780

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     0     0
 gamma[4]    1     1     1     1     1
 gamma[5]    0     1     1     1     1
 gamma[6]    1     1     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     0     1
gamma[10]    0     1     1     1     1

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean       SD        Naive SE       MCSE        ESS    
 gamma[1] 0.6770 0.467646094 0.00467646094 0.016071494   846.68547
 gamma[2] 0.9993 0.026449574 0.00026449574 0.000700000  1427.71420
 gamma[3] 0.0033 0.057353631 0.00057353631 0.003300000   302.06051
 gamma[4] 0.9991 0.029987996 0.00029987996 0.000900000  1110.22213
 gamma[5] 0.9982 0.042390325 0.00042390325 0.001800000   554.61102
 gamma[6] 0.9994 0.024488772 0.00024488772 0.000600000  1665.83325
 gamma[7] 0.9997 0.017318776 0.00017318776 0.000300000  3332.66660
 gamma[8] 0.6785 0.467075546 0.00467075546 0.015762361   878.07523
 gamma[9] 0.0000 0.000000000 0.00000000000 0.000000000 10000.00000
gamma[10] 0.9999 0.010000000 0.00010000000 0.000100000 10000.00000

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     0     0
 gamma[4]    1     1     1     1     1
 gamma[5]    1     1     1     1     1
 gamma[6]    1     1     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     0     0
gamma[10]    1     1     1     1     1


>>> Testing ../doc/samplers/bmg.jl

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean       SD        Naive SE       MCSE        ESS    
 gamma[1] 0.6426 0.479257977 0.00479257977 0.019055273   632.56964
 gamma[2] 0.9974 0.050926411 0.00050926411 0.002600000   383.65375
 gamma[3] 0.0014 0.037392243 0.00037392243 0.001400000   713.35705
 gamma[4] 0.9977 0.047905527 0.00047905527 0.002300000   433.82599
 gamma[5] 0.9961 0.062331200 0.00062331200 0.003900000   255.43580
 gamma[6] 0.9996 0.019996999 0.00019996999 0.000400000  2499.24992
 gamma[7] 1.0000 0.000000000 0.00000000000 0.000000000 10000.00000
 gamma[8] 0.7135 0.452148420 0.00452148420 0.022320157   410.36240
 gamma[9] 0.0005 0.022356207 0.00022356207 0.000500000  1999.19992
gamma[10] 0.9964 0.059894897 0.00059894897 0.003600000   276.80546

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     0     0
 gamma[4]    1     1     1     1     1
 gamma[5]    1     1     1     1     1
 gamma[6]    1     1     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     0     0
gamma[10]    1     1     1     1     1

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean       SD        Naive SE       MCSE        ESS    
 gamma[1] 0.6608 0.473461484 0.00473461484 0.021104684   503.28225
 gamma[2] 0.9973 0.051893924 0.00051893924 0.002700000   369.40731
 gamma[3] 0.0030 0.054692770 0.00054692770 0.003000000   332.36657
 gamma[4] 1.0000 0.000000000 0.00000000000 0.000000000 10000.00000
 gamma[5] 0.9959 0.063903039 0.00063903039 0.004100000   242.92673
 gamma[6] 0.9970 0.054692770 0.00054692770 0.003000000   332.36657
 gamma[7] 0.9996 0.019996999 0.00019996999 0.000400000  2499.24992
 gamma[8] 0.6948 0.460515111 0.00460515111 0.017472911   694.63591
 gamma[9] 0.0000 0.000000000 0.00000000000 0.000000000 10000.00000
gamma[10] 0.9990 0.031608542 0.00031608542 0.001000000   999.09991

Quantiles:
          2.5% 25.0% 50.0% 75.0% 97.5%
 gamma[1]    0     0     1     1     1
 gamma[2]    1     1     1     1     1
 gamma[3]    0     0     0     0     0
 gamma[4]    1     1     1     1     1
 gamma[5]    1     1     1     1     1
 gamma[6]    1     1     1     1     1
 gamma[7]    1     1     1     1     1
 gamma[8]    0     0     1     1     1
 gamma[9]    0     0     0     0     0
gamma[10]    1     1     1     1     1


>>> Testing ../doc/samplers/hmc.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE       ESS   
b0 0.5772432  1.18402293 0.0167446128 0.027883682 1803.1006
b1 0.8022538  0.37671405 0.0053275412 0.008170591 2125.7719
s2 1.4971811 11.28460781 0.1595884542 0.195664541 3326.2025

Quantiles:
       2.5%        25.0%       50.0%      75.0%     97.5%  
b0 -1.714610896 0.015592733 0.55534270 1.17186976 3.0307402
b1  0.092367742 0.631187676 0.80982814 0.97620155 1.4874951
s2  0.178874019 0.383680766 0.66198223 1.22565452 7.0403625

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE       ESS   
b0 0.59496699 1.37677793 0.0194705802 0.035517823 1502.5714
b1 0.79853916 0.41130398 0.0058167167 0.009917444 1719.9916
s2 1.80970811 8.36078976 0.1182394227 0.312469964  715.9423

Quantiles:
       2.5%        25.0%      50.0%     75.0%     97.5%  
b0 -1.89540401 -0.028843232 0.6365522 1.2257351 3.0797518
b1  0.06653081  0.605516575 0.7862590 0.9763511 1.5777984
s2  0.16937961  0.390805781 0.6795564 1.3775763 8.2227653


>>> Testing ../doc/samplers/mala.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE      MCSE        ESS   
b0 0.63913008 0.96456516 0.013641011 0.109737267  77.260028
b1 0.79071667 0.29199225 0.004129394 0.030293853  92.903834
s2 1.16990867 2.21952343 0.031388801 0.159528112 193.573104

Quantiles:
       2.5%       25.0%       50.0%     75.0%     97.5%  
b0 -1.11636066 0.021295738 0.56942794 1.1958553 2.8185967
b1  0.13351555 0.622505238 0.81840154 0.9631912 1.3448359
s2  0.15082458 0.428174945 0.70535341 1.1853768 4.7815748

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean         SD       Naive SE      MCSE       ESS   
b0 0.61457782  1.09976885 0.0155530802 0.12576800  76.46497
b1 0.73181199  0.40025128 0.0056604079 0.04444227  81.10973
s2 2.93138741 13.82161613 0.1954671698 1.21062808 130.34554

Quantiles:
       2.5%       25.0%     50.0%     75.0%      97.5%  
b0 -1.29782609 0.00000000 0.4671962 1.0542319  3.6409243
b1 -0.09214223 0.57229743 0.7547751 0.9690808  1.4525190
s2  0.23962808 0.44855541 0.8566210 1.6689977 13.7557720


>>> Testing ../doc/samplers/nuts.jl

Iterations = 1001:5000
Thinning interval = 1
Chains = 1
Samples per chain = 4000

Empirical Posterior Estimates:
      Mean        SD       Naive SE      MCSE       ESS   
b0 0.59242566 1.12664340 0.0178137962 0.07262530 240.65621
b1 0.79955933 0.34124494 0.0053955563 0.02021753 284.88937
s2 1.23041170 2.28573689 0.0361406736 0.10397815 483.24600

Quantiles:
       2.5%        25.0%       50.0%     75.0%     97.5%  
b0 -1.60156914 -0.018689413 0.55936277 1.1737069 2.9302371
b1  0.09581153  0.620652115 0.81772866 0.9840868 1.4803526
s2  0.20677131  0.401460055 0.67740807 1.2526098 5.6494793


>>> Testing ../doc/samplers/rwm.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE       ESS   
b0 0.50814446 0.95649687 0.0135269085 0.105741241  81.82355
b1 0.82845138 0.29152116 0.0041227318 0.031171455  87.46333
s2 1.09352799 1.51797233 0.0214673706 0.072343598 440.27852

Quantiles:
       2.5%       25.0%       50.0%     75.0%     97.5%  
b0 -1.40016641 -0.10053289 0.52105167 1.1664813 2.3420987
b1  0.27991615  0.63683768 0.81974517 1.0071005 1.4073847
s2  0.18553138  0.40129932 0.68770085 1.1990384 4.5481870


>>> Testing ../doc/samplers/slice.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE     MCSE        ESS   
b0 0.95121197 1.39800189 0.019770732 0.16058158  75.792124
b1 0.70804449 0.38972473 0.005511540 0.04083353  91.092384
s2 1.68897644 4.98568184 0.070508189 0.41400577 145.022818

Quantiles:
       2.5%       25.0%      50.0%     75.0%      97.5%  
b0 -1.18134932 0.22505842 0.75133123 1.3961206  5.2902465
b1 -0.24667682 0.57032710 0.75324890 0.9190770  1.3468726
s2  0.16329786 0.38360098 0.64859723 1.3052359 10.1810850

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean       SD       Naive SE       MCSE       ESS   
b0 0.5918173 0.97247832 0.0137529202 0.088171432 121.64775
b1 0.8010611 0.29639544 0.0041916646 0.023762408 155.58300
s2 1.1918742 2.91584961 0.0412363406 0.118877515 601.63183

Quantiles:
       2.5%       25.0%      50.0%      75.0%     97.5%  
b0 -1.53289453 0.06956086 0.62086125 1.12897029 2.5922503
b1  0.19746079 0.64147194 0.79976963 0.95676223 1.4487573
s2  0.16453963 0.36687076 0.61831108 1.15173238 5.9535381


>>> Testing ../doc/samplers/slicesimplex.jl

Iterations = 1:10000
Thinning interval = 1
Chains = 1
Samples per chain = 10000

Empirical Posterior Estimates:
           Mean         SD        Naive SE        MCSE         ESS   
rho[1] 0.248226234 0.046152163 0.00046152163 0.00157730320  856.15765
rho[2] 0.447550434 0.052114565 0.00052114565 0.00169501907  945.29868
rho[3] 0.037041385 0.019252894 0.00019252894 0.00035283359 2977.50312
rho[4] 0.210953987 0.044335847 0.00044335847 0.00134947710 1079.39147
rho[5] 0.056227959 0.024815678 0.00024815678 0.00055892964 1971.23327

Quantiles:
           2.5%       25.0%       50.0%       75.0%      97.5%   
rho[1] 0.165900321 0.215926527 0.246423426 0.27800776 0.340375406
rho[2] 0.347831251 0.411912681 0.445754037 0.48324099 0.547990222
rho[3] 0.009397986 0.022734919 0.033517933 0.04816529 0.082564177
rho[4] 0.132507662 0.178996117 0.208263195 0.24010722 0.304900970
rho[5] 0.019444822 0.038398321 0.052554144 0.07004051 0.111909279


>>> Testing ../doc/mcmc/readcoda.jl

Iterations = 1:200
Thinning interval = 1
Chains = 1,2
Samples per chain = 200

Empirical Posterior Estimates:
         Mean       SD       Naive SE      MCSE       ESS   
alpha 3.0025394 0.53475753 0.026737877 0.018902157 200.00000
 beta 0.8013086 0.39267477 0.019633739 0.030895834 161.53482
sigma 1.0821777 0.94869150 0.047434575 0.061191837 200.00000

Quantiles:
         2.5%      25.0%   50.0%   75.0%     97.5%  
alpha  1.8322543 2.751095 3.0257 3.2709700 3.9511365
 beta -0.0125375 0.599750 0.8065 1.0079525 1.5292802
sigma  0.4329000 0.625000 0.8360 1.2378125 2.8597185


>>> Testing ../doc/mcmc/newunivardist.jl

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:59 of 0:00:59 remaining]
Chain 1:  10% [0:00:13 of 0:00:15 remaining]
Chain 1:  20% [0:00:10 of 0:00:13 remaining]
Chain 1:  30% [0:00:08 of 0:00:12 remaining]
Chain 1:  40% [0:00:07 of 0:00:11 remaining]
Chain 1:  50% [0:00:06 of 0:00:11 remaining]
Chain 1:  60% [0:00:05 of 0:00:12 remaining]
Chain 1:  70% [0:00:03 of 0:00:11 remaining]
Chain 1:  80% [0:00:02 of 0:00:11 remaining]
Chain 1:  90% [0:00:01 of 0:00:11 remaining]
Chain 1: 100% [0:00:00 of 0:00:10 remaining]

Chain 2:   0% [0:00:08 of 0:00:08 remaining]
Chain 2:  10% [0:00:10 of 0:00:11 remaining]
Chain 2:  20% [0:00:09 of 0:00:11 remaining]
Chain 2:  30% [0:00:09 of 0:00:13 remaining]
Chain 2:  40% [0:00:08 of 0:00:14 remaining]
Chain 2:  50% [0:00:06 of 0:00:13 remaining]
Chain 2:  60% [0:00:05 of 0:00:13 remaining]
Chain 2:  70% [0:00:04 of 0:00:12 remaining]
Chain 2:  80% [0:00:03 of 0:00:13 remaining]
Chain 2:  90% [0:00:01 of 0:00:13 remaining]
Chain 2: 100% [0:00:00 of 0:00:12 remaining]

Chain 3:   0% [0:00:08 of 0:00:08 remaining]
Chain 3:  10% [0:00:09 of 0:00:10 remaining]
Chain 3:  20% [0:00:08 of 0:00:10 remaining]
Chain 3:  30% [0:00:07 of 0:00:10 remaining]
Chain 3:  40% [0:00:07 of 0:00:12 remaining]
Chain 3:  50% [0:00:06 of 0:00:12 remaining]
Chain 3:  60% [0:00:05 of 0:00:13 remaining]
Chain 3:  70% [0:00:04 of 0:00:13 remaining]
Chain 3:  80% [0:00:03 of 0:00:13 remaining]
Chain 3:  90% [0:00:01 of 0:00:13 remaining]
Chain 3: 100% [0:00:00 of 0:00:13 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean        SD       Naive SE       MCSE        ESS   
beta[1] 0.62481855 1.13069488 0.0093496959 0.020284454 3107.16432
beta[2] 0.79324990 0.33717339 0.0027880808 0.005704912 3493.08133
     s2 1.17788901 1.49927725 0.0123974970 0.054386567  759.94227

Quantiles:
            2.5%       25.0%      50.0%      75.0%     97.5%  
beta[1] -1.70846237 0.05381795 0.62671080 1.19181153 2.9771710
beta[2]  0.09323227 0.62373985 0.79354583 0.96727498 1.4827648
     s2  0.17052462 0.38802892 0.66624493 1.28718785 5.7774314


>>> Testing ../doc/mcmc/newmultivardist.jl

WARNING: replacing module Testing
MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:58 of 0:00:58 remaining]
Chain 1:  10% [0:00:14 of 0:00:16 remaining]
Chain 1:  20% [0:00:13 of 0:00:17 remaining]
Chain 1:  30% [0:00:12 of 0:00:18 remaining]
Chain 1:  40% [0:00:09 of 0:00:16 remaining]
Chain 1:  50% [0:00:07 of 0:00:14 remaining]
Chain 1:  60% [0:00:05 of 0:00:14 remaining]
Chain 1:  70% [0:00:04 of 0:00:13 remaining]
Chain 1:  80% [0:00:02 of 0:00:12 remaining]
Chain 1:  90% [0:00:01 of 0:00:14 remaining]
Chain 1: 100% [0:00:00 of 0:00:14 remaining]

Chain 2:   0% [0:00:13 of 0:00:13 remaining]
Chain 2:  10% [0:00:11 of 0:00:13 remaining]
Chain 2:  20% [0:00:12 of 0:00:15 remaining]
Chain 2:  30% [0:00:11 of 0:00:16 remaining]
Chain 2:  40% [0:00:10 of 0:00:16 remaining]
Chain 2:  50% [0:00:08 of 0:00:16 remaining]
Chain 2:  60% [0:00:06 of 0:00:15 remaining]
Chain 2:  70% [0:00:05 of 0:00:15 remaining]
Chain 2:  80% [0:00:03 of 0:00:15 remaining]
Chain 2:  90% [0:00:02 of 0:00:15 remaining]
Chain 2: 100% [0:00:00 of 0:00:15 remaining]

Chain 3:   0% [0:00:06 of 0:00:06 remaining]
Chain 3:  10% [0:00:09 of 0:00:09 remaining]
Chain 3:  20% [0:00:10 of 0:00:12 remaining]
Chain 3:  30% [0:00:09 of 0:00:12 remaining]
Chain 3:  40% [0:00:08 of 0:00:14 remaining]
Chain 3:  50% [0:00:07 of 0:00:13 remaining]
Chain 3:  60% [0:00:06 of 0:00:14 remaining]
Chain 3:  70% [0:00:04 of 0:00:14 remaining]
Chain 3:  80% [0:00:03 of 0:00:15 remaining]
Chain 3:  90% [0:00:01 of 0:00:15 remaining]
Chain 3: 100% [0:00:00 of 0:00:15 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean       SD       Naive SE       MCSE        ESS   
beta[1] 0.5944546 1.15066286 0.0095148109 0.0187248142 3776.2537
beta[2] 0.8026082 0.34856483 0.0028822764 0.0054006603 4165.5601
     s2 1.2761255 1.80789780 0.0149494749 0.0777842596  540.2121

Quantiles:
            2.5%       25.0%       50.0%      75.0%     97.5%  
beta[1] -1.78847515 0.024054024 0.61792614 1.18833558 2.8697230
beta[2]  0.11673659 0.621669413 0.79752883 0.97290976 1.5493335
     s2  0.17118817 0.390583641 0.67100143 1.32440898 6.9417684

INFO: Mamba tests passed

>>> End of log
