>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.7
INFO: Installing Blosc v0.2.0
INFO: Installing Calculus v0.2.1
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.3
INFO: Installing JLD v0.6.9
INFO: Installing LegacyStrings v0.2.0
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.5.6
INFO: Installing Rmath v0.1.6
INFO: Installing SHA v0.3.2
INFO: Installing ScikitLearnBase v0.2.2
INFO: Installing StatsBase v0.12.0
INFO: Installing StatsFuns v0.4.0
INFO: Installing URIParser v0.1.8
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-112-generic #159-Ubuntu SMP Fri Mar 3 15:26:07 UTC 2017 x86_64 x86_64
Memory: 2.9392738342285156 GB (620.62890625 MB free)
Uptime: 31309.0 sec
Load Avg:  1.05615234375  1.0458984375  1.04736328125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1458079 s       4035 s     131249 s    1218465 s        136 s
#2  3500 MHz    1031441 s       3514 s     119186 s    1853906 s          7 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.8.3
19 additional packages:
 - BinDeps                       0.4.7
 - Blosc                         0.2.0
 - Calculus                      0.2.1
 - Clustering                    0.7.0
 - Compat                        0.20.0
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.2
 - HDF5                          0.7.3
 - JLD                           0.6.9
 - LegacyStrings                 0.2.0
 - NearestNeighbors              0.0.5
 - PDMats                        0.5.6
 - Rmath                         0.1.6
 - SHA                           0.3.2
 - ScikitLearnBase               0.2.2
 - StatsBase                     0.12.0
 - StatsFuns                     0.4.0
 - URIParser                     0.1.8
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-1.25937231021467e6,[82584.37155695823,17415.628443041776],
[-10428.201439801252 -9544.349204605129 -7710.244922471163
 10442.03998799414 9553.820945630963 7660.250933596248],

[
[73728.73046056062 -192.92564791521903 6812.370998874485
 -192.92564791521906 82938.79348462613 -6528.673047414932
 6812.370998874485 -6528.673047414932 87095.43876542956],

[26175.306924290628 -811.5707114857438 -7207.095705988852
 -811.5707114857438 17561.813147402172 6668.524566856711
 -7207.095705988852 6668.524566856711 13152.415093093407]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.533630e+03
      1       9.455172e+02      -5.881124e+02 |        8
      2       8.797649e+02      -6.575229e+01 |        2
      3       8.729943e+02      -6.770655e+00 |        0
      4       8.729943e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 872.9942895908698)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.076377
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.859333
INFO: iteration 2, lowerbound -3.749090
INFO: iteration 3, lowerbound -3.616970
INFO: iteration 4, lowerbound -3.439175
INFO: iteration 5, lowerbound -3.233568
INFO: iteration 6, lowerbound -3.037332
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.876352
INFO: iteration 8, lowerbound -2.763025
INFO: dropping number of Gaussions to 6
INFO: iteration 9, lowerbound -2.693155
INFO: dropping number of Gaussions to 3
INFO: iteration 10, lowerbound -2.623175
INFO: iteration 11, lowerbound -2.544881
INFO: iteration 12, lowerbound -2.476939
INFO: iteration 13, lowerbound -2.418543
INFO: iteration 14, lowerbound -2.373462
INFO: iteration 15, lowerbound -2.340043
INFO: iteration 16, lowerbound -2.317334
INFO: iteration 17, lowerbound -2.307636
INFO: dropping number of Gaussions to 2
INFO: iteration 18, lowerbound -2.303000
INFO: iteration 19, lowerbound -2.299263
INFO: iteration 20, lowerbound -2.299257
INFO: iteration 21, lowerbound -2.299255
INFO: iteration 22, lowerbound -2.299254
INFO: iteration 23, lowerbound -2.299253
INFO: iteration 24, lowerbound -2.299253
INFO: iteration 25, lowerbound -2.299253
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Tue 14 Mar 2017 01:03:31 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Tue 14 Mar 2017 01:03:32 PM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Tue 14 Mar 2017 01:03:33 PM UTC: EM with 272 data points 0 iterations avll -2.076377
5.8 data points per parameter
,Tue 14 Mar 2017 01:03:35 PM UTC: GMM converted to Variational GMM
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 1, lowerbound -3.859333
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 2, lowerbound -3.749090
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 3, lowerbound -3.616970
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 4, lowerbound -3.439175
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 5, lowerbound -3.233568
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 6, lowerbound -3.037332
,Tue 14 Mar 2017 01:03:37 PM UTC: dropping number of Gaussions to 7
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 7, lowerbound -2.876352
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 8, lowerbound -2.763025
,Tue 14 Mar 2017 01:03:37 PM UTC: dropping number of Gaussions to 6
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 9, lowerbound -2.693155
,Tue 14 Mar 2017 01:03:37 PM UTC: dropping number of Gaussions to 3
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 10, lowerbound -2.623175
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 11, lowerbound -2.544881
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 12, lowerbound -2.476939
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 13, lowerbound -2.418543
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 14, lowerbound -2.373462
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 15, lowerbound -2.340043
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 16, lowerbound -2.317334
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 17, lowerbound -2.307636
,Tue 14 Mar 2017 01:03:37 PM UTC: dropping number of Gaussions to 2
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 18, lowerbound -2.303000
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 19, lowerbound -2.299263
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 20, lowerbound -2.299257
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 21, lowerbound -2.299255
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 22, lowerbound -2.299254
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 23, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 24, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 25, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 26, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 27, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 28, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 29, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 30, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 31, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 32, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 33, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 34, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 35, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 36, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 37, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 38, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 39, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 40, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 41, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 42, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 43, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 44, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 45, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 46, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 47, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 48, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 49, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: iteration 50, lowerbound -2.299253
,Tue 14 Mar 2017 01:03:37 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.95490777398625,178.04509222601374]
Î² = [95.95490777398625,178.04509222601374]
m = [2.000229257775371 53.85198717246131
 4.250300733269912 79.28686694436183]
Î½ = [97.95490777398625,180.04509222601374]
W = [
[0.37587636119483686 -0.008953123827346032
 0.0 0.012748664777409378],

[0.18404155547484782 -0.007644049042327235
 0.0 0.008581705166333407]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000006
avll from stats: -0.966894608371229
avll from llpg:  -0.9668946083711754
avll direct:     -0.9668946083711756
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9552390824265201
avll from llpg:  -0.9552390824265204
avll direct:     -0.9552390824265206
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.0864349    0.0210708   â€¦   0.0906908   0.007297     0.0237473
 -0.0461662    0.138768        0.0192065  -0.0354811    0.0446949
  0.131687    -0.159924       -0.0408033   0.12489     -0.0457031
  0.134218     0.0637444       0.0449386  -0.0392011    0.224162 
  0.00359707  -0.0824767      -0.098109   -0.0815692    0.124358 
 -0.0449671    0.0358584   â€¦   0.0761399   0.0913381   -0.0795299
 -0.163339    -0.00469615     -0.0988885   0.108455    -0.0198488
  0.10233      0.0725193       0.144516    0.0359267    0.110678 
  0.053894     0.0866159      -0.0109583   0.131705     0.053734 
  0.122498    -0.161416        0.136408   -0.0737828    0.0293907
  â‹®                        â‹±                            â‹®        
 -0.0360457    0.100947       -0.0441179   0.220164    -0.0943009
 -0.0160251    0.170407        0.0668125  -0.00382467   0.0973769
  0.213266    -0.00962796  â€¦   0.0576579   0.0860037    0.0149596
 -0.0273276   -0.00722435      0.0913351   0.16374     -0.0317769
  0.00505591  -0.0636238      -0.101967    0.151598     0.0696074
  0.0694982   -0.164826        0.0714219   0.00313682  -0.0249551
 -0.0290875    0.128022        0.0465819  -0.0585024    0.0406666
 -0.053761    -0.230314    â€¦  -0.0230407   0.139108     0.0854624
  0.0569065   -0.0726091      -0.118993    0.0475207   -0.171686 kind diag, method split
0: avll = -1.446475264868141
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.446557
INFO: iteration 2, average log likelihood -1.446489
INFO: iteration 3, average log likelihood -1.446191
INFO: iteration 4, average log likelihood -1.443057
INFO: iteration 5, average log likelihood -1.432155
INFO: iteration 6, average log likelihood -1.422713
INFO: iteration 7, average log likelihood -1.419027
INFO: iteration 8, average log likelihood -1.416726
INFO: iteration 9, average log likelihood -1.414613
INFO: iteration 10, average log likelihood -1.412465
INFO: iteration 11, average log likelihood -1.410889
INFO: iteration 12, average log likelihood -1.409797
INFO: iteration 13, average log likelihood -1.409093
INFO: iteration 14, average log likelihood -1.408669
INFO: iteration 15, average log likelihood -1.408427
INFO: iteration 16, average log likelihood -1.408285
INFO: iteration 17, average log likelihood -1.408203
INFO: iteration 18, average log likelihood -1.408159
INFO: iteration 19, average log likelihood -1.408136
INFO: iteration 20, average log likelihood -1.408125
INFO: iteration 21, average log likelihood -1.408119
INFO: iteration 22, average log likelihood -1.408116
INFO: iteration 23, average log likelihood -1.408114
INFO: iteration 24, average log likelihood -1.408112
INFO: iteration 25, average log likelihood -1.408112
INFO: iteration 26, average log likelihood -1.408111
INFO: iteration 27, average log likelihood -1.408111
INFO: iteration 28, average log likelihood -1.408111
INFO: iteration 29, average log likelihood -1.408110
INFO: iteration 30, average log likelihood -1.408110
INFO: iteration 31, average log likelihood -1.408110
INFO: iteration 32, average log likelihood -1.408110
INFO: iteration 33, average log likelihood -1.408110
INFO: iteration 34, average log likelihood -1.408110
INFO: iteration 35, average log likelihood -1.408110
INFO: iteration 36, average log likelihood -1.408110
INFO: iteration 37, average log likelihood -1.408110
INFO: iteration 38, average log likelihood -1.408110
INFO: iteration 39, average log likelihood -1.408110
INFO: iteration 40, average log likelihood -1.408110
INFO: iteration 41, average log likelihood -1.408110
INFO: iteration 42, average log likelihood -1.408110
INFO: iteration 43, average log likelihood -1.408110
INFO: iteration 44, average log likelihood -1.408110
INFO: iteration 45, average log likelihood -1.408110
INFO: iteration 46, average log likelihood -1.408110
INFO: iteration 47, average log likelihood -1.408110
INFO: iteration 48, average log likelihood -1.408110
INFO: iteration 49, average log likelihood -1.408110
INFO: iteration 50, average log likelihood -1.408110
INFO: EM with 100000 data points 50 iterations avll -1.408110
952.4 data points per parameter
1: avll = [-1.4465573230924336,-1.4464888464055734,-1.4461909373129789,-1.4430568695468444,-1.4321552577981145,-1.4227129875206679,-1.4190271136937251,-1.4167260797704906,-1.4146126479678798,-1.4124649413318278,-1.4108894951644548,-1.4097974630051617,-1.4090928959926787,-1.4086688448494415,-1.4084265688571298,-1.4082846258218964,-1.4082029522792259,-1.408158553836347,-1.4081360594251453,-1.4081247603915286,-1.4081188503220186,-1.4081155828771572,-1.4081136707942274,-1.408112492484846,-1.408111734284559,-1.4081112295567337,-1.4081108848668065,-1.408110645026189,-1.4081104758774223,-1.408110355428975,-1.4081102690663956,-1.4081102068369835,-1.4081101618368168,-1.4081101292111915,-1.4081101055121745,-1.4081100882730748,-1.4081100757197895,-1.4081100665713582,-1.4081100599002185,-1.408110055033274,-1.4081100514812972,-1.4081100488882727,-1.4081100469948853,-1.4081100456121198,-1.4081100446021282,-1.408110043864334,-1.4081100433253306,-1.4081100429315287,-1.4081100426437956,-1.4081100424335526]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.408249
INFO: iteration 2, average log likelihood -1.408125
INFO: iteration 3, average log likelihood -1.407629
INFO: iteration 4, average log likelihood -1.403131
INFO: iteration 5, average log likelihood -1.389681
INFO: iteration 6, average log likelihood -1.376460
INFO: iteration 7, average log likelihood -1.371436
INFO: iteration 8, average log likelihood -1.369787
INFO: iteration 9, average log likelihood -1.368985
INFO: iteration 10, average log likelihood -1.368483
INFO: iteration 11, average log likelihood -1.368129
INFO: iteration 12, average log likelihood -1.367873
INFO: iteration 13, average log likelihood -1.367690
INFO: iteration 14, average log likelihood -1.367559
INFO: iteration 15, average log likelihood -1.367463
INFO: iteration 16, average log likelihood -1.367389
INFO: iteration 17, average log likelihood -1.367327
INFO: iteration 18, average log likelihood -1.367273
INFO: iteration 19, average log likelihood -1.367219
INFO: iteration 20, average log likelihood -1.367163
INFO: iteration 21, average log likelihood -1.367097
INFO: iteration 22, average log likelihood -1.367010
INFO: iteration 23, average log likelihood -1.366893
INFO: iteration 24, average log likelihood -1.366748
INFO: iteration 25, average log likelihood -1.366591
INFO: iteration 26, average log likelihood -1.366429
INFO: iteration 27, average log likelihood -1.366267
INFO: iteration 28, average log likelihood -1.366107
INFO: iteration 29, average log likelihood -1.365951
INFO: iteration 30, average log likelihood -1.365816
INFO: iteration 31, average log likelihood -1.365716
INFO: iteration 32, average log likelihood -1.365646
INFO: iteration 33, average log likelihood -1.365594
INFO: iteration 34, average log likelihood -1.365555
INFO: iteration 35, average log likelihood -1.365524
INFO: iteration 36, average log likelihood -1.365499
INFO: iteration 37, average log likelihood -1.365479
INFO: iteration 38, average log likelihood -1.365462
INFO: iteration 39, average log likelihood -1.365448
INFO: iteration 40, average log likelihood -1.365437
INFO: iteration 41, average log likelihood -1.365428
INFO: iteration 42, average log likelihood -1.365421
INFO: iteration 43, average log likelihood -1.365416
INFO: iteration 44, average log likelihood -1.365411
INFO: iteration 45, average log likelihood -1.365407
INFO: iteration 46, average log likelihood -1.365405
INFO: iteration 47, average log likelihood -1.365402
INFO: iteration 48, average log likelihood -1.365400
INFO: iteration 49, average log likelihood -1.365399
INFO: iteration 50, average log likelihood -1.365398
INFO: EM with 100000 data points 50 iterations avll -1.365398
473.9 data points per parameter
2: avll = [-1.408248599248965,-1.4081250829614274,-1.4076290285298074,-1.4031308917288807,-1.3896809159230343,-1.3764601935132201,-1.3714360631670641,-1.3697873736366433,-1.3689848825874062,-1.3684828865851189,-1.3681288853066418,-1.367872731463566,-1.3676897280631042,-1.3675587534007367,-1.3674625390953647,-1.3673885063573692,-1.3673273134663197,-1.367272584083949,-1.3672194717297546,-1.3671630854745518,-1.3670966581263084,-1.3670099273505014,-1.36689270830894,-1.3667482880142732,-1.3665907729624032,-1.3664290512703072,-1.3662672097723352,-1.3661066001963795,-1.3659510141870659,-1.3658164260373964,-1.3657164381310878,-1.365645576248064,-1.3655939562803363,-1.365554718721628,-1.3655238222450647,-1.3654988879512986,-1.3654785062058958,-1.3654617945183134,-1.3654481448245355,-1.3654370909148408,-1.3654282240019502,-1.3654211584410834,-1.365415539973209,-1.3654110637657066,-1.365407482021393,-1.3654046002756692,-1.3654022683976759,-1.3654003709575042,-1.365398818962007,-1.3653975433843104]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.365554
INFO: iteration 2, average log likelihood -1.365385
INFO: iteration 3, average log likelihood -1.364745
INFO: iteration 4, average log likelihood -1.359375
INFO: iteration 5, average log likelihood -1.344024
INFO: iteration 6, average log likelihood -1.330262
INFO: iteration 7, average log likelihood -1.322934
INFO: iteration 8, average log likelihood -1.318609
INFO: iteration 9, average log likelihood -1.315448
INFO: iteration 10, average log likelihood -1.312885
INFO: iteration 11, average log likelihood -1.310957
INFO: iteration 12, average log likelihood -1.309599
INFO: iteration 13, average log likelihood -1.308703
INFO: iteration 14, average log likelihood -1.307896
INFO: iteration 15, average log likelihood -1.307052
INFO: iteration 16, average log likelihood -1.306336
INFO: iteration 17, average log likelihood -1.305887
INFO: iteration 18, average log likelihood -1.305589
INFO: iteration 19, average log likelihood -1.305340
INFO: iteration 20, average log likelihood -1.305114
INFO: iteration 21, average log likelihood -1.304911
INFO: iteration 22, average log likelihood -1.304729
INFO: iteration 23, average log likelihood -1.304583
INFO: iteration 24, average log likelihood -1.304481
INFO: iteration 25, average log likelihood -1.304418
INFO: iteration 26, average log likelihood -1.304383
INFO: iteration 27, average log likelihood -1.304364
INFO: iteration 28, average log likelihood -1.304353
INFO: iteration 29, average log likelihood -1.304346
INFO: iteration 30, average log likelihood -1.304340
INFO: iteration 31, average log likelihood -1.304334
INFO: iteration 32, average log likelihood -1.304329
INFO: iteration 33, average log likelihood -1.304325
INFO: iteration 34, average log likelihood -1.304321
INFO: iteration 35, average log likelihood -1.304317
INFO: iteration 36, average log likelihood -1.304313
INFO: iteration 37, average log likelihood -1.304310
INFO: iteration 38, average log likelihood -1.304307
INFO: iteration 39, average log likelihood -1.304304
INFO: iteration 40, average log likelihood -1.304301
INFO: iteration 41, average log likelihood -1.304299
INFO: iteration 42, average log likelihood -1.304297
INFO: iteration 43, average log likelihood -1.304296
INFO: iteration 44, average log likelihood -1.304294
INFO: iteration 45, average log likelihood -1.304293
INFO: iteration 46, average log likelihood -1.304292
INFO: iteration 47, average log likelihood -1.304291
INFO: iteration 48, average log likelihood -1.304291
INFO: iteration 49, average log likelihood -1.304290
INFO: iteration 50, average log likelihood -1.304290
INFO: EM with 100000 data points 50 iterations avll -1.304290
236.4 data points per parameter
3: avll = [-1.3655541973056793,-1.3653849728621303,-1.36474465337863,-1.3593746947681862,-1.3440240049737038,-1.3302618372348936,-1.3229338770527854,-1.3186086772969683,-1.3154476553564314,-1.3128854595045607,-1.3109566774630268,-1.3095993165812936,-1.3087028176027,-1.3078961002730627,-1.3070520542192345,-1.3063364346184823,-1.305887199905495,-1.3055891149225123,-1.3053398198748445,-1.3051144551599698,-1.3049114882755914,-1.304728562156301,-1.304582862636592,-1.3044811426862464,-1.3044181401591164,-1.3043829469127102,-1.3043640299804957,-1.3043530236865533,-1.3043455191207511,-1.304339550351608,-1.3043343073283886,-1.304329474346999,-1.3043249416132012,-1.3043206852358906,-1.3043167127488453,-1.304313035558603,-1.304309658179847,-1.304306578867481,-1.3043037943578146,-1.3043013025391403,-1.3042991011447973,-1.3042971844163709,-1.3042955404752234,-1.304294150716308,-1.3042929910504215,-1.3042920341393893,-1.3042912517529557,-1.304290616686778,-1.3042901040339792,-1.3042896918456253]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.304512
INFO: iteration 2, average log likelihood -1.304259
INFO: iteration 3, average log likelihood -1.303059
INFO: iteration 4, average log likelihood -1.288628
WARNING: Variances had to be floored 3 4 8
INFO: iteration 5, average log likelihood -1.244782
INFO: iteration 6, average log likelihood -1.245609
WARNING: Variances had to be floored 4 8
INFO: iteration 7, average log likelihood -1.223471
WARNING: Variances had to be floored 3
INFO: iteration 8, average log likelihood -1.222783
WARNING: Variances had to be floored 4 8
INFO: iteration 9, average log likelihood -1.219058
WARNING: Variances had to be floored 3
INFO: iteration 10, average log likelihood -1.219531
WARNING: Variances had to be floored 4 8
INFO: iteration 11, average log likelihood -1.214364
WARNING: Variances had to be floored 3
INFO: iteration 12, average log likelihood -1.215369
WARNING: Variances had to be floored 4
INFO: iteration 13, average log likelihood -1.212010
WARNING: Variances had to be floored 3 8 16
INFO: iteration 14, average log likelihood -1.208026
WARNING: Variances had to be floored 4
INFO: iteration 15, average log likelihood -1.225990
WARNING: Variances had to be floored 3
INFO: iteration 16, average log likelihood -1.212534
WARNING: Variances had to be floored 4
INFO: iteration 17, average log likelihood -1.211106
WARNING: Variances had to be floored 3
INFO: iteration 18, average log likelihood -1.207701
WARNING: Variances had to be floored 4
INFO: iteration 19, average log likelihood -1.209534
WARNING: Variances had to be floored 3
INFO: iteration 20, average log likelihood -1.206653
WARNING: Variances had to be floored 4
INFO: iteration 21, average log likelihood -1.208179
WARNING: Variances had to be floored 3
INFO: iteration 22, average log likelihood -1.205029
WARNING: Variances had to be floored 4
INFO: iteration 23, average log likelihood -1.206609
WARNING: Variances had to be floored 3
INFO: iteration 24, average log likelihood -1.204013
WARNING: Variances had to be floored 4 16
INFO: iteration 25, average log likelihood -1.206230
WARNING: Variances had to be floored 3
INFO: iteration 26, average log likelihood -1.214562
WARNING: Variances had to be floored 4
INFO: iteration 27, average log likelihood -1.211383
WARNING: Variances had to be floored 3
INFO: iteration 28, average log likelihood -1.207947
WARNING: Variances had to be floored 4
INFO: iteration 29, average log likelihood -1.209853
WARNING: Variances had to be floored 3
INFO: iteration 30, average log likelihood -1.207191
WARNING: Variances had to be floored 4
INFO: iteration 31, average log likelihood -1.208961
WARNING: Variances had to be floored 3
INFO: iteration 32, average log likelihood -1.205976
WARNING: Variances had to be floored 4
INFO: iteration 33, average log likelihood -1.207419
WARNING: Variances had to be floored 3
INFO: iteration 34, average log likelihood -1.204345
WARNING: Variances had to be floored 4
INFO: iteration 35, average log likelihood -1.206123
WARNING: Variances had to be floored 3 16
INFO: iteration 36, average log likelihood -1.203772
WARNING: Variances had to be floored 4
INFO: iteration 37, average log likelihood -1.216592
WARNING: Variances had to be floored 3
INFO: iteration 38, average log likelihood -1.208897
WARNING: Variances had to be floored 4
INFO: iteration 39, average log likelihood -1.209989
WARNING: Variances had to be floored 3
INFO: iteration 40, average log likelihood -1.207318
WARNING: Variances had to be floored 4
INFO: iteration 41, average log likelihood -1.209265
WARNING: Variances had to be floored 3
INFO: iteration 42, average log likelihood -1.206489
WARNING: Variances had to be floored 4
INFO: iteration 43, average log likelihood -1.208176
WARNING: Variances had to be floored 3
INFO: iteration 44, average log likelihood -1.205071
WARNING: Variances had to be floored 4
INFO: iteration 45, average log likelihood -1.206558
WARNING: Variances had to be floored 3
INFO: iteration 46, average log likelihood -1.203743
WARNING: Variances had to be floored 4 16
INFO: iteration 47, average log likelihood -1.205912
WARNING: Variances had to be floored 3
INFO: iteration 48, average log likelihood -1.214166
WARNING: Variances had to be floored 4
INFO: iteration 49, average log likelihood -1.211061
WARNING: Variances had to be floored 3
INFO: iteration 50, average log likelihood -1.207582
INFO: EM with 100000 data points 50 iterations avll -1.207582
118.1 data points per parameter
4: avll = [-1.3045122379244236,-1.3042591005777098,-1.3030588784317005,-1.2886282005091902,-1.2447824649306571,-1.2456086664543695,-1.2234706278485157,-1.2227828032719208,-1.2190575407829785,-1.2195305518544093,-1.2143641441578696,-1.215369066604324,-1.2120100356341619,-1.2080258162583164,-1.2259896853793637,-1.2125341722279586,-1.2111057923893076,-1.2077010361242944,-1.209534182211045,-1.2066531223782846,-1.2081787531756754,-1.2050288388704447,-1.2066091703406219,-1.204013357848805,-1.2062300325139472,-1.2145617407260605,-1.2113826196533386,-1.207946858307459,-1.2098525276732186,-1.2071909624679613,-1.2089609752703856,-1.2059760603099163,-1.207418791125708,-1.2043448915003854,-1.2061229421849775,-1.2037716953197728,-1.2165919574987394,-1.2088967680057694,-1.209989372441396,-1.2073181131958604,-1.2092647145694813,-1.2064892345203828,-1.2081762843087545,-1.2050712783095026,-1.2065581335812283,-1.2037433497026346,-1.205912248671605,-1.214165579666305,-1.2110614681170084,-1.2075815017923128]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 7 8
INFO: iteration 1, average log likelihood -1.209949
WARNING: Variances had to be floored 5 6 7 8
INFO: iteration 2, average log likelihood -1.199907
WARNING: Variances had to be floored 7 8 16
INFO: iteration 3, average log likelihood -1.206695
WARNING: Variances had to be floored 5 6 7 8 16 23
INFO: iteration 4, average log likelihood -1.179944
WARNING: Variances had to be floored 3 4 7 8 16 17 23
INFO: iteration 5, average log likelihood -1.157064
WARNING: Variances had to be floored 5 6 7 8 16 23 28 31
INFO: iteration 6, average log likelihood -1.141883
WARNING: Variances had to be floored 4 7 8 16 23
INFO: iteration 7, average log likelihood -1.147033
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 32
INFO: iteration 8, average log likelihood -1.124420
WARNING: Variances had to be floored 4 7 8 16 23 28
INFO: iteration 9, average log likelihood -1.140330
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23
INFO: iteration 10, average log likelihood -1.128674
WARNING: Variances had to be floored 4 7 8 16 19 23
INFO: iteration 11, average log likelihood -1.129193
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 28 32
INFO: iteration 12, average log likelihood -1.115671
WARNING: Variances had to be floored 4 7 8 16 23
INFO: iteration 13, average log likelihood -1.139751
WARNING: Variances had to be floored 3 5 6 7 8 16 17 19 23
INFO: iteration 14, average log likelihood -1.112367
WARNING: Variances had to be floored 4 7 8 16 23 28
INFO: iteration 15, average log likelihood -1.129814
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 32
INFO: iteration 16, average log likelihood -1.118288
WARNING: Variances had to be floored 4 7 8 16 19 23
INFO: iteration 17, average log likelihood -1.127765
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 28
INFO: iteration 18, average log likelihood -1.115085
WARNING: Variances had to be floored 4 7 8 16 23
INFO: iteration 19, average log likelihood -1.133375
WARNING: Variances had to be floored 3 5 6 7 8 16 17 19 23 32
INFO: iteration 20, average log likelihood -1.107557
WARNING: Variances had to be floored 4 7 8 16 23 28
INFO: iteration 21, average log likelihood -1.133335
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23
INFO: iteration 22, average log likelihood -1.119474
WARNING: Variances had to be floored 4 7 8 16 19 23
INFO: iteration 23, average log likelihood -1.122631
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 28 32
INFO: iteration 24, average log likelihood -1.113065
WARNING: Variances had to be floored 4 7 8 16 23
INFO: iteration 25, average log likelihood -1.137468
WARNING: Variances had to be floored 3 5 6 7 8 16 17 19 23
INFO: iteration 26, average log likelihood -1.108148
WARNING: Variances had to be floored 4 7 8 12 16 23 28
INFO: iteration 27, average log likelihood -1.123747
WARNING: Variances had to be floored 3 5 6 7 8 16 23 32
INFO: iteration 28, average log likelihood -1.116704
WARNING: Variances had to be floored 4 7 8 16 17 19 23 26
INFO: iteration 29, average log likelihood -1.117639
WARNING: Variances had to be floored 3 5 6 7 8 16 23 28
INFO: iteration 30, average log likelihood -1.130191
WARNING: Variances had to be floored 4 7 8 16 17 23
INFO: iteration 31, average log likelihood -1.132262
WARNING: Variances had to be floored 3 5 6 7 8 16 19 23 28 32
INFO: iteration 32, average log likelihood -1.113836
WARNING: Variances had to be floored 4 7 8 12 16 17 23
INFO: iteration 33, average log likelihood -1.132345
WARNING: Variances had to be floored 3 5 6 7 8 16 23 28
INFO: iteration 34, average log likelihood -1.119432
WARNING: Variances had to be floored 4 7 8 16 19 23
INFO: iteration 35, average log likelihood -1.122830
WARNING: Variances had to be floored 3 5 6 7 8 16 17 23 26 32
INFO: iteration 36, average log likelihood -1.112696
WARNING: Variances had to be floored 4 7 8 16 23 28
INFO: iteration 37, average log likelihood -1.135363
WARNING: Variances had to be floored 3 5 6 7 8 12 16 17 19 23
INFO: iteration 38, average log likelihood -1.115632
WARNING: Variances had to be floored 4 7 8 16 23
INFO: iteration 39, average log likelihood -1.134464
WARNING: Variances had to be floored 3 5 6 7 8 16 23 28 32
INFO: iteration 40, average log likelihood -1.108686
WARNING: Variances had to be floored 4 7 8 16 17 19 23
INFO: iteration 41, average log likelihood -1.126554
WARNING: Variances had to be floored 3 5 6 7 8 16 23
INFO: iteration 42, average log likelihood -1.120487
WARNING: Variances had to be floored 4 7 8 12 16 17 23 26 28
INFO: iteration 43, average log likelihood -1.106961
WARNING: Variances had to be floored 3 5 6 7 8 16 19 23 32
INFO: iteration 44, average log likelihood -1.128452
WARNING: Variances had to be floored 4 7 8 16 17 23
INFO: iteration 45, average log likelihood -1.134269
WARNING: Variances had to be floored 3 5 6 7 8 16 23 28
INFO: iteration 46, average log likelihood -1.115835
WARNING: Variances had to be floored 4 7 8 16 17 19 23
INFO: iteration 47, average log likelihood -1.122947
WARNING: Variances had to be floored 3 5 6 7 8 16 23 28 32
INFO: iteration 48, average log likelihood -1.120655
WARNING: Variances had to be floored 4 7 8 16 17 23
INFO: iteration 49, average log likelihood -1.124042
WARNING: Variances had to be floored 3 5 6 7 8 16 19 22 23 28
INFO: iteration 50, average log likelihood -1.101106
INFO: EM with 100000 data points 50 iterations avll -1.101106
59.0 data points per parameter
5: avll = [-1.2099494162842974,-1.199907244723506,-1.2066947767382212,-1.1799439540399146,-1.157064078327944,-1.14188269224742,-1.1470326077304591,-1.1244195731484607,-1.1403301017276783,-1.1286742359634794,-1.1291929625029948,-1.1156714512933432,-1.1397510702180158,-1.1123674291224348,-1.12981424310205,-1.118287560120219,-1.1277646070744476,-1.1150853084698276,-1.1333753986598587,-1.1075567177469712,-1.1333350515487808,-1.1194735194195207,-1.1226311979649282,-1.1130651583064655,-1.1374678606380417,-1.1081482252615618,-1.1237471495282114,-1.116703669091172,-1.1176391507812664,-1.130191308938175,-1.1322624619187678,-1.1138364786721575,-1.1323449908858059,-1.1194319989419748,-1.1228300195160577,-1.1126956724701926,-1.1353627956063963,-1.1156316799069737,-1.1344635366422868,-1.1086863183353692,-1.126553957933733,-1.1204870800845776,-1.1069607362613583,-1.128452214260804,-1.1342685650254927,-1.1158348909669746,-1.122947315930924,-1.1206552701853552,-1.124041701912479,-1.1011057575203393]
[-1.446475264868141,-1.4465573230924336,-1.4464888464055734,-1.4461909373129789,-1.4430568695468444,-1.4321552577981145,-1.4227129875206679,-1.4190271136937251,-1.4167260797704906,-1.4146126479678798,-1.4124649413318278,-1.4108894951644548,-1.4097974630051617,-1.4090928959926787,-1.4086688448494415,-1.4084265688571298,-1.4082846258218964,-1.4082029522792259,-1.408158553836347,-1.4081360594251453,-1.4081247603915286,-1.4081188503220186,-1.4081155828771572,-1.4081136707942274,-1.408112492484846,-1.408111734284559,-1.4081112295567337,-1.4081108848668065,-1.408110645026189,-1.4081104758774223,-1.408110355428975,-1.4081102690663956,-1.4081102068369835,-1.4081101618368168,-1.4081101292111915,-1.4081101055121745,-1.4081100882730748,-1.4081100757197895,-1.4081100665713582,-1.4081100599002185,-1.408110055033274,-1.4081100514812972,-1.4081100488882727,-1.4081100469948853,-1.4081100456121198,-1.4081100446021282,-1.408110043864334,-1.4081100433253306,-1.4081100429315287,-1.4081100426437956,-1.4081100424335526,-1.408248599248965,-1.4081250829614274,-1.4076290285298074,-1.4031308917288807,-1.3896809159230343,-1.3764601935132201,-1.3714360631670641,-1.3697873736366433,-1.3689848825874062,-1.3684828865851189,-1.3681288853066418,-1.367872731463566,-1.3676897280631042,-1.3675587534007367,-1.3674625390953647,-1.3673885063573692,-1.3673273134663197,-1.367272584083949,-1.3672194717297546,-1.3671630854745518,-1.3670966581263084,-1.3670099273505014,-1.36689270830894,-1.3667482880142732,-1.3665907729624032,-1.3664290512703072,-1.3662672097723352,-1.3661066001963795,-1.3659510141870659,-1.3658164260373964,-1.3657164381310878,-1.365645576248064,-1.3655939562803363,-1.365554718721628,-1.3655238222450647,-1.3654988879512986,-1.3654785062058958,-1.3654617945183134,-1.3654481448245355,-1.3654370909148408,-1.3654282240019502,-1.3654211584410834,-1.365415539973209,-1.3654110637657066,-1.365407482021393,-1.3654046002756692,-1.3654022683976759,-1.3654003709575042,-1.365398818962007,-1.3653975433843104,-1.3655541973056793,-1.3653849728621303,-1.36474465337863,-1.3593746947681862,-1.3440240049737038,-1.3302618372348936,-1.3229338770527854,-1.3186086772969683,-1.3154476553564314,-1.3128854595045607,-1.3109566774630268,-1.3095993165812936,-1.3087028176027,-1.3078961002730627,-1.3070520542192345,-1.3063364346184823,-1.305887199905495,-1.3055891149225123,-1.3053398198748445,-1.3051144551599698,-1.3049114882755914,-1.304728562156301,-1.304582862636592,-1.3044811426862464,-1.3044181401591164,-1.3043829469127102,-1.3043640299804957,-1.3043530236865533,-1.3043455191207511,-1.304339550351608,-1.3043343073283886,-1.304329474346999,-1.3043249416132012,-1.3043206852358906,-1.3043167127488453,-1.304313035558603,-1.304309658179847,-1.304306578867481,-1.3043037943578146,-1.3043013025391403,-1.3042991011447973,-1.3042971844163709,-1.3042955404752234,-1.304294150716308,-1.3042929910504215,-1.3042920341393893,-1.3042912517529557,-1.304290616686778,-1.3042901040339792,-1.3042896918456253,-1.3045122379244236,-1.3042591005777098,-1.3030588784317005,-1.2886282005091902,-1.2447824649306571,-1.2456086664543695,-1.2234706278485157,-1.2227828032719208,-1.2190575407829785,-1.2195305518544093,-1.2143641441578696,-1.215369066604324,-1.2120100356341619,-1.2080258162583164,-1.2259896853793637,-1.2125341722279586,-1.2111057923893076,-1.2077010361242944,-1.209534182211045,-1.2066531223782846,-1.2081787531756754,-1.2050288388704447,-1.2066091703406219,-1.204013357848805,-1.2062300325139472,-1.2145617407260605,-1.2113826196533386,-1.207946858307459,-1.2098525276732186,-1.2071909624679613,-1.2089609752703856,-1.2059760603099163,-1.207418791125708,-1.2043448915003854,-1.2061229421849775,-1.2037716953197728,-1.2165919574987394,-1.2088967680057694,-1.209989372441396,-1.2073181131958604,-1.2092647145694813,-1.2064892345203828,-1.2081762843087545,-1.2050712783095026,-1.2065581335812283,-1.2037433497026346,-1.205912248671605,-1.214165579666305,-1.2110614681170084,-1.2075815017923128,-1.2099494162842974,-1.199907244723506,-1.2066947767382212,-1.1799439540399146,-1.157064078327944,-1.14188269224742,-1.1470326077304591,-1.1244195731484607,-1.1403301017276783,-1.1286742359634794,-1.1291929625029948,-1.1156714512933432,-1.1397510702180158,-1.1123674291224348,-1.12981424310205,-1.118287560120219,-1.1277646070744476,-1.1150853084698276,-1.1333753986598587,-1.1075567177469712,-1.1333350515487808,-1.1194735194195207,-1.1226311979649282,-1.1130651583064655,-1.1374678606380417,-1.1081482252615618,-1.1237471495282114,-1.116703669091172,-1.1176391507812664,-1.130191308938175,-1.1322624619187678,-1.1138364786721575,-1.1323449908858059,-1.1194319989419748,-1.1228300195160577,-1.1126956724701926,-1.1353627956063963,-1.1156316799069737,-1.1344635366422868,-1.1086863183353692,-1.126553957933733,-1.1204870800845776,-1.1069607362613583,-1.128452214260804,-1.1342685650254927,-1.1158348909669746,-1.122947315930924,-1.1206552701853552,-1.124041701912479,-1.1011057575203393]
32x26 Array{Float64,2}:
  0.0913316    0.0130113    0.0188079  â€¦  -0.033036    -0.161889  
  0.147457    -0.0397807    0.0268745     -0.0281606   -0.23647   
 -0.0454054    0.128525    -0.0733657     -0.0574454    0.0791966 
  0.22559     -0.0316824   -0.0925434      0.0833573    0.0180558 
  0.0681313   -0.169155    -0.0337461      0.00835779   0.0515694 
  0.0571016   -0.167864    -0.0345402  â€¦  -0.0110327   -0.136891  
 -0.0863801    0.0110998   -0.120917      -0.0264085    0.235318  
  0.295425     0.160408     0.0894229     -0.0668435    0.191645  
  0.169723    -0.0207054   -0.0456964      0.0243135   -0.0263221 
  0.0319712   -0.00316404  -0.0965729      0.132527    -0.0151992 
  â‹®                                    â‹±                â‹®         
 -0.0271323    0.100474    -0.0409783      0.221462    -0.0746684 
  0.0200899   -0.0616576   -0.088031      -0.0538524   -0.0106832 
  0.00756922  -0.00660373   0.143344   â€¦  -0.00761915  -0.0274284 
 -0.0800628    0.0537077   -0.015476      -0.0277607   -0.00357043
  0.149312     0.00651017  -0.0661808     -0.13654     -0.105238  
  0.122488     0.0274531   -0.0670598      0.0091843    0.0176723 
  0.12173     -0.161074     0.0493179      0.129806    -0.080072  
  0.120185     0.0519294    0.0277747  â€¦   0.0354933    0.0481513 
 -0.137552    -0.0323323   -0.0309876      0.120784    -0.0907421 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 4 7 8 16 17 23
INFO: iteration 1, average log likelihood -1.133647
WARNING: Variances had to be floored 4 5 6 7 8 16 17 23 32
INFO: iteration 2, average log likelihood -1.107033
WARNING: Variances had to be floored 3 4 7 8 16 17 19 23 28 32
INFO: iteration 3, average log likelihood -1.103003
WARNING: Variances had to be floored 4 5 6 7 8 16 17 23 32
INFO: iteration 4, average log likelihood -1.108115
WARNING: Variances had to be floored 3 4 7 8 16 17 22 23 28 32
INFO: iteration 5, average log likelihood -1.101649
WARNING: Variances had to be floored 4 5 6 7 8 12 16 17 19 23
INFO: iteration 6, average log likelihood -1.109449
WARNING: Variances had to be floored 4 7 8 16 23 32
INFO: iteration 7, average log likelihood -1.122884
WARNING: Variances had to be floored 3 4 5 6 7 8 16 17 23 28 32
INFO: iteration 8, average log likelihood -1.092799
WARNING: Variances had to be floored 4 7 8 16 17 19 23 32
INFO: iteration 9, average log likelihood -1.106295
WARNING: Variances had to be floored 3 4 5 6 7 8 12 16 17 22 23 26 28 32
INFO: iteration 10, average log likelihood -1.085135
INFO: EM with 100000 data points 10 iterations avll -1.085135
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.104764e+05
      1       7.306285e+05      -1.798479e+05 |       32
      2       7.025828e+05      -2.804569e+04 |       32
      3       6.877122e+05      -1.487062e+04 |       32
      4       6.776398e+05      -1.007239e+04 |       32
      5       6.695304e+05      -8.109396e+03 |       32
      6       6.629812e+05      -6.549179e+03 |       32
      7       6.587264e+05      -4.254754e+03 |       32
      8       6.559981e+05      -2.728340e+03 |       32
      9       6.543025e+05      -1.695569e+03 |       32
     10       6.533645e+05      -9.380665e+02 |       32
     11       6.529228e+05      -4.416430e+02 |       32
     12       6.527108e+05      -2.120357e+02 |       32
     13       6.525790e+05      -1.317731e+02 |       32
     14       6.524742e+05      -1.048064e+02 |       32
     15       6.523962e+05      -7.801117e+01 |       32
     16       6.523297e+05      -6.646045e+01 |       32
     17       6.522626e+05      -6.712067e+01 |       32
     18       6.521798e+05      -8.281761e+01 |       32
     19       6.520807e+05      -9.908830e+01 |       32
     20       6.519187e+05      -1.620414e+02 |       32
     21       6.516678e+05      -2.508866e+02 |       32
     22       6.513487e+05      -3.191058e+02 |       32
     23       6.510716e+05      -2.771080e+02 |       32
     24       6.508076e+05      -2.639621e+02 |       32
     25       6.505488e+05      -2.588061e+02 |       32
     26       6.503542e+05      -1.945956e+02 |       32
     27       6.502133e+05      -1.408993e+02 |       32
     28       6.500849e+05      -1.284264e+02 |       32
     29       6.499900e+05      -9.491665e+01 |       32
     30       6.499033e+05      -8.662407e+01 |       32
     31       6.498370e+05      -6.629215e+01 |       32
     32       6.497823e+05      -5.475377e+01 |       32
     33       6.497359e+05      -4.641395e+01 |       32
     34       6.496975e+05      -3.833763e+01 |       32
     35       6.496678e+05      -2.977074e+01 |       31
     36       6.496481e+05      -1.967867e+01 |       31
     37       6.496250e+05      -2.311831e+01 |       32
     38       6.495985e+05      -2.646542e+01 |       30
     39       6.495782e+05      -2.025462e+01 |       31
     40       6.495534e+05      -2.480201e+01 |       30
     41       6.495147e+05      -3.877830e+01 |       32
     42       6.494774e+05      -3.721774e+01 |       32
     43       6.494216e+05      -5.582761e+01 |       29
     44       6.493187e+05      -1.029162e+02 |       29
     45       6.490934e+05      -2.253287e+02 |       32
     46       6.486001e+05      -4.932729e+02 |       32
     47       6.480433e+05      -5.567776e+02 |       32
     48       6.476935e+05      -3.497959e+02 |       32
     49       6.475517e+05      -1.418224e+02 |       32
     50       6.474793e+05      -7.242043e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 647479.2834815145)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.367590
INFO: iteration 2, average log likelihood -1.337254
INFO: iteration 3, average log likelihood -1.311412
INFO: iteration 4, average log likelihood -1.281360
INFO: iteration 5, average log likelihood -1.237931
WARNING: Variances had to be floored 11 32
INFO: iteration 6, average log likelihood -1.175829
WARNING: Variances had to be floored 1 2 15
INFO: iteration 7, average log likelihood -1.142188
WARNING: Variances had to be floored 6 8 13 17 30
INFO: iteration 8, average log likelihood -1.139005
WARNING: Variances had to be floored 11
INFO: iteration 9, average log likelihood -1.161657
WARNING: Variances had to be floored 5 15 21 32
INFO: iteration 10, average log likelihood -1.117113
WARNING: Variances had to be floored 1 2
INFO: iteration 11, average log likelihood -1.123145
WARNING: Variances had to be floored 3 11 17 29 30
INFO: iteration 12, average log likelihood -1.102890
WARNING: Variances had to be floored 13 15 32
INFO: iteration 13, average log likelihood -1.136371
WARNING: Variances had to be floored 5 6 8
INFO: iteration 14, average log likelihood -1.135632
WARNING: Variances had to be floored 1 2 11 21
INFO: iteration 15, average log likelihood -1.110900
WARNING: Variances had to be floored 15 30 32
INFO: iteration 16, average log likelihood -1.133983
WARNING: Variances had to be floored 13 17
INFO: iteration 17, average log likelihood -1.135502
WARNING: Variances had to be floored 5 8 11 29
INFO: iteration 18, average log likelihood -1.112905
WARNING: Variances had to be floored 1 2 15
INFO: iteration 19, average log likelihood -1.113684
WARNING: Variances had to be floored 3 6 21 30 32
INFO: iteration 20, average log likelihood -1.114344
WARNING: Variances had to be floored 11 13 17
INFO: iteration 21, average log likelihood -1.132190
WARNING: Variances had to be floored 5 15
INFO: iteration 22, average log likelihood -1.127885
WARNING: Variances had to be floored 1 2 8 29
INFO: iteration 23, average log likelihood -1.111361
WARNING: Variances had to be floored 11 32
INFO: iteration 24, average log likelihood -1.129483
WARNING: Variances had to be floored 13 15 17 21 30
INFO: iteration 25, average log likelihood -1.113765
WARNING: Variances had to be floored 5
INFO: iteration 26, average log likelihood -1.130603
WARNING: Variances had to be floored 1 2 6 8 11
INFO: iteration 27, average log likelihood -1.085322
WARNING: Variances had to be floored 3 15 29 32
INFO: iteration 28, average log likelihood -1.120724
WARNING: Variances had to be floored 13 17 30
INFO: iteration 29, average log likelihood -1.144832
WARNING: Variances had to be floored 5 21
INFO: iteration 30, average log likelihood -1.136947
WARNING: Variances had to be floored 1 2 11
INFO: iteration 31, average log likelihood -1.098311
WARNING: Variances had to be floored 8 15 32
INFO: iteration 32, average log likelihood -1.107253
WARNING: Variances had to be floored 3 6 13 17 29 30
INFO: iteration 33, average log likelihood -1.111073
WARNING: Variances had to be floored 5 11
INFO: iteration 34, average log likelihood -1.138863
WARNING: Variances had to be floored 1 2 15 21
INFO: iteration 35, average log likelihood -1.117008
WARNING: Variances had to be floored 32
INFO: iteration 36, average log likelihood -1.141405
WARNING: Variances had to be floored 8 11 13 17 30
INFO: iteration 37, average log likelihood -1.109999
WARNING: Variances had to be floored 5 15 29
INFO: iteration 38, average log likelihood -1.136988
WARNING: Variances had to be floored 1 2 21
INFO: iteration 39, average log likelihood -1.127757
WARNING: Variances had to be floored 3 11 32
INFO: iteration 40, average log likelihood -1.123194
WARNING: Variances had to be floored 13 15 17 30
INFO: iteration 41, average log likelihood -1.121244
WARNING: Variances had to be floored 5 8
INFO: iteration 42, average log likelihood -1.132141
WARNING: Variances had to be floored 1 2 11 21 29
INFO: iteration 43, average log likelihood -1.099936
WARNING: Variances had to be floored 6 32
INFO: iteration 44, average log likelihood -1.125672
WARNING: Variances had to be floored 13 15 17 30
INFO: iteration 45, average log likelihood -1.118997
WARNING: Variances had to be floored 3 5 8 11
INFO: iteration 46, average log likelihood -1.127618
WARNING: Variances had to be floored 1
INFO: iteration 47, average log likelihood -1.127625
WARNING: Variances had to be floored 2 6 15 21 29 32
INFO: iteration 48, average log likelihood -1.086122
WARNING: Variances had to be floored 11 13 30
INFO: iteration 49, average log likelihood -1.145173
WARNING: Variances had to be floored 5 17
INFO: iteration 50, average log likelihood -1.135643
INFO: EM with 100000 data points 50 iterations avll -1.135643
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.104281      0.0704849  -0.014418    â€¦  -0.0434962   0.209942   
  0.0399509    -0.14833    -0.0461189       0.0369288  -0.0664815  
  0.123649      0.0199893   0.0391889       0.0632709   0.00394014 
 -0.0288178     0.121513   -0.155416       -0.0633853   0.0396299  
  0.0562865    -0.0885605   0.137055       -0.0595135  -0.0718305  
  0.00635476    0.0143863  -0.0258322   â€¦   0.185907    0.0464854  
  0.0771509    -0.0385489   0.0377971       0.0112113   0.0227253  
 -0.142277     -0.0335415  -0.0329563       0.116408   -0.09424    
  0.0979141    -0.0257231   0.0140725      -0.0322441  -0.170391   
  0.0999981     0.0245552  -0.0786205       0.0187151   0.0508328  
  â‹®                                     â‹±               â‹®          
 -0.0313715     0.137784    0.00139461      0.0163835   0.0587787  
  0.0511737    -0.0545489  -0.0207481       0.0633089  -0.171831   
 -0.0415869     0.541845   -0.0487122   â€¦   0.0780902  -0.0497872  
  0.12463      -0.166481    0.0464899       0.133509   -0.0813247  
 -0.0369825    -1.17357    -0.0310344       0.1612     -0.0618304  
 -0.0689693    -0.357043    0.00334821      0.154712    0.0855416  
  0.00253713    0.129204   -0.0199392      -0.0501151  -0.000622978
  0.0600027    -0.256553   -0.0819706   â€¦  -0.076961   -0.102912   
  0.000904634  -0.119499   -0.138761        0.0638329  -0.0333991  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 1 8 15
INFO: iteration 1, average log likelihood -1.113671
WARNING: Variances had to be floored 1 2 3 6 8 11 15 21 32
INFO: iteration 2, average log likelihood -1.064163
WARNING: Variances had to be floored 1 8 13 15 29 30 32
INFO: iteration 3, average log likelihood -1.072337
WARNING: Variances had to be floored 1 2 3 5 6 8 11 15 17 21 32
INFO: iteration 4, average log likelihood -1.059089
WARNING: Variances had to be floored 1 8 15
INFO: iteration 5, average log likelihood -1.098984
WARNING: Variances had to be floored 1 2 3 6 8 11 13 15 29 30 32
INFO: iteration 6, average log likelihood -1.051192
WARNING: Variances had to be floored 1 8 15 21 32
INFO: iteration 7, average log likelihood -1.090284
WARNING: Variances had to be floored 1 2 3 5 6 8 11 15 17 32
INFO: iteration 8, average log likelihood -1.047630
WARNING: Variances had to be floored 1 8 13 15 29 30
INFO: iteration 9, average log likelihood -1.084483
WARNING: Variances had to be floored 1 2 3 6 8 11 15 21 32
INFO: iteration 10, average log likelihood -1.069887
INFO: EM with 100000 data points 10 iterations avll -1.069887
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0242787    0.0838026   0.0402857  â€¦   0.187015     0.0723482 
  0.104493    -0.239466    0.0391813     -0.00614056  -0.0528871 
  0.0139115    0.145586   -0.0314115     -0.10372      0.0157786 
 -0.154843     0.0956456  -0.049674       0.185879     0.00278825
 -0.106233     0.116234   -0.0805513     -0.362989    -0.10134   
  0.0484718   -0.0927838  -0.0643183  â€¦   0.0820441    0.139599  
 -0.0224304   -0.0143455  -0.0342097     -0.00845593  -0.00797366
  0.107368    -0.144427   -0.079562       0.018691     0.0896625 
  0.0271298   -0.066284   -0.136048      -0.17683     -0.00352712
 -0.0207713   -0.219151   -0.069416       0.128539     0.0449783 
  â‹®                                   â‹±                â‹®         
  0.116264    -0.0737221  -0.0264745      0.0721427   -0.0537765 
 -0.0235664    0.111611   -0.139821      -0.139313     0.0931314 
  0.0152725   -0.0511822  -0.0917709  â€¦   0.101105     0.015453  
  0.0901572    0.248402    0.100078       0.115017    -0.164789  
  0.0220334   -0.0477047   0.135921       0.0209519    0.118104  
  0.268197     0.154955   -0.0749894     -0.183997     0.127587  
  0.00870751   0.0245592  -0.0939986     -0.122133     0.0957681 
 -0.157622    -0.0577726  -0.211894   â€¦   0.0267858   -0.0156147 
  0.0445236   -0.146521    0.0528701      0.224106     0.126087  kind full, method split
0: avll = -1.414631959926994
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414651
INFO: iteration 2, average log likelihood -1.414581
INFO: iteration 3, average log likelihood -1.414533
INFO: iteration 4, average log likelihood -1.414479
INFO: iteration 5, average log likelihood -1.414417
INFO: iteration 6, average log likelihood -1.414346
INFO: iteration 7, average log likelihood -1.414263
INFO: iteration 8, average log likelihood -1.414160
INFO: iteration 9, average log likelihood -1.414012
INFO: iteration 10, average log likelihood -1.413751
INFO: iteration 11, average log likelihood -1.413262
INFO: iteration 12, average log likelihood -1.412425
INFO: iteration 13, average log likelihood -1.411301
INFO: iteration 14, average log likelihood -1.410250
INFO: iteration 15, average log likelihood -1.409589
INFO: iteration 16, average log likelihood -1.409284
INFO: iteration 17, average log likelihood -1.409163
INFO: iteration 18, average log likelihood -1.409116
INFO: iteration 19, average log likelihood -1.409098
INFO: iteration 20, average log likelihood -1.409091
INFO: iteration 21, average log likelihood -1.409088
INFO: iteration 22, average log likelihood -1.409087
INFO: iteration 23, average log likelihood -1.409086
INFO: iteration 24, average log likelihood -1.409086
INFO: iteration 25, average log likelihood -1.409086
INFO: iteration 26, average log likelihood -1.409085
INFO: iteration 27, average log likelihood -1.409085
INFO: iteration 28, average log likelihood -1.409085
INFO: iteration 29, average log likelihood -1.409085
INFO: iteration 30, average log likelihood -1.409085
INFO: iteration 31, average log likelihood -1.409085
INFO: iteration 32, average log likelihood -1.409085
INFO: iteration 33, average log likelihood -1.409085
INFO: iteration 34, average log likelihood -1.409085
INFO: iteration 35, average log likelihood -1.409084
INFO: iteration 36, average log likelihood -1.409084
INFO: iteration 37, average log likelihood -1.409084
INFO: iteration 38, average log likelihood -1.409084
INFO: iteration 39, average log likelihood -1.409084
INFO: iteration 40, average log likelihood -1.409084
INFO: iteration 41, average log likelihood -1.409084
INFO: iteration 42, average log likelihood -1.409084
INFO: iteration 43, average log likelihood -1.409084
INFO: iteration 44, average log likelihood -1.409084
INFO: iteration 45, average log likelihood -1.409084
INFO: iteration 46, average log likelihood -1.409084
INFO: iteration 47, average log likelihood -1.409084
INFO: iteration 48, average log likelihood -1.409084
INFO: iteration 49, average log likelihood -1.409084
INFO: iteration 50, average log likelihood -1.409084
INFO: EM with 100000 data points 50 iterations avll -1.409084
952.4 data points per parameter
1: avll = [-1.4146509097876787,-1.414581264731206,-1.4145325481846938,-1.4144792486542612,-1.4144174728749115,-1.4143457577196397,-1.414262603254113,-1.4141602021326647,-1.4140115808707419,-1.4137510322629214,-1.4132617682308117,-1.4124249457248612,-1.4113006516556992,-1.4102499822952164,-1.4095894798242314,-1.409283920604551,-1.4091625707859643,-1.4091162030143416,-1.4090983180864916,-1.4090912314689614,-1.409088296309767,-1.4090869848186645,-1.4090863231263853,-1.4090859316622524,-1.409085660579638,-1.4090854495838694,-1.4090852735738697,-1.4090851214218296,-1.4090849876403575,-1.4090848690894668,-1.4090847636638857,-1.4090846697620811,-1.4090845860655115,-1.4090845114419146,-1.4090844448988393,-1.4090843855580375,-1.4090843326389302,-1.4090842854463892,-1.4090842433608384,-1.4090842058298318,-1.4090841723606962,-1.4090841425140366,-1.4090841158979661,-1.4090840921629668,-1.4090840709973131,-1.4090840521229873,-1.409084035292036,-1.4090840202833235,-1.4090840068996333,-1.4090839949650809]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409099
INFO: iteration 2, average log likelihood -1.409038
INFO: iteration 3, average log likelihood -1.408996
INFO: iteration 4, average log likelihood -1.408950
INFO: iteration 5, average log likelihood -1.408897
INFO: iteration 6, average log likelihood -1.408836
INFO: iteration 7, average log likelihood -1.408767
INFO: iteration 8, average log likelihood -1.408694
INFO: iteration 9, average log likelihood -1.408622
INFO: iteration 10, average log likelihood -1.408554
INFO: iteration 11, average log likelihood -1.408494
INFO: iteration 12, average log likelihood -1.408443
INFO: iteration 13, average log likelihood -1.408403
INFO: iteration 14, average log likelihood -1.408371
INFO: iteration 15, average log likelihood -1.408347
INFO: iteration 16, average log likelihood -1.408328
INFO: iteration 17, average log likelihood -1.408312
INFO: iteration 18, average log likelihood -1.408299
INFO: iteration 19, average log likelihood -1.408288
INFO: iteration 20, average log likelihood -1.408277
INFO: iteration 21, average log likelihood -1.408266
INFO: iteration 22, average log likelihood -1.408256
INFO: iteration 23, average log likelihood -1.408246
INFO: iteration 24, average log likelihood -1.408235
INFO: iteration 25, average log likelihood -1.408225
INFO: iteration 26, average log likelihood -1.408215
INFO: iteration 27, average log likelihood -1.408205
INFO: iteration 28, average log likelihood -1.408194
INFO: iteration 29, average log likelihood -1.408184
INFO: iteration 30, average log likelihood -1.408174
INFO: iteration 31, average log likelihood -1.408164
INFO: iteration 32, average log likelihood -1.408154
INFO: iteration 33, average log likelihood -1.408145
INFO: iteration 34, average log likelihood -1.408135
INFO: iteration 35, average log likelihood -1.408126
INFO: iteration 36, average log likelihood -1.408117
INFO: iteration 37, average log likelihood -1.408108
INFO: iteration 38, average log likelihood -1.408099
INFO: iteration 39, average log likelihood -1.408090
INFO: iteration 40, average log likelihood -1.408082
INFO: iteration 41, average log likelihood -1.408074
INFO: iteration 42, average log likelihood -1.408065
INFO: iteration 43, average log likelihood -1.408058
INFO: iteration 44, average log likelihood -1.408050
INFO: iteration 45, average log likelihood -1.408042
INFO: iteration 46, average log likelihood -1.408035
INFO: iteration 47, average log likelihood -1.408028
INFO: iteration 48, average log likelihood -1.408021
INFO: iteration 49, average log likelihood -1.408015
INFO: iteration 50, average log likelihood -1.408009
INFO: EM with 100000 data points 50 iterations avll -1.408009
473.9 data points per parameter
2: avll = [-1.4090991949512792,-1.4090383588172637,-1.4089957523468424,-1.4089502210907399,-1.4088974310747318,-1.4088360616652287,-1.4087672781998144,-1.4086943308220912,-1.4086216593648306,-1.4085536602052784,-1.408493647004638,-1.4084433496389237,-1.4084029339465118,-1.4083713690717228,-1.4083469576369836,-1.408327846285931,-1.4083123797066717,-1.408299260541793,-1.4082875621131021,-1.4082766667311348,-1.4082661852334224,-1.4082558859503294,-1.4082456414562952,-1.4082353917993937,-1.4082251199444757,-1.4082148353149126,-1.4082045624360735,-1.4081943328230875,-1.4081841791063,-1.4081741309111326,-1.4081642122635754,-1.4081544403645754,-1.4081448255501376,-1.4081353721955843,-1.408126080275091,-1.4081169472712838,-1.408107970147138,-1.408099147136335,-1.4080904791679854,-1.4080819708073096,-1.4080736306585298,-1.408065471235456,-1.4080575083564526,-1.4080497601613917,-1.408042245876714,-1.4080349844687583,-1.4080279933240407,-1.4080212870787285,-1.4080148766909888,-1.4080087688137966]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.408014
INFO: iteration 2, average log likelihood -1.407956
INFO: iteration 3, average log likelihood -1.407908
INFO: iteration 4, average log likelihood -1.407854
INFO: iteration 5, average log likelihood -1.407789
INFO: iteration 6, average log likelihood -1.407712
INFO: iteration 7, average log likelihood -1.407623
INFO: iteration 8, average log likelihood -1.407527
INFO: iteration 9, average log likelihood -1.407428
INFO: iteration 10, average log likelihood -1.407333
INFO: iteration 11, average log likelihood -1.407246
INFO: iteration 12, average log likelihood -1.407166
INFO: iteration 13, average log likelihood -1.407095
INFO: iteration 14, average log likelihood -1.407031
INFO: iteration 15, average log likelihood -1.406974
INFO: iteration 16, average log likelihood -1.406924
INFO: iteration 17, average log likelihood -1.406879
INFO: iteration 18, average log likelihood -1.406839
INFO: iteration 19, average log likelihood -1.406804
INFO: iteration 20, average log likelihood -1.406772
INFO: iteration 21, average log likelihood -1.406743
INFO: iteration 22, average log likelihood -1.406717
INFO: iteration 23, average log likelihood -1.406692
INFO: iteration 24, average log likelihood -1.406669
INFO: iteration 25, average log likelihood -1.406647
INFO: iteration 26, average log likelihood -1.406626
INFO: iteration 27, average log likelihood -1.406606
INFO: iteration 28, average log likelihood -1.406588
INFO: iteration 29, average log likelihood -1.406570
INFO: iteration 30, average log likelihood -1.406553
INFO: iteration 31, average log likelihood -1.406537
INFO: iteration 32, average log likelihood -1.406522
INFO: iteration 33, average log likelihood -1.406508
INFO: iteration 34, average log likelihood -1.406494
INFO: iteration 35, average log likelihood -1.406481
INFO: iteration 36, average log likelihood -1.406469
INFO: iteration 37, average log likelihood -1.406457
INFO: iteration 38, average log likelihood -1.406446
INFO: iteration 39, average log likelihood -1.406435
INFO: iteration 40, average log likelihood -1.406425
INFO: iteration 41, average log likelihood -1.406415
INFO: iteration 42, average log likelihood -1.406406
INFO: iteration 43, average log likelihood -1.406396
INFO: iteration 44, average log likelihood -1.406388
INFO: iteration 45, average log likelihood -1.406379
INFO: iteration 46, average log likelihood -1.406371
INFO: iteration 47, average log likelihood -1.406363
INFO: iteration 48, average log likelihood -1.406355
INFO: iteration 49, average log likelihood -1.406347
INFO: iteration 50, average log likelihood -1.406340
INFO: EM with 100000 data points 50 iterations avll -1.406340
236.4 data points per parameter
3: avll = [-1.4080143182303,-1.4079563464633298,-1.407907830158059,-1.407853562656349,-1.4077889597645536,-1.4077118958735748,-1.4076231762906533,-1.4075266662232122,-1.4074281685531602,-1.4073332785033505,-1.4072455792517888,-1.4071662922387482,-1.4070951441151833,-1.4070314152903003,-1.4069744808182225,-1.406923843831477,-1.4068789806098128,-1.406839242920603,-1.4068038772990619,-1.40677211018417,-1.4067432342054178,-1.4067166615011888,-1.4066919399839313,-1.4066687432161487,-1.4066468470081228,-1.4066261026893283,-1.4066064128039208,-1.4065877116722683,-1.4065699512185916,-1.4065530914427617,-1.406537094546479,-1.4065219217121991,-1.4065075316810454,-1.4064938804709484,-1.4064809217615508,-1.4064686076245974,-1.4064568893926093,-1.4064457185385957,-1.4064350474928466,-1.4064248303570666,-1.4064150234976645,-1.4064055860134603,-1.406396480081435,-1.4063876711892431,-1.4063791282660498,-1.4063708237244814,-1.4063627334265367,-1.4063548365855594,-1.4063471156151768,-1.4063395559347904]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.406341
INFO: iteration 2, average log likelihood -1.406277
INFO: iteration 3, average log likelihood -1.406218
INFO: iteration 4, average log likelihood -1.406149
INFO: iteration 5, average log likelihood -1.406062
INFO: iteration 6, average log likelihood -1.405954
INFO: iteration 7, average log likelihood -1.405828
INFO: iteration 8, average log likelihood -1.405689
INFO: iteration 9, average log likelihood -1.405548
INFO: iteration 10, average log likelihood -1.405415
INFO: iteration 11, average log likelihood -1.405296
INFO: iteration 12, average log likelihood -1.405194
INFO: iteration 13, average log likelihood -1.405108
INFO: iteration 14, average log likelihood -1.405035
INFO: iteration 15, average log likelihood -1.404973
INFO: iteration 16, average log likelihood -1.404920
INFO: iteration 17, average log likelihood -1.404874
INFO: iteration 18, average log likelihood -1.404834
INFO: iteration 19, average log likelihood -1.404800
INFO: iteration 20, average log likelihood -1.404769
INFO: iteration 21, average log likelihood -1.404743
INFO: iteration 22, average log likelihood -1.404719
INFO: iteration 23, average log likelihood -1.404698
INFO: iteration 24, average log likelihood -1.404679
INFO: iteration 25, average log likelihood -1.404662
INFO: iteration 26, average log likelihood -1.404646
INFO: iteration 27, average log likelihood -1.404632
INFO: iteration 28, average log likelihood -1.404618
INFO: iteration 29, average log likelihood -1.404606
INFO: iteration 30, average log likelihood -1.404594
INFO: iteration 31, average log likelihood -1.404583
INFO: iteration 32, average log likelihood -1.404573
INFO: iteration 33, average log likelihood -1.404563
INFO: iteration 34, average log likelihood -1.404554
INFO: iteration 35, average log likelihood -1.404545
INFO: iteration 36, average log likelihood -1.404536
INFO: iteration 37, average log likelihood -1.404528
INFO: iteration 38, average log likelihood -1.404520
INFO: iteration 39, average log likelihood -1.404512
INFO: iteration 40, average log likelihood -1.404504
INFO: iteration 41, average log likelihood -1.404497
INFO: iteration 42, average log likelihood -1.404489
INFO: iteration 43, average log likelihood -1.404482
INFO: iteration 44, average log likelihood -1.404475
INFO: iteration 45, average log likelihood -1.404468
INFO: iteration 46, average log likelihood -1.404461
INFO: iteration 47, average log likelihood -1.404454
INFO: iteration 48, average log likelihood -1.404447
INFO: iteration 49, average log likelihood -1.404441
INFO: iteration 50, average log likelihood -1.404434
INFO: EM with 100000 data points 50 iterations avll -1.404434
118.1 data points per parameter
4: avll = [-1.4063407827110679,-1.4062773360999377,-1.4062181165611216,-1.4061486320808638,-1.4060618869086696,-1.4059544325992286,-1.4058277015276786,-1.40568860662523,-1.4055475908475032,-1.405414687556883,-1.4052962652504573,-1.4051943466292913,-1.4051079578619217,-1.4050348717699477,-1.4049727492516582,-1.4049195962540093,-1.4048738267565197,-1.4048341874641346,-1.404799668971116,-1.4047694402169724,-1.4047428069810128,-1.4047191863167108,-1.4046980895157024,-1.4046791089377388,-1.404661906458126,-1.4046462028096383,-1.404631767812987,-1.4046184116839484,-1.4046059775515192,-1.4045943352006145,-1.4045833759509747,-1.4045730085262158,-1.4045631557490201,-1.4045537519065616,-1.4045447406510292,-1.4045360733242986,-1.4045277076183336,-1.4045196065018897,-1.4045117373592972,-1.4045040712989918,-1.404496582598672,-1.4044892482609592,-1.4044820476586526,-1.4044749622523716,-1.404467975365901,-1.4044610720062478,-1.4044542387166674,-1.4044474634522648,-1.4044407354694928,-1.404434045223196]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.404437
INFO: iteration 2, average log likelihood -1.404368
INFO: iteration 3, average log likelihood -1.404303
INFO: iteration 4, average log likelihood -1.404224
INFO: iteration 5, average log likelihood -1.404123
INFO: iteration 6, average log likelihood -1.403995
INFO: iteration 7, average log likelihood -1.403841
INFO: iteration 8, average log likelihood -1.403668
INFO: iteration 9, average log likelihood -1.403487
INFO: iteration 10, average log likelihood -1.403308
INFO: iteration 11, average log likelihood -1.403143
INFO: iteration 12, average log likelihood -1.402993
INFO: iteration 13, average log likelihood -1.402862
INFO: iteration 14, average log likelihood -1.402746
INFO: iteration 15, average log likelihood -1.402643
INFO: iteration 16, average log likelihood -1.402552
INFO: iteration 17, average log likelihood -1.402471
INFO: iteration 18, average log likelihood -1.402398
INFO: iteration 19, average log likelihood -1.402331
INFO: iteration 20, average log likelihood -1.402271
INFO: iteration 21, average log likelihood -1.402215
INFO: iteration 22, average log likelihood -1.402165
INFO: iteration 23, average log likelihood -1.402118
INFO: iteration 24, average log likelihood -1.402074
INFO: iteration 25, average log likelihood -1.402033
INFO: iteration 26, average log likelihood -1.401994
INFO: iteration 27, average log likelihood -1.401957
INFO: iteration 28, average log likelihood -1.401922
INFO: iteration 29, average log likelihood -1.401888
INFO: iteration 30, average log likelihood -1.401856
INFO: iteration 31, average log likelihood -1.401825
INFO: iteration 32, average log likelihood -1.401796
INFO: iteration 33, average log likelihood -1.401767
INFO: iteration 34, average log likelihood -1.401741
INFO: iteration 35, average log likelihood -1.401715
INFO: iteration 36, average log likelihood -1.401691
INFO: iteration 37, average log likelihood -1.401668
INFO: iteration 38, average log likelihood -1.401647
INFO: iteration 39, average log likelihood -1.401627
INFO: iteration 40, average log likelihood -1.401607
INFO: iteration 41, average log likelihood -1.401589
INFO: iteration 42, average log likelihood -1.401572
INFO: iteration 43, average log likelihood -1.401556
INFO: iteration 44, average log likelihood -1.401541
INFO: iteration 45, average log likelihood -1.401526
INFO: iteration 46, average log likelihood -1.401512
INFO: iteration 47, average log likelihood -1.401500
INFO: iteration 48, average log likelihood -1.401487
INFO: iteration 49, average log likelihood -1.401476
INFO: iteration 50, average log likelihood -1.401465
INFO: EM with 100000 data points 50 iterations avll -1.401465
59.0 data points per parameter
5: avll = [-1.4044368447896474,-1.4043682892564735,-1.4043027188820487,-1.4042235999329402,-1.4041226184351239,-1.4039950101000733,-1.4038412847248507,-1.4036681034547238,-1.4034865666747376,-1.4033084388975816,-1.403142585888018,-1.4029934547819767,-1.4028616962225415,-1.4027457754783246,-1.402643414689413,-1.4025524122338395,-1.402470938669053,-1.4023975528563408,-1.4023311143165231,-1.402270681387281,-1.4022154337255355,-1.4021646308658713,-1.4021176023018687,-1.4020737555011138,-1.4020325873756005,-1.4019936903809753,-1.4019567507661188,-1.4019215395516875,-1.4018878983413245,-1.4018557234396114,-1.4018249513395837,-1.401795546461674,-1.4017674903353914,-1.4017407716054004,-1.4017153775666127,-1.4016912885229125,-1.4016684753866446,-1.4016468997534637,-1.4016265153073728,-1.401607269695601,-1.4015891064122825,-1.4015719664951338,-1.4015557899690219,-1.4015405170218553,-1.4015260889197434,-1.4015124486880441,-1.4014995416127887,-1.401487315649193,-1.4014757218438236,-1.4014647148512327]
[-1.414631959926994,-1.4146509097876787,-1.414581264731206,-1.4145325481846938,-1.4144792486542612,-1.4144174728749115,-1.4143457577196397,-1.414262603254113,-1.4141602021326647,-1.4140115808707419,-1.4137510322629214,-1.4132617682308117,-1.4124249457248612,-1.4113006516556992,-1.4102499822952164,-1.4095894798242314,-1.409283920604551,-1.4091625707859643,-1.4091162030143416,-1.4090983180864916,-1.4090912314689614,-1.409088296309767,-1.4090869848186645,-1.4090863231263853,-1.4090859316622524,-1.409085660579638,-1.4090854495838694,-1.4090852735738697,-1.4090851214218296,-1.4090849876403575,-1.4090848690894668,-1.4090847636638857,-1.4090846697620811,-1.4090845860655115,-1.4090845114419146,-1.4090844448988393,-1.4090843855580375,-1.4090843326389302,-1.4090842854463892,-1.4090842433608384,-1.4090842058298318,-1.4090841723606962,-1.4090841425140366,-1.4090841158979661,-1.4090840921629668,-1.4090840709973131,-1.4090840521229873,-1.409084035292036,-1.4090840202833235,-1.4090840068996333,-1.4090839949650809,-1.4090991949512792,-1.4090383588172637,-1.4089957523468424,-1.4089502210907399,-1.4088974310747318,-1.4088360616652287,-1.4087672781998144,-1.4086943308220912,-1.4086216593648306,-1.4085536602052784,-1.408493647004638,-1.4084433496389237,-1.4084029339465118,-1.4083713690717228,-1.4083469576369836,-1.408327846285931,-1.4083123797066717,-1.408299260541793,-1.4082875621131021,-1.4082766667311348,-1.4082661852334224,-1.4082558859503294,-1.4082456414562952,-1.4082353917993937,-1.4082251199444757,-1.4082148353149126,-1.4082045624360735,-1.4081943328230875,-1.4081841791063,-1.4081741309111326,-1.4081642122635754,-1.4081544403645754,-1.4081448255501376,-1.4081353721955843,-1.408126080275091,-1.4081169472712838,-1.408107970147138,-1.408099147136335,-1.4080904791679854,-1.4080819708073096,-1.4080736306585298,-1.408065471235456,-1.4080575083564526,-1.4080497601613917,-1.408042245876714,-1.4080349844687583,-1.4080279933240407,-1.4080212870787285,-1.4080148766909888,-1.4080087688137966,-1.4080143182303,-1.4079563464633298,-1.407907830158059,-1.407853562656349,-1.4077889597645536,-1.4077118958735748,-1.4076231762906533,-1.4075266662232122,-1.4074281685531602,-1.4073332785033505,-1.4072455792517888,-1.4071662922387482,-1.4070951441151833,-1.4070314152903003,-1.4069744808182225,-1.406923843831477,-1.4068789806098128,-1.406839242920603,-1.4068038772990619,-1.40677211018417,-1.4067432342054178,-1.4067166615011888,-1.4066919399839313,-1.4066687432161487,-1.4066468470081228,-1.4066261026893283,-1.4066064128039208,-1.4065877116722683,-1.4065699512185916,-1.4065530914427617,-1.406537094546479,-1.4065219217121991,-1.4065075316810454,-1.4064938804709484,-1.4064809217615508,-1.4064686076245974,-1.4064568893926093,-1.4064457185385957,-1.4064350474928466,-1.4064248303570666,-1.4064150234976645,-1.4064055860134603,-1.406396480081435,-1.4063876711892431,-1.4063791282660498,-1.4063708237244814,-1.4063627334265367,-1.4063548365855594,-1.4063471156151768,-1.4063395559347904,-1.4063407827110679,-1.4062773360999377,-1.4062181165611216,-1.4061486320808638,-1.4060618869086696,-1.4059544325992286,-1.4058277015276786,-1.40568860662523,-1.4055475908475032,-1.405414687556883,-1.4052962652504573,-1.4051943466292913,-1.4051079578619217,-1.4050348717699477,-1.4049727492516582,-1.4049195962540093,-1.4048738267565197,-1.4048341874641346,-1.404799668971116,-1.4047694402169724,-1.4047428069810128,-1.4047191863167108,-1.4046980895157024,-1.4046791089377388,-1.404661906458126,-1.4046462028096383,-1.404631767812987,-1.4046184116839484,-1.4046059775515192,-1.4045943352006145,-1.4045833759509747,-1.4045730085262158,-1.4045631557490201,-1.4045537519065616,-1.4045447406510292,-1.4045360733242986,-1.4045277076183336,-1.4045196065018897,-1.4045117373592972,-1.4045040712989918,-1.404496582598672,-1.4044892482609592,-1.4044820476586526,-1.4044749622523716,-1.404467975365901,-1.4044610720062478,-1.4044542387166674,-1.4044474634522648,-1.4044407354694928,-1.404434045223196,-1.4044368447896474,-1.4043682892564735,-1.4043027188820487,-1.4042235999329402,-1.4041226184351239,-1.4039950101000733,-1.4038412847248507,-1.4036681034547238,-1.4034865666747376,-1.4033084388975816,-1.403142585888018,-1.4029934547819767,-1.4028616962225415,-1.4027457754783246,-1.402643414689413,-1.4025524122338395,-1.402470938669053,-1.4023975528563408,-1.4023311143165231,-1.402270681387281,-1.4022154337255355,-1.4021646308658713,-1.4021176023018687,-1.4020737555011138,-1.4020325873756005,-1.4019936903809753,-1.4019567507661188,-1.4019215395516875,-1.4018878983413245,-1.4018557234396114,-1.4018249513395837,-1.401795546461674,-1.4017674903353914,-1.4017407716054004,-1.4017153775666127,-1.4016912885229125,-1.4016684753866446,-1.4016468997534637,-1.4016265153073728,-1.401607269695601,-1.4015891064122825,-1.4015719664951338,-1.4015557899690219,-1.4015405170218553,-1.4015260889197434,-1.4015124486880441,-1.4014995416127887,-1.401487315649193,-1.4014757218438236,-1.4014647148512327]
32x26 Array{Float64,2}:
 -0.146804     0.253455   0.024255   â€¦  -0.284904   -0.356836   -0.286812 
 -0.215743     0.784429   0.312054       0.0536133  -0.0878854  -0.464396 
  0.0457569    0.796557   0.185117       0.0829114  -0.559336    0.409951 
  0.0482683    0.576896  -0.127263       0.0587555   0.430933   -0.166871 
 -0.737541     0.099171  -0.439728      -0.200367   -0.0338246   0.460784 
 -0.935326     0.625766   0.0628451  â€¦   0.0561175   0.459935    0.20799  
 -0.1253       0.16279   -0.241658      -0.0901981  -0.896526    0.607247 
  0.343195     0.360239  -0.964361      -0.147459    0.110687    0.192073 
 -0.223571     0.718722  -0.20498       -0.307563   -0.102045   -0.195035 
  0.167347     0.245248  -0.236312      -0.87852     0.347385   -0.0879324
  â‹®                                  â‹±                           â‹®        
  0.330981    -0.339197   0.112935       0.324943    0.068607   -0.38233  
 -0.357627    -0.285168   0.652143      -0.173286    0.158376    0.0392959
 -0.152537    -0.285005   0.448769   â€¦   0.596091    0.030622    0.23095  
  0.140291    -0.366315   0.394285      -0.323702   -0.0481824   0.324595 
  0.108514    -0.2163    -0.325997       0.135203    0.611465   -0.119162 
  0.177301     0.350383   0.0652668     -0.0740231   0.340291    0.49666  
 -0.129194    -0.16384    0.567208       0.0767106  -0.02361     0.65306  
 -0.00810716  -0.185943  -0.289305   â€¦   0.0751655  -0.0163303   0.57877  
  0.541743    -0.681697  -0.11416        0.334862   -0.100351    0.0965344INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.401454
INFO: iteration 2, average log likelihood -1.401444
INFO: iteration 3, average log likelihood -1.401435
INFO: iteration 4, average log likelihood -1.401426
INFO: iteration 5, average log likelihood -1.401417
INFO: iteration 6, average log likelihood -1.401409
INFO: iteration 7, average log likelihood -1.401401
INFO: iteration 8, average log likelihood -1.401394
INFO: iteration 9, average log likelihood -1.401387
INFO: iteration 10, average log likelihood -1.401380
INFO: EM with 100000 data points 10 iterations avll -1.401380
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.714225e+05
      1       6.920751e+05      -1.793474e+05 |       32
      2       6.791500e+05      -1.292511e+04 |       32
      3       6.744582e+05      -4.691816e+03 |       32
      4       6.721491e+05      -2.309103e+03 |       32
      5       6.706602e+05      -1.488844e+03 |       32
      6       6.695871e+05      -1.073133e+03 |       32
      7       6.687124e+05      -8.746570e+02 |       32
      8       6.679755e+05      -7.369299e+02 |       32
      9       6.673796e+05      -5.959203e+02 |       32
     10       6.669189e+05      -4.607067e+02 |       32
     11       6.665280e+05      -3.908483e+02 |       32
     12       6.661829e+05      -3.451088e+02 |       32
     13       6.658720e+05      -3.108909e+02 |       32
     14       6.655882e+05      -2.838449e+02 |       32
     15       6.653334e+05      -2.548026e+02 |       32
     16       6.650935e+05      -2.398802e+02 |       32
     17       6.648694e+05      -2.241192e+02 |       32
     18       6.646417e+05      -2.276465e+02 |       32
     19       6.644350e+05      -2.067559e+02 |       32
     20       6.642326e+05      -2.024068e+02 |       32
     21       6.640666e+05      -1.659356e+02 |       32
     22       6.639099e+05      -1.567790e+02 |       32
     23       6.637599e+05      -1.499476e+02 |       32
     24       6.636224e+05      -1.374695e+02 |       32
     25       6.635009e+05      -1.215432e+02 |       32
     26       6.633926e+05      -1.083166e+02 |       32
     27       6.632870e+05      -1.056367e+02 |       32
     28       6.632020e+05      -8.494731e+01 |       32
     29       6.631169e+05      -8.510321e+01 |       32
     30       6.630256e+05      -9.134124e+01 |       32
     31       6.629381e+05      -8.742193e+01 |       32
     32       6.628511e+05      -8.707865e+01 |       32
     33       6.627703e+05      -8.080784e+01 |       32
     34       6.626815e+05      -8.870590e+01 |       32
     35       6.626079e+05      -7.364728e+01 |       32
     36       6.625430e+05      -6.490356e+01 |       32
     37       6.624914e+05      -5.160421e+01 |       32
     38       6.624420e+05      -4.936825e+01 |       32
     39       6.623916e+05      -5.039136e+01 |       32
     40       6.623493e+05      -4.235877e+01 |       32
     41       6.623068e+05      -4.243661e+01 |       32
     42       6.622560e+05      -5.083711e+01 |       32
     43       6.621991e+05      -5.687938e+01 |       32
     44       6.621467e+05      -5.246730e+01 |       32
     45       6.620987e+05      -4.791777e+01 |       32
     46       6.620552e+05      -4.358092e+01 |       32
     47       6.620203e+05      -3.484003e+01 |       32
     48       6.619867e+05      -3.356677e+01 |       32
     49       6.619554e+05      -3.135771e+01 |       32
     50       6.619167e+05      -3.867682e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 661916.7133337364)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413266
INFO: iteration 2, average log likelihood -1.408398
INFO: iteration 3, average log likelihood -1.407131
INFO: iteration 4, average log likelihood -1.406204
INFO: iteration 5, average log likelihood -1.405170
INFO: iteration 6, average log likelihood -1.404105
INFO: iteration 7, average log likelihood -1.403286
INFO: iteration 8, average log likelihood -1.402808
INFO: iteration 9, average log likelihood -1.402553
INFO: iteration 10, average log likelihood -1.402403
INFO: iteration 11, average log likelihood -1.402303
INFO: iteration 12, average log likelihood -1.402227
INFO: iteration 13, average log likelihood -1.402166
INFO: iteration 14, average log likelihood -1.402115
INFO: iteration 15, average log likelihood -1.402071
INFO: iteration 16, average log likelihood -1.402032
INFO: iteration 17, average log likelihood -1.401998
INFO: iteration 18, average log likelihood -1.401967
INFO: iteration 19, average log likelihood -1.401939
INFO: iteration 20, average log likelihood -1.401912
INFO: iteration 21, average log likelihood -1.401888
INFO: iteration 22, average log likelihood -1.401864
INFO: iteration 23, average log likelihood -1.401842
INFO: iteration 24, average log likelihood -1.401821
INFO: iteration 25, average log likelihood -1.401800
INFO: iteration 26, average log likelihood -1.401780
INFO: iteration 27, average log likelihood -1.401761
INFO: iteration 28, average log likelihood -1.401741
INFO: iteration 29, average log likelihood -1.401722
INFO: iteration 30, average log likelihood -1.401704
INFO: iteration 31, average log likelihood -1.401685
INFO: iteration 32, average log likelihood -1.401667
INFO: iteration 33, average log likelihood -1.401649
INFO: iteration 34, average log likelihood -1.401631
INFO: iteration 35, average log likelihood -1.401614
INFO: iteration 36, average log likelihood -1.401597
INFO: iteration 37, average log likelihood -1.401581
INFO: iteration 38, average log likelihood -1.401566
INFO: iteration 39, average log likelihood -1.401551
INFO: iteration 40, average log likelihood -1.401536
INFO: iteration 41, average log likelihood -1.401523
INFO: iteration 42, average log likelihood -1.401509
INFO: iteration 43, average log likelihood -1.401497
INFO: iteration 44, average log likelihood -1.401485
INFO: iteration 45, average log likelihood -1.401473
INFO: iteration 46, average log likelihood -1.401462
INFO: iteration 47, average log likelihood -1.401451
INFO: iteration 48, average log likelihood -1.401440
INFO: iteration 49, average log likelihood -1.401430
INFO: iteration 50, average log likelihood -1.401421
INFO: EM with 100000 data points 50 iterations avll -1.401421
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.682822    0.682461   -0.0795149   -0.338426   â€¦   0.345662    0.13146   
  0.166004    0.953636   -0.570317     0.209605      -0.0426038  -0.234644  
  0.117026    0.0249075  -0.888471    -0.144736       0.899799   -0.771631  
  0.176843   -0.293598   -0.217106     0.12406       -0.334928   -0.374399  
 -0.134537    0.43742    -0.215526     0.115266      -0.296718   -0.4929    
  0.180281   -0.0331768  -0.120856    -0.0231166  â€¦   0.0431309  -0.285011  
  0.10119     0.336451   -0.208368     0.163919       0.198116   -0.214243  
  0.161679   -0.554618    0.201816    -0.511692       0.211917    0.158652  
 -0.404736   -0.13253     0.534939    -0.102064      -0.62036     0.11269   
 -0.0269322   0.0129111  -0.179072     0.207587      -0.173339    0.279801  
  â‹®                                               â‹±               â‹®         
  0.0494997  -0.367288   -0.0556349   -0.151261      -0.0404618   0.00683972
  0.208687   -0.440137    0.0923876   -0.018943      -0.0756226  -0.0822351 
 -0.228383   -0.360274   -0.127342     0.0281854  â€¦   0.258692    0.147708  
  0.48398     0.130312    0.230795    -0.741346       0.244402    0.27045   
 -0.219916    0.138551    0.0280385   -0.109567       0.0607685   0.309038  
  0.895655   -0.288062    0.00108091   0.658478      -0.126965   -0.0196446 
 -0.0492922   0.776924    0.698908     0.100661      -0.0693884  -0.39039   
 -0.0780202   0.307184   -0.251014     1.14086    â€¦  -0.322262    0.181493  
 -0.782623    0.652251   -0.126155    -0.236903      -0.104759    0.249298  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.401411
INFO: iteration 2, average log likelihood -1.401402
INFO: iteration 3, average log likelihood -1.401393
INFO: iteration 4, average log likelihood -1.401385
INFO: iteration 5, average log likelihood -1.401376
INFO: iteration 6, average log likelihood -1.401368
INFO: iteration 7, average log likelihood -1.401360
INFO: iteration 8, average log likelihood -1.401353
INFO: iteration 9, average log likelihood -1.401345
INFO: iteration 10, average log likelihood -1.401338
INFO: EM with 100000 data points 10 iterations avll -1.401338
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
