>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.0
INFO: Installing FileIO v0.2.0
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.5
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.5.1
INFO: Installing Rmath v0.1.4
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.2.0
INFO: Installing StatsBase v0.11.1
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64
Memory: 2.939289093017578 GB (658.02734375 MB free)
Uptime: 25895.0 sec
Load Avg:  0.9326171875  0.9853515625  1.033203125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz    1180578 s       3993 s     104774 s    1036788 s        109 s
#2  3499 MHz     800514 s       3282 s      91480 s    1588852 s          2 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.8.0
19 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.3
 - Distances                     0.3.2
 - Distributions                 0.11.0
 - FileIO                        0.2.0
 - HDF5                          0.6.6
 - JLD                           0.6.5
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.0.5
 - PDMats                        0.5.1
 - Rmath                         0.1.4
 - SHA                           0.2.1
 - ScikitLearnBase               0.2.0
 - StatsBase                     0.11.1
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-529447.9896271374,[29223.223766733492,70776.7762332665],
[4810.516087289721 -8303.281032184821 -6905.37084581101
 -4709.609732796469 8074.10235046545 6137.105512742853],

[
[35794.0027629001 -7903.6380800768075 -14643.786558845197
 -7903.6380800768075 47389.787092447456 15429.953158673348
 -14643.786558845199 15429.953158673348 37317.69996853648],

[64562.12376351892 7936.847948848975 14479.933275462132
 7936.847948848975 52838.693866188085 -15349.836426868223
 14479.933275462132 -15349.836426868225 63368.388311983304]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.757950e+03
      1       9.487825e+02      -8.091676e+02 |        8
      2       8.683517e+02      -8.043077e+01 |        2
      3       8.550298e+02      -1.332193e+01 |        0
      4       8.550298e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 855.0297794783355)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.085433
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.888038
INFO: iteration 2, lowerbound -3.773560
INFO: iteration 3, lowerbound -3.644489
INFO: iteration 4, lowerbound -3.483146
INFO: iteration 5, lowerbound -3.308392
INFO: iteration 6, lowerbound -3.151448
INFO: iteration 7, lowerbound -3.037723
INFO: dropping number of Gaussions to 6
INFO: iteration 8, lowerbound -2.956362
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.876936
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.788756
INFO: iteration 11, lowerbound -2.698888
INFO: iteration 12, lowerbound -2.611949
INFO: iteration 13, lowerbound -2.532188
INFO: iteration 14, lowerbound -2.467914
INFO: iteration 15, lowerbound -2.423653
INFO: dropping number of Gaussions to 3
INFO: iteration 16, lowerbound -2.383791
INFO: iteration 17, lowerbound -2.349115
INFO: iteration 18, lowerbound -2.324067
INFO: iteration 19, lowerbound -2.309513
INFO: iteration 20, lowerbound -2.308621
INFO: dropping number of Gaussions to 2
INFO: iteration 21, lowerbound -2.302914
INFO: iteration 22, lowerbound -2.299258
INFO: iteration 23, lowerbound -2.299255
INFO: iteration 24, lowerbound -2.299254
INFO: iteration 25, lowerbound -2.299254
INFO: iteration 26, lowerbound -2.299253
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Sun 06 Nov 2016 11:33:02 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sun 06 Nov 2016 11:33:03 AM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Sun 06 Nov 2016 11:33:04 AM UTC: EM with 272 data points 0 iterations avll -2.085433
5.8 data points per parameter
,Sun 06 Nov 2016 11:33:04 AM UTC: GMM converted to Variational GMM
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 1, lowerbound -3.888038
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 2, lowerbound -3.773560
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 3, lowerbound -3.644489
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 4, lowerbound -3.483146
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 5, lowerbound -3.308392
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 6, lowerbound -3.151448
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 7, lowerbound -3.037723
,Sun 06 Nov 2016 11:33:06 AM UTC: dropping number of Gaussions to 6
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 8, lowerbound -2.956362
,Sun 06 Nov 2016 11:33:06 AM UTC: dropping number of Gaussions to 5
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 9, lowerbound -2.876936
,Sun 06 Nov 2016 11:33:06 AM UTC: dropping number of Gaussions to 4
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 10, lowerbound -2.788756
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 11, lowerbound -2.698888
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 12, lowerbound -2.611949
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 13, lowerbound -2.532188
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 14, lowerbound -2.467914
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 15, lowerbound -2.423653
,Sun 06 Nov 2016 11:33:06 AM UTC: dropping number of Gaussions to 3
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 16, lowerbound -2.383791
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 17, lowerbound -2.349115
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 18, lowerbound -2.324067
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 19, lowerbound -2.309513
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 20, lowerbound -2.308621
,Sun 06 Nov 2016 11:33:06 AM UTC: dropping number of Gaussions to 2
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 21, lowerbound -2.302914
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 22, lowerbound -2.299258
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 23, lowerbound -2.299255
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 24, lowerbound -2.299254
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 25, lowerbound -2.299254
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 26, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 27, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 28, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 29, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 30, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 31, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 32, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 33, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 34, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 35, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 36, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 37, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 38, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 39, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 40, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 41, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 42, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 43, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 44, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 45, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 46, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 47, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 48, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 49, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: iteration 50, lowerbound -2.299253
,Sun 06 Nov 2016 11:33:06 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.0450922260145,95.95490777398548]
Î² = [178.0450922260145,95.95490777398548]
m = [4.250300733269906 79.28686694436176
 2.0002292577753646 53.85198717246128]
Î½ = [180.0450922260145,97.95490777398548]
W = [
[0.18404155547484727 -0.007644049042327251
 0.0 0.008581705166333352],

[0.3758763611948483 -0.00895312382734614
 0.0 0.012748664777409408]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000003
avll from stats: -0.9860494210970168
avll from llpg:  -0.9860494210970168
avll direct:     -0.9860494210970168
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0195306459167546
avll from llpg:  -1.0195306459167546
avll direct:     -1.0195306459167546
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.117423    -0.0956009    0.140799   â€¦  -0.0358472  -0.0239899 
 -0.0151112   -0.0568348   -0.010312       0.026489    0.247543  
  0.132413    -0.0369617    0.0253319     -0.0194474  -0.0134745 
  0.12817      0.0266798    0.0815811     -0.189794   -0.162721  
 -0.0418593    0.0287456   -0.0144565      0.0819688  -0.0969598 
  0.180054    -0.114801    -0.0229204  â€¦  -0.0187166  -0.00848415
 -0.0702801   -0.0758767    0.0854962      0.0381441   0.015558  
 -0.0175415    0.0316949    0.0543755      0.150242   -0.0774833 
  0.014788     0.130693     0.0443281      0.0729529   0.151956  
  0.0773964    0.0143426    0.0538041     -0.131267    0.0948459 
  â‹®                                    â‹±               â‹®         
  0.07361     -0.0954139   -0.0728721     -0.178704   -0.166049  
 -0.127675    -0.0115453   -0.0231033     -0.186642   -0.0998014 
 -0.0974285   -0.151434     0.113245   â€¦   0.0696356   0.0466533 
 -0.0876567    0.00948766  -0.211983       0.0971158   0.147684  
  0.00823866   0.0130916    0.0334339     -0.0636566  -0.296823  
  0.0210263    0.0452247   -0.0877739      0.0142958   0.09562   
  0.125227     0.0431924    0.153275      -0.0287502   0.241595  
 -0.0157693   -0.102696    -0.119922   â€¦   0.0680581   0.174375  
 -0.151657    -0.058871     0.0635964      0.0123101   0.134654  kind diag, method split
0: avll = -1.394959189025722
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.395012
INFO: iteration 2, average log likelihood -1.394919
INFO: iteration 3, average log likelihood -1.393656
INFO: iteration 4, average log likelihood -1.382579
INFO: iteration 5, average log likelihood -1.366235
INFO: iteration 6, average log likelihood -1.362430
INFO: iteration 7, average log likelihood -1.361589
INFO: iteration 8, average log likelihood -1.361078
INFO: iteration 9, average log likelihood -1.360674
INFO: iteration 10, average log likelihood -1.360293
INFO: iteration 11, average log likelihood -1.359894
INFO: iteration 12, average log likelihood -1.359503
INFO: iteration 13, average log likelihood -1.359181
INFO: iteration 14, average log likelihood -1.358937
INFO: iteration 15, average log likelihood -1.358754
INFO: iteration 16, average log likelihood -1.358615
INFO: iteration 17, average log likelihood -1.358510
INFO: iteration 18, average log likelihood -1.358434
INFO: iteration 19, average log likelihood -1.358379
INFO: iteration 20, average log likelihood -1.358339
INFO: iteration 21, average log likelihood -1.358311
INFO: iteration 22, average log likelihood -1.358290
INFO: iteration 23, average log likelihood -1.358275
INFO: iteration 24, average log likelihood -1.358263
INFO: iteration 25, average log likelihood -1.358254
INFO: iteration 26, average log likelihood -1.358248
INFO: iteration 27, average log likelihood -1.358242
INFO: iteration 28, average log likelihood -1.358238
INFO: iteration 29, average log likelihood -1.358235
INFO: iteration 30, average log likelihood -1.358233
INFO: iteration 31, average log likelihood -1.358231
INFO: iteration 32, average log likelihood -1.358229
INFO: iteration 33, average log likelihood -1.358228
INFO: iteration 34, average log likelihood -1.358227
INFO: iteration 35, average log likelihood -1.358226
INFO: iteration 36, average log likelihood -1.358225
INFO: iteration 37, average log likelihood -1.358225
INFO: iteration 38, average log likelihood -1.358224
INFO: iteration 39, average log likelihood -1.358224
INFO: iteration 40, average log likelihood -1.358224
INFO: iteration 41, average log likelihood -1.358223
INFO: iteration 42, average log likelihood -1.358223
INFO: iteration 43, average log likelihood -1.358223
INFO: iteration 44, average log likelihood -1.358223
INFO: iteration 45, average log likelihood -1.358223
INFO: iteration 46, average log likelihood -1.358223
INFO: iteration 47, average log likelihood -1.358222
INFO: iteration 48, average log likelihood -1.358222
INFO: iteration 49, average log likelihood -1.358222
INFO: iteration 50, average log likelihood -1.358222
INFO: EM with 100000 data points 50 iterations avll -1.358222
952.4 data points per parameter
1: avll = [-1.395012493928155,-1.3949187639452831,-1.393656132445882,-1.3825790471102195,-1.3662350770917535,-1.3624295202883043,-1.3615887200758616,-1.361078438029909,-1.3606737423334951,-1.3602932798877287,-1.3598937943481737,-1.3595033445488962,-1.359180931526213,-1.3589371178952239,-1.3587542452559007,-1.3586153081852617,-1.3585104350303885,-1.3584337022223358,-1.358378642035357,-1.3583391779922855,-1.3583106873088535,-1.358289912890497,-1.358274570152653,-1.3582630687072255,-1.358254324351473,-1.358247605093883,-1.3582424049168567,-1.3582383586373659,-1.3582351937570643,-1.3582327039970836,-1.3582307328667087,-1.3582291618412274,-1.35822790122011,-1.3582268830052375,-1.3582260554433292,-1.3582253789179073,-1.358224822895092,-1.3582243636669633,-1.3582239826863396,-1.358223665335196,-1.358223400009565,-1.3582231774353946,-1.3582229901534544,-1.358222832128586,-1.3582226984509966,-1.3582225851061562,-1.358222488796219,-1.3582224068004312,-1.3582223368652597,-1.3582222771173564]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.358316
INFO: iteration 2, average log likelihood -1.358227
INFO: iteration 3, average log likelihood -1.357913
INFO: iteration 4, average log likelihood -1.354814
INFO: iteration 5, average log likelihood -1.341996
INFO: iteration 6, average log likelihood -1.328276
INFO: iteration 7, average log likelihood -1.321741
INFO: iteration 8, average log likelihood -1.318173
INFO: iteration 9, average log likelihood -1.316227
INFO: iteration 10, average log likelihood -1.315227
INFO: iteration 11, average log likelihood -1.314641
INFO: iteration 12, average log likelihood -1.314268
INFO: iteration 13, average log likelihood -1.314012
INFO: iteration 14, average log likelihood -1.313818
INFO: iteration 15, average log likelihood -1.313643
INFO: iteration 16, average log likelihood -1.313438
INFO: iteration 17, average log likelihood -1.313169
INFO: iteration 18, average log likelihood -1.312915
INFO: iteration 19, average log likelihood -1.312760
INFO: iteration 20, average log likelihood -1.312670
INFO: iteration 21, average log likelihood -1.312611
INFO: iteration 22, average log likelihood -1.312569
INFO: iteration 23, average log likelihood -1.312538
INFO: iteration 24, average log likelihood -1.312513
INFO: iteration 25, average log likelihood -1.312493
INFO: iteration 26, average log likelihood -1.312476
INFO: iteration 27, average log likelihood -1.312462
INFO: iteration 28, average log likelihood -1.312450
INFO: iteration 29, average log likelihood -1.312440
INFO: iteration 30, average log likelihood -1.312431
INFO: iteration 31, average log likelihood -1.312424
INFO: iteration 32, average log likelihood -1.312417
INFO: iteration 33, average log likelihood -1.312411
INFO: iteration 34, average log likelihood -1.312407
INFO: iteration 35, average log likelihood -1.312402
INFO: iteration 36, average log likelihood -1.312399
INFO: iteration 37, average log likelihood -1.312395
INFO: iteration 38, average log likelihood -1.312393
INFO: iteration 39, average log likelihood -1.312390
INFO: iteration 40, average log likelihood -1.312387
INFO: iteration 41, average log likelihood -1.312385
INFO: iteration 42, average log likelihood -1.312383
INFO: iteration 43, average log likelihood -1.312381
INFO: iteration 44, average log likelihood -1.312379
INFO: iteration 45, average log likelihood -1.312378
INFO: iteration 46, average log likelihood -1.312376
INFO: iteration 47, average log likelihood -1.312375
INFO: iteration 48, average log likelihood -1.312373
INFO: iteration 49, average log likelihood -1.312372
INFO: iteration 50, average log likelihood -1.312370
INFO: EM with 100000 data points 50 iterations avll -1.312370
473.9 data points per parameter
2: avll = [-1.3583164299487989,-1.3582266604090987,-1.3579130078766741,-1.354813556068773,-1.3419964972555527,-1.3282762971377746,-1.321740961739067,-1.3181732977147007,-1.3162270971810712,-1.315226841933984,-1.3146410526093195,-1.3142684574002905,-1.3140122324760726,-1.3138182878341587,-1.3136432375673197,-1.3134379503341036,-1.313169010787683,-1.3129149121364778,-1.3127596364314298,-1.3126697218892613,-1.3126112984268559,-1.3125694328476571,-1.3125377554609778,-1.3125129707924732,-1.3124929877012226,-1.312476422776263,-1.312462413767985,-1.312450438713606,-1.312440140214198,-1.3124312591826703,-1.3124236081811305,-1.3124170348258437,-1.3124113953372711,-1.3124065460217165,-1.3124023484948115,-1.3123986785083104,-1.3123954313540158,-1.3123925229215068,-1.3123898879812272,-1.312387477152554,-1.3123852534407987,-1.3123831889008204,-1.3123812618126036,-1.3123794545585,-1.3123777521835396,-1.3123761414925934,-1.3123746105131924,-1.3123731481834706,-1.3123717441648377,-1.312370388710119]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.312501
INFO: iteration 2, average log likelihood -1.312344
INFO: iteration 3, average log likelihood -1.311811
INFO: iteration 4, average log likelihood -1.307778
INFO: iteration 5, average log likelihood -1.296075
INFO: iteration 6, average log likelihood -1.284701
INFO: iteration 7, average log likelihood -1.277847
INFO: iteration 8, average log likelihood -1.273204
INFO: iteration 9, average log likelihood -1.269693
INFO: iteration 10, average log likelihood -1.267210
INFO: iteration 11, average log likelihood -1.265530
INFO: iteration 12, average log likelihood -1.264348
INFO: iteration 13, average log likelihood -1.263446
INFO: iteration 14, average log likelihood -1.262664
INFO: iteration 15, average log likelihood -1.261913
INFO: iteration 16, average log likelihood -1.261146
INFO: iteration 17, average log likelihood -1.260301
INFO: iteration 18, average log likelihood -1.259217
INFO: iteration 19, average log likelihood -1.257835
INFO: iteration 20, average log likelihood -1.256490
INFO: iteration 21, average log likelihood -1.255242
INFO: iteration 22, average log likelihood -1.254177
INFO: iteration 23, average log likelihood -1.253325
INFO: iteration 24, average log likelihood -1.252592
INFO: iteration 25, average log likelihood -1.251861
INFO: iteration 26, average log likelihood -1.251150
INFO: iteration 27, average log likelihood -1.250623
INFO: iteration 28, average log likelihood -1.250312
INFO: iteration 29, average log likelihood -1.250123
INFO: iteration 30, average log likelihood -1.249993
INFO: iteration 31, average log likelihood -1.249894
INFO: iteration 32, average log likelihood -1.249813
INFO: iteration 33, average log likelihood -1.249743
INFO: iteration 34, average log likelihood -1.249683
INFO: iteration 35, average log likelihood -1.249628
INFO: iteration 36, average log likelihood -1.249576
INFO: iteration 37, average log likelihood -1.249522
INFO: iteration 38, average log likelihood -1.249457
INFO: iteration 39, average log likelihood -1.249368
INFO: iteration 40, average log likelihood -1.249226
INFO: iteration 41, average log likelihood -1.249001
INFO: iteration 42, average log likelihood -1.248701
INFO: iteration 43, average log likelihood -1.248413
INFO: iteration 44, average log likelihood -1.248242
INFO: iteration 45, average log likelihood -1.248176
INFO: iteration 46, average log likelihood -1.248153
INFO: iteration 47, average log likelihood -1.248142
INFO: iteration 48, average log likelihood -1.248133
INFO: iteration 49, average log likelihood -1.248125
INFO: iteration 50, average log likelihood -1.248116
INFO: EM with 100000 data points 50 iterations avll -1.248116
236.4 data points per parameter
3: avll = [-1.3125009790633972,-1.3123440795273535,-1.3118109505390074,-1.3077779103460059,-1.296074711481346,-1.284700648245611,-1.2778473930207253,-1.273204180934033,-1.269692665608185,-1.26721033207054,-1.265530113912486,-1.2643482315292063,-1.2634455560771944,-1.2626640510440044,-1.2619133803798335,-1.2611464633532259,-1.260301133756396,-1.259216916477132,-1.2578354896338797,-1.2564904236197076,-1.255241872976129,-1.2541766865922648,-1.2533253009955323,-1.2525918292345446,-1.2518605815761432,-1.251150063451643,-1.2506225868383247,-1.250312004898973,-1.2501230774239813,-1.2499929644278036,-1.2498941668499461,-1.249812820359241,-1.249743368818408,-1.2496828827710564,-1.2496284233807655,-1.2495762251609153,-1.249521500341484,-1.249457301504957,-1.249368213530815,-1.2492262224523045,-1.2490013867649397,-1.248700550078275,-1.2484131602236772,-1.2482424781957586,-1.248175510469742,-1.2481527738895748,-1.2481418211895048,-1.2481333983706029,-1.2481251331462828,-1.248116184877736]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.248278
INFO: iteration 2, average log likelihood -1.248008
INFO: iteration 3, average log likelihood -1.246750
INFO: iteration 4, average log likelihood -1.237311
INFO: iteration 5, average log likelihood -1.211282
INFO: iteration 6, average log likelihood -1.186952
WARNING: Variances had to be floored 4
INFO: iteration 7, average log likelihood -1.170252
WARNING: Variances had to be floored 13
INFO: iteration 8, average log likelihood -1.171542
INFO: iteration 9, average log likelihood -1.165856
WARNING: Variances had to be floored 4
INFO: iteration 10, average log likelihood -1.155902
INFO: iteration 11, average log likelihood -1.165327
INFO: iteration 12, average log likelihood -1.157742
WARNING: Variances had to be floored 4
INFO: iteration 13, average log likelihood -1.152032
WARNING: Variances had to be floored 13
INFO: iteration 14, average log likelihood -1.162006
INFO: iteration 15, average log likelihood -1.161522
WARNING: Variances had to be floored 4
INFO: iteration 16, average log likelihood -1.153710
INFO: iteration 17, average log likelihood -1.163918
INFO: iteration 18, average log likelihood -1.155794
WARNING: Variances had to be floored 4
INFO: iteration 19, average log likelihood -1.149398
WARNING: Variances had to be floored 13
INFO: iteration 20, average log likelihood -1.159158
INFO: iteration 21, average log likelihood -1.158590
WARNING: Variances had to be floored 4
INFO: iteration 22, average log likelihood -1.151006
INFO: iteration 23, average log likelihood -1.161528
INFO: iteration 24, average log likelihood -1.154257
WARNING: Variances had to be floored 4
INFO: iteration 25, average log likelihood -1.148783
WARNING: Variances had to be floored 13
INFO: iteration 26, average log likelihood -1.159029
INFO: iteration 27, average log likelihood -1.158484
WARNING: Variances had to be floored 4
INFO: iteration 28, average log likelihood -1.150933
INFO: iteration 29, average log likelihood -1.161541
INFO: iteration 30, average log likelihood -1.154273
WARNING: Variances had to be floored 4
INFO: iteration 31, average log likelihood -1.148769
WARNING: Variances had to be floored 13
INFO: iteration 32, average log likelihood -1.159076
INFO: iteration 33, average log likelihood -1.158448
WARNING: Variances had to be floored 4
INFO: iteration 34, average log likelihood -1.150888
INFO: iteration 35, average log likelihood -1.161550
INFO: iteration 36, average log likelihood -1.154281
WARNING: Variances had to be floored 4
INFO: iteration 37, average log likelihood -1.148767
WARNING: Variances had to be floored 13
INFO: iteration 38, average log likelihood -1.159095
INFO: iteration 39, average log likelihood -1.158437
WARNING: Variances had to be floored 4
INFO: iteration 40, average log likelihood -1.150876
INFO: iteration 41, average log likelihood -1.161555
INFO: iteration 42, average log likelihood -1.154287
WARNING: Variances had to be floored 4
INFO: iteration 43, average log likelihood -1.148772
WARNING: Variances had to be floored 13
INFO: iteration 44, average log likelihood -1.159102
INFO: iteration 45, average log likelihood -1.158434
WARNING: Variances had to be floored 4
INFO: iteration 46, average log likelihood -1.150874
INFO: iteration 47, average log likelihood -1.161556
INFO: iteration 48, average log likelihood -1.154290
WARNING: Variances had to be floored 4
INFO: iteration 49, average log likelihood -1.148776
WARNING: Variances had to be floored 13
INFO: iteration 50, average log likelihood -1.159105
INFO: EM with 100000 data points 50 iterations avll -1.159105
118.1 data points per parameter
4: avll = [-1.2482782615363404,-1.2480079996051876,-1.2467500605712436,-1.237310758005873,-1.2112821784366463,-1.1869521541051955,-1.1702515695055007,-1.1715421465131186,-1.1658559593527407,-1.1559015776876123,-1.1653269941145834,-1.1577422949963112,-1.1520318442001485,-1.1620058287381063,-1.161522021520052,-1.1537100924633819,-1.1639184640166704,-1.1557944305484678,-1.1493984146717684,-1.1591583336557094,-1.1585898481297372,-1.15100565377597,-1.1615284690036929,-1.1542568094552332,-1.148782731837955,-1.1590288532416073,-1.158483824361551,-1.1509325437229894,-1.1615408521342847,-1.154272987956697,-1.1487687400127002,-1.1590756922672991,-1.1584484377683983,-1.1508876697342605,-1.1615502865916036,-1.1542812849229434,-1.1487672563881808,-1.1590946227217693,-1.158437248895983,-1.1508756728150904,-1.1615547095055476,-1.1542869738112065,-1.1487716225159275,-1.1591024893677313,-1.1584342506346152,-1.1508742442556736,-1.1615562832348751,-1.1542902287022658,-1.1487758680538365,-1.1591053659506962]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.158636
WARNING: Variances had to be floored 7 8
INFO: iteration 2, average log likelihood -1.150735
INFO: iteration 3, average log likelihood -1.152829
WARNING: Variances had to be floored 7 8
INFO: iteration 4, average log likelihood -1.129653
WARNING: Variances had to be floored 4 25
INFO: iteration 5, average log likelihood -1.094921
WARNING: Variances had to be floored 7 8 9 10 20 26
INFO: iteration 6, average log likelihood -1.063147
WARNING: Variances had to be floored 1 4
INFO: iteration 7, average log likelihood -1.075734
WARNING: Variances had to be floored 7 8
INFO: iteration 8, average log likelihood -1.061609
WARNING: Variances had to be floored 4 10 20 25 26
INFO: iteration 9, average log likelihood -1.038613
WARNING: Variances had to be floored 7 8 9
INFO: iteration 10, average log likelihood -1.064514
WARNING: Variances had to be floored 1 4 10
INFO: iteration 11, average log likelihood -1.055130
WARNING: Variances had to be floored 7 8 20
INFO: iteration 12, average log likelihood -1.055522
WARNING: Variances had to be floored 4 7 8 9 10 26
INFO: iteration 13, average log likelihood -1.044184
WARNING: Variances had to be floored 25
INFO: iteration 14, average log likelihood -1.058474
WARNING: Variances had to be floored 4 7 8 20
INFO: iteration 15, average log likelihood -1.044630
WARNING: Variances had to be floored 1 10 26
INFO: iteration 16, average log likelihood -1.049633
WARNING: Variances had to be floored 4 7 8 9
INFO: iteration 17, average log likelihood -1.043576
WARNING: Variances had to be floored 10 20 25
INFO: iteration 18, average log likelihood -1.044664
WARNING: Variances had to be floored 4 7 8 26
INFO: iteration 19, average log likelihood -1.047009
WARNING: Variances had to be floored 1 9 10
INFO: iteration 20, average log likelihood -1.047996
WARNING: Variances had to be floored 4 7 8 20
INFO: iteration 21, average log likelihood -1.040944
WARNING: Variances had to be floored 4 25 26
INFO: iteration 22, average log likelihood -1.051369
WARNING: Variances had to be floored 7 8 10
INFO: iteration 23, average log likelihood -1.047962
WARNING: Variances had to be floored 1 4 9 20
INFO: iteration 24, average log likelihood -1.046807
WARNING: Variances had to be floored 7 8 10
INFO: iteration 25, average log likelihood -1.059907
WARNING: Variances had to be floored 4 7 26
INFO: iteration 26, average log likelihood -1.043214
WARNING: Variances had to be floored 8 9 10 20 25
INFO: iteration 27, average log likelihood -1.035289
WARNING: Variances had to be floored 1 4
INFO: iteration 28, average log likelihood -1.059625
WARNING: Variances had to be floored 8 26
INFO: iteration 29, average log likelihood -1.050727
WARNING: Variances had to be floored 4 8 10 20
INFO: iteration 30, average log likelihood -1.037198
WARNING: Variances had to be floored 4 8 9 25
INFO: iteration 31, average log likelihood -1.045102
WARNING: Variances had to be floored 1 10 26
INFO: iteration 32, average log likelihood -1.045011
WARNING: Variances had to be floored 4 8 20
INFO: iteration 33, average log likelihood -1.035075
WARNING: Variances had to be floored 4 8 9 10 23 25 26
INFO: iteration 34, average log likelihood -1.032201
WARNING: Variances had to be floored 1 20
INFO: iteration 35, average log likelihood -1.061427
WARNING: Variances had to be floored 4 8
INFO: iteration 36, average log likelihood -1.047742
WARNING: Variances had to be floored 4 8 10
INFO: iteration 37, average log likelihood -1.040072
WARNING: Variances had to be floored 4 8 9 20 23 26
INFO: iteration 38, average log likelihood -1.031429
WARNING: Variances had to be floored 1 4 8 10 25
INFO: iteration 39, average log likelihood -1.050257
WARNING: Variances had to be floored 4 17
INFO: iteration 40, average log likelihood -1.052494
WARNING: Variances had to be floored 4 8 9 10 20 26
INFO: iteration 41, average log likelihood -1.024863
WARNING: Variances had to be floored 4 8 23 25
INFO: iteration 42, average log likelihood -1.049646
WARNING: Variances had to be floored 1 20
INFO: iteration 43, average log likelihood -1.053093
WARNING: Variances had to be floored 4 8 10 26
INFO: iteration 44, average log likelihood -1.030538
WARNING: Variances had to be floored 4 8 9 20 25
INFO: iteration 45, average log likelihood -1.038999
WARNING: Variances had to be floored 1 10 23 26
INFO: iteration 46, average log likelihood -1.048879
WARNING: Variances had to be floored 4 8 17 20
INFO: iteration 47, average log likelihood -1.044345
WARNING: Variances had to be floored 4 8 9 10 25 26
INFO: iteration 48, average log likelihood -1.035416
WARNING: Variances had to be floored 1 20
INFO: iteration 49, average log likelihood -1.054096
WARNING: Variances had to be floored 4 8 23
INFO: iteration 50, average log likelihood -1.044886
INFO: EM with 100000 data points 50 iterations avll -1.044886
59.0 data points per parameter
5: avll = [-1.1586355938010233,-1.1507349461863992,-1.1528288674490705,-1.1296532349044306,-1.0949208919301743,-1.0631474372745946,-1.0757341190710896,-1.061608645134145,-1.0386133033441411,-1.064513868101846,-1.0551298519520453,-1.055522496858555,-1.0441837370608869,-1.0584738344427795,-1.0446302707892856,-1.0496329382423486,-1.0435758308941008,-1.0446642095905647,-1.0470086257330125,-1.0479959490838766,-1.0409441376554271,-1.0513691048835827,-1.0479618467160952,-1.0468069301816287,-1.0599070557003525,-1.0432142285457762,-1.0352893035481898,-1.0596246777796126,-1.050727100119453,-1.0371984666833542,-1.0451016041260446,-1.0450108074600286,-1.0350745376012649,-1.032201350931224,-1.0614272104593394,-1.0477419183782974,-1.0400721359538865,-1.031428862657938,-1.0502573713359205,-1.0524936807543315,-1.0248627330241917,-1.0496456440322943,-1.0530931626318838,-1.0305381639335345,-1.0389990786024796,-1.0488787822373349,-1.0443451094469396,-1.0354159011157236,-1.0540961190801832,-1.0448863508711408]
[-1.394959189025722,-1.395012493928155,-1.3949187639452831,-1.393656132445882,-1.3825790471102195,-1.3662350770917535,-1.3624295202883043,-1.3615887200758616,-1.361078438029909,-1.3606737423334951,-1.3602932798877287,-1.3598937943481737,-1.3595033445488962,-1.359180931526213,-1.3589371178952239,-1.3587542452559007,-1.3586153081852617,-1.3585104350303885,-1.3584337022223358,-1.358378642035357,-1.3583391779922855,-1.3583106873088535,-1.358289912890497,-1.358274570152653,-1.3582630687072255,-1.358254324351473,-1.358247605093883,-1.3582424049168567,-1.3582383586373659,-1.3582351937570643,-1.3582327039970836,-1.3582307328667087,-1.3582291618412274,-1.35822790122011,-1.3582268830052375,-1.3582260554433292,-1.3582253789179073,-1.358224822895092,-1.3582243636669633,-1.3582239826863396,-1.358223665335196,-1.358223400009565,-1.3582231774353946,-1.3582229901534544,-1.358222832128586,-1.3582226984509966,-1.3582225851061562,-1.358222488796219,-1.3582224068004312,-1.3582223368652597,-1.3582222771173564,-1.3583164299487989,-1.3582266604090987,-1.3579130078766741,-1.354813556068773,-1.3419964972555527,-1.3282762971377746,-1.321740961739067,-1.3181732977147007,-1.3162270971810712,-1.315226841933984,-1.3146410526093195,-1.3142684574002905,-1.3140122324760726,-1.3138182878341587,-1.3136432375673197,-1.3134379503341036,-1.313169010787683,-1.3129149121364778,-1.3127596364314298,-1.3126697218892613,-1.3126112984268559,-1.3125694328476571,-1.3125377554609778,-1.3125129707924732,-1.3124929877012226,-1.312476422776263,-1.312462413767985,-1.312450438713606,-1.312440140214198,-1.3124312591826703,-1.3124236081811305,-1.3124170348258437,-1.3124113953372711,-1.3124065460217165,-1.3124023484948115,-1.3123986785083104,-1.3123954313540158,-1.3123925229215068,-1.3123898879812272,-1.312387477152554,-1.3123852534407987,-1.3123831889008204,-1.3123812618126036,-1.3123794545585,-1.3123777521835396,-1.3123761414925934,-1.3123746105131924,-1.3123731481834706,-1.3123717441648377,-1.312370388710119,-1.3125009790633972,-1.3123440795273535,-1.3118109505390074,-1.3077779103460059,-1.296074711481346,-1.284700648245611,-1.2778473930207253,-1.273204180934033,-1.269692665608185,-1.26721033207054,-1.265530113912486,-1.2643482315292063,-1.2634455560771944,-1.2626640510440044,-1.2619133803798335,-1.2611464633532259,-1.260301133756396,-1.259216916477132,-1.2578354896338797,-1.2564904236197076,-1.255241872976129,-1.2541766865922648,-1.2533253009955323,-1.2525918292345446,-1.2518605815761432,-1.251150063451643,-1.2506225868383247,-1.250312004898973,-1.2501230774239813,-1.2499929644278036,-1.2498941668499461,-1.249812820359241,-1.249743368818408,-1.2496828827710564,-1.2496284233807655,-1.2495762251609153,-1.249521500341484,-1.249457301504957,-1.249368213530815,-1.2492262224523045,-1.2490013867649397,-1.248700550078275,-1.2484131602236772,-1.2482424781957586,-1.248175510469742,-1.2481527738895748,-1.2481418211895048,-1.2481333983706029,-1.2481251331462828,-1.248116184877736,-1.2482782615363404,-1.2480079996051876,-1.2467500605712436,-1.237310758005873,-1.2112821784366463,-1.1869521541051955,-1.1702515695055007,-1.1715421465131186,-1.1658559593527407,-1.1559015776876123,-1.1653269941145834,-1.1577422949963112,-1.1520318442001485,-1.1620058287381063,-1.161522021520052,-1.1537100924633819,-1.1639184640166704,-1.1557944305484678,-1.1493984146717684,-1.1591583336557094,-1.1585898481297372,-1.15100565377597,-1.1615284690036929,-1.1542568094552332,-1.148782731837955,-1.1590288532416073,-1.158483824361551,-1.1509325437229894,-1.1615408521342847,-1.154272987956697,-1.1487687400127002,-1.1590756922672991,-1.1584484377683983,-1.1508876697342605,-1.1615502865916036,-1.1542812849229434,-1.1487672563881808,-1.1590946227217693,-1.158437248895983,-1.1508756728150904,-1.1615547095055476,-1.1542869738112065,-1.1487716225159275,-1.1591024893677313,-1.1584342506346152,-1.1508742442556736,-1.1615562832348751,-1.1542902287022658,-1.1487758680538365,-1.1591053659506962,-1.1586355938010233,-1.1507349461863992,-1.1528288674490705,-1.1296532349044306,-1.0949208919301743,-1.0631474372745946,-1.0757341190710896,-1.061608645134145,-1.0386133033441411,-1.064513868101846,-1.0551298519520453,-1.055522496858555,-1.0441837370608869,-1.0584738344427795,-1.0446302707892856,-1.0496329382423486,-1.0435758308941008,-1.0446642095905647,-1.0470086257330125,-1.0479959490838766,-1.0409441376554271,-1.0513691048835827,-1.0479618467160952,-1.0468069301816287,-1.0599070557003525,-1.0432142285457762,-1.0352893035481898,-1.0596246777796126,-1.050727100119453,-1.0371984666833542,-1.0451016041260446,-1.0450108074600286,-1.0350745376012649,-1.032201350931224,-1.0614272104593394,-1.0477419183782974,-1.0400721359538865,-1.031428862657938,-1.0502573713359205,-1.0524936807543315,-1.0248627330241917,-1.0496456440322943,-1.0530931626318838,-1.0305381639335345,-1.0389990786024796,-1.0488787822373349,-1.0443451094469396,-1.0354159011157236,-1.0540961190801832,-1.0448863508711408]
32x26 Array{Float64,2}:
 -0.0303349    0.0467425  -0.0834469  -0.110995   â€¦  -0.219556    -0.100419  
 -0.0528959    0.130453   -0.0918979  -0.128952      -0.0895119    0.033697  
  0.12093      0.0309308   0.0973018  -0.11577       -0.195003    -0.159881  
  0.0619396    0.136009    0.0132934   0.0765755     -0.0598071   -0.00322659
 -0.020715     0.0151315  -0.0591934   0.0253716     -0.280774    -0.0783375 
 -0.0661197    0.0423385   0.0438089  -0.058903   â€¦   0.623643    -0.129023  
 -0.102322    -0.15814     0.114459   -0.0988649      0.0449858    0.0477684 
  0.013418     0.137285    0.0442009   0.124774       0.114142     0.151904  
  0.116379    -0.115827    0.181688   -0.0620815     -0.0390386   -0.0275398 
  0.175223     0.0906301  -0.0626218  -0.0599213      0.00539163   0.0653282 
  â‹®                                               â‹±                â‹®         
  0.0599306   -0.0239434  -0.0393575   0.126627      -0.0713678   -0.0775862 
 -0.0397577    0.0204097   0.150411    0.0374897      0.114499    -0.0791713 
  0.0197418   -0.0190602  -0.33289     0.0397693  â€¦   0.0134631   -0.0279074 
  0.0275897    0.107148    0.0386522  -0.213702      -0.124066     0.129286  
  0.105648    -0.0491145   0.0695457  -0.197294      -0.155041     0.054939  
  0.125341     0.0383892   0.142379   -0.0138386     -0.0272678    0.224886  
  0.00387429   0.0161143   0.0600402  -0.0162555     -0.0643126   -0.307814  
 -0.137518    -0.116585   -0.0822954   0.0186211  â€¦  -0.0791188    0.292105  
 -0.0562158   -0.032801   -0.0672462   0.0726793     -0.00657126   0.247722  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 4 8 10
INFO: iteration 1, average log likelihood -1.047379
WARNING: Variances had to be floored 4 8 9 10 20 26
INFO: iteration 2, average log likelihood -1.027890
WARNING: Variances had to be floored 1 4 8 9 10 17 20 25
INFO: iteration 3, average log likelihood -1.026233
WARNING: Variances had to be floored 4 8 10 20 23 26
INFO: iteration 4, average log likelihood -1.036679
WARNING: Variances had to be floored 4 8 9 10 17 20
INFO: iteration 5, average log likelihood -1.036674
WARNING: Variances had to be floored 1 4 8 9 10 20 25 26
INFO: iteration 6, average log likelihood -1.025555
WARNING: Variances had to be floored 4 8 10 20
INFO: iteration 7, average log likelihood -1.039959
WARNING: Variances had to be floored 4 8 9 10 17 20 23 26
INFO: iteration 8, average log likelihood -1.026629
WARNING: Variances had to be floored 1 4 8 10 20 25
INFO: iteration 9, average log likelihood -1.033702
WARNING: Variances had to be floored 4 8 9 10 17 20 26
INFO: iteration 10, average log likelihood -1.037811
INFO: EM with 100000 data points 10 iterations avll -1.037811
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.345978e+05
      1       6.580946e+05      -1.765033e+05 |       32
      2       6.304173e+05      -2.767725e+04 |       32
      3       6.156201e+05      -1.479721e+04 |       32
      4       6.067418e+05      -8.878345e+03 |       32
      5       6.010726e+05      -5.669145e+03 |       32
      6       5.976385e+05      -3.434106e+03 |       32
      7       5.952638e+05      -2.374664e+03 |       32
      8       5.937798e+05      -1.483999e+03 |       32
      9       5.928194e+05      -9.604494e+02 |       32
     10       5.922568e+05      -5.625448e+02 |       32
     11       5.919633e+05      -2.935873e+02 |       32
     12       5.917680e+05      -1.952151e+02 |       32
     13       5.916345e+05      -1.335616e+02 |       32
     14       5.915304e+05      -1.040667e+02 |       32
     15       5.914352e+05      -9.521702e+01 |       32
     16       5.913366e+05      -9.857076e+01 |       32
     17       5.912488e+05      -8.786287e+01 |       32
     18       5.911597e+05      -8.905321e+01 |       32
     19       5.910509e+05      -1.088345e+02 |       32
     20       5.908825e+05      -1.683844e+02 |       32
     21       5.905721e+05      -3.103704e+02 |       32
     22       5.901032e+05      -4.689470e+02 |       32
     23       5.895637e+05      -5.394614e+02 |       32
     24       5.890225e+05      -5.412362e+02 |       32
     25       5.886682e+05      -3.543125e+02 |       32
     26       5.884596e+05      -2.085263e+02 |       32
     27       5.883042e+05      -1.554779e+02 |       32
     28       5.881142e+05      -1.900003e+02 |       32
     29       5.879161e+05      -1.980271e+02 |       32
     30       5.877457e+05      -1.703880e+02 |       32
     31       5.876265e+05      -1.191941e+02 |       32
     32       5.875569e+05      -6.964696e+01 |       32
     33       5.875010e+05      -5.592834e+01 |       31
     34       5.874528e+05      -4.812565e+01 |       32
     35       5.873932e+05      -5.964636e+01 |       32
     36       5.872892e+05      -1.039550e+02 |       31
     37       5.870686e+05      -2.206729e+02 |       32
     38       5.866705e+05      -3.980973e+02 |       32
     39       5.861263e+05      -5.441345e+02 |       32
     40       5.855827e+05      -5.436342e+02 |       32
     41       5.852735e+05      -3.092409e+02 |       32
     42       5.851936e+05      -7.983293e+01 |       32
     43       5.851585e+05      -3.511268e+01 |       32
     44       5.851494e+05      -9.082941e+00 |       28
     45       5.851452e+05      -4.264768e+00 |       23
     46       5.851433e+05      -1.921660e+00 |       17
     47       5.851425e+05      -7.795281e-01 |       12
     48       5.851420e+05      -4.469507e-01 |       10
     49       5.851416e+05      -4.439163e-01 |       15
     50       5.851408e+05      -7.387290e-01 |       19
K-means terminated without convergence after 50 iterations (objv = 585140.8424798368)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.313724
INFO: iteration 2, average log likelihood -1.284106
INFO: iteration 3, average log likelihood -1.254772
INFO: iteration 4, average log likelihood -1.219697
INFO: iteration 5, average log likelihood -1.181707
WARNING: Variances had to be floored 9
INFO: iteration 6, average log likelihood -1.137853
WARNING: Variances had to be floored 1 4 23
INFO: iteration 7, average log likelihood -1.098141
WARNING: Variances had to be floored 7 12 26 29
INFO: iteration 8, average log likelihood -1.087596
WARNING: Variances had to be floored 24 32
INFO: iteration 9, average log likelihood -1.098885
WARNING: Variances had to be floored 9 16 22
INFO: iteration 10, average log likelihood -1.072982
WARNING: Variances had to be floored 1 23
INFO: iteration 11, average log likelihood -1.069278
WARNING: Variances had to be floored 7 12 18 26
INFO: iteration 12, average log likelihood -1.058193
WARNING: Variances had to be floored 9 16 24 29 32
INFO: iteration 13, average log likelihood -1.062979
WARNING: Variances had to be floored 1 15
INFO: iteration 14, average log likelihood -1.093729
WARNING: Variances had to be floored 22 23
INFO: iteration 15, average log likelihood -1.079521
WARNING: Variances had to be floored 7 9 12 26
INFO: iteration 16, average log likelihood -1.047980
WARNING: Variances had to be floored 1 16 24 29 32
INFO: iteration 17, average log likelihood -1.060593
WARNING: Variances had to be floored 18
INFO: iteration 18, average log likelihood -1.104108
WARNING: Variances had to be floored 9 23
INFO: iteration 19, average log likelihood -1.063612
WARNING: Variances had to be floored 1 7 12 15 26
INFO: iteration 20, average log likelihood -1.043789
WARNING: Variances had to be floored 16 24 29 32
INFO: iteration 21, average log likelihood -1.078279
WARNING: Variances had to be floored 9
INFO: iteration 22, average log likelihood -1.104507
INFO: iteration 23, average log likelihood -1.076172
WARNING: Variances had to be floored 1 7 12 15 23 26
INFO: iteration 24, average log likelihood -1.022498
WARNING: Variances had to be floored 9 16 24 29 32
INFO: iteration 25, average log likelihood -1.071767
WARNING: Variances had to be floored 18
INFO: iteration 26, average log likelihood -1.106285
WARNING: Variances had to be floored 7
INFO: iteration 27, average log likelihood -1.060498
WARNING: Variances had to be floored 1 9 12 23 26
INFO: iteration 28, average log likelihood -1.022076
WARNING: Variances had to be floored 16 24 29 32
INFO: iteration 29, average log likelihood -1.064999
WARNING: Variances had to be floored 7 18
INFO: iteration 30, average log likelihood -1.082179
WARNING: Variances had to be floored 9
INFO: iteration 31, average log likelihood -1.063170
WARNING: Variances had to be floored 1 12 23 26 32
INFO: iteration 32, average log likelihood -1.026665
WARNING: Variances had to be floored 7 16 24 29 30
INFO: iteration 33, average log likelihood -1.062350
WARNING: Variances had to be floored 18
INFO: iteration 34, average log likelihood -1.088606
WARNING: Variances had to be floored 9
INFO: iteration 35, average log likelihood -1.049531
WARNING: Variances had to be floored 1 7 12 23 26 30 32
INFO: iteration 36, average log likelihood -1.012370
WARNING: Variances had to be floored 16 18 24 29
INFO: iteration 37, average log likelihood -1.080685
INFO: iteration 38, average log likelihood -1.092495
WARNING: Variances had to be floored 7 9 30
INFO: iteration 39, average log likelihood -1.040582
WARNING: Variances had to be floored 1 12 23 24 26 32
INFO: iteration 40, average log likelihood -1.035158
WARNING: Variances had to be floored 16 18 29
INFO: iteration 41, average log likelihood -1.076989
WARNING: Variances had to be floored 7 30
INFO: iteration 42, average log likelihood -1.066319
WARNING: Variances had to be floored 9 23 26
INFO: iteration 43, average log likelihood -1.053432
WARNING: Variances had to be floored 1 12 24 29 32
INFO: iteration 44, average log likelihood -1.035525
WARNING: Variances had to be floored 7 16 18 30
INFO: iteration 45, average log likelihood -1.063981
WARNING: Variances had to be floored 9
INFO: iteration 46, average log likelihood -1.082541
WARNING: Variances had to be floored 1 23 26
INFO: iteration 47, average log likelihood -1.047483
WARNING: Variances had to be floored 7 12 24 29 30 32
INFO: iteration 48, average log likelihood -1.035658
WARNING: Variances had to be floored 16 18
INFO: iteration 49, average log likelihood -1.077380
WARNING: Variances had to be floored 1 9
INFO: iteration 50, average log likelihood -1.057027
INFO: EM with 100000 data points 50 iterations avll -1.057027
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.0130001    0.136905     0.0437856   â€¦   0.110846     0.150925  
  0.0209978    0.01927     -0.0663551      -0.0806488    0.0251115 
 -0.0896812   -0.13022      0.109284        0.0276858    0.0423519 
 -0.142914    -0.0576734    0.060122        0.00413509   0.130537  
  0.0634418   -0.0324574   -0.0408032      -0.0775638   -0.0773571 
 -0.0511412    0.13291     -0.0934797   â€¦  -0.109159     0.0255473 
 -0.118631    -0.0052924   -0.0377046      -0.183285    -0.133585  
  0.108819    -0.13862      0.142192       -0.011796     0.00808017
 -0.010792    -0.0502586    0.00282279      0.010407     0.25212   
 -0.0974518   -0.075438    -0.0745318      -0.0434574    0.270069  
  â‹®                                     â‹±                â‹®         
 -0.0734063    0.0337399    0.0687709       0.144921    -0.0834821 
 -0.0684635   -0.0775092    0.0654999       0.0757074    0.0375198 
  0.0997975   -0.0240969    0.0402693   â€¦   0.00293759  -0.0214257 
  0.122302     0.0393135    0.142028       -0.0280799    0.226508  
  0.0825485    0.00462968  -0.175421       -0.0135118    0.121224  
  0.0493658    0.114074     0.00630714     -0.0341604   -0.0168673 
  0.00286184   0.0409886   -0.102474       -0.0108226    0.113476  
  0.0334296    0.00349322  -0.0771763   â€¦  -0.0481083    0.0224651 
  0.116458    -0.136582     0.171037       -0.06133     -0.0369532 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 7 23 26 30
INFO: iteration 1, average log likelihood -1.049236
WARNING: Variances had to be floored 7 9 12 18 23 24 26 29 30 32
INFO: iteration 2, average log likelihood -0.998673
WARNING: Variances had to be floored 1 7 16 23 26 30
INFO: iteration 3, average log likelihood -1.010873
WARNING: Variances had to be floored 7 12 23 24 26 29 30 32
INFO: iteration 4, average log likelihood -1.017625
WARNING: Variances had to be floored 7 9 18 23 26 30
INFO: iteration 5, average log likelihood -1.006599
WARNING: Variances had to be floored 1 7 12 16 23 24 26 29 30 32
INFO: iteration 6, average log likelihood -0.995178
WARNING: Variances had to be floored 7 9 23 26 30
INFO: iteration 7, average log likelihood -1.032296
WARNING: Variances had to be floored 7 12 18 23 24 26 29 30 32
INFO: iteration 8, average log likelihood -1.008225
WARNING: Variances had to be floored 1 7 9 16 23 26 30
INFO: iteration 9, average log likelihood -0.998585
WARNING: Variances had to be floored 7 12 23 24 26 29 30 32
INFO: iteration 10, average log likelihood -1.029426
INFO: EM with 100000 data points 10 iterations avll -1.029426
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0960223    0.0610796   -0.0726195   â€¦  -0.0651425    0.201183  
 -0.106066    -0.051236     0.0761622       0.0594229    0.0200991 
  0.172391     0.015937     0.128058        0.0882979   -0.128137  
  0.0659808   -0.118548     0.0909217      -0.0604063    0.0304471 
  0.0176782    0.119455     0.0819032       0.135461    -0.0186469 
  0.112946    -0.00185022   0.0482249   â€¦   0.148342     0.178849  
  0.172587    -0.0390112   -0.0323895       0.0706049    0.0929817 
  0.117892     0.0433108    0.0657809       0.169065    -0.0865445 
  0.161036    -0.0688871   -0.28343         0.0497829   -0.066924  
  0.102283    -0.0252567   -0.00219793     -0.0491706    0.174271  
  â‹®                                     â‹±                â‹®         
 -0.0723621   -0.109264     0.0386713      -0.101453     0.109567  
 -0.118617     0.147343    -0.0587068      -0.0486344    0.00466506
  0.0338044    0.172223    -0.0910007   â€¦  -0.0389515    0.0432861 
 -0.0173153    0.0354495   -0.0651314      -0.0786263   -0.0251224 
 -0.251193     0.00144889   0.174942       -0.00860125  -0.0986164 
 -0.103666     0.154301    -0.196916        0.25329      0.00560665
 -0.0582701    0.0807043    0.073113        0.114947    -0.174482  
  0.00954507  -0.193192    -0.0185693   â€¦   0.138885     0.149251  
 -0.0650216    0.0919903   -0.0482115      -0.0560659    0.0918199 kind full, method split
0: avll = -1.4277030277680678
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.427721
INFO: iteration 2, average log likelihood -1.427657
INFO: iteration 3, average log likelihood -1.427602
INFO: iteration 4, average log likelihood -1.427534
INFO: iteration 5, average log likelihood -1.427450
INFO: iteration 6, average log likelihood -1.427354
INFO: iteration 7, average log likelihood -1.427254
INFO: iteration 8, average log likelihood -1.427164
INFO: iteration 9, average log likelihood -1.427092
INFO: iteration 10, average log likelihood -1.427042
INFO: iteration 11, average log likelihood -1.427011
INFO: iteration 12, average log likelihood -1.426992
INFO: iteration 13, average log likelihood -1.426981
INFO: iteration 14, average log likelihood -1.426974
INFO: iteration 15, average log likelihood -1.426969
INFO: iteration 16, average log likelihood -1.426966
INFO: iteration 17, average log likelihood -1.426963
INFO: iteration 18, average log likelihood -1.426960
INFO: iteration 19, average log likelihood -1.426957
INFO: iteration 20, average log likelihood -1.426954
INFO: iteration 21, average log likelihood -1.426950
INFO: iteration 22, average log likelihood -1.426944
INFO: iteration 23, average log likelihood -1.426933
INFO: iteration 24, average log likelihood -1.426911
INFO: iteration 25, average log likelihood -1.426866
INFO: iteration 26, average log likelihood -1.426774
INFO: iteration 27, average log likelihood -1.426585
INFO: iteration 28, average log likelihood -1.426217
INFO: iteration 29, average log likelihood -1.425574
INFO: iteration 30, average log likelihood -1.424652
INFO: iteration 31, average log likelihood -1.423673
INFO: iteration 32, average log likelihood -1.422946
INFO: iteration 33, average log likelihood -1.422551
INFO: iteration 34, average log likelihood -1.422373
INFO: iteration 35, average log likelihood -1.422298
INFO: iteration 36, average log likelihood -1.422268
INFO: iteration 37, average log likelihood -1.422254
INFO: iteration 38, average log likelihood -1.422249
INFO: iteration 39, average log likelihood -1.422246
INFO: iteration 40, average log likelihood -1.422244
INFO: iteration 41, average log likelihood -1.422244
INFO: iteration 42, average log likelihood -1.422243
INFO: iteration 43, average log likelihood -1.422242
INFO: iteration 44, average log likelihood -1.422242
INFO: iteration 45, average log likelihood -1.422241
INFO: iteration 46, average log likelihood -1.422241
INFO: iteration 47, average log likelihood -1.422241
INFO: iteration 48, average log likelihood -1.422241
INFO: iteration 49, average log likelihood -1.422240
INFO: iteration 50, average log likelihood -1.422240
INFO: EM with 100000 data points 50 iterations avll -1.422240
952.4 data points per parameter
1: avll = [-1.427721496171006,-1.427657351792142,-1.4276024246206618,-1.4275342033103413,-1.4274503197863038,-1.4273538357409103,-1.427254062904194,-1.427163544834153,-1.4270920284478743,-1.4270422732319743,-1.4270109079622884,-1.4269922034326323,-1.4269810759340134,-1.4269741027387275,-1.42696931149432,-1.4269656568695148,-1.4269625931807273,-1.4269598041999203,-1.4269570338207305,-1.4269539433971201,-1.4269499141748285,-1.4269436740531374,-1.4269325225071186,-1.4269107024547079,-1.4268660542826228,-1.4267735423820123,-1.4265845635225678,-1.4262169527829083,-1.425574094005089,-1.4246517115508222,-1.4236726538591675,-1.4229459892392105,-1.4225508824558915,-1.422372943163836,-1.4222984512722623,-1.422267556346565,-1.4222544814682465,-1.4222486972485666,-1.4222459300168138,-1.4222444373497822,-1.4222435039699866,-1.422242833401347,-1.4222423006788076,-1.4222418514174449,-1.4222414604930693,-1.4222411150801544,-1.4222408076642832,-1.422240533146577,-1.422240287630017,-1.4222400678989509]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.422255
INFO: iteration 2, average log likelihood -1.422197
INFO: iteration 3, average log likelihood -1.422147
INFO: iteration 4, average log likelihood -1.422086
INFO: iteration 5, average log likelihood -1.422007
INFO: iteration 6, average log likelihood -1.421906
INFO: iteration 7, average log likelihood -1.421785
INFO: iteration 8, average log likelihood -1.421653
INFO: iteration 9, average log likelihood -1.421522
INFO: iteration 10, average log likelihood -1.421405
INFO: iteration 11, average log likelihood -1.421308
INFO: iteration 12, average log likelihood -1.421234
INFO: iteration 13, average log likelihood -1.421179
INFO: iteration 14, average log likelihood -1.421139
INFO: iteration 15, average log likelihood -1.421109
INFO: iteration 16, average log likelihood -1.421086
INFO: iteration 17, average log likelihood -1.421068
INFO: iteration 18, average log likelihood -1.421053
INFO: iteration 19, average log likelihood -1.421041
INFO: iteration 20, average log likelihood -1.421031
INFO: iteration 21, average log likelihood -1.421023
INFO: iteration 22, average log likelihood -1.421016
INFO: iteration 23, average log likelihood -1.421010
INFO: iteration 24, average log likelihood -1.421005
INFO: iteration 25, average log likelihood -1.421000
INFO: iteration 26, average log likelihood -1.420996
INFO: iteration 27, average log likelihood -1.420993
INFO: iteration 28, average log likelihood -1.420990
INFO: iteration 29, average log likelihood -1.420987
INFO: iteration 30, average log likelihood -1.420984
INFO: iteration 31, average log likelihood -1.420982
INFO: iteration 32, average log likelihood -1.420980
INFO: iteration 33, average log likelihood -1.420978
INFO: iteration 34, average log likelihood -1.420976
INFO: iteration 35, average log likelihood -1.420975
INFO: iteration 36, average log likelihood -1.420973
INFO: iteration 37, average log likelihood -1.420972
INFO: iteration 38, average log likelihood -1.420970
INFO: iteration 39, average log likelihood -1.420969
INFO: iteration 40, average log likelihood -1.420968
INFO: iteration 41, average log likelihood -1.420967
INFO: iteration 42, average log likelihood -1.420966
INFO: iteration 43, average log likelihood -1.420965
INFO: iteration 44, average log likelihood -1.420964
INFO: iteration 45, average log likelihood -1.420963
INFO: iteration 46, average log likelihood -1.420962
INFO: iteration 47, average log likelihood -1.420961
INFO: iteration 48, average log likelihood -1.420960
INFO: iteration 49, average log likelihood -1.420959
INFO: iteration 50, average log likelihood -1.420959
INFO: EM with 100000 data points 50 iterations avll -1.420959
473.9 data points per parameter
2: avll = [-1.4222545055481122,-1.4221967652050218,-1.422147360435793,-1.4220861560222142,-1.4220067445401177,-1.4219057450988284,-1.4217849755246945,-1.4216527476054657,-1.421521853096146,-1.4214045653343703,-1.4213081908071088,-1.4212339937481389,-1.4211790130911608,-1.421138668146228,-1.4211086437961349,-1.4210856819675939,-1.4210676055215,-1.4210530345168069,-1.4210410875901138,-1.4210311717720148,-1.4210228608259388,-1.4210158319209587,-1.4210098333958932,-1.4210046669508,-1.4210001760805973,-1.4209962373795164,-1.4209927535332212,-1.4209896476141683,-1.4209868585075311,-1.4209843373170625,-1.4209820445892902,-1.42097994819506,-1.4209780217229662,-1.4209762432626942,-1.4209745944811811,-1.4209730599170431,-1.4209716264373187,-1.420970282815167,-1.4209690193981765,-1.4209678278450644,-1.420966700914478,-1.4209656322939124,-1.4209646164598309,-1.420963648562336,-1.4209627243293488,-1.4209618399864519,-1.4209609921894257,-1.4209601779671572,-1.4209593946730898,-1.4209586399437635]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.420968
INFO: iteration 2, average log likelihood -1.420921
INFO: iteration 3, average log likelihood -1.420881
INFO: iteration 4, average log likelihood -1.420835
INFO: iteration 5, average log likelihood -1.420778
INFO: iteration 6, average log likelihood -1.420708
INFO: iteration 7, average log likelihood -1.420623
INFO: iteration 8, average log likelihood -1.420523
INFO: iteration 9, average log likelihood -1.420413
INFO: iteration 10, average log likelihood -1.420301
INFO: iteration 11, average log likelihood -1.420194
INFO: iteration 12, average log likelihood -1.420099
INFO: iteration 13, average log likelihood -1.420020
INFO: iteration 14, average log likelihood -1.419955
INFO: iteration 15, average log likelihood -1.419904
INFO: iteration 16, average log likelihood -1.419863
INFO: iteration 17, average log likelihood -1.419829
INFO: iteration 18, average log likelihood -1.419801
INFO: iteration 19, average log likelihood -1.419777
INFO: iteration 20, average log likelihood -1.419756
INFO: iteration 21, average log likelihood -1.419737
INFO: iteration 22, average log likelihood -1.419720
INFO: iteration 23, average log likelihood -1.419703
INFO: iteration 24, average log likelihood -1.419688
INFO: iteration 25, average log likelihood -1.419673
INFO: iteration 26, average log likelihood -1.419659
INFO: iteration 27, average log likelihood -1.419646
INFO: iteration 28, average log likelihood -1.419632
INFO: iteration 29, average log likelihood -1.419620
INFO: iteration 30, average log likelihood -1.419608
INFO: iteration 31, average log likelihood -1.419596
INFO: iteration 32, average log likelihood -1.419585
INFO: iteration 33, average log likelihood -1.419574
INFO: iteration 34, average log likelihood -1.419564
INFO: iteration 35, average log likelihood -1.419554
INFO: iteration 36, average log likelihood -1.419545
INFO: iteration 37, average log likelihood -1.419536
INFO: iteration 38, average log likelihood -1.419527
INFO: iteration 39, average log likelihood -1.419519
INFO: iteration 40, average log likelihood -1.419511
INFO: iteration 41, average log likelihood -1.419503
INFO: iteration 42, average log likelihood -1.419496
INFO: iteration 43, average log likelihood -1.419489
INFO: iteration 44, average log likelihood -1.419482
INFO: iteration 45, average log likelihood -1.419475
INFO: iteration 46, average log likelihood -1.419469
INFO: iteration 47, average log likelihood -1.419463
INFO: iteration 48, average log likelihood -1.419457
INFO: iteration 49, average log likelihood -1.419451
INFO: iteration 50, average log likelihood -1.419445
INFO: EM with 100000 data points 50 iterations avll -1.419445
236.4 data points per parameter
3: avll = [-1.4209678552845948,-1.420921040975005,-1.420880723132489,-1.4208347448800294,-1.4207784120873832,-1.4207083189039005,-1.420622840716492,-1.4205230644691047,-1.4204134024681592,-1.4203010834178604,-1.4201942377949879,-1.4200993736656704,-1.4200197095321976,-1.4199551946865903,-1.4199037323092267,-1.4198625421590785,-1.419829021822374,-1.419801075599052,-1.419777136245395,-1.419756074413455,-1.4197370926576822,-1.4197196358830206,-1.4197033229462759,-1.4196878963035164,-1.41967318550339,-1.419659080894446,-1.4196455147038087,-1.4196324473602278,-1.4196198575324719,-1.419607734827404,-1.4195960744438403,-1.41958487332101,-1.4195741274741105,-1.4195638302970324,-1.4195539716560144,-1.4195445376165188,-1.4195355106532566,-1.419526870199591,-1.4195185934028998,-1.4195106559687236,-1.4195030329979599,-1.4194956997457366,-1.4194886322553057,-1.4194818078428726,-1.4194752054282282,-1.419468805720459,-1.419462591277861,-1.4194565464668114,-1.419450657346462,-1.4194449115054861]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419449
INFO: iteration 2, average log likelihood -1.419392
INFO: iteration 3, average log likelihood -1.419339
INFO: iteration 4, average log likelihood -1.419281
INFO: iteration 5, average log likelihood -1.419210
INFO: iteration 6, average log likelihood -1.419125
INFO: iteration 7, average log likelihood -1.419026
INFO: iteration 8, average log likelihood -1.418915
INFO: iteration 9, average log likelihood -1.418796
INFO: iteration 10, average log likelihood -1.418677
INFO: iteration 11, average log likelihood -1.418560
INFO: iteration 12, average log likelihood -1.418450
INFO: iteration 13, average log likelihood -1.418349
INFO: iteration 14, average log likelihood -1.418259
INFO: iteration 15, average log likelihood -1.418180
INFO: iteration 16, average log likelihood -1.418112
INFO: iteration 17, average log likelihood -1.418053
INFO: iteration 18, average log likelihood -1.418003
INFO: iteration 19, average log likelihood -1.417960
INFO: iteration 20, average log likelihood -1.417922
INFO: iteration 21, average log likelihood -1.417889
INFO: iteration 22, average log likelihood -1.417859
INFO: iteration 23, average log likelihood -1.417831
INFO: iteration 24, average log likelihood -1.417806
INFO: iteration 25, average log likelihood -1.417783
INFO: iteration 26, average log likelihood -1.417762
INFO: iteration 27, average log likelihood -1.417741
INFO: iteration 28, average log likelihood -1.417722
INFO: iteration 29, average log likelihood -1.417703
INFO: iteration 30, average log likelihood -1.417686
INFO: iteration 31, average log likelihood -1.417669
INFO: iteration 32, average log likelihood -1.417653
INFO: iteration 33, average log likelihood -1.417637
INFO: iteration 34, average log likelihood -1.417622
INFO: iteration 35, average log likelihood -1.417607
INFO: iteration 36, average log likelihood -1.417594
INFO: iteration 37, average log likelihood -1.417580
INFO: iteration 38, average log likelihood -1.417567
INFO: iteration 39, average log likelihood -1.417555
INFO: iteration 40, average log likelihood -1.417543
INFO: iteration 41, average log likelihood -1.417531
INFO: iteration 42, average log likelihood -1.417520
INFO: iteration 43, average log likelihood -1.417510
INFO: iteration 44, average log likelihood -1.417500
INFO: iteration 45, average log likelihood -1.417490
INFO: iteration 46, average log likelihood -1.417481
INFO: iteration 47, average log likelihood -1.417472
INFO: iteration 48, average log likelihood -1.417463
INFO: iteration 49, average log likelihood -1.417455
INFO: iteration 50, average log likelihood -1.417447
INFO: EM with 100000 data points 50 iterations avll -1.417447
118.1 data points per parameter
4: avll = [-1.4194485355288178,-1.4193915530154635,-1.4193394508748527,-1.4192805140276077,-1.4192099312293955,-1.41912501738844,-1.4190256708910896,-1.4189145737588595,-1.4187964672786624,-1.4186767259931445,-1.4185601011152684,-1.418450192590989,-1.4183494599296482,-1.418259338511835,-1.4181803067145482,-1.4181119915193359,-1.4180533839186829,-1.4180031233964072,-1.4179597633121792,-1.4179219571898043,-1.4178885546168105,-1.417858626991388,-1.4178314518880228,-1.4178064796554124,-1.4177832968276725,-1.4177615933413326,-1.4177411358501146,-1.4177217471464714,-1.4177032908727973,-1.4176856605451267,-1.4176687719627288,-1.417652558155882,-1.4176369660980275,-1.4176219544952944,-1.4176074920848323,-1.4175935560284616,-1.4175801301694202,-1.4175672031029003,-1.4175547661627885,-1.4175428115169038,-1.4175313305758828,-1.4175203128648226,-1.4175097454112546,-1.4174996126059254,-1.417489896425067,-1.417480576877239,-1.4174716325492451,-1.4174630411582716,-1.4174547800545896,-1.4174468266498068]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417448
INFO: iteration 2, average log likelihood -1.417382
INFO: iteration 3, average log likelihood -1.417317
INFO: iteration 4, average log likelihood -1.417241
INFO: iteration 5, average log likelihood -1.417144
INFO: iteration 6, average log likelihood -1.417023
INFO: iteration 7, average log likelihood -1.416876
INFO: iteration 8, average log likelihood -1.416707
INFO: iteration 9, average log likelihood -1.416525
INFO: iteration 10, average log likelihood -1.416341
INFO: iteration 11, average log likelihood -1.416165
INFO: iteration 12, average log likelihood -1.416003
INFO: iteration 13, average log likelihood -1.415860
INFO: iteration 14, average log likelihood -1.415735
INFO: iteration 15, average log likelihood -1.415627
INFO: iteration 16, average log likelihood -1.415534
INFO: iteration 17, average log likelihood -1.415454
INFO: iteration 18, average log likelihood -1.415385
INFO: iteration 19, average log likelihood -1.415325
INFO: iteration 20, average log likelihood -1.415272
INFO: iteration 21, average log likelihood -1.415225
INFO: iteration 22, average log likelihood -1.415183
INFO: iteration 23, average log likelihood -1.415145
INFO: iteration 24, average log likelihood -1.415110
INFO: iteration 25, average log likelihood -1.415078
INFO: iteration 26, average log likelihood -1.415048
INFO: iteration 27, average log likelihood -1.415020
INFO: iteration 28, average log likelihood -1.414993
INFO: iteration 29, average log likelihood -1.414968
INFO: iteration 30, average log likelihood -1.414943
INFO: iteration 31, average log likelihood -1.414920
INFO: iteration 32, average log likelihood -1.414898
INFO: iteration 33, average log likelihood -1.414877
INFO: iteration 34, average log likelihood -1.414856
INFO: iteration 35, average log likelihood -1.414836
INFO: iteration 36, average log likelihood -1.414817
INFO: iteration 37, average log likelihood -1.414797
INFO: iteration 38, average log likelihood -1.414779
INFO: iteration 39, average log likelihood -1.414760
INFO: iteration 40, average log likelihood -1.414742
INFO: iteration 41, average log likelihood -1.414725
INFO: iteration 42, average log likelihood -1.414707
INFO: iteration 43, average log likelihood -1.414690
INFO: iteration 44, average log likelihood -1.414673
INFO: iteration 45, average log likelihood -1.414656
INFO: iteration 46, average log likelihood -1.414639
INFO: iteration 47, average log likelihood -1.414623
INFO: iteration 48, average log likelihood -1.414607
INFO: iteration 49, average log likelihood -1.414591
INFO: iteration 50, average log likelihood -1.414575
INFO: EM with 100000 data points 50 iterations avll -1.414575
59.0 data points per parameter
5: avll = [-1.4174475769992458,-1.4173817591887496,-1.4173172853884617,-1.417240701720283,-1.417144330820588,-1.4170231501348296,-1.4168760718406688,-1.4167071314266972,-1.416525087385284,-1.4163409753348366,-1.4161648177459536,-1.4160033850399565,-1.4158598355196739,-1.4157346016204875,-1.4156265135324966,-1.4155336400176206,-1.4154538013854943,-1.4153848610437336,-1.4153248815701907,-1.4152721936653654,-1.41522540923794,-1.4151834024739123,-1.415145276243814,-1.4151103246301513,-1.4150779968301233,-1.415047864180813,-1.415019591011813,-1.414992910316192,-1.4149676049563962,-1.4149434940960521,-1.4149204238271973,-1.4148982609003447,-1.4148768886865362,-1.4148562046967474,-1.4148361191050303,-1.4148165538233795,-1.4147974418017606,-1.4147787263725387,-1.4147603605806967,-1.4147423064912306,-1.4147245344430674,-1.4147070221914693,-1.4146897539192491,-1.4146727191920372,-1.414655912003198,-1.414639330039824,-1.4146229742152834,-1.4146068484073742,-1.4145909592605332,-1.4145753158885477]
[-1.4277030277680678,-1.427721496171006,-1.427657351792142,-1.4276024246206618,-1.4275342033103413,-1.4274503197863038,-1.4273538357409103,-1.427254062904194,-1.427163544834153,-1.4270920284478743,-1.4270422732319743,-1.4270109079622884,-1.4269922034326323,-1.4269810759340134,-1.4269741027387275,-1.42696931149432,-1.4269656568695148,-1.4269625931807273,-1.4269598041999203,-1.4269570338207305,-1.4269539433971201,-1.4269499141748285,-1.4269436740531374,-1.4269325225071186,-1.4269107024547079,-1.4268660542826228,-1.4267735423820123,-1.4265845635225678,-1.4262169527829083,-1.425574094005089,-1.4246517115508222,-1.4236726538591675,-1.4229459892392105,-1.4225508824558915,-1.422372943163836,-1.4222984512722623,-1.422267556346565,-1.4222544814682465,-1.4222486972485666,-1.4222459300168138,-1.4222444373497822,-1.4222435039699866,-1.422242833401347,-1.4222423006788076,-1.4222418514174449,-1.4222414604930693,-1.4222411150801544,-1.4222408076642832,-1.422240533146577,-1.422240287630017,-1.4222400678989509,-1.4222545055481122,-1.4221967652050218,-1.422147360435793,-1.4220861560222142,-1.4220067445401177,-1.4219057450988284,-1.4217849755246945,-1.4216527476054657,-1.421521853096146,-1.4214045653343703,-1.4213081908071088,-1.4212339937481389,-1.4211790130911608,-1.421138668146228,-1.4211086437961349,-1.4210856819675939,-1.4210676055215,-1.4210530345168069,-1.4210410875901138,-1.4210311717720148,-1.4210228608259388,-1.4210158319209587,-1.4210098333958932,-1.4210046669508,-1.4210001760805973,-1.4209962373795164,-1.4209927535332212,-1.4209896476141683,-1.4209868585075311,-1.4209843373170625,-1.4209820445892902,-1.42097994819506,-1.4209780217229662,-1.4209762432626942,-1.4209745944811811,-1.4209730599170431,-1.4209716264373187,-1.420970282815167,-1.4209690193981765,-1.4209678278450644,-1.420966700914478,-1.4209656322939124,-1.4209646164598309,-1.420963648562336,-1.4209627243293488,-1.4209618399864519,-1.4209609921894257,-1.4209601779671572,-1.4209593946730898,-1.4209586399437635,-1.4209678552845948,-1.420921040975005,-1.420880723132489,-1.4208347448800294,-1.4207784120873832,-1.4207083189039005,-1.420622840716492,-1.4205230644691047,-1.4204134024681592,-1.4203010834178604,-1.4201942377949879,-1.4200993736656704,-1.4200197095321976,-1.4199551946865903,-1.4199037323092267,-1.4198625421590785,-1.419829021822374,-1.419801075599052,-1.419777136245395,-1.419756074413455,-1.4197370926576822,-1.4197196358830206,-1.4197033229462759,-1.4196878963035164,-1.41967318550339,-1.419659080894446,-1.4196455147038087,-1.4196324473602278,-1.4196198575324719,-1.419607734827404,-1.4195960744438403,-1.41958487332101,-1.4195741274741105,-1.4195638302970324,-1.4195539716560144,-1.4195445376165188,-1.4195355106532566,-1.419526870199591,-1.4195185934028998,-1.4195106559687236,-1.4195030329979599,-1.4194956997457366,-1.4194886322553057,-1.4194818078428726,-1.4194752054282282,-1.419468805720459,-1.419462591277861,-1.4194565464668114,-1.419450657346462,-1.4194449115054861,-1.4194485355288178,-1.4193915530154635,-1.4193394508748527,-1.4192805140276077,-1.4192099312293955,-1.41912501738844,-1.4190256708910896,-1.4189145737588595,-1.4187964672786624,-1.4186767259931445,-1.4185601011152684,-1.418450192590989,-1.4183494599296482,-1.418259338511835,-1.4181803067145482,-1.4181119915193359,-1.4180533839186829,-1.4180031233964072,-1.4179597633121792,-1.4179219571898043,-1.4178885546168105,-1.417858626991388,-1.4178314518880228,-1.4178064796554124,-1.4177832968276725,-1.4177615933413326,-1.4177411358501146,-1.4177217471464714,-1.4177032908727973,-1.4176856605451267,-1.4176687719627288,-1.417652558155882,-1.4176369660980275,-1.4176219544952944,-1.4176074920848323,-1.4175935560284616,-1.4175801301694202,-1.4175672031029003,-1.4175547661627885,-1.4175428115169038,-1.4175313305758828,-1.4175203128648226,-1.4175097454112546,-1.4174996126059254,-1.417489896425067,-1.417480576877239,-1.4174716325492451,-1.4174630411582716,-1.4174547800545896,-1.4174468266498068,-1.4174475769992458,-1.4173817591887496,-1.4173172853884617,-1.417240701720283,-1.417144330820588,-1.4170231501348296,-1.4168760718406688,-1.4167071314266972,-1.416525087385284,-1.4163409753348366,-1.4161648177459536,-1.4160033850399565,-1.4158598355196739,-1.4157346016204875,-1.4156265135324966,-1.4155336400176206,-1.4154538013854943,-1.4153848610437336,-1.4153248815701907,-1.4152721936653654,-1.41522540923794,-1.4151834024739123,-1.415145276243814,-1.4151103246301513,-1.4150779968301233,-1.415047864180813,-1.415019591011813,-1.414992910316192,-1.4149676049563962,-1.4149434940960521,-1.4149204238271973,-1.4148982609003447,-1.4148768886865362,-1.4148562046967474,-1.4148361191050303,-1.4148165538233795,-1.4147974418017606,-1.4147787263725387,-1.4147603605806967,-1.4147423064912306,-1.4147245344430674,-1.4147070221914693,-1.4146897539192491,-1.4146727191920372,-1.414655912003198,-1.414639330039824,-1.4146229742152834,-1.4146068484073742,-1.4145909592605332,-1.4145753158885477]
32x26 Array{Float64,2}:
  0.71228     0.277426    0.150894    0.0381293  â€¦  -0.375194    -0.349351 
 -0.15704    -0.029967    0.687661   -0.632711      -0.341044    -0.286425 
  0.26433     0.0753316  -0.674634   -0.378795       0.401559     0.116936 
 -0.0766575  -0.175098   -0.767268    0.541295       0.0457491    0.14793  
 -0.311909   -0.339267   -0.0585304  -0.0475676     -0.54804      0.117924 
 -0.0241279   0.0404168  -0.225342    0.648299   â€¦  -0.23997     -0.505181 
  0.0250921   0.243134    0.066649    0.610566       0.300931     0.0168064
  0.482765    0.259618   -0.0553235   0.309788       0.492032    -0.140867 
 -0.518839   -0.297248   -0.184862   -0.139085       0.236172     0.348387 
  0.463623   -0.0475348   0.268251    0.32195       -0.00966989   0.314132 
  â‹®                                              â‹±                â‹®        
 -0.426509    0.466215   -0.397011   -0.645857       0.204952    -0.279756 
  0.118572    0.748471    0.0976108   0.923014       0.154398     0.136995 
  0.389438   -0.0315273   0.0947622   0.223692   â€¦   0.204962     0.0880184
  0.582437    0.0627776  -0.374329    0.293145       0.400958     0.219857 
  0.0531758   0.483972   -0.169707   -0.0611682      0.294043     0.195147 
  0.0932085   0.114361    0.357625   -0.187787       0.370163    -0.195641 
  0.274508   -0.8384      0.594686    0.444564      -0.573617    -0.503531 
  0.0899068   0.376865   -0.140201   -0.31752    â€¦  -0.0524413   -0.599509 
  0.361712    0.524804    0.408742   -0.16468        0.374038     0.228255 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414560
INFO: iteration 2, average log likelihood -1.414545
INFO: iteration 3, average log likelihood -1.414530
INFO: iteration 4, average log likelihood -1.414515
INFO: iteration 5, average log likelihood -1.414501
INFO: iteration 6, average log likelihood -1.414487
INFO: iteration 7, average log likelihood -1.414474
INFO: iteration 8, average log likelihood -1.414460
INFO: iteration 9, average log likelihood -1.414447
INFO: iteration 10, average log likelihood -1.414435
INFO: EM with 100000 data points 10 iterations avll -1.414435
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.512352e+05
      1       7.135473e+05      -2.376879e+05 |       32
      2       6.988005e+05      -1.474684e+04 |       32
      3       6.936408e+05      -5.159654e+03 |       32
      4       6.910946e+05      -2.546189e+03 |       32
      5       6.895171e+05      -1.577518e+03 |       32
      6       6.884059e+05      -1.111234e+03 |       32
      7       6.875319e+05      -8.739915e+02 |       32
      8       6.867459e+05      -7.860219e+02 |       32
      9       6.860507e+05      -6.951522e+02 |       32
     10       6.854329e+05      -6.177626e+02 |       32
     11       6.848921e+05      -5.408385e+02 |       32
     12       6.843954e+05      -4.966821e+02 |       32
     13       6.839271e+05      -4.683497e+02 |       32
     14       6.834970e+05      -4.300315e+02 |       32
     15       6.831258e+05      -3.712530e+02 |       32
     16       6.828254e+05      -3.003474e+02 |       32
     17       6.825499e+05      -2.755895e+02 |       32
     18       6.822866e+05      -2.632759e+02 |       32
     19       6.820499e+05      -2.366965e+02 |       32
     20       6.818546e+05      -1.953063e+02 |       32
     21       6.816696e+05      -1.849645e+02 |       32
     22       6.815038e+05      -1.658225e+02 |       32
     23       6.813403e+05      -1.634431e+02 |       32
     24       6.811747e+05      -1.656792e+02 |       32
     25       6.810247e+05      -1.499272e+02 |       32
     26       6.808818e+05      -1.429032e+02 |       32
     27       6.807363e+05      -1.455640e+02 |       32
     28       6.806027e+05      -1.335460e+02 |       32
     29       6.804828e+05      -1.199538e+02 |       32
     30       6.803605e+05      -1.222920e+02 |       32
     31       6.802503e+05      -1.102023e+02 |       32
     32       6.801645e+05      -8.573821e+01 |       32
     33       6.800895e+05      -7.507150e+01 |       32
     34       6.800232e+05      -6.630628e+01 |       32
     35       6.799677e+05      -5.544587e+01 |       32
     36       6.799157e+05      -5.204634e+01 |       32
     37       6.798681e+05      -4.760851e+01 |       32
     38       6.798181e+05      -4.997800e+01 |       32
     39       6.797701e+05      -4.802854e+01 |       32
     40       6.797318e+05      -3.823222e+01 |       32
     41       6.796917e+05      -4.012104e+01 |       32
     42       6.796499e+05      -4.177380e+01 |       32
     43       6.796064e+05      -4.351650e+01 |       32
     44       6.795631e+05      -4.336200e+01 |       32
     45       6.795223e+05      -4.073734e+01 |       32
     46       6.794892e+05      -3.315485e+01 |       32
     47       6.794564e+05      -3.271384e+01 |       32
     48       6.794244e+05      -3.201998e+01 |       32
     49       6.793923e+05      -3.213055e+01 |       32
     50       6.793626e+05      -2.969348e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679362.6027670379)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.426082
INFO: iteration 2, average log likelihood -1.421081
INFO: iteration 3, average log likelihood -1.419739
INFO: iteration 4, average log likelihood -1.418754
INFO: iteration 5, average log likelihood -1.417735
INFO: iteration 6, average log likelihood -1.416796
INFO: iteration 7, average log likelihood -1.416137
INFO: iteration 8, average log likelihood -1.415762
INFO: iteration 9, average log likelihood -1.415557
INFO: iteration 10, average log likelihood -1.415433
INFO: iteration 11, average log likelihood -1.415347
INFO: iteration 12, average log likelihood -1.415281
INFO: iteration 13, average log likelihood -1.415228
INFO: iteration 14, average log likelihood -1.415184
INFO: iteration 15, average log likelihood -1.415146
INFO: iteration 16, average log likelihood -1.415112
INFO: iteration 17, average log likelihood -1.415082
INFO: iteration 18, average log likelihood -1.415055
INFO: iteration 19, average log likelihood -1.415030
INFO: iteration 20, average log likelihood -1.415007
INFO: iteration 21, average log likelihood -1.414985
INFO: iteration 22, average log likelihood -1.414966
INFO: iteration 23, average log likelihood -1.414947
INFO: iteration 24, average log likelihood -1.414929
INFO: iteration 25, average log likelihood -1.414913
INFO: iteration 26, average log likelihood -1.414897
INFO: iteration 27, average log likelihood -1.414882
INFO: iteration 28, average log likelihood -1.414867
INFO: iteration 29, average log likelihood -1.414853
INFO: iteration 30, average log likelihood -1.414840
INFO: iteration 31, average log likelihood -1.414827
INFO: iteration 32, average log likelihood -1.414814
INFO: iteration 33, average log likelihood -1.414802
INFO: iteration 34, average log likelihood -1.414790
INFO: iteration 35, average log likelihood -1.414779
INFO: iteration 36, average log likelihood -1.414768
INFO: iteration 37, average log likelihood -1.414757
INFO: iteration 38, average log likelihood -1.414747
INFO: iteration 39, average log likelihood -1.414736
INFO: iteration 40, average log likelihood -1.414726
INFO: iteration 41, average log likelihood -1.414716
INFO: iteration 42, average log likelihood -1.414707
INFO: iteration 43, average log likelihood -1.414697
INFO: iteration 44, average log likelihood -1.414688
INFO: iteration 45, average log likelihood -1.414679
INFO: iteration 46, average log likelihood -1.414670
INFO: iteration 47, average log likelihood -1.414661
INFO: iteration 48, average log likelihood -1.414652
INFO: iteration 49, average log likelihood -1.414643
INFO: iteration 50, average log likelihood -1.414635
INFO: EM with 100000 data points 50 iterations avll -1.414635
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.408577    -0.296008    0.331134    â€¦  -0.769733   -0.34077    -0.285401  
 -0.226472    -0.0422547  -0.186718       -0.328618   -0.558531    0.217306  
 -0.857231    -0.278794   -0.143192       -0.717349    0.523877    0.785501  
 -0.328574    -0.0691707   0.771658        0.169482   -0.413055    0.0326247 
  0.0048377    0.0509505  -0.24857        -0.51207    -0.246993   -0.669557  
 -0.170949     0.216458   -0.567374    â€¦  -0.312062   -0.0344812  -0.00960919
 -0.149556    -0.0662712  -0.00514387     -0.0602674  -0.0410879  -0.140686  
 -0.00265753   0.310699   -0.0417742      -0.608727    0.527279   -0.268372  
  0.382749     0.310711   -0.548312        0.405852    0.644387    0.00934929
  0.402439     0.49034    -0.092063       -0.114142    0.455012   -0.233092  
  â‹®                                    â‹±                           â‹®         
  0.303074     0.247153    0.117842        0.259377    0.186963    0.173591  
 -0.390661    -0.360571   -0.246067       -0.246748   -0.336106   -0.00728158
  0.256249     0.134334    0.111186    â€¦   0.396675   -0.357625   -0.327169  
 -0.466765    -0.748734   -0.276091        0.189361   -0.427947   -0.0266328 
  1.25717     -0.26126     0.3535          0.127223   -0.61741    -0.401161  
 -0.329712     0.344755   -0.293941        0.528646    0.448416    0.416922  
 -0.0853604    0.132382   -0.0636232      -0.129618   -0.0647677  -0.38745   
  0.564168     0.411243   -0.129923    â€¦   0.654867    0.630487    0.0498736 
 -0.510698     0.458853   -0.201469        0.0659282  -0.137426    0.454649  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414626
INFO: iteration 2, average log likelihood -1.414617
INFO: iteration 3, average log likelihood -1.414609
INFO: iteration 4, average log likelihood -1.414600
INFO: iteration 5, average log likelihood -1.414591
INFO: iteration 6, average log likelihood -1.414583
INFO: iteration 7, average log likelihood -1.414574
INFO: iteration 8, average log likelihood -1.414565
INFO: iteration 9, average log likelihood -1.414557
INFO: iteration 10, average log likelihood -1.414548
INFO: EM with 100000 data points 10 iterations avll -1.414548
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
