>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.6.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.5
INFO: Installing JLD v0.6.3
INFO: Installing LegacyStrings v0.1.1
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.2
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StatsBase v0.9.0
INFO: Installing StatsFuns v0.3.0
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.6
Commit 2e358ce (2016-06-19 17:16 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-95-generic #142-Ubuntu SMP Fri Aug 12 17:00:09 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (649.41015625 MB free)
Uptime: 22130.0 sec
Load Avg:  0.95654296875  0.953125  0.99169921875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1021969 s       3880 s     103756 s     792444 s         40 s
#2  3500 MHz     620036 s       1783 s      92929 s    1379781 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.0
18 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.6.0
 - Compat                        0.8.8
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.5
 - JLD                           0.6.3
 - LegacyStrings                 0.1.1
 - PDMats                        0.4.2
 - Rmath                         0.1.2
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StatsBase                     0.9.0
 - StatsFuns                     0.3.0
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Recompiling stale cache file /home/vagrant/.julia/lib/v0.4/GaussianMixtures.ji for module GaussianMixtures.
INFO: Testing Data
(100000,-2.0337752337175007e6,[95809.319976434,4190.680023565995],
[-2714.9149789578396 -294.75049846111517 2039.2658359459979
 2895.527427418194 294.6201923754785 -2264.992446505906],

[
[97481.94530461296 717.3531394589874 1209.1327425037657
 717.3531394589874 96260.44247809853 441.2104048141641
 1209.1327425037657 441.21040481416406 96357.51554890264],

[2285.1474935483275 -790.3914417710353 -1608.8391731205827
 -790.3914417710353 3688.8892589191346 -309.9901175319998
 -1608.8391731205827 -309.9901175319998 4038.6772776273865]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.301435e+03
      1       1.160410e+03      -1.410256e+02 |        7
      2       1.052348e+03      -1.080616e+02 |        4
      3       9.907778e+02      -6.157024e+01 |        0
      4       9.907778e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 990.777804563797)
INFO: K-means with 272 data points using 4 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.062576
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.726723
INFO: iteration 2, lowerbound -3.592857
INFO: iteration 3, lowerbound -3.467956
INFO: iteration 4, lowerbound -3.344582
INFO: dropping number of Gaussions to 7
INFO: iteration 5, lowerbound -3.228682
INFO: iteration 6, lowerbound -3.132510
INFO: dropping number of Gaussions to 6
INFO: iteration 7, lowerbound -3.059264
INFO: iteration 8, lowerbound -3.002352
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.952338
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.891856
INFO: iteration 11, lowerbound -2.834952
INFO: iteration 12, lowerbound -2.791613
INFO: iteration 13, lowerbound -2.763375
INFO: iteration 14, lowerbound -2.748547
INFO: dropping number of Gaussions to 3
INFO: iteration 15, lowerbound -2.724339
INFO: iteration 16, lowerbound -2.695871
INFO: iteration 17, lowerbound -2.664776
INFO: iteration 18, lowerbound -2.627772
INFO: iteration 19, lowerbound -2.586154
INFO: iteration 20, lowerbound -2.542113
INFO: iteration 21, lowerbound -2.498320
INFO: iteration 22, lowerbound -2.457083
INFO: iteration 23, lowerbound -2.419507
INFO: iteration 24, lowerbound -2.385387
INFO: iteration 25, lowerbound -2.354357
INFO: iteration 26, lowerbound -2.328055
INFO: iteration 27, lowerbound -2.311182
INFO: iteration 28, lowerbound -2.307870
INFO: dropping number of Gaussions to 2
INFO: iteration 29, lowerbound -2.302916
INFO: iteration 30, lowerbound -2.299259
INFO: iteration 31, lowerbound -2.299256
INFO: iteration 32, lowerbound -2.299254
INFO: iteration 33, lowerbound -2.299254
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Fri 02 Sep 2016 10:31:19 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Fri 02 Sep 2016 10:31:20 AM UTC: K-means with 272 data points using 4 iterations
11.3 data points per parameter
,Fri 02 Sep 2016 10:31:21 AM UTC: EM with 272 data points 0 iterations avll -2.062576
5.8 data points per parameter
,Fri 02 Sep 2016 10:31:22 AM UTC: GMM converted to Variational GMM
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 1, lowerbound -3.726723
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 2, lowerbound -3.592857
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 3, lowerbound -3.467956
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 4, lowerbound -3.344582
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 7
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 5, lowerbound -3.228682
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 6, lowerbound -3.132510
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 6
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 7, lowerbound -3.059264
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 8, lowerbound -3.002352
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 5
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 9, lowerbound -2.952338
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 4
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 10, lowerbound -2.891856
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 11, lowerbound -2.834952
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 12, lowerbound -2.791613
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 13, lowerbound -2.763375
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 14, lowerbound -2.748547
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 3
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 15, lowerbound -2.724339
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 16, lowerbound -2.695871
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 17, lowerbound -2.664776
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 18, lowerbound -2.627772
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 19, lowerbound -2.586154
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 20, lowerbound -2.542113
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 21, lowerbound -2.498320
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 22, lowerbound -2.457083
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 23, lowerbound -2.419507
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 24, lowerbound -2.385387
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 25, lowerbound -2.354357
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 26, lowerbound -2.328055
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 27, lowerbound -2.311182
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 28, lowerbound -2.307870
,Fri 02 Sep 2016 10:31:24 AM UTC: dropping number of Gaussions to 2
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 29, lowerbound -2.302916
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 30, lowerbound -2.299259
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 31, lowerbound -2.299256
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 32, lowerbound -2.299254
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 33, lowerbound -2.299254
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 34, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 35, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 36, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 37, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 38, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 39, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 40, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 41, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 42, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 43, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 44, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 45, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 46, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 47, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 48, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 49, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: iteration 50, lowerbound -2.299253
,Fri 02 Sep 2016 10:31:24 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [95.95490777329718,178.04509222670282]
Î² = [95.95490777329718,178.04509222670282]
m = [2.0002292577695817 53.85198717243115
 4.250300733264323 79.28686694427967]
Î½ = [97.95490777329718,180.04509222670282]
W = [
[0.3758763612044552 -0.00895312382746036
 0.0 0.01274866477743878],

[0.1840415554740795 -0.007644049042400808
 0.0 0.008581705166230212]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.00340903164006
avll from llpg:  -1.0034090316400583
avll direct:     -1.0034090316400586
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9611143639444527
avll from llpg:  -0.9611143639444527
avll direct:     -0.9611143639444528
sum posterior: 100000.0
32x26 Array{Float64,2}:
  0.0264486   0.0938266   0.133973     â€¦  -0.207301     0.140723  
 -0.0202404   0.147465    0.000152201      0.157151    -0.0135607 
 -0.0754808  -0.0364924  -0.261865        -0.0339775    0.147048  
  0.0174099  -0.147694   -0.105352        -0.0160375    0.108168  
  0.184077   -0.251773   -0.0266615       -0.0110621   -0.0970944 
  0.122624   -0.10417     0.0907725    â€¦   0.00612357   0.185521  
  0.0278139  -0.119429    0.15801          0.0570736    0.00723752
 -0.286055    0.0781972  -0.0469257        0.317887    -0.0564834 
  0.0671087   0.09638     0.0112856       -0.0291818    0.161613  
  0.143904   -0.0923314   0.0422349       -0.0602572    0.0101439 
  â‹®                                    â‹±                â‹®         
 -0.189621   -0.0791103  -0.0323448        0.0922252    0.0283489 
  0.0315252  -0.0311602   0.0801841       -0.0603961   -0.0539617 
 -0.125626   -0.127164    0.00653384   â€¦  -0.124724    -0.10015   
 -0.0663423  -0.0221496   0.0851512        0.0910829   -0.00681128
 -0.122082   -0.0504961   0.0220338        0.0606036   -0.173648  
  0.119799   -0.0599066   0.0413124       -0.0425484   -0.0380077 
  0.0275169  -0.0192978   0.0259379        0.124872    -0.135954  
  0.131195    0.0672339  -0.122245     â€¦   0.143245     0.156386  
 -0.0680758  -0.205736    0.138524         0.0597889    0.19034   kind diag, method split
0: avll = -1.4117983039982522
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411894
INFO: iteration 2, average log likelihood -1.411785
INFO: iteration 3, average log likelihood -1.410625
INFO: iteration 4, average log likelihood -1.400140
INFO: iteration 5, average log likelihood -1.384048
INFO: iteration 6, average log likelihood -1.379250
INFO: iteration 7, average log likelihood -1.378112
INFO: iteration 8, average log likelihood -1.377561
INFO: iteration 9, average log likelihood -1.377227
INFO: iteration 10, average log likelihood -1.376990
INFO: iteration 11, average log likelihood -1.376803
INFO: iteration 12, average log likelihood -1.376645
INFO: iteration 13, average log likelihood -1.376508
INFO: iteration 14, average log likelihood -1.376381
INFO: iteration 15, average log likelihood -1.376258
INFO: iteration 16, average log likelihood -1.376134
INFO: iteration 17, average log likelihood -1.375997
INFO: iteration 18, average log likelihood -1.375816
INFO: iteration 19, average log likelihood -1.375526
INFO: iteration 20, average log likelihood -1.375133
INFO: iteration 21, average log likelihood -1.374842
INFO: iteration 22, average log likelihood -1.374668
INFO: iteration 23, average log likelihood -1.374557
INFO: iteration 24, average log likelihood -1.374476
INFO: iteration 25, average log likelihood -1.374410
INFO: iteration 26, average log likelihood -1.374345
INFO: iteration 27, average log likelihood -1.374265
INFO: iteration 28, average log likelihood -1.374157
INFO: iteration 29, average log likelihood -1.374046
INFO: iteration 30, average log likelihood -1.373965
INFO: iteration 31, average log likelihood -1.373913
INFO: iteration 32, average log likelihood -1.373880
INFO: iteration 33, average log likelihood -1.373857
INFO: iteration 34, average log likelihood -1.373840
INFO: iteration 35, average log likelihood -1.373826
INFO: iteration 36, average log likelihood -1.373815
INFO: iteration 37, average log likelihood -1.373807
INFO: iteration 38, average log likelihood -1.373801
INFO: iteration 39, average log likelihood -1.373797
INFO: iteration 40, average log likelihood -1.373794
INFO: iteration 41, average log likelihood -1.373792
INFO: iteration 42, average log likelihood -1.373791
INFO: iteration 43, average log likelihood -1.373790
INFO: iteration 44, average log likelihood -1.373790
INFO: iteration 45, average log likelihood -1.373789
INFO: iteration 46, average log likelihood -1.373789
INFO: iteration 47, average log likelihood -1.373789
INFO: iteration 48, average log likelihood -1.373789
INFO: iteration 49, average log likelihood -1.373789
INFO: iteration 50, average log likelihood -1.373788
INFO: EM with 100000 data points 50 iterations avll -1.373788
952.4 data points per parameter
1: avll = [-1.4118944348863949,-1.4117851862670183,-1.4106245837963742,-1.4001396967616633,-1.3840476672847561,-1.3792498301189582,-1.3781120224180363,-1.377561317659943,-1.3772271511115972,-1.376990240194081,-1.3768027693922973,-1.376645428132347,-1.3765076912158158,-1.3763807770829555,-1.3762577383461598,-1.3761336892723468,-1.375996930727081,-1.3758163847029363,-1.3755256417428356,-1.3751333867262032,-1.3748424418486138,-1.3746680335384704,-1.3745566418735762,-1.3744760674443168,-1.3744099145685773,-1.3743453041621334,-1.3742650515122308,-1.374156837060881,-1.3740458701698046,-1.3739645018751852,-1.3739134522395537,-1.373880046285441,-1.3738568248903842,-1.3738395399178356,-1.3738258497670446,-1.373815137654436,-1.373807081832396,-1.37380119190959,-1.373797014068972,-1.3737941413611294,-1.3737922123564188,-1.373790934253063,-1.3737900912559673,-1.373789533368881,-1.3737891600684595,-1.3737889058040726,-1.3737887286586383,-1.3737886021077053,-1.3737885093891484,-1.3737884398357294]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.373938
INFO: iteration 2, average log likelihood -1.373796
INFO: iteration 3, average log likelihood -1.373022
INFO: iteration 4, average log likelihood -1.365741
INFO: iteration 5, average log likelihood -1.347734
INFO: iteration 6, average log likelihood -1.337994
INFO: iteration 7, average log likelihood -1.334861
INFO: iteration 8, average log likelihood -1.332626
INFO: iteration 9, average log likelihood -1.330795
INFO: iteration 10, average log likelihood -1.329304
INFO: iteration 11, average log likelihood -1.328030
INFO: iteration 12, average log likelihood -1.327050
INFO: iteration 13, average log likelihood -1.326360
INFO: iteration 14, average log likelihood -1.325856
INFO: iteration 15, average log likelihood -1.325469
INFO: iteration 16, average log likelihood -1.325162
INFO: iteration 17, average log likelihood -1.324915
INFO: iteration 18, average log likelihood -1.324713
INFO: iteration 19, average log likelihood -1.324531
INFO: iteration 20, average log likelihood -1.324354
INFO: iteration 21, average log likelihood -1.324179
INFO: iteration 22, average log likelihood -1.324000
INFO: iteration 23, average log likelihood -1.323804
INFO: iteration 24, average log likelihood -1.323594
INFO: iteration 25, average log likelihood -1.323385
INFO: iteration 26, average log likelihood -1.323188
INFO: iteration 27, average log likelihood -1.323021
INFO: iteration 28, average log likelihood -1.322892
INFO: iteration 29, average log likelihood -1.322793
INFO: iteration 30, average log likelihood -1.322709
INFO: iteration 31, average log likelihood -1.322628
INFO: iteration 32, average log likelihood -1.322532
INFO: iteration 33, average log likelihood -1.322394
INFO: iteration 34, average log likelihood -1.322166
INFO: iteration 35, average log likelihood -1.321846
INFO: iteration 36, average log likelihood -1.321500
INFO: iteration 37, average log likelihood -1.321172
INFO: iteration 38, average log likelihood -1.320886
INFO: iteration 39, average log likelihood -1.320641
INFO: iteration 40, average log likelihood -1.320433
INFO: iteration 41, average log likelihood -1.320259
INFO: iteration 42, average log likelihood -1.320109
INFO: iteration 43, average log likelihood -1.319981
INFO: iteration 44, average log likelihood -1.319867
INFO: iteration 45, average log likelihood -1.319754
INFO: iteration 46, average log likelihood -1.319637
INFO: iteration 47, average log likelihood -1.319511
INFO: iteration 48, average log likelihood -1.319372
INFO: iteration 49, average log likelihood -1.319216
INFO: iteration 50, average log likelihood -1.319043
INFO: EM with 100000 data points 50 iterations avll -1.319043
473.9 data points per parameter
2: avll = [-1.373937662253593,-1.3737957820477575,-1.3730224029092941,-1.3657411596969027,-1.3477342079806187,-1.3379937976920995,-1.3348606416340165,-1.3326264912862082,-1.3307945005312751,-1.3293038399921489,-1.3280295516801914,-1.3270497145148867,-1.3263603182581647,-1.3258556704061848,-1.3254686504840947,-1.3251615255219833,-1.3249151300308721,-1.3247125108338613,-1.324531007303846,-1.324354318500356,-1.3241793565495437,-1.32399992150314,-1.3238035658769582,-1.3235936632545007,-1.3233846437448213,-1.3231878295159711,-1.3230207790326438,-1.3228918490717396,-1.3227928555651267,-1.3227094507832873,-1.32262794131559,-1.3225324613161236,-1.3223938015312753,-1.3221662952049449,-1.3218458746994513,-1.3215002379237797,-1.3211720683169454,-1.320885502585967,-1.3206412983732652,-1.320433443798884,-1.3202586102686715,-1.320108855402823,-1.319981397487782,-1.3198666517187023,-1.3197543061108674,-1.3196367450969912,-1.3195111757976932,-1.3193719168299076,-1.319216294590131,-1.3190428249402009]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.319028
INFO: iteration 2, average log likelihood -1.318615
INFO: iteration 3, average log likelihood -1.317247
INFO: iteration 4, average log likelihood -1.306512
INFO: iteration 5, average log likelihood -1.283372
INFO: iteration 6, average log likelihood -1.269183
INFO: iteration 7, average log likelihood -1.263772
INFO: iteration 8, average log likelihood -1.261366
INFO: iteration 9, average log likelihood -1.259836
INFO: iteration 10, average log likelihood -1.258503
INFO: iteration 11, average log likelihood -1.257096
INFO: iteration 12, average log likelihood -1.255585
INFO: iteration 13, average log likelihood -1.254195
INFO: iteration 14, average log likelihood -1.253202
INFO: iteration 15, average log likelihood -1.252590
INFO: iteration 16, average log likelihood -1.252252
INFO: iteration 17, average log likelihood -1.252067
INFO: iteration 18, average log likelihood -1.251957
INFO: iteration 19, average log likelihood -1.251879
INFO: iteration 20, average log likelihood -1.251815
INFO: iteration 21, average log likelihood -1.251754
INFO: iteration 22, average log likelihood -1.251685
INFO: iteration 23, average log likelihood -1.251600
INFO: iteration 24, average log likelihood -1.251489
INFO: iteration 25, average log likelihood -1.251331
INFO: iteration 26, average log likelihood -1.251085
INFO: iteration 27, average log likelihood -1.250683
INFO: iteration 28, average log likelihood -1.250064
INFO: iteration 29, average log likelihood -1.249387
INFO: iteration 30, average log likelihood -1.248989
INFO: iteration 31, average log likelihood -1.248881
INFO: iteration 32, average log likelihood -1.248857
INFO: iteration 33, average log likelihood -1.248851
INFO: iteration 34, average log likelihood -1.248848
INFO: iteration 35, average log likelihood -1.248847
INFO: iteration 36, average log likelihood -1.248846
INFO: iteration 37, average log likelihood -1.248846
INFO: iteration 38, average log likelihood -1.248846
INFO: iteration 39, average log likelihood -1.248846
INFO: iteration 40, average log likelihood -1.248846
INFO: iteration 41, average log likelihood -1.248845
INFO: iteration 42, average log likelihood -1.248845
INFO: iteration 43, average log likelihood -1.248845
INFO: iteration 44, average log likelihood -1.248845
INFO: iteration 45, average log likelihood -1.248845
INFO: iteration 46, average log likelihood -1.248845
INFO: iteration 47, average log likelihood -1.248845
INFO: iteration 48, average log likelihood -1.248845
INFO: iteration 49, average log likelihood -1.248845
INFO: iteration 50, average log likelihood -1.248845
INFO: EM with 100000 data points 50 iterations avll -1.248845
236.4 data points per parameter
3: avll = [-1.3190276207716043,-1.3186150026920396,-1.3172468234069936,-1.3065116633575686,-1.2833717087220982,-1.2691827838729057,-1.263772305127574,-1.2613657683557424,-1.2598357434111571,-1.2585027236905946,-1.2570959801249626,-1.255585240838979,-1.254194889180014,-1.2532019071027183,-1.2525899643144562,-1.2522520360787646,-1.2520673404817717,-1.251956936376191,-1.251879081133053,-1.2518153386952262,-1.251753929463912,-1.2516845957353488,-1.2515996738627069,-1.2514891219925788,-1.2513308874231022,-1.251085036353483,-1.250682718838966,-1.2500641349415371,-1.249387109703213,-1.2489894634238423,-1.2488807302544294,-1.2488572642672262,-1.2488506663417802,-1.2488481744803221,-1.248847019031731,-1.248846403884315,-1.248846042502527,-1.2488458144902774,-1.2488456631554319,-1.248845559173764,-1.2488454860771874,-1.2488454339355406,-1.2488453964019037,-1.2488453692349422,-1.2488453495085163,-1.2488453351596676,-1.2488453247133937,-1.248845317105778,-1.248845311565368,-1.248845307531095]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.249085
INFO: iteration 2, average log likelihood -1.248754
INFO: iteration 3, average log likelihood -1.246499
INFO: iteration 4, average log likelihood -1.231550
INFO: iteration 5, average log likelihood -1.204352
INFO: iteration 6, average log likelihood -1.167950
WARNING: Variances had to be floored 3
INFO: iteration 7, average log likelihood -1.140193
WARNING: Variances had to be floored 16
INFO: iteration 8, average log likelihood -1.144913
INFO: iteration 9, average log likelihood -1.149340
INFO: iteration 10, average log likelihood -1.137329
WARNING: Variances had to be floored 3 16
INFO: iteration 11, average log likelihood -1.129535
INFO: iteration 12, average log likelihood -1.147795
INFO: iteration 13, average log likelihood -1.130252
WARNING: Variances had to be floored 13 16
INFO: iteration 14, average log likelihood -1.123804
WARNING: Variances had to be floored 3
INFO: iteration 15, average log likelihood -1.153224
INFO: iteration 16, average log likelihood -1.148116
WARNING: Variances had to be floored 16
INFO: iteration 17, average log likelihood -1.136913
INFO: iteration 18, average log likelihood -1.145279
WARNING: Variances had to be floored 3
INFO: iteration 19, average log likelihood -1.133469
WARNING: Variances had to be floored 16
INFO: iteration 20, average log likelihood -1.138310
INFO: iteration 21, average log likelihood -1.140812
INFO: iteration 22, average log likelihood -1.127276
WARNING: Variances had to be floored 3 13 16
INFO: iteration 23, average log likelihood -1.121270
INFO: iteration 24, average log likelihood -1.163307
INFO: iteration 25, average log likelihood -1.142637
WARNING: Variances had to be floored 16
INFO: iteration 26, average log likelihood -1.134780
WARNING: Variances had to be floored 3
INFO: iteration 27, average log likelihood -1.142819
INFO: iteration 28, average log likelihood -1.143515
WARNING: Variances had to be floored 16
INFO: iteration 29, average log likelihood -1.132651
INFO: iteration 30, average log likelihood -1.138644
WARNING: Variances had to be floored 3
INFO: iteration 31, average log likelihood -1.124823
WARNING: Variances had to be floored 13 16
INFO: iteration 32, average log likelihood -1.131328
INFO: iteration 33, average log likelihood -1.157645
INFO: iteration 34, average log likelihood -1.140476
WARNING: Variances had to be floored 3 16
INFO: iteration 35, average log likelihood -1.132369
INFO: iteration 36, average log likelihood -1.153049
INFO: iteration 37, average log likelihood -1.138043
WARNING: Variances had to be floored 16
INFO: iteration 38, average log likelihood -1.130666
WARNING: Variances had to be floored 3
INFO: iteration 39, average log likelihood -1.136424
INFO: iteration 40, average log likelihood -1.134970
WARNING: Variances had to be floored 13 16
INFO: iteration 41, average log likelihood -1.125713
INFO: iteration 42, average log likelihood -1.155526
WARNING: Variances had to be floored 3
INFO: iteration 43, average log likelihood -1.138045
WARNING: Variances had to be floored 16
INFO: iteration 44, average log likelihood -1.142519
INFO: iteration 45, average log likelihood -1.147467
INFO: iteration 46, average log likelihood -1.135918
WARNING: Variances had to be floored 3 16
INFO: iteration 47, average log likelihood -1.128251
INFO: iteration 48, average log likelihood -1.146420
INFO: iteration 49, average log likelihood -1.129371
WARNING: Variances had to be floored 13 16
INFO: iteration 50, average log likelihood -1.123590
INFO: EM with 100000 data points 50 iterations avll -1.123590
118.1 data points per parameter
4: avll = [-1.249084838698553,-1.2487535291697585,-1.2464994519130068,-1.2315499433652275,-1.2043518602779164,-1.1679499502111095,-1.1401931008513402,-1.1449134331142605,-1.1493395029463849,-1.1373293040962928,-1.1295351724510432,-1.1477947929159005,-1.1302524063622112,-1.1238035717420949,-1.1532239773602497,-1.1481159336182387,-1.1369134344209186,-1.1452786693991224,-1.1334690570768444,-1.1383096913570059,-1.1408118895779524,-1.1272755040963558,-1.121269854259846,-1.1633068765428662,-1.1426373728255712,-1.1347803449504537,-1.142819009405552,-1.1435153626049872,-1.1326508683452747,-1.13864381002872,-1.1248234944804134,-1.1313284281036355,-1.1576454633540858,-1.140475813389339,-1.1323688003010102,-1.1530489077314778,-1.1380429568597448,-1.1306659676117679,-1.1364241121793184,-1.1349695698093505,-1.1257131049229245,-1.1555255121785606,-1.1380445159368355,-1.1425188389455312,-1.1474666749016378,-1.1359182717457936,-1.128250827666678,-1.1464202016108085,-1.1293713747464342,-1.123590057253629]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 5 6
INFO: iteration 1, average log likelihood -1.153424
WARNING: Variances had to be floored 5 6
INFO: iteration 2, average log likelihood -1.137883
WARNING: Variances had to be floored 5 6 20 31 32
INFO: iteration 3, average log likelihood -1.129915
WARNING: Variances had to be floored 5 6 19 20 22
INFO: iteration 4, average log likelihood -1.110888
WARNING: Variances had to be floored 5 6 9 10 11 12 19 20
INFO: iteration 5, average log likelihood -1.052956
WARNING: Variances had to be floored 5 6 19 20 22 26 31 32
INFO: iteration 6, average log likelihood -1.056097
WARNING: Variances had to be floored 5 6 9 11 19 20 24
INFO: iteration 7, average log likelihood -1.071737
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 8, average log likelihood -1.034199
WARNING: Variances had to be floored 5 6 7 9 11 19 20 25
INFO: iteration 9, average log likelihood -1.045926
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 10, average log likelihood -1.038644
WARNING: Variances had to be floored 5 6 9 11 19 20 24 26
INFO: iteration 11, average log likelihood -1.049494
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 12, average log likelihood -1.045408
WARNING: Variances had to be floored 5 6 7 9 11 19 20
INFO: iteration 13, average log likelihood -1.054773
WARNING: Variances had to be floored 5 6 10 11 12 19 20 22 25 31 32
INFO: iteration 14, average log likelihood -1.032687
WARNING: Variances had to be floored 5 6 9 19 20
INFO: iteration 15, average log likelihood -1.069940
WARNING: Variances had to be floored 5 6 10 11 19 20 22 24 26 31 32
INFO: iteration 16, average log likelihood -1.021965
WARNING: Variances had to be floored 5 6 7 9 11 12 19 20
INFO: iteration 17, average log likelihood -1.068301
WARNING: Variances had to be floored 5 6 10 19 20 22 31 32
INFO: iteration 18, average log likelihood -1.050547
WARNING: Variances had to be floored 5 6 9 11 19 20 25
INFO: iteration 19, average log likelihood -1.053907
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 20, average log likelihood -1.033558
WARNING: Variances had to be floored 5 6 7 9 11 19 20 24
INFO: iteration 21, average log likelihood -1.045396
WARNING: Variances had to be floored 5 6 10 11 12 19 20 22 26 31 32
INFO: iteration 22, average log likelihood -1.031774
WARNING: Variances had to be floored 5 6 9 19 20
INFO: iteration 23, average log likelihood -1.078675
WARNING: Variances had to be floored 5 6 10 11 19 20 22 25 31 32
INFO: iteration 24, average log likelihood -1.031946
WARNING: Variances had to be floored 5 6 7 9 11 12 19 20 24
INFO: iteration 25, average log likelihood -1.060611
WARNING: Variances had to be floored 5 6 10 19 20 22 31 32
INFO: iteration 26, average log likelihood -1.046873
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 27, average log likelihood -1.050633
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 28, average log likelihood -1.042860
WARNING: Variances had to be floored 5 6 7 9 11 19 20
INFO: iteration 29, average log likelihood -1.057425
WARNING: Variances had to be floored 5 6 10 11 12 19 20 22 24 31 32
INFO: iteration 30, average log likelihood -1.039904
WARNING: Variances had to be floored 5 6 9 19 20
INFO: iteration 31, average log likelihood -1.070258
WARNING: Variances had to be floored 5 6 10 11 19 20 22 25 31 32
INFO: iteration 32, average log likelihood -1.027832
WARNING: Variances had to be floored 5 6 7 9 11 12 19 20
INFO: iteration 33, average log likelihood -1.061211
WARNING: Variances had to be floored 5 6 10 19 20 22 31 32
INFO: iteration 34, average log likelihood -1.043688
WARNING: Variances had to be floored 5 6 9 11 19 20 24 26
INFO: iteration 35, average log likelihood -1.047174
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 36, average log likelihood -1.041530
WARNING: Variances had to be floored 5 6 7 9 11 19 20 27
INFO: iteration 37, average log likelihood -1.052708
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 38, average log likelihood -1.038941
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 39, average log likelihood -1.047490
WARNING: Variances had to be floored 5 6 10 12 19 20 22 24 31 32
INFO: iteration 40, average log likelihood -1.039155
WARNING: Variances had to be floored 5 6 7 9 11 19 20 27
INFO: iteration 41, average log likelihood -1.055004
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 42, average log likelihood -1.039315
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 43, average log likelihood -1.047701
WARNING: Variances had to be floored 5 6 10 12 19 20 22 24 31 32
INFO: iteration 44, average log likelihood -1.039680
WARNING: Variances had to be floored 5 6 7 9 11 19 20 27
INFO: iteration 45, average log likelihood -1.054902
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 46, average log likelihood -1.039281
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 47, average log likelihood -1.047765
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 48, average log likelihood -1.039880
WARNING: Variances had to be floored 5 6 7 9 11 19 20 24 27
INFO: iteration 49, average log likelihood -1.051115
WARNING: Variances had to be floored 5 6 10 12 19 20 22 31 32
INFO: iteration 50, average log likelihood -1.041645
INFO: EM with 100000 data points 50 iterations avll -1.041645
59.0 data points per parameter
5: avll = [-1.1534236068867854,-1.1378830875830832,-1.1299151400439906,-1.110887804507428,-1.0529558559787209,-1.0560970584725162,-1.0717373879291159,-1.0341986184523906,-1.0459256576641993,-1.038644461206359,-1.0494943306910014,-1.0454081491249947,-1.0547731475031223,-1.032686878937873,-1.069940442148602,-1.0219651069803888,-1.0683013361840805,-1.0505474514497848,-1.0539071747166473,-1.033557513918416,-1.0453956402155702,-1.0317736033604787,-1.078675495028358,-1.0319456841086139,-1.0606105053458776,-1.0468726594721203,-1.0506326466886269,-1.0428602384837957,-1.057424894833545,-1.0399041059917327,-1.0702581481809288,-1.0278324492509416,-1.0612107788975984,-1.043688080811445,-1.0471736143665613,-1.0415296958637001,-1.052707690466487,-1.038941448245617,-1.0474898191393074,-1.039154838174895,-1.0550042825879007,-1.0393153054556943,-1.04770135300075,-1.0396795866758164,-1.0549019549102439,-1.0392810635400485,-1.047765162319801,-1.0398797688174282,-1.051115325878969,-1.041644954173146]
[-1.4117983039982522,-1.4118944348863949,-1.4117851862670183,-1.4106245837963742,-1.4001396967616633,-1.3840476672847561,-1.3792498301189582,-1.3781120224180363,-1.377561317659943,-1.3772271511115972,-1.376990240194081,-1.3768027693922973,-1.376645428132347,-1.3765076912158158,-1.3763807770829555,-1.3762577383461598,-1.3761336892723468,-1.375996930727081,-1.3758163847029363,-1.3755256417428356,-1.3751333867262032,-1.3748424418486138,-1.3746680335384704,-1.3745566418735762,-1.3744760674443168,-1.3744099145685773,-1.3743453041621334,-1.3742650515122308,-1.374156837060881,-1.3740458701698046,-1.3739645018751852,-1.3739134522395537,-1.373880046285441,-1.3738568248903842,-1.3738395399178356,-1.3738258497670446,-1.373815137654436,-1.373807081832396,-1.37380119190959,-1.373797014068972,-1.3737941413611294,-1.3737922123564188,-1.373790934253063,-1.3737900912559673,-1.373789533368881,-1.3737891600684595,-1.3737889058040726,-1.3737887286586383,-1.3737886021077053,-1.3737885093891484,-1.3737884398357294,-1.373937662253593,-1.3737957820477575,-1.3730224029092941,-1.3657411596969027,-1.3477342079806187,-1.3379937976920995,-1.3348606416340165,-1.3326264912862082,-1.3307945005312751,-1.3293038399921489,-1.3280295516801914,-1.3270497145148867,-1.3263603182581647,-1.3258556704061848,-1.3254686504840947,-1.3251615255219833,-1.3249151300308721,-1.3247125108338613,-1.324531007303846,-1.324354318500356,-1.3241793565495437,-1.32399992150314,-1.3238035658769582,-1.3235936632545007,-1.3233846437448213,-1.3231878295159711,-1.3230207790326438,-1.3228918490717396,-1.3227928555651267,-1.3227094507832873,-1.32262794131559,-1.3225324613161236,-1.3223938015312753,-1.3221662952049449,-1.3218458746994513,-1.3215002379237797,-1.3211720683169454,-1.320885502585967,-1.3206412983732652,-1.320433443798884,-1.3202586102686715,-1.320108855402823,-1.319981397487782,-1.3198666517187023,-1.3197543061108674,-1.3196367450969912,-1.3195111757976932,-1.3193719168299076,-1.319216294590131,-1.3190428249402009,-1.3190276207716043,-1.3186150026920396,-1.3172468234069936,-1.3065116633575686,-1.2833717087220982,-1.2691827838729057,-1.263772305127574,-1.2613657683557424,-1.2598357434111571,-1.2585027236905946,-1.2570959801249626,-1.255585240838979,-1.254194889180014,-1.2532019071027183,-1.2525899643144562,-1.2522520360787646,-1.2520673404817717,-1.251956936376191,-1.251879081133053,-1.2518153386952262,-1.251753929463912,-1.2516845957353488,-1.2515996738627069,-1.2514891219925788,-1.2513308874231022,-1.251085036353483,-1.250682718838966,-1.2500641349415371,-1.249387109703213,-1.2489894634238423,-1.2488807302544294,-1.2488572642672262,-1.2488506663417802,-1.2488481744803221,-1.248847019031731,-1.248846403884315,-1.248846042502527,-1.2488458144902774,-1.2488456631554319,-1.248845559173764,-1.2488454860771874,-1.2488454339355406,-1.2488453964019037,-1.2488453692349422,-1.2488453495085163,-1.2488453351596676,-1.2488453247133937,-1.248845317105778,-1.248845311565368,-1.248845307531095,-1.249084838698553,-1.2487535291697585,-1.2464994519130068,-1.2315499433652275,-1.2043518602779164,-1.1679499502111095,-1.1401931008513402,-1.1449134331142605,-1.1493395029463849,-1.1373293040962928,-1.1295351724510432,-1.1477947929159005,-1.1302524063622112,-1.1238035717420949,-1.1532239773602497,-1.1481159336182387,-1.1369134344209186,-1.1452786693991224,-1.1334690570768444,-1.1383096913570059,-1.1408118895779524,-1.1272755040963558,-1.121269854259846,-1.1633068765428662,-1.1426373728255712,-1.1347803449504537,-1.142819009405552,-1.1435153626049872,-1.1326508683452747,-1.13864381002872,-1.1248234944804134,-1.1313284281036355,-1.1576454633540858,-1.140475813389339,-1.1323688003010102,-1.1530489077314778,-1.1380429568597448,-1.1306659676117679,-1.1364241121793184,-1.1349695698093505,-1.1257131049229245,-1.1555255121785606,-1.1380445159368355,-1.1425188389455312,-1.1474666749016378,-1.1359182717457936,-1.128250827666678,-1.1464202016108085,-1.1293713747464342,-1.123590057253629,-1.1534236068867854,-1.1378830875830832,-1.1299151400439906,-1.110887804507428,-1.0529558559787209,-1.0560970584725162,-1.0717373879291159,-1.0341986184523906,-1.0459256576641993,-1.038644461206359,-1.0494943306910014,-1.0454081491249947,-1.0547731475031223,-1.032686878937873,-1.069940442148602,-1.0219651069803888,-1.0683013361840805,-1.0505474514497848,-1.0539071747166473,-1.033557513918416,-1.0453956402155702,-1.0317736033604787,-1.078675495028358,-1.0319456841086139,-1.0606105053458776,-1.0468726594721203,-1.0506326466886269,-1.0428602384837957,-1.057424894833545,-1.0399041059917327,-1.0702581481809288,-1.0278324492509416,-1.0612107788975984,-1.043688080811445,-1.0471736143665613,-1.0415296958637001,-1.052707690466487,-1.038941448245617,-1.0474898191393074,-1.039154838174895,-1.0550042825879007,-1.0393153054556943,-1.04770135300075,-1.0396795866758164,-1.0549019549102439,-1.0392810635400485,-1.047765162319801,-1.0398797688174282,-1.051115325878969,-1.041644954173146]
32x26 Array{Float64,2}:
 -0.147347    -0.0913942   â€¦   0.0969586   0.066755     0.014708 
 -0.166111    -0.0854667      -0.33258     0.0870045    0.0437231
  0.0347699   -0.00306257     -1.4117      0.167297     0.198659 
  0.203124     0.0688116       0.906031    0.221159     0.103462 
  0.18104     -0.824772        0.0298621  -0.00798309  -0.364635 
  0.183129     0.264207    â€¦   0.237944   -0.0161798    0.153344 
  8.05901e-6   0.0323808      -0.106276   -0.13905      0.0650495
 -0.0381903    0.0444059       0.104922   -0.126549     0.159349 
 -0.123666    -0.0682742       0.0868955   0.0645263   -0.170213 
 -0.286044     0.079462        0.0151278   0.317923    -0.05863  
  â‹®                        â‹±                            â‹®        
  0.0923934   -0.0771776      -0.0356973  -0.00147857   0.110076 
  0.0413137    0.0445065      -0.0438625  -0.122228     0.0848982
  0.0717485   -0.0324789   â€¦   0.0594426  -0.0099761   -0.141353 
  0.151636    -0.0599919       0.13243    -0.0405674   -0.0345856
  0.0253597   -0.0825393      -0.106592    0.00702481   0.172213 
  0.15969     -0.0570682      -0.12685     0.20504     -0.162879 
  0.191607    -0.130454       -0.138963   -0.0388719   -0.161483 
  0.0250891   -0.108788    â€¦  -0.0806994   0.05671     -0.0402145
  0.0281147   -0.115612       -0.0118469   0.0698628    0.0797718INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 1, average log likelihood -1.048011
WARNING: Variances had to be floored 5 6 9 10 11 12 19 20 22 26 31 32
INFO: iteration 2, average log likelihood -1.002033
WARNING: Variances had to be floored 5 6 7 9 11 19 20 26 27
INFO: iteration 3, average log likelihood -1.039496
WARNING: Variances had to be floored 5 6 9 10 11 12 19 20 22 24 26 31 32
INFO: iteration 4, average log likelihood -1.005317
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 5, average log likelihood -1.042518
WARNING: Variances had to be floored 5 6 7 9 10 11 12 19 20 22 24 26 27 31 32
INFO: iteration 6, average log likelihood -0.997375
WARNING: Variances had to be floored 5 6 9 11 19 20 26
INFO: iteration 7, average log likelihood -1.048035
WARNING: Variances had to be floored 5 6 9 10 11 12 19 20 22 24 26 31 32
INFO: iteration 8, average log likelihood -1.000500
WARNING: Variances had to be floored 5 6 7 9 11 19 20 26 27
INFO: iteration 9, average log likelihood -1.039506
WARNING: Variances had to be floored 5 6 9 10 11 12 19 20 22 24 26 31 32
INFO: iteration 10, average log likelihood -1.005938
INFO: EM with 100000 data points 10 iterations avll -1.005938
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.435750e+05
      1       6.795936e+05      -1.639814e+05 |       32
      2       6.475446e+05      -3.204895e+04 |       32
      3       6.318750e+05      -1.566962e+04 |       32
      4       6.224059e+05      -9.469082e+03 |       32
      5       6.171040e+05      -5.301970e+03 |       32
      6       6.132438e+05      -3.860210e+03 |       32
      7       6.101388e+05      -3.104961e+03 |       32
      8       6.079252e+05      -2.213571e+03 |       32
      9       6.061224e+05      -1.802843e+03 |       32
     10       6.045942e+05      -1.528221e+03 |       32
     11       6.034138e+05      -1.180367e+03 |       32
     12       6.025491e+05      -8.646816e+02 |       32
     13       6.020064e+05      -5.427314e+02 |       32
     14       6.016199e+05      -3.865004e+02 |       32
     15       6.013337e+05      -2.862016e+02 |       32
     16       6.011620e+05      -1.716958e+02 |       32
     17       6.009908e+05      -1.712331e+02 |       32
     18       6.007249e+05      -2.659000e+02 |       32
     19       6.003219e+05      -4.029063e+02 |       32
     20       5.999896e+05      -3.323948e+02 |       32
     21       5.998926e+05      -9.692744e+01 |       32
     22       5.998742e+05      -1.844098e+01 |       31
     23       5.998697e+05      -4.489887e+00 |       21
     24       5.998678e+05      -1.929900e+00 |       26
     25       5.998664e+05      -1.357821e+00 |       21
     26       5.998653e+05      -1.102129e+00 |       19
     27       5.998647e+05      -6.162133e-01 |       12
     28       5.998641e+05      -5.648451e-01 |        9
     29       5.998638e+05      -3.662811e-01 |        9
     30       5.998636e+05      -1.948560e-01 |        0
     31       5.998636e+05       0.000000e+00 |        0
K-means converged with 31 iterations (objv = 599863.5611017325)
INFO: K-means with 32000 data points using 31 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.316584
INFO: iteration 2, average log likelihood -1.286487
INFO: iteration 3, average log likelihood -1.252484
INFO: iteration 4, average log likelihood -1.209849
INFO: iteration 5, average log likelihood -1.144936
WARNING: Variances had to be floored 1 4 12 14 24
INFO: iteration 6, average log likelihood -1.055078
WARNING: Variances had to be floored 9 16 19 22 23
INFO: iteration 7, average log likelihood -1.054321
WARNING: Variances had to be floored 10 11 15 21 27
INFO: iteration 8, average log likelihood -1.095468
INFO: iteration 9, average log likelihood -1.103135
WARNING: Variances had to be floored 1 3 4 14 18 31
INFO: iteration 10, average log likelihood -1.037144
WARNING: Variances had to be floored 6 16 22 24
INFO: iteration 11, average log likelihood -1.064123
WARNING: Variances had to be floored 9 23 27
INFO: iteration 12, average log likelihood -1.054649
WARNING: Variances had to be floored 1 4 10 11 12 21
INFO: iteration 13, average log likelihood -1.055631
WARNING: Variances had to be floored 15 31
INFO: iteration 14, average log likelihood -1.097715
WARNING: Variances had to be floored 14 16 18 22
INFO: iteration 15, average log likelihood -1.054954
WARNING: Variances had to be floored 1 2 3 4 23
INFO: iteration 16, average log likelihood -1.046382
WARNING: Variances had to be floored 6 9 12
INFO: iteration 17, average log likelihood -1.038871
WARNING: Variances had to be floored 15 21 27 31
INFO: iteration 18, average log likelihood -1.044609
WARNING: Variances had to be floored 1 4 10 11 14 16 22
INFO: iteration 19, average log likelihood -1.044352
WARNING: Variances had to be floored 3 23 24
INFO: iteration 20, average log likelihood -1.095656
WARNING: Variances had to be floored 2 6 9 18
INFO: iteration 21, average log likelihood -1.065326
WARNING: Variances had to be floored 4
INFO: iteration 22, average log likelihood -1.051319
WARNING: Variances had to be floored 1 12 14 15 16 21 22 27 31
INFO: iteration 23, average log likelihood -1.002608
INFO: iteration 24, average log likelihood -1.100025
WARNING: Variances had to be floored 6 9 11 18
INFO: iteration 25, average log likelihood -1.043275
WARNING: Variances had to be floored 2 3 4 10 24
INFO: iteration 26, average log likelihood -1.066197
WARNING: Variances had to be floored 1 16 23
INFO: iteration 27, average log likelihood -1.066493
WARNING: Variances had to be floored 15 22 31
INFO: iteration 28, average log likelihood -1.047244
WARNING: Variances had to be floored 4 6 9 12 14 21
INFO: iteration 29, average log likelihood -1.028958
WARNING: Variances had to be floored 1
INFO: iteration 30, average log likelihood -1.085615
WARNING: Variances had to be floored 2 11 16 27
INFO: iteration 31, average log likelihood -1.029530
WARNING: Variances had to be floored 3 10 18 22 31
INFO: iteration 32, average log likelihood -1.038875
WARNING: Variances had to be floored 1 4 6 9 14 15 21
INFO: iteration 33, average log likelihood -1.047130
WARNING: Variances had to be floored 24
INFO: iteration 34, average log likelihood -1.094002
WARNING: Variances had to be floored 2 16 19 22
INFO: iteration 35, average log likelihood -1.035207
WARNING: Variances had to be floored 9 31
INFO: iteration 36, average log likelihood -1.042118
WARNING: Variances had to be floored 1 6 11 12 14 15 18 21
INFO: iteration 37, average log likelihood -1.013051
WARNING: Variances had to be floored 2 3
INFO: iteration 38, average log likelihood -1.072257
WARNING: Variances had to be floored 16 19 22 24 27
INFO: iteration 39, average log likelihood -1.044222
WARNING: Variances had to be floored 9 15 31
INFO: iteration 40, average log likelihood -1.046653
WARNING: Variances had to be floored 1 2 6 10 12 14 18 21
INFO: iteration 41, average log likelihood -1.022017
INFO: iteration 42, average log likelihood -1.101085
WARNING: Variances had to be floored 4 11 16 22
INFO: iteration 43, average log likelihood -1.027898
WARNING: Variances had to be floored 3 9 15 31
INFO: iteration 44, average log likelihood -1.028638
WARNING: Variances had to be floored 1 2 6 12 14 18 19 21 27
INFO: iteration 45, average log likelihood -1.025043
WARNING: Variances had to be floored 10 22 24
INFO: iteration 46, average log likelihood -1.087603
WARNING: Variances had to be floored 4 16
INFO: iteration 47, average log likelihood -1.053133
WARNING: Variances had to be floored 3 9 11 15 19 31
INFO: iteration 48, average log likelihood -1.021587
WARNING: Variances had to be floored 1 2 6 12 18 21
INFO: iteration 49, average log likelihood -1.055823
WARNING: Variances had to be floored 4 14 16 22 24
INFO: iteration 50, average log likelihood -1.068806
INFO: EM with 100000 data points 50 iterations avll -1.068806
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.03666      0.152798   -0.322659     â€¦  -0.201219     0.0901831  
 -0.0123972   -0.123662   -0.00211636       0.10814     -0.190939   
 -0.0224312   -0.084631    0.0861032        0.0595724   -0.000358898
  0.0335526    0.0286813  -0.0839633        0.0855508    0.0632503  
  0.122963     0.0331171  -0.122256         0.195719     0.147974   
 -0.223166     0.0742197  -0.0281371    â€¦   0.19106     -0.0953121  
 -0.0603712   -0.203757    0.143974         0.0712288    0.175906   
 -0.140661    -0.0965001   0.00375942      -0.112515    -0.0953063  
  0.154366    -0.243043   -0.0299729        0.00616093  -0.10416    
 -0.0865377    0.233726   -0.196635         0.0303096    0.05551    
  â‹®                                     â‹±                â‹®          
  0.0483957    0.0277023  -0.100916        -0.022425    -0.0422826  
  0.216098    -0.147932    0.0123025       -0.0931689   -0.0133817  
 -0.158262    -0.089598    0.000557635  â€¦   0.0777901    0.0279084  
  0.0803002   -0.0480466   0.0440937        0.00894096   0.0611515  
  0.0498971    0.183383    0.0145837       -0.0196899   -0.0421792  
  0.169843    -0.0946604   0.0100841        0.0763833   -0.161535   
  0.0339614   -0.136808   -0.104053         0.0615248    0.0926438  
  0.0844822    0.0959213   0.00499486   â€¦  -0.0329771    0.146614   
  0.00965947   0.046861    0.126578        -0.160557     0.0989411  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.074662
WARNING: Variances had to be floored 1 2 3 9 10 15 19 27 31
INFO: iteration 2, average log likelihood -0.999306
WARNING: Variances had to be floored 6 9 11 12 14 15 16 18 19 21 22 27 31
INFO: iteration 3, average log likelihood -0.967620
WARNING: Variances had to be floored 1 2 3 4 10 19 24
INFO: iteration 4, average log likelihood -1.026895
WARNING: Variances had to be floored 9 15 19 27 31
INFO: iteration 5, average log likelihood -1.023510
WARNING: Variances had to be floored 1 2 3 6 9 10 11 12 14 15 16 18 19 21 22 27 31
INFO: iteration 6, average log likelihood -0.954584
WARNING: Variances had to be floored 4 19 24
INFO: iteration 7, average log likelihood -1.051109
WARNING: Variances had to be floored 1 2 3 9 10 15 19 27 31
INFO: iteration 8, average log likelihood -1.006292
WARNING: Variances had to be floored 6 9 11 12 14 15 16 18 19 21 22 27 31
INFO: iteration 9, average log likelihood -0.979917
WARNING: Variances had to be floored 1 2 3 10 19 24
INFO: iteration 10, average log likelihood -1.020324
INFO: EM with 100000 data points 10 iterations avll -1.020324
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.134401     0.0971017   0.0131301   â€¦   0.120592    -0.106891  
 -0.151069     0.103368   -0.0395007      -0.0991156    0.0442216 
  0.014118     0.154227    0.126537       -0.119806     0.0705785 
  0.146936     0.0191908   0.00290613      0.120733    -0.0964825 
 -0.053448     0.252463   -0.183775        0.0824828    0.0997414 
  0.0303973   -0.0384986   0.0567538   â€¦   0.0094708    0.0804191 
 -0.00102108  -0.11421    -0.0137099       0.0467531   -0.105265  
 -0.0612676    0.0611006  -0.00969047      0.0613217    0.0144822 
 -0.104605     0.0241562   0.0796889      -0.0257847   -0.0572405 
 -0.105038    -0.0741353  -0.0041824      -0.014729    -0.0650954 
  â‹®                                    â‹±                â‹®         
 -0.016728     0.0405213  -0.0983394       0.113307     0.00102108
  0.116947    -0.178618   -0.0270478      -0.0708637    0.0329946 
 -0.0145786   -0.064603   -0.0241955   â€¦   0.0754691   -0.0914849 
  0.181006    -0.0798613   0.0615132      -0.158412    -0.040775  
 -0.0141658   -0.0710812  -0.0277925      -0.00666971  -0.0324129 
  0.00396988   0.0938478   0.0898857      -0.00148033  -0.00898048
  0.00911846   0.0101775   0.0383621       0.0273904   -0.11589   
  0.113971     0.0389146  -0.113614    â€¦   0.00391296  -0.0417308 
  0.0320232   -0.0322658   0.0358556      -0.0708381    0.0270255 kind full, method split
0: avll = -1.416508532194089
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.416528
INFO: iteration 2, average log likelihood -1.416451
INFO: iteration 3, average log likelihood -1.416390
INFO: iteration 4, average log likelihood -1.416317
INFO: iteration 5, average log likelihood -1.416229
INFO: iteration 6, average log likelihood -1.416127
INFO: iteration 7, average log likelihood -1.416018
INFO: iteration 8, average log likelihood -1.415915
INFO: iteration 9, average log likelihood -1.415823
INFO: iteration 10, average log likelihood -1.415739
INFO: iteration 11, average log likelihood -1.415650
INFO: iteration 12, average log likelihood -1.415524
INFO: iteration 13, average log likelihood -1.415313
INFO: iteration 14, average log likelihood -1.414942
INFO: iteration 15, average log likelihood -1.414332
INFO: iteration 16, average log likelihood -1.413486
INFO: iteration 17, average log likelihood -1.412580
INFO: iteration 18, average log likelihood -1.411870
INFO: iteration 19, average log likelihood -1.411452
INFO: iteration 20, average log likelihood -1.411247
INFO: iteration 21, average log likelihood -1.411155
INFO: iteration 22, average log likelihood -1.411114
INFO: iteration 23, average log likelihood -1.411096
INFO: iteration 24, average log likelihood -1.411088
INFO: iteration 25, average log likelihood -1.411084
INFO: iteration 26, average log likelihood -1.411082
INFO: iteration 27, average log likelihood -1.411081
INFO: iteration 28, average log likelihood -1.411080
INFO: iteration 29, average log likelihood -1.411080
INFO: iteration 30, average log likelihood -1.411080
INFO: iteration 31, average log likelihood -1.411080
INFO: iteration 32, average log likelihood -1.411079
INFO: iteration 33, average log likelihood -1.411079
INFO: iteration 34, average log likelihood -1.411079
INFO: iteration 35, average log likelihood -1.411079
INFO: iteration 36, average log likelihood -1.411079
INFO: iteration 37, average log likelihood -1.411079
INFO: iteration 38, average log likelihood -1.411079
INFO: iteration 39, average log likelihood -1.411079
INFO: iteration 40, average log likelihood -1.411079
INFO: iteration 41, average log likelihood -1.411079
INFO: iteration 42, average log likelihood -1.411079
INFO: iteration 43, average log likelihood -1.411079
INFO: iteration 44, average log likelihood -1.411079
INFO: iteration 45, average log likelihood -1.411078
INFO: iteration 46, average log likelihood -1.411078
INFO: iteration 47, average log likelihood -1.411078
INFO: iteration 48, average log likelihood -1.411078
INFO: iteration 49, average log likelihood -1.411078
INFO: iteration 50, average log likelihood -1.411078
INFO: EM with 100000 data points 50 iterations avll -1.411078
952.4 data points per parameter
1: avll = [-1.4165280479838005,-1.4164512812204764,-1.416389883549623,-1.41631716160823,-1.4162288486097496,-1.416126622360083,-1.4160183233953758,-1.4159146678733714,-1.4158226279316082,-1.4157394630916138,-1.4156499998168388,-1.4155244972630063,-1.4153132789987488,-1.4149419704970145,-1.4143321681980803,-1.4134864064507462,-1.4125801506518807,-1.4118698209405351,-1.411451845042693,-1.4112473128499552,-1.4111549039216176,-1.4111139702951552,-1.4110957537687447,-1.4110875217098038,-1.4110837061163786,-1.411081863550398,-1.4110809142292426,-1.4110803773256504,-1.4110800369272734,-1.4110797950669092,-1.4110796066239804,-1.4110794503157045,-1.4110793156992572,-1.4110791973174304,-1.411079092047531,-1.4110789978932214,-1.4110789134291815,-1.411078837542383,-1.4110787693088327,-1.4110787079325755,-1.4110786527136066,-1.4110786030294318,-1.4110785583232561,-1.4110785180955492,-1.4110784818974627,-1.4110784493253714,-1.411078420016173,-1.411078393643153,-1.411078369912314,-1.4110783485590839]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411094
INFO: iteration 2, average log likelihood -1.411025
INFO: iteration 3, average log likelihood -1.410967
INFO: iteration 4, average log likelihood -1.410898
INFO: iteration 5, average log likelihood -1.410814
INFO: iteration 6, average log likelihood -1.410716
INFO: iteration 7, average log likelihood -1.410611
INFO: iteration 8, average log likelihood -1.410507
INFO: iteration 9, average log likelihood -1.410409
INFO: iteration 10, average log likelihood -1.410319
INFO: iteration 11, average log likelihood -1.410234
INFO: iteration 12, average log likelihood -1.410153
INFO: iteration 13, average log likelihood -1.410076
INFO: iteration 14, average log likelihood -1.410006
INFO: iteration 15, average log likelihood -1.409945
INFO: iteration 16, average log likelihood -1.409895
INFO: iteration 17, average log likelihood -1.409855
INFO: iteration 18, average log likelihood -1.409823
INFO: iteration 19, average log likelihood -1.409798
INFO: iteration 20, average log likelihood -1.409778
INFO: iteration 21, average log likelihood -1.409762
INFO: iteration 22, average log likelihood -1.409749
INFO: iteration 23, average log likelihood -1.409739
INFO: iteration 24, average log likelihood -1.409729
INFO: iteration 25, average log likelihood -1.409722
INFO: iteration 26, average log likelihood -1.409715
INFO: iteration 27, average log likelihood -1.409709
INFO: iteration 28, average log likelihood -1.409704
INFO: iteration 29, average log likelihood -1.409700
INFO: iteration 30, average log likelihood -1.409696
INFO: iteration 31, average log likelihood -1.409692
INFO: iteration 32, average log likelihood -1.409689
INFO: iteration 33, average log likelihood -1.409686
INFO: iteration 34, average log likelihood -1.409684
INFO: iteration 35, average log likelihood -1.409681
INFO: iteration 36, average log likelihood -1.409679
INFO: iteration 37, average log likelihood -1.409677
INFO: iteration 38, average log likelihood -1.409675
INFO: iteration 39, average log likelihood -1.409674
INFO: iteration 40, average log likelihood -1.409672
INFO: iteration 41, average log likelihood -1.409671
INFO: iteration 42, average log likelihood -1.409669
INFO: iteration 43, average log likelihood -1.409668
INFO: iteration 44, average log likelihood -1.409667
INFO: iteration 45, average log likelihood -1.409666
INFO: iteration 46, average log likelihood -1.409665
INFO: iteration 47, average log likelihood -1.409664
INFO: iteration 48, average log likelihood -1.409663
INFO: iteration 49, average log likelihood -1.409662
INFO: iteration 50, average log likelihood -1.409661
INFO: EM with 100000 data points 50 iterations avll -1.409661
473.9 data points per parameter
2: avll = [-1.411094230010172,-1.4110254411999756,-1.410967352353763,-1.410898394888828,-1.4108142634838996,-1.4107162632887307,-1.4106109103215299,-1.4105066483825084,-1.4104090843392705,-1.4103189224848434,-1.4102340320359052,-1.4101528405597017,-1.4100760436639237,-1.4100060446605596,-1.4099452897506344,-1.4098949431710612,-1.4098546066338111,-1.409822844225986,-1.4097978876594368,-1.4097781121776145,-1.409762221605224,-1.4097492515081116,-1.4097385033436856,-1.4097294719240814,-1.4097217877745405,-1.4097151764712308,-1.4097094310803013,-1.4097043934689952,-1.4096999413829674,-1.4096959792887227,-1.409692431743034,-1.4096892385168553,-1.4096863509744015,-1.4096837293697488,-1.4096813408229898,-1.4096791578029275,-1.4096771569880664,-1.4096753184098296,-1.4096736248058228,-1.4096720611289444,-1.4096706141717987,-1.409669272276251,-1.4096680251058251,-1.4096668634645553,-1.4096657791503318,-1.409664764834061,-1.4096638139583608,-1.409662920651272,-1.409662079651722,-1.4096612862443851]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409673
INFO: iteration 2, average log likelihood -1.409608
INFO: iteration 3, average log likelihood -1.409549
INFO: iteration 4, average log likelihood -1.409477
INFO: iteration 5, average log likelihood -1.409387
INFO: iteration 6, average log likelihood -1.409275
INFO: iteration 7, average log likelihood -1.409148
INFO: iteration 8, average log likelihood -1.409013
INFO: iteration 9, average log likelihood -1.408884
INFO: iteration 10, average log likelihood -1.408769
INFO: iteration 11, average log likelihood -1.408671
INFO: iteration 12, average log likelihood -1.408590
INFO: iteration 13, average log likelihood -1.408522
INFO: iteration 14, average log likelihood -1.408465
INFO: iteration 15, average log likelihood -1.408416
INFO: iteration 16, average log likelihood -1.408374
INFO: iteration 17, average log likelihood -1.408336
INFO: iteration 18, average log likelihood -1.408301
INFO: iteration 19, average log likelihood -1.408270
INFO: iteration 20, average log likelihood -1.408241
INFO: iteration 21, average log likelihood -1.408213
INFO: iteration 22, average log likelihood -1.408187
INFO: iteration 23, average log likelihood -1.408163
INFO: iteration 24, average log likelihood -1.408140
INFO: iteration 25, average log likelihood -1.408119
INFO: iteration 26, average log likelihood -1.408098
INFO: iteration 27, average log likelihood -1.408079
INFO: iteration 28, average log likelihood -1.408062
INFO: iteration 29, average log likelihood -1.408045
INFO: iteration 30, average log likelihood -1.408030
INFO: iteration 31, average log likelihood -1.408015
INFO: iteration 32, average log likelihood -1.408002
INFO: iteration 33, average log likelihood -1.407989
INFO: iteration 34, average log likelihood -1.407978
INFO: iteration 35, average log likelihood -1.407967
INFO: iteration 36, average log likelihood -1.407957
INFO: iteration 37, average log likelihood -1.407947
INFO: iteration 38, average log likelihood -1.407938
INFO: iteration 39, average log likelihood -1.407929
INFO: iteration 40, average log likelihood -1.407921
INFO: iteration 41, average log likelihood -1.407912
INFO: iteration 42, average log likelihood -1.407905
INFO: iteration 43, average log likelihood -1.407897
INFO: iteration 44, average log likelihood -1.407890
INFO: iteration 45, average log likelihood -1.407883
INFO: iteration 46, average log likelihood -1.407876
INFO: iteration 47, average log likelihood -1.407869
INFO: iteration 48, average log likelihood -1.407862
INFO: iteration 49, average log likelihood -1.407856
INFO: iteration 50, average log likelihood -1.407849
INFO: EM with 100000 data points 50 iterations avll -1.407849
236.4 data points per parameter
3: avll = [-1.4096729585932275,-1.409607587073839,-1.4095485904102378,-1.4094770917051724,-1.4093866992870898,-1.40927547273872,-1.40914764195707,-1.4090132016966532,-1.4088840042386608,-1.408768790878043,-1.4086709415215124,-1.4085895959998076,-1.4085219705336989,-1.408465040031119,-1.408416246662465,-1.408373620462047,-1.408335690379281,-1.4083013694362214,-1.40826986517359,-1.4082406147438222,-1.408213234213046,-1.4081874752116013,-1.4081631866792959,-1.4081402819004254,-1.4081187115769727,-1.4080984433091583,-1.408079447256414,-1.408061687269621,-1.4080451164963736,-1.4080296763454139,-1.4080152977180527,-1.4080019035389582,-1.4079894118097975,-1.4079777386283252,-1.4079668008275208,-1.4079565180685076,-1.407946814353256,-1.4079376190063755,-1.4079288672164805,-1.4079205002383846,-1.4079124653499877,-1.407904715641997,-1.4078972097010642,-1.407889911230896,-1.407882788642733,-1.407875814636413,-1.4078689657857064,-1.4078622221361892,-1.4078555668201829,-1.407848985690772]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407851
INFO: iteration 2, average log likelihood -1.407782
INFO: iteration 3, average log likelihood -1.407714
INFO: iteration 4, average log likelihood -1.407632
INFO: iteration 5, average log likelihood -1.407528
INFO: iteration 6, average log likelihood -1.407401
INFO: iteration 7, average log likelihood -1.407254
INFO: iteration 8, average log likelihood -1.407094
INFO: iteration 9, average log likelihood -1.406934
INFO: iteration 10, average log likelihood -1.406781
INFO: iteration 11, average log likelihood -1.406639
INFO: iteration 12, average log likelihood -1.406512
INFO: iteration 13, average log likelihood -1.406398
INFO: iteration 14, average log likelihood -1.406299
INFO: iteration 15, average log likelihood -1.406213
INFO: iteration 16, average log likelihood -1.406141
INFO: iteration 17, average log likelihood -1.406079
INFO: iteration 18, average log likelihood -1.406028
INFO: iteration 19, average log likelihood -1.405984
INFO: iteration 20, average log likelihood -1.405946
INFO: iteration 21, average log likelihood -1.405913
INFO: iteration 22, average log likelihood -1.405884
INFO: iteration 23, average log likelihood -1.405857
INFO: iteration 24, average log likelihood -1.405833
INFO: iteration 25, average log likelihood -1.405811
INFO: iteration 26, average log likelihood -1.405791
INFO: iteration 27, average log likelihood -1.405771
INFO: iteration 28, average log likelihood -1.405753
INFO: iteration 29, average log likelihood -1.405736
INFO: iteration 30, average log likelihood -1.405719
INFO: iteration 31, average log likelihood -1.405703
INFO: iteration 32, average log likelihood -1.405688
INFO: iteration 33, average log likelihood -1.405673
INFO: iteration 34, average log likelihood -1.405659
INFO: iteration 35, average log likelihood -1.405645
INFO: iteration 36, average log likelihood -1.405632
INFO: iteration 37, average log likelihood -1.405619
INFO: iteration 38, average log likelihood -1.405607
INFO: iteration 39, average log likelihood -1.405595
INFO: iteration 40, average log likelihood -1.405584
INFO: iteration 41, average log likelihood -1.405572
INFO: iteration 42, average log likelihood -1.405562
INFO: iteration 43, average log likelihood -1.405551
INFO: iteration 44, average log likelihood -1.405541
INFO: iteration 45, average log likelihood -1.405531
INFO: iteration 46, average log likelihood -1.405522
INFO: iteration 47, average log likelihood -1.405513
INFO: iteration 48, average log likelihood -1.405504
INFO: iteration 49, average log likelihood -1.405495
INFO: iteration 50, average log likelihood -1.405487
INFO: EM with 100000 data points 50 iterations avll -1.405487
118.1 data points per parameter
4: avll = [-1.4078512722271084,-1.4077819756269894,-1.407713803154335,-1.407631680229954,-1.4075284544946367,-1.4074013819854005,-1.4072536968900031,-1.4070941952332454,-1.4069336574671214,-1.4067805484005838,-1.4066393624938058,-1.4065117661499782,-1.4063982616258104,-1.4062989259730612,-1.4062133859295145,-1.4061406761909032,-1.4060793081349976,-1.4060275145664363,-1.4059835168743446,-1.4059457113261298,-1.405912754233362,-1.4058835726990844,-1.4058573359613464,-1.4058334128417218,-1.4058113293301266,-1.4057907322270562,-1.4057713600661663,-1.4057530203102768,-1.405735571271047,-1.4057189076665704,-1.405702949429105,-1.4056876336424942,-1.405672909246425,-1.4056587338096078,-1.4056450715787487,-1.4056318921603614,-1.4056191694477613,-1.4056068806484125,-1.4055950054273045,-1.405583525234132,-1.405572422851963,-1.4055616821498296,-1.4055512879846659,-1.405541226189158,-1.4055314835911645,-1.4055220480259816,-1.4055129083188906,-1.4055040542301114,-1.4054954763662002,-1.4054871660697261]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.405490
INFO: iteration 2, average log likelihood -1.405415
INFO: iteration 3, average log likelihood -1.405343
INFO: iteration 4, average log likelihood -1.405255
INFO: iteration 5, average log likelihood -1.405143
INFO: iteration 6, average log likelihood -1.405004
INFO: iteration 7, average log likelihood -1.404838
INFO: iteration 8, average log likelihood -1.404654
INFO: iteration 9, average log likelihood -1.404466
INFO: iteration 10, average log likelihood -1.404285
INFO: iteration 11, average log likelihood -1.404118
INFO: iteration 12, average log likelihood -1.403969
INFO: iteration 13, average log likelihood -1.403838
INFO: iteration 14, average log likelihood -1.403724
INFO: iteration 15, average log likelihood -1.403624
INFO: iteration 16, average log likelihood -1.403537
INFO: iteration 17, average log likelihood -1.403460
INFO: iteration 18, average log likelihood -1.403392
INFO: iteration 19, average log likelihood -1.403332
INFO: iteration 20, average log likelihood -1.403277
INFO: iteration 21, average log likelihood -1.403228
INFO: iteration 22, average log likelihood -1.403183
INFO: iteration 23, average log likelihood -1.403142
INFO: iteration 24, average log likelihood -1.403105
INFO: iteration 25, average log likelihood -1.403070
INFO: iteration 26, average log likelihood -1.403037
INFO: iteration 27, average log likelihood -1.403007
INFO: iteration 28, average log likelihood -1.402979
INFO: iteration 29, average log likelihood -1.402952
INFO: iteration 30, average log likelihood -1.402927
INFO: iteration 31, average log likelihood -1.402904
INFO: iteration 32, average log likelihood -1.402882
INFO: iteration 33, average log likelihood -1.402861
INFO: iteration 34, average log likelihood -1.402841
INFO: iteration 35, average log likelihood -1.402822
INFO: iteration 36, average log likelihood -1.402804
INFO: iteration 37, average log likelihood -1.402786
INFO: iteration 38, average log likelihood -1.402770
INFO: iteration 39, average log likelihood -1.402754
INFO: iteration 40, average log likelihood -1.402738
INFO: iteration 41, average log likelihood -1.402723
INFO: iteration 42, average log likelihood -1.402709
INFO: iteration 43, average log likelihood -1.402694
INFO: iteration 44, average log likelihood -1.402680
INFO: iteration 45, average log likelihood -1.402667
INFO: iteration 46, average log likelihood -1.402653
INFO: iteration 47, average log likelihood -1.402640
INFO: iteration 48, average log likelihood -1.402626
INFO: iteration 49, average log likelihood -1.402613
INFO: iteration 50, average log likelihood -1.402600
INFO: EM with 100000 data points 50 iterations avll -1.402600
59.0 data points per parameter
5: avll = [-1.4054895482042482,-1.4054150947575874,-1.405342584452228,-1.405254943015096,-1.4051434304504986,-1.405003682256495,-1.4048376799600961,-1.4046542128013189,-1.4044659117176213,-1.404284513863935,-1.404117722591832,-1.4039688480379666,-1.4038380694557815,-1.403723917382631,-1.4036243168985525,-1.4035371375373324,-1.403460426343799,-1.4033924872697916,-1.403331892753494,-1.403277463820232,-1.4032282367344289,-1.4031834269698555,-1.403142396150604,-1.4031046240912592,-1.4030696860604404,-1.4030372343616366,-1.4030069830232232,-1.4029786947006297,-1.4029521694731801,-1.4029272356174325,-1.4029037424577444,-1.4028815551701528,-1.4028605511966448,-1.4028406178441075,-1.4028216506791986,-1.402803552422637,-1.4027862321522897,-1.4027696047239746,-1.40275359038932,-1.4027381145963842,-1.4027231078780735,-1.4027085056140192,-1.4026942474407238,-1.4026802762968134,-1.402666537400564,-1.4026529775861396,-1.4026395452958524,-1.4026261913289433,-1.4026128703377023,-1.4025995429944031]
[-1.416508532194089,-1.4165280479838005,-1.4164512812204764,-1.416389883549623,-1.41631716160823,-1.4162288486097496,-1.416126622360083,-1.4160183233953758,-1.4159146678733714,-1.4158226279316082,-1.4157394630916138,-1.4156499998168388,-1.4155244972630063,-1.4153132789987488,-1.4149419704970145,-1.4143321681980803,-1.4134864064507462,-1.4125801506518807,-1.4118698209405351,-1.411451845042693,-1.4112473128499552,-1.4111549039216176,-1.4111139702951552,-1.4110957537687447,-1.4110875217098038,-1.4110837061163786,-1.411081863550398,-1.4110809142292426,-1.4110803773256504,-1.4110800369272734,-1.4110797950669092,-1.4110796066239804,-1.4110794503157045,-1.4110793156992572,-1.4110791973174304,-1.411079092047531,-1.4110789978932214,-1.4110789134291815,-1.411078837542383,-1.4110787693088327,-1.4110787079325755,-1.4110786527136066,-1.4110786030294318,-1.4110785583232561,-1.4110785180955492,-1.4110784818974627,-1.4110784493253714,-1.411078420016173,-1.411078393643153,-1.411078369912314,-1.4110783485590839,-1.411094230010172,-1.4110254411999756,-1.410967352353763,-1.410898394888828,-1.4108142634838996,-1.4107162632887307,-1.4106109103215299,-1.4105066483825084,-1.4104090843392705,-1.4103189224848434,-1.4102340320359052,-1.4101528405597017,-1.4100760436639237,-1.4100060446605596,-1.4099452897506344,-1.4098949431710612,-1.4098546066338111,-1.409822844225986,-1.4097978876594368,-1.4097781121776145,-1.409762221605224,-1.4097492515081116,-1.4097385033436856,-1.4097294719240814,-1.4097217877745405,-1.4097151764712308,-1.4097094310803013,-1.4097043934689952,-1.4096999413829674,-1.4096959792887227,-1.409692431743034,-1.4096892385168553,-1.4096863509744015,-1.4096837293697488,-1.4096813408229898,-1.4096791578029275,-1.4096771569880664,-1.4096753184098296,-1.4096736248058228,-1.4096720611289444,-1.4096706141717987,-1.409669272276251,-1.4096680251058251,-1.4096668634645553,-1.4096657791503318,-1.409664764834061,-1.4096638139583608,-1.409662920651272,-1.409662079651722,-1.4096612862443851,-1.4096729585932275,-1.409607587073839,-1.4095485904102378,-1.4094770917051724,-1.4093866992870898,-1.40927547273872,-1.40914764195707,-1.4090132016966532,-1.4088840042386608,-1.408768790878043,-1.4086709415215124,-1.4085895959998076,-1.4085219705336989,-1.408465040031119,-1.408416246662465,-1.408373620462047,-1.408335690379281,-1.4083013694362214,-1.40826986517359,-1.4082406147438222,-1.408213234213046,-1.4081874752116013,-1.4081631866792959,-1.4081402819004254,-1.4081187115769727,-1.4080984433091583,-1.408079447256414,-1.408061687269621,-1.4080451164963736,-1.4080296763454139,-1.4080152977180527,-1.4080019035389582,-1.4079894118097975,-1.4079777386283252,-1.4079668008275208,-1.4079565180685076,-1.407946814353256,-1.4079376190063755,-1.4079288672164805,-1.4079205002383846,-1.4079124653499877,-1.407904715641997,-1.4078972097010642,-1.407889911230896,-1.407882788642733,-1.407875814636413,-1.4078689657857064,-1.4078622221361892,-1.4078555668201829,-1.407848985690772,-1.4078512722271084,-1.4077819756269894,-1.407713803154335,-1.407631680229954,-1.4075284544946367,-1.4074013819854005,-1.4072536968900031,-1.4070941952332454,-1.4069336574671214,-1.4067805484005838,-1.4066393624938058,-1.4065117661499782,-1.4063982616258104,-1.4062989259730612,-1.4062133859295145,-1.4061406761909032,-1.4060793081349976,-1.4060275145664363,-1.4059835168743446,-1.4059457113261298,-1.405912754233362,-1.4058835726990844,-1.4058573359613464,-1.4058334128417218,-1.4058113293301266,-1.4057907322270562,-1.4057713600661663,-1.4057530203102768,-1.405735571271047,-1.4057189076665704,-1.405702949429105,-1.4056876336424942,-1.405672909246425,-1.4056587338096078,-1.4056450715787487,-1.4056318921603614,-1.4056191694477613,-1.4056068806484125,-1.4055950054273045,-1.405583525234132,-1.405572422851963,-1.4055616821498296,-1.4055512879846659,-1.405541226189158,-1.4055314835911645,-1.4055220480259816,-1.4055129083188906,-1.4055040542301114,-1.4054954763662002,-1.4054871660697261,-1.4054895482042482,-1.4054150947575874,-1.405342584452228,-1.405254943015096,-1.4051434304504986,-1.405003682256495,-1.4048376799600961,-1.4046542128013189,-1.4044659117176213,-1.404284513863935,-1.404117722591832,-1.4039688480379666,-1.4038380694557815,-1.403723917382631,-1.4036243168985525,-1.4035371375373324,-1.403460426343799,-1.4033924872697916,-1.403331892753494,-1.403277463820232,-1.4032282367344289,-1.4031834269698555,-1.403142396150604,-1.4031046240912592,-1.4030696860604404,-1.4030372343616366,-1.4030069830232232,-1.4029786947006297,-1.4029521694731801,-1.4029272356174325,-1.4029037424577444,-1.4028815551701528,-1.4028605511966448,-1.4028406178441075,-1.4028216506791986,-1.402803552422637,-1.4027862321522897,-1.4027696047239746,-1.40275359038932,-1.4027381145963842,-1.4027231078780735,-1.4027085056140192,-1.4026942474407238,-1.4026802762968134,-1.402666537400564,-1.4026529775861396,-1.4026395452958524,-1.4026261913289433,-1.4026128703377023,-1.4025995429944031]
32x26 Array{Float64,2}:
  0.0320538   0.611253     0.0169603  -0.23702    â€¦   0.246159     0.00605958
 -0.406685    0.0342571    0.260762   -0.0363588     -0.10555      0.423553  
  0.391458    0.121623     0.0724992  -0.607261       0.26893      0.0310017 
  0.112635    8.78502e-5   0.139715    0.181917       0.0140803    0.199422  
 -0.845804   -0.673625    -0.549077   -0.616229      -0.0498418   -0.168202  
  0.250919    0.0149887    0.0475126  -0.0114753  â€¦  -0.184274    -0.987389  
  0.23726    -0.272572    -0.342739    0.368279      -0.59887      0.123726  
  0.100816   -0.0508735   -0.114822    0.19207        0.393175    -0.381932  
 -0.598326   -0.469706    -0.0289828   0.0332119      0.0575711   -0.0493238 
  0.156621   -0.350698    -0.034165    0.16618       -0.163359    -0.144995  
  â‹®                                               â‹±                â‹®         
  0.132963   -0.19484      0.520404   -0.315979       0.212348    -0.0955602 
 -0.494717   -0.268055    -0.011856   -0.494908      -0.238842     0.474881  
 -0.613396    0.029296    -0.577677   -0.599546   â€¦  -0.707078     0.462164  
 -0.601984   -0.291724     0.313863   -0.242293       0.00601323  -0.0198912 
  0.400841    0.176736    -0.142334   -0.343641       0.134274    -0.132326  
 -0.222363   -0.304265     0.0715192  -0.0308299      0.407439    -0.134832  
 -0.098598   -0.252226    -0.0889596   0.239021      -0.188032    -0.141419  
  0.127814    0.37787      0.0778766  -0.0109024  â€¦  -0.0507904   -0.0464092 
  0.272509    0.0445344   -0.292887    0.114591      -0.272798     0.173588  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402586
INFO: iteration 2, average log likelihood -1.402573
INFO: iteration 3, average log likelihood -1.402559
INFO: iteration 4, average log likelihood -1.402546
INFO: iteration 5, average log likelihood -1.402532
INFO: iteration 6, average log likelihood -1.402519
INFO: iteration 7, average log likelihood -1.402505
INFO: iteration 8, average log likelihood -1.402492
INFO: iteration 9, average log likelihood -1.402478
INFO: iteration 10, average log likelihood -1.402465
INFO: EM with 100000 data points 10 iterations avll -1.402465
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.773920e+05
      1       6.966485e+05      -2.807435e+05 |       32
      2       6.817132e+05      -1.493538e+04 |       32
      3       6.764625e+05      -5.250710e+03 |       32
      4       6.737101e+05      -2.752321e+03 |       32
      5       6.719812e+05      -1.728942e+03 |       32
      6       6.707807e+05      -1.200525e+03 |       32
      7       6.698831e+05      -8.975558e+02 |       32
      8       6.691297e+05      -7.534098e+02 |       32
      9       6.685333e+05      -5.963808e+02 |       32
     10       6.680656e+05      -4.676924e+02 |       32
     11       6.676525e+05      -4.131736e+02 |       32
     12       6.672958e+05      -3.566126e+02 |       32
     13       6.670092e+05      -2.866416e+02 |       32
     14       6.667528e+05      -2.564535e+02 |       32
     15       6.664933e+05      -2.594228e+02 |       32
     16       6.662320e+05      -2.612796e+02 |       32
     17       6.659869e+05      -2.451788e+02 |       32
     18       6.657926e+05      -1.942253e+02 |       32
     19       6.656271e+05      -1.655890e+02 |       32
     20       6.654774e+05      -1.497047e+02 |       32
     21       6.653453e+05      -1.320890e+02 |       32
     22       6.652262e+05      -1.190201e+02 |       32
     23       6.651106e+05      -1.156556e+02 |       32
     24       6.650037e+05      -1.068972e+02 |       32
     25       6.649093e+05      -9.439684e+01 |       32
     26       6.648222e+05      -8.704544e+01 |       32
     27       6.647469e+05      -7.536540e+01 |       32
     28       6.646773e+05      -6.957580e+01 |       32
     29       6.646130e+05      -6.430582e+01 |       32
     30       6.645526e+05      -6.041835e+01 |       32
     31       6.644927e+05      -5.984239e+01 |       32
     32       6.644256e+05      -6.716104e+01 |       32
     33       6.643711e+05      -5.443865e+01 |       32
     34       6.643261e+05      -4.503090e+01 |       32
     35       6.642828e+05      -4.326551e+01 |       32
     36       6.642366e+05      -4.621914e+01 |       32
     37       6.641826e+05      -5.397573e+01 |       32
     38       6.641245e+05      -5.816025e+01 |       32
     39       6.640726e+05      -5.188507e+01 |       32
     40       6.640149e+05      -5.767705e+01 |       32
     41       6.639632e+05      -5.174684e+01 |       32
     42       6.639138e+05      -4.939793e+01 |       32
     43       6.638693e+05      -4.444892e+01 |       32
     44       6.638285e+05      -4.084100e+01 |       32
     45       6.637900e+05      -3.851771e+01 |       32
     46       6.637601e+05      -2.989346e+01 |       32
     47       6.637310e+05      -2.904056e+01 |       32
     48       6.637058e+05      -2.521628e+01 |       32
     49       6.636865e+05      -1.934378e+01 |       32
     50       6.636659e+05      -2.061139e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 663665.8687295335)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413905
INFO: iteration 2, average log likelihood -1.409136
INFO: iteration 3, average log likelihood -1.407866
INFO: iteration 4, average log likelihood -1.406967
INFO: iteration 5, average log likelihood -1.406052
INFO: iteration 6, average log likelihood -1.405184
INFO: iteration 7, average log likelihood -1.404528
INFO: iteration 8, average log likelihood -1.404120
INFO: iteration 9, average log likelihood -1.403876
INFO: iteration 10, average log likelihood -1.403717
INFO: iteration 11, average log likelihood -1.403599
INFO: iteration 12, average log likelihood -1.403504
INFO: iteration 13, average log likelihood -1.403423
INFO: iteration 14, average log likelihood -1.403352
INFO: iteration 15, average log likelihood -1.403287
INFO: iteration 16, average log likelihood -1.403228
INFO: iteration 17, average log likelihood -1.403174
INFO: iteration 18, average log likelihood -1.403124
INFO: iteration 19, average log likelihood -1.403077
INFO: iteration 20, average log likelihood -1.403032
INFO: iteration 21, average log likelihood -1.402990
INFO: iteration 22, average log likelihood -1.402950
INFO: iteration 23, average log likelihood -1.402912
INFO: iteration 24, average log likelihood -1.402876
INFO: iteration 25, average log likelihood -1.402842
INFO: iteration 26, average log likelihood -1.402809
INFO: iteration 27, average log likelihood -1.402778
INFO: iteration 28, average log likelihood -1.402749
INFO: iteration 29, average log likelihood -1.402721
INFO: iteration 30, average log likelihood -1.402694
INFO: iteration 31, average log likelihood -1.402669
INFO: iteration 32, average log likelihood -1.402645
INFO: iteration 33, average log likelihood -1.402622
INFO: iteration 34, average log likelihood -1.402601
INFO: iteration 35, average log likelihood -1.402581
INFO: iteration 36, average log likelihood -1.402562
INFO: iteration 37, average log likelihood -1.402544
INFO: iteration 38, average log likelihood -1.402527
INFO: iteration 39, average log likelihood -1.402510
INFO: iteration 40, average log likelihood -1.402495
INFO: iteration 41, average log likelihood -1.402480
INFO: iteration 42, average log likelihood -1.402466
INFO: iteration 43, average log likelihood -1.402452
INFO: iteration 44, average log likelihood -1.402439
INFO: iteration 45, average log likelihood -1.402426
INFO: iteration 46, average log likelihood -1.402414
INFO: iteration 47, average log likelihood -1.402402
INFO: iteration 48, average log likelihood -1.402391
INFO: iteration 49, average log likelihood -1.402380
INFO: iteration 50, average log likelihood -1.402369
INFO: EM with 100000 data points 50 iterations avll -1.402369
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.0176021  -0.0161016  -0.0645521  â€¦  -0.190423   -0.428215    0.632412 
  0.0249207  -0.0525893   0.55746       -0.0944422   0.322621   -0.0765344
  0.0908502  -0.374106    0.445699      -0.672794    0.0744164   0.149735 
  0.344132    0.0996356  -0.199241      -0.0272485  -0.0498854  -0.303927 
 -0.627915   -0.260175   -0.152307      -0.219793   -0.0737093  -0.0824256
 -0.568977    0.291089    0.338213   â€¦   0.168355   -0.176719    0.0840898
  0.0623177   0.162581   -0.290486       0.455347   -0.152574    0.221613 
 -0.0469754  -0.0306943   0.11849        0.052734    0.143518   -0.0827011
 -0.437544   -0.0190454  -0.201229      -0.260104   -0.3195      0.0838391
 -0.0147292  -0.326072   -0.145946       0.137511   -0.0982102  -0.0647201
  â‹®                                  â‹±                           â‹®        
  0.435444    0.181224   -0.544687       0.144404   -0.128485    0.363658 
 -0.0975538  -0.331253    0.256433      -0.40153    -0.131158    0.0318764
  0.0259465  -0.0538698  -0.0267479  â€¦  -0.123548   -0.356998   -0.11431  
  0.466418    0.0283975  -0.368286       0.20156    -0.551283    0.0619195
 -0.109665    0.391455   -0.25758        0.819521    0.119878   -0.242994 
 -0.157251    0.0860318   0.132839      -0.101297    0.557285    0.0805749
  0.0899761   0.135399    0.507786      -0.0675878   0.589039    0.64869  
  0.101378    0.116983    0.269553   â€¦  -0.334455    0.0704929   0.160694 
 -0.306132    0.458597   -0.749316       0.0244627  -0.674923    0.589461 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.402359
INFO: iteration 2, average log likelihood -1.402348
INFO: iteration 3, average log likelihood -1.402338
INFO: iteration 4, average log likelihood -1.402329
INFO: iteration 5, average log likelihood -1.402319
INFO: iteration 6, average log likelihood -1.402310
INFO: iteration 7, average log likelihood -1.402301
INFO: iteration 8, average log likelihood -1.402292
INFO: iteration 9, average log likelihood -1.402284
INFO: iteration 10, average log likelihood -1.402275
INFO: EM with 100000 data points 10 iterations avll -1.402275
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
