>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.1
INFO: Installing FileIO v0.2.0
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.0
INFO: Installing JLD v0.6.7
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.5.2
INFO: Installing Rmath v0.1.5
INFO: Installing SHA v0.3.0
INFO: Installing ScikitLearnBase v0.2.1
INFO: Installing StatsBase v0.11.1
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-105-generic #152-Ubuntu SMP Fri Dec 2 15:37:11 UTC 2016 x86_64 x86_64
Memory: 2.9392738342285156 GB (658.07421875 MB free)
Uptime: 26904.0 sec
Load Avg:  1.09228515625  1.017578125  1.02392578125
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3490 MHz    1285894 s       6000 s     110885 s    1017184 s         79 s
#2  3490 MHz     839276 s        935 s      98897 s    1646087 s          3 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.8.0
19 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.5
 - Distances                     0.3.2
 - Distributions                 0.11.1
 - FileIO                        0.2.0
 - HDF5                          0.7.0
 - JLD                           0.6.7
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.0.5
 - PDMats                        0.5.2
 - Rmath                         0.1.5
 - SHA                           0.3.0
 - ScikitLearnBase               0.2.1
 - StatsBase                     0.11.1
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-5.063362487806747e6,[78943.36345363452,21056.63654636548],
[3287.96415239037 1705.6567602473842 2690.1455849891254
 -2898.7234979391014 -1995.6616588100223 -2359.210192739334],

[
[80815.08118458893 -587.9170885464129 -1953.807946002041
 -587.9170885464131 93741.25456722011 7610.927459585753
 -1953.8079460020408 7610.927459585753 83185.29502668502],

[19215.233801350732 430.66426119233444 1669.5220644402252
 430.6642611923343 5125.005175445812 -8104.625150037496
 1669.5220644402252 -8104.625150037496 16767.925394243615]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.927097e+03
      1       1.134985e+03      -7.921126e+02 |        6
      2       1.085561e+03      -4.942315e+01 |        5
      3       1.008180e+03      -7.738094e+01 |        2
      4       9.529379e+02      -5.524254e+01 |        0
      5       9.529379e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 952.9379040875665)
INFO: K-means with 272 data points using 5 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.071986
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.866177
INFO: iteration 2, lowerbound -3.776932
INFO: iteration 3, lowerbound -3.688668
INFO: iteration 4, lowerbound -3.587589
INFO: iteration 5, lowerbound -3.483490
INFO: iteration 6, lowerbound -3.390556
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -3.308028
INFO: iteration 8, lowerbound -3.232075
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -3.145605
INFO: iteration 10, lowerbound -3.046610
INFO: iteration 11, lowerbound -2.959764
INFO: iteration 12, lowerbound -2.890318
INFO: iteration 13, lowerbound -2.844533
INFO: dropping number of Gaussions to 4
INFO: iteration 14, lowerbound -2.816458
INFO: iteration 15, lowerbound -2.802666
INFO: dropping number of Gaussions to 3
INFO: iteration 16, lowerbound -2.798115
INFO: iteration 17, lowerbound -2.793516
INFO: iteration 18, lowerbound -2.792682
INFO: iteration 19, lowerbound -2.791907
INFO: iteration 20, lowerbound -2.791176
INFO: iteration 21, lowerbound -2.790478
INFO: iteration 22, lowerbound -2.789800
INFO: iteration 23, lowerbound -2.789127
INFO: iteration 24, lowerbound -2.788438
INFO: iteration 25, lowerbound -2.787702
INFO: iteration 26, lowerbound -2.786876
INFO: iteration 27, lowerbound -2.785891
INFO: iteration 28, lowerbound -2.784646
INFO: iteration 29, lowerbound -2.782991
INFO: iteration 30, lowerbound -2.780698
INFO: iteration 31, lowerbound -2.777437
INFO: iteration 32, lowerbound -2.772733
INFO: iteration 33, lowerbound -2.765934
INFO: iteration 34, lowerbound -2.756187
INFO: iteration 35, lowerbound -2.742467
INFO: iteration 36, lowerbound -2.723688
INFO: iteration 37, lowerbound -2.698928
INFO: iteration 38, lowerbound -2.667741
INFO: iteration 39, lowerbound -2.630468
INFO: iteration 40, lowerbound -2.588429
INFO: iteration 41, lowerbound -2.543875
INFO: iteration 42, lowerbound -2.499563
INFO: iteration 43, lowerbound -2.457887
INFO: iteration 44, lowerbound -2.420006
INFO: iteration 45, lowerbound -2.385724
INFO: iteration 46, lowerbound -2.354620
INFO: iteration 47, lowerbound -2.328254
INFO: iteration 48, lowerbound -2.311274
INFO: iteration 49, lowerbound -2.307842
INFO: dropping number of Gaussions to 2
INFO: iteration 50, lowerbound -2.302917
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.302917
[Fri 23 Dec 2016 12:50:09 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Fri 23 Dec 2016 12:50:10 PM UTC: K-means with 272 data points using 5 iterations
11.3 data points per parameter
,Fri 23 Dec 2016 12:50:12 PM UTC: EM with 272 data points 0 iterations avll -2.071986
5.8 data points per parameter
,Fri 23 Dec 2016 12:50:13 PM UTC: GMM converted to Variational GMM
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 1, lowerbound -3.866177
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 2, lowerbound -3.776932
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 3, lowerbound -3.688668
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 4, lowerbound -3.587589
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 5, lowerbound -3.483490
,Fri 23 Dec 2016 12:50:15 PM UTC: iteration 6, lowerbound -3.390556
,Fri 23 Dec 2016 12:50:16 PM UTC: dropping number of Gaussions to 7
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 7, lowerbound -3.308028
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 8, lowerbound -3.232075
,Fri 23 Dec 2016 12:50:16 PM UTC: dropping number of Gaussions to 5
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 9, lowerbound -3.145605
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 10, lowerbound -3.046610
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 11, lowerbound -2.959764
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 12, lowerbound -2.890318
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 13, lowerbound -2.844533
,Fri 23 Dec 2016 12:50:16 PM UTC: dropping number of Gaussions to 4
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 14, lowerbound -2.816458
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 15, lowerbound -2.802666
,Fri 23 Dec 2016 12:50:16 PM UTC: dropping number of Gaussions to 3
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 16, lowerbound -2.798115
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 17, lowerbound -2.793516
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 18, lowerbound -2.792682
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 19, lowerbound -2.791907
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 20, lowerbound -2.791176
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 21, lowerbound -2.790478
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 22, lowerbound -2.789800
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 23, lowerbound -2.789127
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 24, lowerbound -2.788438
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 25, lowerbound -2.787702
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 26, lowerbound -2.786876
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 27, lowerbound -2.785891
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 28, lowerbound -2.784646
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 29, lowerbound -2.782991
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 30, lowerbound -2.780698
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 31, lowerbound -2.777437
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 32, lowerbound -2.772733
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 33, lowerbound -2.765934
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 34, lowerbound -2.756187
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 35, lowerbound -2.742467
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 36, lowerbound -2.723688
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 37, lowerbound -2.698928
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 38, lowerbound -2.667741
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 39, lowerbound -2.630468
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 40, lowerbound -2.588429
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 41, lowerbound -2.543875
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 42, lowerbound -2.499563
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 43, lowerbound -2.457887
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 44, lowerbound -2.420006
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 45, lowerbound -2.385724
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 46, lowerbound -2.354620
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 47, lowerbound -2.328254
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 48, lowerbound -2.311274
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 49, lowerbound -2.307842
,Fri 23 Dec 2016 12:50:16 PM UTC: dropping number of Gaussions to 2
,Fri 23 Dec 2016 12:50:16 PM UTC: iteration 50, lowerbound -2.302917
,Fri 23 Dec 2016 12:50:16 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.302917
]
Î± = [95.93897325605583,178.06102674394427]
Î² = [95.93897325605583,178.06102674394427]
m = [2.000095147490775 53.851295326912584
 4.250171634827178 79.28496356549006]
Î½ = [97.93897325605583,180.06102674394427]
W = [
[0.3761000304879531 -0.008955797505249418
 0.0 0.012749334396020717],

[0.18402396137498556 -0.007645747624316644
 0.0 0.008579311597402751]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9778833107398907
avll from llpg:  -0.9778833107398877
avll direct:     -0.9778833107398877
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9924787113318684
avll from llpg:  -0.9924787113318682
avll direct:     -0.9924787113318682
sum posterior: 100000.0
32x26 Array{Float64,2}:
 -0.0218279   -0.0947829   -0.0708577   â€¦   0.0577435   -0.0691133
 -0.0250941    0.0187391   -0.04248        -0.0569432    0.0841732
 -0.124434     0.148429    -0.0893953      -0.223797    -0.0379031
 -0.0213297    0.0528079    0.0559201      -0.0238695    0.0243944
  0.207291    -0.106107    -0.102625       -0.110842     0.0184625
 -0.0512386   -0.214078     0.0165545   â€¦  -0.0987669   -0.11776  
  0.0256303    0.0291573   -0.0881986       0.0424697   -0.0713738
 -0.0879483    0.0901318    0.263712       -0.0286705    0.0181331
  0.00491747  -0.111636    -0.0382507      -0.241856     0.0114176
  0.0985252    0.134686    -0.0355395       0.0392678   -0.0811172
  â‹®                                     â‹±                â‹®        
 -0.236925     0.0637855   -0.0958519      -0.0123371    0.104458 
  0.0117895   -0.0103776    0.031118        0.0813573   -0.0318433
  0.147203     0.00607743   0.225979    â€¦  -0.0297047   -0.110174 
 -0.0762256   -0.289538    -0.00458429      0.261186     0.0493094
 -0.00173298   0.138044    -0.0581401      -0.00155254   0.0463524
  0.0519626    0.0683689   -0.0120495      -0.0741539   -0.0874501
  0.0765327   -0.0137738   -0.00255777     -0.0282385   -0.0629212
  0.137182    -0.0107094   -0.16375     â€¦  -0.0626527    0.332936 
  0.0985291    0.072031    -0.117218       -0.0586385    0.0132036kind diag, method split
0: avll = -1.4308169622765337
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.430891
INFO: iteration 2, average log likelihood -1.430802
INFO: iteration 3, average log likelihood -1.430068
INFO: iteration 4, average log likelihood -1.422686
INFO: iteration 5, average log likelihood -1.404625
INFO: iteration 6, average log likelihood -1.397792
INFO: iteration 7, average log likelihood -1.396415
INFO: iteration 8, average log likelihood -1.395895
INFO: iteration 9, average log likelihood -1.395693
INFO: iteration 10, average log likelihood -1.395608
INFO: iteration 11, average log likelihood -1.395568
INFO: iteration 12, average log likelihood -1.395547
INFO: iteration 13, average log likelihood -1.395537
INFO: iteration 14, average log likelihood -1.395530
INFO: iteration 15, average log likelihood -1.395526
INFO: iteration 16, average log likelihood -1.395523
INFO: iteration 17, average log likelihood -1.395521
INFO: iteration 18, average log likelihood -1.395519
INFO: iteration 19, average log likelihood -1.395518
INFO: iteration 20, average log likelihood -1.395517
INFO: iteration 21, average log likelihood -1.395516
INFO: iteration 22, average log likelihood -1.395515
INFO: iteration 23, average log likelihood -1.395514
INFO: iteration 24, average log likelihood -1.395513
INFO: iteration 25, average log likelihood -1.395512
INFO: iteration 26, average log likelihood -1.395511
INFO: iteration 27, average log likelihood -1.395511
INFO: iteration 28, average log likelihood -1.395510
INFO: iteration 29, average log likelihood -1.395510
INFO: iteration 30, average log likelihood -1.395509
INFO: iteration 31, average log likelihood -1.395509
INFO: iteration 32, average log likelihood -1.395508
INFO: iteration 33, average log likelihood -1.395508
INFO: iteration 34, average log likelihood -1.395508
INFO: iteration 35, average log likelihood -1.395507
INFO: iteration 36, average log likelihood -1.395507
INFO: iteration 37, average log likelihood -1.395507
INFO: iteration 38, average log likelihood -1.395507
INFO: iteration 39, average log likelihood -1.395506
INFO: iteration 40, average log likelihood -1.395506
INFO: iteration 41, average log likelihood -1.395506
INFO: iteration 42, average log likelihood -1.395506
INFO: iteration 43, average log likelihood -1.395506
INFO: iteration 44, average log likelihood -1.395505
INFO: iteration 45, average log likelihood -1.395505
INFO: iteration 46, average log likelihood -1.395505
INFO: iteration 47, average log likelihood -1.395505
INFO: iteration 48, average log likelihood -1.395505
INFO: iteration 49, average log likelihood -1.395505
INFO: iteration 50, average log likelihood -1.395505
INFO: EM with 100000 data points 50 iterations avll -1.395505
952.4 data points per parameter
1: avll = [-1.4308911204231147,-1.4308015560046041,-1.430068461878001,-1.422685877104412,-1.4046245311770629,-1.3977922537072465,-1.3964153300029372,-1.395894919744629,-1.3956933933350737,-1.3956075198966498,-1.395567525885913,-1.395547411382293,-1.395536510201012,-1.395530118654107,-1.3955260422922797,-1.3955232115537166,-1.395521086049847,-1.395519383758991,-1.395517952798292,-1.3955167087099747,-1.3955156028959277,-1.3955146062836505,-1.3955137006410603,-1.395512873841971,-1.3955121172351146,-1.3955114241675355,-1.3955107891574468,-1.3955102074377335,-1.3955096747110074,-1.3955091870234906,-1.395508740703359,-1.3955083323320043,-1.395507958730379,-1.395507616950853,-1.3955073042698416,-1.395507018179227,-1.3955067563760817,-1.395506516750913,-1.3955062973749321,-1.3955060964868873,-1.3955059124799358,-1.3955057438889074,-1.3955055893782093,-1.395505447730503,-1.3955053178362309,-1.3955051986839877,-1.3955050893517247,-1.3955049889987299,-1.3955048968583326,-1.395504812231269]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.395625
INFO: iteration 2, average log likelihood -1.395488
INFO: iteration 3, average log likelihood -1.394887
INFO: iteration 4, average log likelihood -1.389708
INFO: iteration 5, average log likelihood -1.376130
INFO: iteration 6, average log likelihood -1.367740
INFO: iteration 7, average log likelihood -1.364458
INFO: iteration 8, average log likelihood -1.362557
INFO: iteration 9, average log likelihood -1.361352
INFO: iteration 10, average log likelihood -1.360580
INFO: iteration 11, average log likelihood -1.360012
INFO: iteration 12, average log likelihood -1.359527
INFO: iteration 13, average log likelihood -1.359082
INFO: iteration 14, average log likelihood -1.358690
INFO: iteration 15, average log likelihood -1.358384
INFO: iteration 16, average log likelihood -1.358155
INFO: iteration 17, average log likelihood -1.357984
INFO: iteration 18, average log likelihood -1.357852
INFO: iteration 19, average log likelihood -1.357744
INFO: iteration 20, average log likelihood -1.357659
INFO: iteration 21, average log likelihood -1.357591
INFO: iteration 22, average log likelihood -1.357532
INFO: iteration 23, average log likelihood -1.357478
INFO: iteration 24, average log likelihood -1.357423
INFO: iteration 25, average log likelihood -1.357363
INFO: iteration 26, average log likelihood -1.357295
INFO: iteration 27, average log likelihood -1.357220
INFO: iteration 28, average log likelihood -1.357139
INFO: iteration 29, average log likelihood -1.357054
INFO: iteration 30, average log likelihood -1.356970
INFO: iteration 31, average log likelihood -1.356889
INFO: iteration 32, average log likelihood -1.356814
INFO: iteration 33, average log likelihood -1.356744
INFO: iteration 34, average log likelihood -1.356677
INFO: iteration 35, average log likelihood -1.356611
INFO: iteration 36, average log likelihood -1.356544
INFO: iteration 37, average log likelihood -1.356478
INFO: iteration 38, average log likelihood -1.356410
INFO: iteration 39, average log likelihood -1.356340
INFO: iteration 40, average log likelihood -1.356268
INFO: iteration 41, average log likelihood -1.356193
INFO: iteration 42, average log likelihood -1.356117
INFO: iteration 43, average log likelihood -1.356042
INFO: iteration 44, average log likelihood -1.355968
INFO: iteration 45, average log likelihood -1.355895
INFO: iteration 46, average log likelihood -1.355826
INFO: iteration 47, average log likelihood -1.355761
INFO: iteration 48, average log likelihood -1.355701
INFO: iteration 49, average log likelihood -1.355648
INFO: iteration 50, average log likelihood -1.355601
INFO: EM with 100000 data points 50 iterations avll -1.355601
473.9 data points per parameter
2: avll = [-1.3956247886510045,-1.3954878942948337,-1.394887103519222,-1.389708338089443,-1.3761301210054206,-1.3677400705028382,-1.3644579687204068,-1.3625571078633,-1.3613515420728044,-1.3605800159222927,-1.3600119406716036,-1.359527342244583,-1.3590824333856166,-1.358690461769906,-1.3583841485564596,-1.3581547188096135,-1.3579844436382478,-1.3578520921438206,-1.357744452856033,-1.357658882343758,-1.357590636911309,-1.35753199298494,-1.3574776021698531,-1.357422710394273,-1.3573627241226294,-1.3572948016494832,-1.3572196139273136,-1.3571388145502266,-1.3570544170849677,-1.3569698656386875,-1.3568891077845493,-1.3568139192868942,-1.3567437268688718,-1.356676766403983,-1.3566106897118675,-1.3565444503019453,-1.356477769712192,-1.35640992144435,-1.3563400386371127,-1.356267667976722,-1.3561929225109561,-1.3561170508356977,-1.3560416735855687,-1.355967537390605,-1.3558952679515501,-1.3558259226001477,-1.3557608312339038,-1.3557013479591247,-1.3556478772433447,-1.3556006372826193]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.355700
INFO: iteration 2, average log likelihood -1.355518
INFO: iteration 3, average log likelihood -1.354955
INFO: iteration 4, average log likelihood -1.350301
INFO: iteration 5, average log likelihood -1.335177
INFO: iteration 6, average log likelihood -1.321041
INFO: iteration 7, average log likelihood -1.315171
INFO: iteration 8, average log likelihood -1.312355
INFO: iteration 9, average log likelihood -1.310459
INFO: iteration 10, average log likelihood -1.308899
INFO: iteration 11, average log likelihood -1.307559
INFO: iteration 12, average log likelihood -1.306442
INFO: iteration 13, average log likelihood -1.305598
INFO: iteration 14, average log likelihood -1.305026
INFO: iteration 15, average log likelihood -1.304642
INFO: iteration 16, average log likelihood -1.304369
INFO: iteration 17, average log likelihood -1.304150
INFO: iteration 18, average log likelihood -1.303963
INFO: iteration 19, average log likelihood -1.303810
INFO: iteration 20, average log likelihood -1.303697
INFO: iteration 21, average log likelihood -1.303618
INFO: iteration 22, average log likelihood -1.303562
INFO: iteration 23, average log likelihood -1.303521
INFO: iteration 24, average log likelihood -1.303490
INFO: iteration 25, average log likelihood -1.303465
INFO: iteration 26, average log likelihood -1.303444
INFO: iteration 27, average log likelihood -1.303425
INFO: iteration 28, average log likelihood -1.303408
INFO: iteration 29, average log likelihood -1.303393
INFO: iteration 30, average log likelihood -1.303379
INFO: iteration 31, average log likelihood -1.303365
INFO: iteration 32, average log likelihood -1.303351
INFO: iteration 33, average log likelihood -1.303337
INFO: iteration 34, average log likelihood -1.303322
INFO: iteration 35, average log likelihood -1.303308
INFO: iteration 36, average log likelihood -1.303293
INFO: iteration 37, average log likelihood -1.303277
INFO: iteration 38, average log likelihood -1.303259
INFO: iteration 39, average log likelihood -1.303241
INFO: iteration 40, average log likelihood -1.303217
INFO: iteration 41, average log likelihood -1.303181
INFO: iteration 42, average log likelihood -1.303122
INFO: iteration 43, average log likelihood -1.303036
INFO: iteration 44, average log likelihood -1.302931
INFO: iteration 45, average log likelihood -1.302828
INFO: iteration 46, average log likelihood -1.302765
INFO: iteration 47, average log likelihood -1.302732
INFO: iteration 48, average log likelihood -1.302716
INFO: iteration 49, average log likelihood -1.302708
INFO: iteration 50, average log likelihood -1.302703
INFO: EM with 100000 data points 50 iterations avll -1.302703
236.4 data points per parameter
3: avll = [-1.3556996076667978,-1.3555177074977212,-1.354955163407958,-1.3503008628083537,-1.3351772529214643,-1.3210408807488694,-1.3151708121566528,-1.3123551879520008,-1.3104587193461603,-1.308899145145004,-1.307559024985996,-1.3064421273120654,-1.305598410873208,-1.3050260640455078,-1.3046423132413583,-1.3043692700190839,-1.304150245282667,-1.3039625679991884,-1.30381034367113,-1.3036972685788708,-1.3036175255579956,-1.3035617247414708,-1.3035211774857534,-1.30349004932425,-1.3034648807338216,-1.3034436532995475,-1.3034251298511725,-1.3034084813714446,-1.303393114541003,-1.3033785864894125,-1.3033645320622491,-1.3033506316903951,-1.3033366552889694,-1.3033224781694637,-1.3033079486339707,-1.3032927869982376,-1.3032766870596673,-1.30325949704575,-1.3032406880856657,-1.303217347062459,-1.3031812816250492,-1.3031215389243733,-1.3030364749025491,-1.3029313987334201,-1.302828157612065,-1.3027647356415333,-1.3027324463314491,-1.302716097525036,-1.3027078858558179,-1.3027034170432916]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.302927
INFO: iteration 2, average log likelihood -1.302699
INFO: iteration 3, average log likelihood -1.302064
INFO: iteration 4, average log likelihood -1.294367
INFO: iteration 5, average log likelihood -1.262485
WARNING: Variances had to be floored 8
INFO: iteration 6, average log likelihood -1.231916
INFO: iteration 7, average log likelihood -1.235703
INFO: iteration 8, average log likelihood -1.223824
WARNING: Variances had to be floored 8
INFO: iteration 9, average log likelihood -1.214774
WARNING: Variances had to be floored 3
INFO: iteration 10, average log likelihood -1.226676
INFO: iteration 11, average log likelihood -1.222686
WARNING: Variances had to be floored 8
INFO: iteration 12, average log likelihood -1.210854
INFO: iteration 13, average log likelihood -1.220461
WARNING: Variances had to be floored 10
INFO: iteration 14, average log likelihood -1.209356
WARNING: Variances had to be floored 8
INFO: iteration 15, average log likelihood -1.214797
INFO: iteration 16, average log likelihood -1.222437
WARNING: Variances had to be floored 3 14
INFO: iteration 17, average log likelihood -1.209587
WARNING: Variances had to be floored 8
INFO: iteration 18, average log likelihood -1.217620
INFO: iteration 19, average log likelihood -1.220506
WARNING: Variances had to be floored 10
INFO: iteration 20, average log likelihood -1.207899
WARNING: Variances had to be floored 8 14
INFO: iteration 21, average log likelihood -1.212178
INFO: iteration 22, average log likelihood -1.231494
INFO: iteration 23, average log likelihood -1.215112
WARNING: Variances had to be floored 8
INFO: iteration 24, average log likelihood -1.203544
WARNING: Variances had to be floored 1 14
INFO: iteration 25, average log likelihood -1.211623
WARNING: Variances had to be floored 3 10
INFO: iteration 26, average log likelihood -1.222447
WARNING: Variances had to be floored 8
INFO: iteration 27, average log likelihood -1.225960
INFO: iteration 28, average log likelihood -1.227868
WARNING: Variances had to be floored 14
INFO: iteration 29, average log likelihood -1.213680
WARNING: Variances had to be floored 8
INFO: iteration 30, average log likelihood -1.214506
INFO: iteration 31, average log likelihood -1.219616
WARNING: Variances had to be floored 4 10
INFO: iteration 32, average log likelihood -1.206271
WARNING: Variances had to be floored 8
INFO: iteration 33, average log likelihood -1.225243
INFO: iteration 34, average log likelihood -1.230642
WARNING: Variances had to be floored 14
INFO: iteration 35, average log likelihood -1.215967
WARNING: Variances had to be floored 8
INFO: iteration 36, average log likelihood -1.215697
INFO: iteration 37, average log likelihood -1.220293
WARNING: Variances had to be floored 10
INFO: iteration 38, average log likelihood -1.208547
WARNING: Variances had to be floored 8
INFO: iteration 39, average log likelihood -1.213758
INFO: iteration 40, average log likelihood -1.221276
WARNING: Variances had to be floored 3 14
INFO: iteration 41, average log likelihood -1.208758
WARNING: Variances had to be floored 8
INFO: iteration 42, average log likelihood -1.216469
INFO: iteration 43, average log likelihood -1.220249
WARNING: Variances had to be floored 10
INFO: iteration 44, average log likelihood -1.208401
WARNING: Variances had to be floored 8 14
INFO: iteration 45, average log likelihood -1.212946
INFO: iteration 46, average log likelihood -1.232212
INFO: iteration 47, average log likelihood -1.216207
WARNING: Variances had to be floored 1 8
INFO: iteration 48, average log likelihood -1.204879
INFO: iteration 49, average log likelihood -1.223647
WARNING: Variances had to be floored 10 14
INFO: iteration 50, average log likelihood -1.208837
INFO: EM with 100000 data points 50 iterations avll -1.208837
118.1 data points per parameter
4: avll = [-1.3029269583256744,-1.3026994358223516,-1.3020643419753148,-1.2943669981621673,-1.2624847514268835,-1.2319160460932594,-1.2357031777634244,-1.2238235340362382,-1.2147738334910678,-1.2266759358970216,-1.2226863976076416,-1.210853870661368,-1.2204608217460051,-1.2093561757961453,-1.2147970586756416,-1.2224372141749276,-1.2095868703968249,-1.2176204993732,-1.2205059873426372,-1.2078989428706126,-1.2121776158371684,-1.2314944498686364,-1.2151118699207577,-1.2035444142355498,-1.211622687715486,-1.2224469343497562,-1.225959766115436,-1.2278677142076182,-1.213679873028812,-1.2145060820918467,-1.2196163456360165,-1.2062710176082847,-1.2252429356985803,-1.2306416860542464,-1.2159669685767889,-1.2156967656500266,-1.2202928585201824,-1.2085465889562481,-1.2137580557708454,-1.221276175123018,-1.2087583110876783,-1.2164693446466082,-1.2202489337040483,-1.2084009557556565,-1.212946352926032,-1.2322122200442447,-1.2162066687999293,-1.204878798474857,-1.22364722791968,-1.208836615521626]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 15 16
INFO: iteration 1, average log likelihood -1.225673
WARNING: Variances had to be floored 15 16
INFO: iteration 2, average log likelihood -1.213554
WARNING: Variances had to be floored 15 16
INFO: iteration 3, average log likelihood -1.206118
WARNING: Variances had to be floored 5 6 15 16 28
INFO: iteration 4, average log likelihood -1.184696
WARNING: Variances had to be floored 7 15 16 20 24 27
INFO: iteration 5, average log likelihood -1.147169
WARNING: Variances had to be floored 15 16 19 25
INFO: iteration 6, average log likelihood -1.149371
WARNING: Variances had to be floored 1 5 6 7 15 16 24
INFO: iteration 7, average log likelihood -1.117678
WARNING: Variances had to be floored 15 16 25 26 27
INFO: iteration 8, average log likelihood -1.111078
WARNING: Variances had to be floored 7 15 16 24
INFO: iteration 9, average log likelihood -1.112080
WARNING: Variances had to be floored 5 6 15 16 19
INFO: iteration 10, average log likelihood -1.101900
WARNING: Variances had to be floored 1 7 15 16 24 25 27
INFO: iteration 11, average log likelihood -1.085416
WARNING: Variances had to be floored 5 6 15 16 26
INFO: iteration 12, average log likelihood -1.109950
WARNING: Variances had to be floored 7 15 16 24 25
INFO: iteration 13, average log likelihood -1.085901
WARNING: Variances had to be floored 5 6 15 16 19 27
INFO: iteration 14, average log likelihood -1.089268
WARNING: Variances had to be floored 1 7 15 16 24 25 26
INFO: iteration 15, average log likelihood -1.093488
WARNING: Variances had to be floored 5 6 15 16
INFO: iteration 16, average log likelihood -1.110666
WARNING: Variances had to be floored 7 15 16 24 27
INFO: iteration 17, average log likelihood -1.082214
WARNING: Variances had to be floored 5 6 15 16 19 25
INFO: iteration 18, average log likelihood -1.094158
WARNING: Variances had to be floored 1 7 15 16 24 26
INFO: iteration 19, average log likelihood -1.089165
WARNING: Variances had to be floored 5 6 15 16 25 27
INFO: iteration 20, average log likelihood -1.101793
WARNING: Variances had to be floored 7 15 16 24
INFO: iteration 21, average log likelihood -1.093037
WARNING: Variances had to be floored 5 6 15 16 19 25 26
INFO: iteration 22, average log likelihood -1.083495
WARNING: Variances had to be floored 1 7 15 16 24 27
INFO: iteration 23, average log likelihood -1.094046
WARNING: Variances had to be floored 5 6 15 16
INFO: iteration 24, average log likelihood -1.105691
WARNING: Variances had to be floored 3 7 15 16 24 25 27
INFO: iteration 25, average log likelihood -1.057223
WARNING: Variances had to be floored 1 5 6 15 16 19 26
INFO: iteration 26, average log likelihood -1.093213
WARNING: Variances had to be floored 7 15 16 24 25
INFO: iteration 27, average log likelihood -1.092544
WARNING: Variances had to be floored 5 6 15 16 27
INFO: iteration 28, average log likelihood -1.082686
WARNING: Variances had to be floored 1 3 7 15 16 24 25 26
INFO: iteration 29, average log likelihood -1.062991
WARNING: Variances had to be floored 5 6 15 16 19 27
INFO: iteration 30, average log likelihood -1.099691
WARNING: Variances had to be floored 7 15 16 24
INFO: iteration 31, average log likelihood -1.097936
WARNING: Variances had to be floored 5 6 15 16 25
INFO: iteration 32, average log likelihood -1.076511
WARNING: Variances had to be floored 1 3 7 15 16 24 26 27
INFO: iteration 33, average log likelihood -1.055165
WARNING: Variances had to be floored 5 6 15 16 19 25
INFO: iteration 34, average log likelihood -1.104540
WARNING: Variances had to be floored 7 15 16 24
INFO: iteration 35, average log likelihood -1.089096
WARNING: Variances had to be floored 5 6 15 16 25 26 27
INFO: iteration 36, average log likelihood -1.072941
WARNING: Variances had to be floored 1 3 7 15 16 24
INFO: iteration 37, average log likelihood -1.078405
WARNING: Variances had to be floored 5 6 15 16 19
INFO: iteration 38, average log likelihood -1.095767
WARNING: Variances had to be floored 7 15 16 24 25 27
INFO: iteration 39, average log likelihood -1.076170
WARNING: Variances had to be floored 5 6 15 16 26
INFO: iteration 40, average log likelihood -1.090657
WARNING: Variances had to be floored 1 3 7 15 16 24 25
INFO: iteration 41, average log likelihood -1.063320
WARNING: Variances had to be floored 5 6 15 16 19 27
INFO: iteration 42, average log likelihood -1.089472
WARNING: Variances had to be floored 7 15 16 24 25 26
INFO: iteration 43, average log likelihood -1.087750
WARNING: Variances had to be floored 5 6 15 16 27
INFO: iteration 44, average log likelihood -1.091245
WARNING: Variances had to be floored 1 3 7 15 16 24
INFO: iteration 45, average log likelihood -1.072935
WARNING: Variances had to be floored 5 6 15 16 19 25
INFO: iteration 46, average log likelihood -1.084613
WARNING: Variances had to be floored 7 15 16 24 26 27
INFO: iteration 47, average log likelihood -1.079489
WARNING: Variances had to be floored 5 6 15 16 25
INFO: iteration 48, average log likelihood -1.095591
WARNING: Variances had to be floored 1 3 7 15 16 24
INFO: iteration 49, average log likelihood -1.063120
WARNING: Variances had to be floored 5 6 15 16 19 25 26 27
INFO: iteration 50, average log likelihood -1.081375
INFO: EM with 100000 data points 50 iterations avll -1.081375
59.0 data points per parameter
5: avll = [-1.2256734692365094,-1.2135537134520287,-1.2061178570897069,-1.1846958546858075,-1.1471691304834803,-1.14937133995477,-1.1176776396353298,-1.1110777266857035,-1.1120802563090628,-1.1018999372986447,-1.0854155088673212,-1.1099501555324862,-1.0859005909079076,-1.0892679435583694,-1.0934884321608913,-1.110666354844841,-1.0822143965206994,-1.0941580641758175,-1.0891651984657118,-1.1017928584981622,-1.0930369504212465,-1.083495465315801,-1.094046096753934,-1.1056908818278208,-1.057222558576224,-1.093212786194966,-1.092544218276329,-1.0826862729115385,-1.0629910545210697,-1.0996912883060133,-1.0979355258029648,-1.076510645427764,-1.0551652816708,-1.1045402128193904,-1.089095820521888,-1.0729406773516115,-1.0784052888582758,-1.0957669747368086,-1.0761702566355185,-1.0906565172128881,-1.0633198259634937,-1.0894719769993253,-1.0877495999767108,-1.0912452640266312,-1.0729346430329012,-1.0846130072907638,-1.0794894373635366,-1.0955909279757599,-1.0631196382539287,-1.0813752235465965]
[-1.4308169622765337,-1.4308911204231147,-1.4308015560046041,-1.430068461878001,-1.422685877104412,-1.4046245311770629,-1.3977922537072465,-1.3964153300029372,-1.395894919744629,-1.3956933933350737,-1.3956075198966498,-1.395567525885913,-1.395547411382293,-1.395536510201012,-1.395530118654107,-1.3955260422922797,-1.3955232115537166,-1.395521086049847,-1.395519383758991,-1.395517952798292,-1.3955167087099747,-1.3955156028959277,-1.3955146062836505,-1.3955137006410603,-1.395512873841971,-1.3955121172351146,-1.3955114241675355,-1.3955107891574468,-1.3955102074377335,-1.3955096747110074,-1.3955091870234906,-1.395508740703359,-1.3955083323320043,-1.395507958730379,-1.395507616950853,-1.3955073042698416,-1.395507018179227,-1.3955067563760817,-1.395506516750913,-1.3955062973749321,-1.3955060964868873,-1.3955059124799358,-1.3955057438889074,-1.3955055893782093,-1.395505447730503,-1.3955053178362309,-1.3955051986839877,-1.3955050893517247,-1.3955049889987299,-1.3955048968583326,-1.395504812231269,-1.3956247886510045,-1.3954878942948337,-1.394887103519222,-1.389708338089443,-1.3761301210054206,-1.3677400705028382,-1.3644579687204068,-1.3625571078633,-1.3613515420728044,-1.3605800159222927,-1.3600119406716036,-1.359527342244583,-1.3590824333856166,-1.358690461769906,-1.3583841485564596,-1.3581547188096135,-1.3579844436382478,-1.3578520921438206,-1.357744452856033,-1.357658882343758,-1.357590636911309,-1.35753199298494,-1.3574776021698531,-1.357422710394273,-1.3573627241226294,-1.3572948016494832,-1.3572196139273136,-1.3571388145502266,-1.3570544170849677,-1.3569698656386875,-1.3568891077845493,-1.3568139192868942,-1.3567437268688718,-1.356676766403983,-1.3566106897118675,-1.3565444503019453,-1.356477769712192,-1.35640992144435,-1.3563400386371127,-1.356267667976722,-1.3561929225109561,-1.3561170508356977,-1.3560416735855687,-1.355967537390605,-1.3558952679515501,-1.3558259226001477,-1.3557608312339038,-1.3557013479591247,-1.3556478772433447,-1.3556006372826193,-1.3556996076667978,-1.3555177074977212,-1.354955163407958,-1.3503008628083537,-1.3351772529214643,-1.3210408807488694,-1.3151708121566528,-1.3123551879520008,-1.3104587193461603,-1.308899145145004,-1.307559024985996,-1.3064421273120654,-1.305598410873208,-1.3050260640455078,-1.3046423132413583,-1.3043692700190839,-1.304150245282667,-1.3039625679991884,-1.30381034367113,-1.3036972685788708,-1.3036175255579956,-1.3035617247414708,-1.3035211774857534,-1.30349004932425,-1.3034648807338216,-1.3034436532995475,-1.3034251298511725,-1.3034084813714446,-1.303393114541003,-1.3033785864894125,-1.3033645320622491,-1.3033506316903951,-1.3033366552889694,-1.3033224781694637,-1.3033079486339707,-1.3032927869982376,-1.3032766870596673,-1.30325949704575,-1.3032406880856657,-1.303217347062459,-1.3031812816250492,-1.3031215389243733,-1.3030364749025491,-1.3029313987334201,-1.302828157612065,-1.3027647356415333,-1.3027324463314491,-1.302716097525036,-1.3027078858558179,-1.3027034170432916,-1.3029269583256744,-1.3026994358223516,-1.3020643419753148,-1.2943669981621673,-1.2624847514268835,-1.2319160460932594,-1.2357031777634244,-1.2238235340362382,-1.2147738334910678,-1.2266759358970216,-1.2226863976076416,-1.210853870661368,-1.2204608217460051,-1.2093561757961453,-1.2147970586756416,-1.2224372141749276,-1.2095868703968249,-1.2176204993732,-1.2205059873426372,-1.2078989428706126,-1.2121776158371684,-1.2314944498686364,-1.2151118699207577,-1.2035444142355498,-1.211622687715486,-1.2224469343497562,-1.225959766115436,-1.2278677142076182,-1.213679873028812,-1.2145060820918467,-1.2196163456360165,-1.2062710176082847,-1.2252429356985803,-1.2306416860542464,-1.2159669685767889,-1.2156967656500266,-1.2202928585201824,-1.2085465889562481,-1.2137580557708454,-1.221276175123018,-1.2087583110876783,-1.2164693446466082,-1.2202489337040483,-1.2084009557556565,-1.212946352926032,-1.2322122200442447,-1.2162066687999293,-1.204878798474857,-1.22364722791968,-1.208836615521626,-1.2256734692365094,-1.2135537134520287,-1.2061178570897069,-1.1846958546858075,-1.1471691304834803,-1.14937133995477,-1.1176776396353298,-1.1110777266857035,-1.1120802563090628,-1.1018999372986447,-1.0854155088673212,-1.1099501555324862,-1.0859005909079076,-1.0892679435583694,-1.0934884321608913,-1.110666354844841,-1.0822143965206994,-1.0941580641758175,-1.0891651984657118,-1.1017928584981622,-1.0930369504212465,-1.083495465315801,-1.094046096753934,-1.1056908818278208,-1.057222558576224,-1.093212786194966,-1.092544218276329,-1.0826862729115385,-1.0629910545210697,-1.0996912883060133,-1.0979355258029648,-1.076510645427764,-1.0551652816708,-1.1045402128193904,-1.089095820521888,-1.0729406773516115,-1.0784052888582758,-1.0957669747368086,-1.0761702566355185,-1.0906565172128881,-1.0633198259634937,-1.0894719769993253,-1.0877495999767108,-1.0912452640266312,-1.0729346430329012,-1.0846130072907638,-1.0794894373635366,-1.0955909279757599,-1.0631196382539287,-1.0813752235465965]
32x26 Array{Float64,2}:
  0.00718372   0.05811     -0.0301556   â€¦  -0.0679083   -0.0377355  
 -0.0109282    0.107765     0.0336128      -0.0316976    0.0344234  
 -0.0116482    0.138224    -0.0589026       0.0427634    0.0573258  
 -0.127549    -0.0514666   -0.0838567      -0.160135     0.0554642  
 -0.0367788   -0.0244776   -0.240032        0.349732    -0.154681   
 -0.0473414    0.0130846    0.226507    â€¦   0.00962099  -0.155256   
 -0.061643    -0.306177     0.00970676      0.238585     0.0342855  
 -0.0557013   -0.0353946    0.256953       -0.0790631   -0.0915884  
  0.0968037   -0.00875535  -0.199846       -0.199851    -0.165972   
  0.041089     0.216114    -0.097695        0.127412    -0.0773331  
  â‹®                                     â‹±                â‹®          
 -0.0271765   -0.0464003   -0.123927        0.0859902    0.0234298  
  0.075382     0.109597    -0.18702        -0.0608389    0.000370843
  0.0946449   -0.0477364    0.0376146   â€¦  -0.0430214   -0.0489618  
  0.00372805  -0.076056    -0.114351       -0.225602     0.0176257  
  0.0853614   -0.010251    -0.0197482      -0.0306155   -0.0776812  
  0.106837    -0.0596849    0.108992        0.0204676   -0.0221254  
 -0.0253376   -0.114182    -0.0742933       0.0563068   -0.0675363  
 -0.0455079    0.0802661    0.258351    â€¦  -0.07574      0.118737   
 -0.144724     0.068013    -0.0354439      -0.0664709    0.134507   INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 7 15 16 24
INFO: iteration 1, average log likelihood -1.102910
WARNING: Variances had to be floored 1 5 6 7 15 16 24
INFO: iteration 2, average log likelihood -1.073266
WARNING: Variances had to be floored 3 7 15 16 24 25 27
INFO: iteration 3, average log likelihood -1.054898
WARNING: Variances had to be floored 1 5 6 7 15 16 19 24 26
INFO: iteration 4, average log likelihood -1.073895
WARNING: Variances had to be floored 7 15 16 24 25
INFO: iteration 5, average log likelihood -1.083308
WARNING: Variances had to be floored 1 3 5 6 7 15 16 24 27
INFO: iteration 6, average log likelihood -1.061203
WARNING: Variances had to be floored 7 15 16 24 25 26
INFO: iteration 7, average log likelihood -1.073841
WARNING: Variances had to be floored 1 5 6 7 15 16 19 24 27
INFO: iteration 8, average log likelihood -1.069681
WARNING: Variances had to be floored 3 7 15 16 24
INFO: iteration 9, average log likelihood -1.088254
WARNING: Variances had to be floored 1 5 6 7 15 16 24 25 27
INFO: iteration 10, average log likelihood -1.064419
INFO: EM with 100000 data points 10 iterations avll -1.064419
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.247716e+05
      1       7.117336e+05      -2.130379e+05 |       32
      2       6.783838e+05      -3.334985e+04 |       32
      3       6.627545e+05      -1.562926e+04 |       32
      4       6.522794e+05      -1.047517e+04 |       32
      5       6.441371e+05      -8.142219e+03 |       32
      6       6.387551e+05      -5.382012e+03 |       32
      7       6.355878e+05      -3.167348e+03 |       32
      8       6.340253e+05      -1.562466e+03 |       32
      9       6.332172e+05      -8.081537e+02 |       32
     10       6.324564e+05      -7.607984e+02 |       32
     11       6.316486e+05      -8.077894e+02 |       32
     12       6.308233e+05      -8.252859e+02 |       32
     13       6.301032e+05      -7.200788e+02 |       32
     14       6.295848e+05      -5.183945e+02 |       32
     15       6.292641e+05      -3.207251e+02 |       32
     16       6.290368e+05      -2.273076e+02 |       32
     17       6.288526e+05      -1.842049e+02 |       32
     18       6.286822e+05      -1.703524e+02 |       32
     19       6.285420e+05      -1.402565e+02 |       32
     20       6.284483e+05      -9.363103e+01 |       32
     21       6.283811e+05      -6.723857e+01 |       32
     22       6.283494e+05      -3.167080e+01 |       31
     23       6.283350e+05      -1.442592e+01 |       29
     24       6.283278e+05      -7.188764e+00 |       30
     25       6.283242e+05      -3.651332e+00 |       27
     26       6.283209e+05      -3.244197e+00 |       27
     27       6.283178e+05      -3.092355e+00 |       25
     28       6.283159e+05      -1.880785e+00 |       19
     29       6.283148e+05      -1.107446e+00 |       14
     30       6.283139e+05      -9.855230e-01 |       19
     31       6.283127e+05      -1.130940e+00 |       15
     32       6.283119e+05      -8.003975e-01 |       12
     33       6.283115e+05      -4.094113e-01 |        7
     34       6.283113e+05      -1.662460e-01 |       10
     35       6.283111e+05      -2.783926e-01 |        9
     36       6.283108e+05      -2.503686e-01 |        4
     37       6.283108e+05      -6.058215e-02 |        2
     38       6.283107e+05      -2.336969e-02 |        0
     39       6.283107e+05       0.000000e+00 |        0
K-means converged with 39 iterations (objv = 628310.7346626932)
INFO: K-means with 32000 data points using 39 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.353032
INFO: iteration 2, average log likelihood -1.328158
INFO: iteration 3, average log likelihood -1.300231
INFO: iteration 4, average log likelihood -1.269601
INFO: iteration 5, average log likelihood -1.232553
WARNING: Variances had to be floored 11
INFO: iteration 6, average log likelihood -1.184509
WARNING: Variances had to be floored 24 29
INFO: iteration 7, average log likelihood -1.139237
WARNING: Variances had to be floored 8 20 30
INFO: iteration 8, average log likelihood -1.107643
WARNING: Variances had to be floored 13 19
INFO: iteration 9, average log likelihood -1.121102
WARNING: Variances had to be floored 7 11 15
INFO: iteration 10, average log likelihood -1.089683
WARNING: Variances had to be floored 24 29 30
INFO: iteration 11, average log likelihood -1.090985
WARNING: Variances had to be floored 8 20 32
INFO: iteration 12, average log likelihood -1.108281
WARNING: Variances had to be floored 13
INFO: iteration 13, average log likelihood -1.116929
WARNING: Variances had to be floored 11
INFO: iteration 14, average log likelihood -1.091001
WARNING: Variances had to be floored 7 15 19 24 29 30
INFO: iteration 15, average log likelihood -1.073479
WARNING: Variances had to be floored 20
INFO: iteration 16, average log likelihood -1.116431
WARNING: Variances had to be floored 8 13
INFO: iteration 17, average log likelihood -1.089603
WARNING: Variances had to be floored 11 23
INFO: iteration 18, average log likelihood -1.098377
WARNING: Variances had to be floored 29 30
INFO: iteration 19, average log likelihood -1.099694
WARNING: Variances had to be floored 7 20 24 32
INFO: iteration 20, average log likelihood -1.090111
WARNING: Variances had to be floored 8 13 15
INFO: iteration 21, average log likelihood -1.088644
WARNING: Variances had to be floored 11 19 23
INFO: iteration 22, average log likelihood -1.097376
WARNING: Variances had to be floored 29 30
INFO: iteration 23, average log likelihood -1.109570
WARNING: Variances had to be floored 20 24
INFO: iteration 24, average log likelihood -1.096572
WARNING: Variances had to be floored 8 13 31
INFO: iteration 25, average log likelihood -1.077383
WARNING: Variances had to be floored 11 15 19 23
INFO: iteration 26, average log likelihood -1.080086
WARNING: Variances had to be floored 29 30
INFO: iteration 27, average log likelihood -1.103912
WARNING: Variances had to be floored 8 20 24
INFO: iteration 28, average log likelihood -1.092240
WARNING: Variances had to be floored 13
INFO: iteration 29, average log likelihood -1.097588
WARNING: Variances had to be floored 11 15 19 23 29 30 31
INFO: iteration 30, average log likelihood -1.061851
INFO: iteration 31, average log likelihood -1.132026
WARNING: Variances had to be floored 8 20 24
INFO: iteration 32, average log likelihood -1.078091
WARNING: Variances had to be floored 11 13 29
INFO: iteration 33, average log likelihood -1.092743
WARNING: Variances had to be floored 23 30
INFO: iteration 34, average log likelihood -1.095202
WARNING: Variances had to be floored 8 15 19 24 31
INFO: iteration 35, average log likelihood -1.081941
WARNING: Variances had to be floored 11 20
INFO: iteration 36, average log likelihood -1.106351
WARNING: Variances had to be floored 13 23 29
INFO: iteration 37, average log likelihood -1.097966
WARNING: Variances had to be floored 30
INFO: iteration 38, average log likelihood -1.106025
WARNING: Variances had to be floored 8 24
INFO: iteration 39, average log likelihood -1.083206
WARNING: Variances had to be floored 11 15 19 20 23 31
INFO: iteration 40, average log likelihood -1.072104
WARNING: Variances had to be floored 13 29 30
INFO: iteration 41, average log likelihood -1.114991
WARNING: Variances had to be floored 8 24
INFO: iteration 42, average log likelihood -1.118794
INFO: iteration 43, average log likelihood -1.108990
WARNING: Variances had to be floored 11 19 20 23 30 31
INFO: iteration 44, average log likelihood -1.051608
WARNING: Variances had to be floored 8 13 15 24 29
INFO: iteration 45, average log likelihood -1.100947
INFO: iteration 46, average log likelihood -1.146638
INFO: iteration 47, average log likelihood -1.098217
WARNING: Variances had to be floored 8 11 20 23 30 31
INFO: iteration 48, average log likelihood -1.055363
WARNING: Variances had to be floored 13 24 29
INFO: iteration 49, average log likelihood -1.125869
WARNING: Variances had to be floored 19
INFO: iteration 50, average log likelihood -1.126683
INFO: EM with 100000 data points 50 iterations avll -1.126683
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.127181    -0.0007952    0.21481    â€¦  -0.0558077  -0.105642  
 -0.0507382   -0.0527364    0.225178      -0.0476327  -0.0722744 
 -0.0882628    0.100686     0.263738      -0.0271309   0.00143062
 -0.0258245    0.0152644   -0.042881      -0.0403898   0.0802272 
 -0.0268201   -0.109339    -0.075044       0.0550913  -0.0667595 
  0.0975734   -0.00866012  -0.2031     â€¦  -0.200507   -0.166391  
 -0.0128966    0.100377     0.0405818     -0.0282576   0.032411  
  0.0200777   -0.0478574    0.0137886      0.0657318  -0.0314523 
  0.041527     0.21602     -0.0992597      0.12697    -0.0767206 
  0.110635    -0.0831886    0.130611       0.0259112  -0.0176009 
  â‹®                                    â‹±               â‹®         
  0.0922325    0.276415    -0.239214      -0.0852629   0.00212   
 -0.0223235   -0.1082       0.11403        0.0464528   0.0161513 
  0.0228529    0.0265232   -0.0797915  â€¦   0.041929   -0.0617526 
  0.201409    -0.108142    -0.0981981     -0.124864    0.023335  
 -0.0990039    0.0753279    0.105561      -0.0712376   0.126647  
 -0.0690944   -0.632125     0.0522846      0.322442   -0.00250873
 -0.0886246   -0.0990005   -0.0393641      0.0720998  -0.123829  
 -0.00125763   0.0726683   -0.0240621  â€¦  -0.0697065  -0.0752085 
 -0.102155     0.090937    -0.101518      -0.142151   -0.0139078 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 15 31
INFO: iteration 1, average log likelihood -1.080056
WARNING: Variances had to be floored 8 11 15 20 23 24 30 31
INFO: iteration 2, average log likelihood -1.032316
WARNING: Variances had to be floored 11 13 15 19 23 29 31
INFO: iteration 3, average log likelihood -1.047201
WARNING: Variances had to be floored 8 15 20 24 30
INFO: iteration 4, average log likelihood -1.054177
WARNING: Variances had to be floored 11 15 23 31
INFO: iteration 5, average log likelihood -1.051076
WARNING: Variances had to be floored 8 11 13 15 19 20 23 24 29 30 31
INFO: iteration 6, average log likelihood -1.021713
WARNING: Variances had to be floored 15
INFO: iteration 7, average log likelihood -1.078801
WARNING: Variances had to be floored 8 11 15 20 23 24 30 31 32
INFO: iteration 8, average log likelihood -1.028971
WARNING: Variances had to be floored 11 13 15 19 23 29 31
INFO: iteration 9, average log likelihood -1.047158
WARNING: Variances had to be floored 8 15 20 24 30
INFO: iteration 10, average log likelihood -1.054231
INFO: EM with 100000 data points 10 iterations avll -1.054231
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0494881   0.0836922    0.242017    â€¦  -0.265404    0.235617    0.0555528
  0.12232    -0.0648382    0.166889       -0.105106   -0.0846605  -0.154255 
 -0.139326    0.0609577   -0.151724       -0.118582   -0.0675479   0.0297346
  0.12893     0.0459765   -0.0977646       0.111715   -0.098511   -0.0425941
 -0.144638   -0.128235    -0.0587387      -0.101133   -0.162347   -0.103714 
  0.0239916  -0.00446359   0.12176     â€¦  -0.020787    0.0273757  -0.0710212
 -0.237012    0.00271584  -0.0494492       0.181417   -0.078683   -0.0764187
 -0.0257123  -0.0104045   -0.0856696      -0.11258     0.0705825  -0.130167 
 -0.0292464  -0.0334088    0.00201015      0.134848    0.0796966   0.0271183
  0.0485914   0.052854     0.0597961      -0.122278   -0.167625    0.0104293
  â‹®                                    â‹±                           â‹®        
 -0.0460081  -0.0979295    0.205312       -0.160084    0.0267027   0.0733511
 -0.117047   -0.0985629    0.157669        0.03686    -0.100762   -0.163457 
  0.0567599   0.0478713    0.0608809   â€¦  -0.0186329  -0.0234292   0.140377 
  0.0403203  -0.0542973    0.0375552      -0.116253    0.0637252  -0.105727 
 -0.0954265  -0.0690147   -0.143045        0.0614505  -0.0128803  -0.0180047
 -0.125663   -0.0569674    0.363505        0.10516     0.196762   -0.139983 
  0.120991   -0.0432841    0.136805        0.0289117   0.0215882  -0.0998016
  0.013466   -0.0421797    0.109124    â€¦   0.0135279  -0.0534386   0.189899 
  0.234636    0.0271605   -0.0698046      -0.0440142   0.106261    0.189403 kind full, method split
0: avll = -1.422809466679431
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.422826
INFO: iteration 2, average log likelihood -1.422757
INFO: iteration 3, average log likelihood -1.422697
INFO: iteration 4, average log likelihood -1.422622
INFO: iteration 5, average log likelihood -1.422524
INFO: iteration 6, average log likelihood -1.422403
INFO: iteration 7, average log likelihood -1.422261
INFO: iteration 8, average log likelihood -1.422095
INFO: iteration 9, average log likelihood -1.421881
INFO: iteration 10, average log likelihood -1.421556
INFO: iteration 11, average log likelihood -1.421023
INFO: iteration 12, average log likelihood -1.420221
INFO: iteration 13, average log likelihood -1.419254
INFO: iteration 14, average log likelihood -1.418396
INFO: iteration 15, average log likelihood -1.417840
INFO: iteration 16, average log likelihood -1.417554
INFO: iteration 17, average log likelihood -1.417424
INFO: iteration 18, average log likelihood -1.417367
INFO: iteration 19, average log likelihood -1.417342
INFO: iteration 20, average log likelihood -1.417331
INFO: iteration 21, average log likelihood -1.417326
INFO: iteration 22, average log likelihood -1.417324
INFO: iteration 23, average log likelihood -1.417323
INFO: iteration 24, average log likelihood -1.417322
INFO: iteration 25, average log likelihood -1.417322
INFO: iteration 26, average log likelihood -1.417321
INFO: iteration 27, average log likelihood -1.417321
INFO: iteration 28, average log likelihood -1.417321
INFO: iteration 29, average log likelihood -1.417321
INFO: iteration 30, average log likelihood -1.417321
INFO: iteration 31, average log likelihood -1.417321
INFO: iteration 32, average log likelihood -1.417321
INFO: iteration 33, average log likelihood -1.417320
INFO: iteration 34, average log likelihood -1.417320
INFO: iteration 35, average log likelihood -1.417320
INFO: iteration 36, average log likelihood -1.417320
INFO: iteration 37, average log likelihood -1.417320
INFO: iteration 38, average log likelihood -1.417320
INFO: iteration 39, average log likelihood -1.417320
INFO: iteration 40, average log likelihood -1.417320
INFO: iteration 41, average log likelihood -1.417320
INFO: iteration 42, average log likelihood -1.417320
INFO: iteration 43, average log likelihood -1.417320
INFO: iteration 44, average log likelihood -1.417320
INFO: iteration 45, average log likelihood -1.417320
INFO: iteration 46, average log likelihood -1.417320
INFO: iteration 47, average log likelihood -1.417320
INFO: iteration 48, average log likelihood -1.417320
INFO: iteration 49, average log likelihood -1.417320
INFO: iteration 50, average log likelihood -1.417320
INFO: EM with 100000 data points 50 iterations avll -1.417320
952.4 data points per parameter
1: avll = [-1.4228264063204903,-1.422757121764872,-1.4226972875934014,-1.4226215213838882,-1.422523830022535,-1.4224028073686412,-1.4222607639659912,-1.4220951175864256,-1.4218812819552236,-1.4215560510500134,-1.4210230821079337,-1.4202207788709897,-1.4192536676820524,-1.4183957897011354,-1.417839676976801,-1.4175537862437995,-1.4174235473069503,-1.4173666787340349,-1.4173419712832387,-1.417331117184124,-1.4173262362897325,-1.4173239490730345,-1.4173228011059287,-1.4173221632203326,-1.4173217614988525,-1.4173214755888357,-1.4173212518004221,-1.4173210655275783,-1.4173209049448758,-1.4173207639111793,-1.4173206388686281,-1.4173205274797664,-1.4173204280228522,-1.4173203391189164,-1.4173202596046441,-1.4173201884698403,-1.417320124823884,-1.417320067875531,-1.4173200169191438,-1.4173199713242477,-1.4173199305270172,-1.4173198940230114,-1.4173198613608282,-1.417319832136497,-1.4173198059884824,-1.4173197825932276,-1.4173197616611672,-1.4173197429331619,-1.4173197261773043,-1.4173197111860634]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.417334
INFO: iteration 2, average log likelihood -1.417273
INFO: iteration 3, average log likelihood -1.417218
INFO: iteration 4, average log likelihood -1.417148
INFO: iteration 5, average log likelihood -1.417057
INFO: iteration 6, average log likelihood -1.416942
INFO: iteration 7, average log likelihood -1.416810
INFO: iteration 8, average log likelihood -1.416675
INFO: iteration 9, average log likelihood -1.416548
INFO: iteration 10, average log likelihood -1.416440
INFO: iteration 11, average log likelihood -1.416352
INFO: iteration 12, average log likelihood -1.416285
INFO: iteration 13, average log likelihood -1.416236
INFO: iteration 14, average log likelihood -1.416201
INFO: iteration 15, average log likelihood -1.416175
INFO: iteration 16, average log likelihood -1.416155
INFO: iteration 17, average log likelihood -1.416138
INFO: iteration 18, average log likelihood -1.416124
INFO: iteration 19, average log likelihood -1.416111
INFO: iteration 20, average log likelihood -1.416100
INFO: iteration 21, average log likelihood -1.416089
INFO: iteration 22, average log likelihood -1.416079
INFO: iteration 23, average log likelihood -1.416070
INFO: iteration 24, average log likelihood -1.416062
INFO: iteration 25, average log likelihood -1.416055
INFO: iteration 26, average log likelihood -1.416048
INFO: iteration 27, average log likelihood -1.416041
INFO: iteration 28, average log likelihood -1.416035
INFO: iteration 29, average log likelihood -1.416030
INFO: iteration 30, average log likelihood -1.416025
INFO: iteration 31, average log likelihood -1.416021
INFO: iteration 32, average log likelihood -1.416017
INFO: iteration 33, average log likelihood -1.416014
INFO: iteration 34, average log likelihood -1.416011
INFO: iteration 35, average log likelihood -1.416008
INFO: iteration 36, average log likelihood -1.416005
INFO: iteration 37, average log likelihood -1.416003
INFO: iteration 38, average log likelihood -1.416001
INFO: iteration 39, average log likelihood -1.415999
INFO: iteration 40, average log likelihood -1.415997
INFO: iteration 41, average log likelihood -1.415996
INFO: iteration 42, average log likelihood -1.415994
INFO: iteration 43, average log likelihood -1.415993
INFO: iteration 44, average log likelihood -1.415992
INFO: iteration 45, average log likelihood -1.415991
INFO: iteration 46, average log likelihood -1.415990
INFO: iteration 47, average log likelihood -1.415989
INFO: iteration 48, average log likelihood -1.415988
INFO: iteration 49, average log likelihood -1.415987
INFO: iteration 50, average log likelihood -1.415987
INFO: EM with 100000 data points 50 iterations avll -1.415987
473.9 data points per parameter
2: avll = [-1.4173338583837791,-1.4172731009619601,-1.4172183633077862,-1.4171484199763535,-1.4170566759699763,-1.4169419157055974,-1.416810495234942,-1.4166749403532923,-1.4165483739285905,-1.416439547564607,-1.4163519574642711,-1.4162852024526242,-1.416236306979304,-1.4162009849577768,-1.4161749573730387,-1.4161548344082289,-1.4161383404692005,-1.4161241184615587,-1.416111422657224,-1.4160998637521824,-1.416089242200493,-1.4160794524594669,-1.416070432221162,-1.416062137044951,-1.4160545284314423,-1.416047568728339,-1.4160412193917566,-1.416035440815316,-1.4160301928176853,-1.4160254353328314,-1.4160211290834543,-1.4160172361426062,-1.4160137203539502,-1.4160105476143405,-1.416007686037525,-1.4160051060228216,-1.416002780252211,-1.4160006836363561,-1.4159987932261449,-1.4159970881025374,-1.4159955492541108,-1.415994159448981,-1.4159929031056926,-1.4159917661661547,-1.4159907359726234,-1.4159898011499856,-1.4159889514941069,-1.4159881778666632,-1.4159874720966572,-1.4159868268886582]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.415997
INFO: iteration 2, average log likelihood -1.415949
INFO: iteration 3, average log likelihood -1.415908
INFO: iteration 4, average log likelihood -1.415860
INFO: iteration 5, average log likelihood -1.415799
INFO: iteration 6, average log likelihood -1.415724
INFO: iteration 7, average log likelihood -1.415636
INFO: iteration 8, average log likelihood -1.415540
INFO: iteration 9, average log likelihood -1.415443
INFO: iteration 10, average log likelihood -1.415352
INFO: iteration 11, average log likelihood -1.415274
INFO: iteration 12, average log likelihood -1.415207
INFO: iteration 13, average log likelihood -1.415152
INFO: iteration 14, average log likelihood -1.415105
INFO: iteration 15, average log likelihood -1.415065
INFO: iteration 16, average log likelihood -1.415030
INFO: iteration 17, average log likelihood -1.414999
INFO: iteration 18, average log likelihood -1.414973
INFO: iteration 19, average log likelihood -1.414949
INFO: iteration 20, average log likelihood -1.414929
INFO: iteration 21, average log likelihood -1.414910
INFO: iteration 22, average log likelihood -1.414894
INFO: iteration 23, average log likelihood -1.414880
INFO: iteration 24, average log likelihood -1.414867
INFO: iteration 25, average log likelihood -1.414855
INFO: iteration 26, average log likelihood -1.414843
INFO: iteration 27, average log likelihood -1.414833
INFO: iteration 28, average log likelihood -1.414823
INFO: iteration 29, average log likelihood -1.414813
INFO: iteration 30, average log likelihood -1.414804
INFO: iteration 31, average log likelihood -1.414795
INFO: iteration 32, average log likelihood -1.414786
INFO: iteration 33, average log likelihood -1.414778
INFO: iteration 34, average log likelihood -1.414769
INFO: iteration 35, average log likelihood -1.414761
INFO: iteration 36, average log likelihood -1.414753
INFO: iteration 37, average log likelihood -1.414745
INFO: iteration 38, average log likelihood -1.414738
INFO: iteration 39, average log likelihood -1.414730
INFO: iteration 40, average log likelihood -1.414723
INFO: iteration 41, average log likelihood -1.414715
INFO: iteration 42, average log likelihood -1.414708
INFO: iteration 43, average log likelihood -1.414701
INFO: iteration 44, average log likelihood -1.414695
INFO: iteration 45, average log likelihood -1.414688
INFO: iteration 46, average log likelihood -1.414682
INFO: iteration 47, average log likelihood -1.414675
INFO: iteration 48, average log likelihood -1.414669
INFO: iteration 49, average log likelihood -1.414663
INFO: iteration 50, average log likelihood -1.414658
INFO: EM with 100000 data points 50 iterations avll -1.414658
236.4 data points per parameter
3: avll = [-1.4159966250850915,-1.4159494934636652,-1.4159084214655127,-1.415859754838219,-1.4157990655978543,-1.4157241449850948,-1.4156360545723015,-1.4155397045475198,-1.415442694408625,-1.4153524772320418,-1.4152736627948288,-1.415207259621356,-1.415151805829788,-1.4151050149620128,-1.415064865283243,-1.4150299507435458,-1.4149993893907846,-1.4149726018603555,-1.414949129642477,-1.4149285402887666,-1.41491040334721,-1.4148943028941992,-1.4148798586975073,-1.4148667413647518,-1.4148546777405273,-1.4148434484962373,-1.414832881379457,-1.4148228430178067,-1.414813231041637,-1.4148039673299593,-1.4147949925798635,-1.414786262096379,-1.4147777425871577,-1.4147694097332453,-1.4147612463360668,-1.4147532408813075,-1.4147453863991253,-1.4147376795325823,-1.414730119751734,-1.414722708670472,-1.4147154494382157,-1.4147083461899475,-1.414701403546697,-1.414694626164909,-1.4146880183374229,-1.4146815836513125,-1.4146753247086432,-1.4146692429154955,-1.4146633383426213,-1.414657609658177]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414660
INFO: iteration 2, average log likelihood -1.414600
INFO: iteration 3, average log likelihood -1.414543
INFO: iteration 4, average log likelihood -1.414479
INFO: iteration 5, average log likelihood -1.414402
INFO: iteration 6, average log likelihood -1.414311
INFO: iteration 7, average log likelihood -1.414207
INFO: iteration 8, average log likelihood -1.414094
INFO: iteration 9, average log likelihood -1.413978
INFO: iteration 10, average log likelihood -1.413864
INFO: iteration 11, average log likelihood -1.413756
INFO: iteration 12, average log likelihood -1.413655
INFO: iteration 13, average log likelihood -1.413564
INFO: iteration 14, average log likelihood -1.413481
INFO: iteration 15, average log likelihood -1.413407
INFO: iteration 16, average log likelihood -1.413342
INFO: iteration 17, average log likelihood -1.413284
INFO: iteration 18, average log likelihood -1.413233
INFO: iteration 19, average log likelihood -1.413187
INFO: iteration 20, average log likelihood -1.413146
INFO: iteration 21, average log likelihood -1.413108
INFO: iteration 22, average log likelihood -1.413073
INFO: iteration 23, average log likelihood -1.413041
INFO: iteration 24, average log likelihood -1.413010
INFO: iteration 25, average log likelihood -1.412980
INFO: iteration 26, average log likelihood -1.412952
INFO: iteration 27, average log likelihood -1.412926
INFO: iteration 28, average log likelihood -1.412900
INFO: iteration 29, average log likelihood -1.412875
INFO: iteration 30, average log likelihood -1.412851
INFO: iteration 31, average log likelihood -1.412828
INFO: iteration 32, average log likelihood -1.412806
INFO: iteration 33, average log likelihood -1.412785
INFO: iteration 34, average log likelihood -1.412764
INFO: iteration 35, average log likelihood -1.412744
INFO: iteration 36, average log likelihood -1.412725
INFO: iteration 37, average log likelihood -1.412707
INFO: iteration 38, average log likelihood -1.412690
INFO: iteration 39, average log likelihood -1.412673
INFO: iteration 40, average log likelihood -1.412656
INFO: iteration 41, average log likelihood -1.412641
INFO: iteration 42, average log likelihood -1.412626
INFO: iteration 43, average log likelihood -1.412611
INFO: iteration 44, average log likelihood -1.412598
INFO: iteration 45, average log likelihood -1.412584
INFO: iteration 46, average log likelihood -1.412572
INFO: iteration 47, average log likelihood -1.412559
INFO: iteration 48, average log likelihood -1.412548
INFO: iteration 49, average log likelihood -1.412536
INFO: iteration 50, average log likelihood -1.412526
INFO: EM with 100000 data points 50 iterations avll -1.412526
118.1 data points per parameter
4: avll = [-1.4146603374811044,-1.4145997192315045,-1.4145431610502526,-1.4144790334785602,-1.4144023428590844,-1.4143111246237277,-1.4142067845444033,-1.4140936948839522,-1.413977608642448,-1.413863728261631,-1.4137556180551436,-1.4136552470618189,-1.4135635470075345,-1.4134808543067616,-1.4134070745053557,-1.4133417174950593,-1.4132839591518829,-1.413232767672368,-1.4131870523912677,-1.413145785320856,-1.4131080737261832,-1.4130731876972142,-1.4130405573732538,-1.4130097541899456,-1.4129804661410423,-1.4129524726998182,-1.4129256220758788,-1.412899811844152,-1.4128749732082093,-1.412851058808429,-1.4128280337864523,-1.4128058696697332,-1.412784540538457,-1.412764020900693,-1.4127442847398772,-1.4127253053010174,-1.4127070553131176,-1.4126895074576462,-1.4126726349568135,-1.4126564121769924,-1.4126408151502663,-1.4126258219345598,-1.4126114127649865,-1.412597569987275,-1.4125842777975035,-1.4125715218351031,-1.4125592886876792,-1.4125475653687898,-1.4125363388254177,-1.4125255955219402]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.412523
INFO: iteration 2, average log likelihood -1.412451
INFO: iteration 3, average log likelihood -1.412377
INFO: iteration 4, average log likelihood -1.412288
INFO: iteration 5, average log likelihood -1.412174
INFO: iteration 6, average log likelihood -1.412033
INFO: iteration 7, average log likelihood -1.411869
INFO: iteration 8, average log likelihood -1.411689
INFO: iteration 9, average log likelihood -1.411504
INFO: iteration 10, average log likelihood -1.411322
INFO: iteration 11, average log likelihood -1.411150
INFO: iteration 12, average log likelihood -1.410992
INFO: iteration 13, average log likelihood -1.410851
INFO: iteration 14, average log likelihood -1.410726
INFO: iteration 15, average log likelihood -1.410618
INFO: iteration 16, average log likelihood -1.410523
INFO: iteration 17, average log likelihood -1.410442
INFO: iteration 18, average log likelihood -1.410370
INFO: iteration 19, average log likelihood -1.410307
INFO: iteration 20, average log likelihood -1.410252
INFO: iteration 21, average log likelihood -1.410202
INFO: iteration 22, average log likelihood -1.410157
INFO: iteration 23, average log likelihood -1.410116
INFO: iteration 24, average log likelihood -1.410078
INFO: iteration 25, average log likelihood -1.410044
INFO: iteration 26, average log likelihood -1.410012
INFO: iteration 27, average log likelihood -1.409982
INFO: iteration 28, average log likelihood -1.409954
INFO: iteration 29, average log likelihood -1.409927
INFO: iteration 30, average log likelihood -1.409902
INFO: iteration 31, average log likelihood -1.409878
INFO: iteration 32, average log likelihood -1.409856
INFO: iteration 33, average log likelihood -1.409834
INFO: iteration 34, average log likelihood -1.409814
INFO: iteration 35, average log likelihood -1.409794
INFO: iteration 36, average log likelihood -1.409776
INFO: iteration 37, average log likelihood -1.409758
INFO: iteration 38, average log likelihood -1.409741
INFO: iteration 39, average log likelihood -1.409724
INFO: iteration 40, average log likelihood -1.409708
INFO: iteration 41, average log likelihood -1.409693
INFO: iteration 42, average log likelihood -1.409679
INFO: iteration 43, average log likelihood -1.409665
INFO: iteration 44, average log likelihood -1.409651
INFO: iteration 45, average log likelihood -1.409639
INFO: iteration 46, average log likelihood -1.409626
INFO: iteration 47, average log likelihood -1.409614
INFO: iteration 48, average log likelihood -1.409602
INFO: iteration 49, average log likelihood -1.409591
INFO: iteration 50, average log likelihood -1.409580
INFO: EM with 100000 data points 50 iterations avll -1.409580
59.0 data points per parameter
5: avll = [-1.4125234568584633,-1.4124511107138558,-1.4123774500872783,-1.4122876912625069,-1.412173827248018,-1.4120330671447803,-1.4118689013206716,-1.4116894714463573,-1.4115043734264683,-1.4113223216270232,-1.4111500926519465,-1.410992149935192,-1.410850710718177,-1.4107261577556471,-1.4106175931921034,-1.4105233675367612,-1.410441514419645,-1.4103700653205182,-1.4103072385853428,-1.4102515200689583,-1.4102016695789887,-1.4101566891497093,-1.4101157790970726,-1.4100782960586296,-1.410043718909061,-1.4100116233979971,-1.4099816637961269,-1.4099535591621106,-1.4099270822749843,-1.409902050053805,-1.409878314970216,-1.4098557574079056,-1.4098342791203666,-1.4098137979204932,-1.4097942435874156,-1.4097755548164579,-1.4097576769663156,-1.40974056039605,-1.4097241592729306,-1.4097084307900896,-1.409693334732476,-1.4096788333009886,-1.4096648910878466,-1.4096514751060378,-1.4096385548049706,-1.4096261020395016,-1.409614090988678,-1.4096024980371922,-1.4095913016360304,-1.4095804821530045]
[-1.422809466679431,-1.4228264063204903,-1.422757121764872,-1.4226972875934014,-1.4226215213838882,-1.422523830022535,-1.4224028073686412,-1.4222607639659912,-1.4220951175864256,-1.4218812819552236,-1.4215560510500134,-1.4210230821079337,-1.4202207788709897,-1.4192536676820524,-1.4183957897011354,-1.417839676976801,-1.4175537862437995,-1.4174235473069503,-1.4173666787340349,-1.4173419712832387,-1.417331117184124,-1.4173262362897325,-1.4173239490730345,-1.4173228011059287,-1.4173221632203326,-1.4173217614988525,-1.4173214755888357,-1.4173212518004221,-1.4173210655275783,-1.4173209049448758,-1.4173207639111793,-1.4173206388686281,-1.4173205274797664,-1.4173204280228522,-1.4173203391189164,-1.4173202596046441,-1.4173201884698403,-1.417320124823884,-1.417320067875531,-1.4173200169191438,-1.4173199713242477,-1.4173199305270172,-1.4173198940230114,-1.4173198613608282,-1.417319832136497,-1.4173198059884824,-1.4173197825932276,-1.4173197616611672,-1.4173197429331619,-1.4173197261773043,-1.4173197111860634,-1.4173338583837791,-1.4172731009619601,-1.4172183633077862,-1.4171484199763535,-1.4170566759699763,-1.4169419157055974,-1.416810495234942,-1.4166749403532923,-1.4165483739285905,-1.416439547564607,-1.4163519574642711,-1.4162852024526242,-1.416236306979304,-1.4162009849577768,-1.4161749573730387,-1.4161548344082289,-1.4161383404692005,-1.4161241184615587,-1.416111422657224,-1.4160998637521824,-1.416089242200493,-1.4160794524594669,-1.416070432221162,-1.416062137044951,-1.4160545284314423,-1.416047568728339,-1.4160412193917566,-1.416035440815316,-1.4160301928176853,-1.4160254353328314,-1.4160211290834543,-1.4160172361426062,-1.4160137203539502,-1.4160105476143405,-1.416007686037525,-1.4160051060228216,-1.416002780252211,-1.4160006836363561,-1.4159987932261449,-1.4159970881025374,-1.4159955492541108,-1.415994159448981,-1.4159929031056926,-1.4159917661661547,-1.4159907359726234,-1.4159898011499856,-1.4159889514941069,-1.4159881778666632,-1.4159874720966572,-1.4159868268886582,-1.4159966250850915,-1.4159494934636652,-1.4159084214655127,-1.415859754838219,-1.4157990655978543,-1.4157241449850948,-1.4156360545723015,-1.4155397045475198,-1.415442694408625,-1.4153524772320418,-1.4152736627948288,-1.415207259621356,-1.415151805829788,-1.4151050149620128,-1.415064865283243,-1.4150299507435458,-1.4149993893907846,-1.4149726018603555,-1.414949129642477,-1.4149285402887666,-1.41491040334721,-1.4148943028941992,-1.4148798586975073,-1.4148667413647518,-1.4148546777405273,-1.4148434484962373,-1.414832881379457,-1.4148228430178067,-1.414813231041637,-1.4148039673299593,-1.4147949925798635,-1.414786262096379,-1.4147777425871577,-1.4147694097332453,-1.4147612463360668,-1.4147532408813075,-1.4147453863991253,-1.4147376795325823,-1.414730119751734,-1.414722708670472,-1.4147154494382157,-1.4147083461899475,-1.414701403546697,-1.414694626164909,-1.4146880183374229,-1.4146815836513125,-1.4146753247086432,-1.4146692429154955,-1.4146633383426213,-1.414657609658177,-1.4146603374811044,-1.4145997192315045,-1.4145431610502526,-1.4144790334785602,-1.4144023428590844,-1.4143111246237277,-1.4142067845444033,-1.4140936948839522,-1.413977608642448,-1.413863728261631,-1.4137556180551436,-1.4136552470618189,-1.4135635470075345,-1.4134808543067616,-1.4134070745053557,-1.4133417174950593,-1.4132839591518829,-1.413232767672368,-1.4131870523912677,-1.413145785320856,-1.4131080737261832,-1.4130731876972142,-1.4130405573732538,-1.4130097541899456,-1.4129804661410423,-1.4129524726998182,-1.4129256220758788,-1.412899811844152,-1.4128749732082093,-1.412851058808429,-1.4128280337864523,-1.4128058696697332,-1.412784540538457,-1.412764020900693,-1.4127442847398772,-1.4127253053010174,-1.4127070553131176,-1.4126895074576462,-1.4126726349568135,-1.4126564121769924,-1.4126408151502663,-1.4126258219345598,-1.4126114127649865,-1.412597569987275,-1.4125842777975035,-1.4125715218351031,-1.4125592886876792,-1.4125475653687898,-1.4125363388254177,-1.4125255955219402,-1.4125234568584633,-1.4124511107138558,-1.4123774500872783,-1.4122876912625069,-1.412173827248018,-1.4120330671447803,-1.4118689013206716,-1.4116894714463573,-1.4115043734264683,-1.4113223216270232,-1.4111500926519465,-1.410992149935192,-1.410850710718177,-1.4107261577556471,-1.4106175931921034,-1.4105233675367612,-1.410441514419645,-1.4103700653205182,-1.4103072385853428,-1.4102515200689583,-1.4102016695789887,-1.4101566891497093,-1.4101157790970726,-1.4100782960586296,-1.410043718909061,-1.4100116233979971,-1.4099816637961269,-1.4099535591621106,-1.4099270822749843,-1.409902050053805,-1.409878314970216,-1.4098557574079056,-1.4098342791203666,-1.4098137979204932,-1.4097942435874156,-1.4097755548164579,-1.4097576769663156,-1.40974056039605,-1.4097241592729306,-1.4097084307900896,-1.409693334732476,-1.4096788333009886,-1.4096648910878466,-1.4096514751060378,-1.4096385548049706,-1.4096261020395016,-1.409614090988678,-1.4096024980371922,-1.4095913016360304,-1.4095804821530045]
32x26 Array{Float64,2}:
  0.0384234  -0.259341   -0.224545    â€¦   0.253251    -0.0146493 
 -0.351347   -0.257727   -0.388391        0.52406      0.0784545 
 -0.103068    0.239915    0.143244        0.0160856    0.00960942
  0.123875    0.597887   -0.0466735      -0.103795    -0.228999  
 -0.02938     0.192575    0.409952        0.141699    -0.0516391 
  0.534545   -0.0967715  -0.593913    â€¦   0.333435    -0.491599  
  0.106887    0.120657   -0.281403       -0.0857206   -0.0864603 
 -0.0658775  -0.0842564   0.33756         0.0118114    0.103921  
 -0.179235   -0.466633    0.376851       -0.0601705   -0.260167  
 -0.102283    0.284184   -0.333261        0.223444    -0.51673   
  â‹®                                   â‹±                â‹®         
  1.17353    -0.295741    0.00709054      0.317892    -0.0189142 
 -0.370291   -0.0230075  -0.786629       -0.493087    -0.767728  
 -0.0123741   0.5096     -0.815342    â€¦  -0.0318496    0.388778  
  0.0309868   0.199135    0.039269       -0.551887    -0.0992495 
 -0.301021    0.0754166   0.149461       -0.00114937  -0.666393  
  0.130274    0.093423   -0.423566        0.697678     0.370223  
  0.3156     -0.0148378  -0.214599        0.385868     0.10006   
 -0.338441   -0.054417    0.171753    â€¦   0.133513     0.0155436 
 -1.47164     0.0662711  -0.013572       -0.560341    -0.0370052 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409570
INFO: iteration 2, average log likelihood -1.409560
INFO: iteration 3, average log likelihood -1.409550
INFO: iteration 4, average log likelihood -1.409541
INFO: iteration 5, average log likelihood -1.409531
INFO: iteration 6, average log likelihood -1.409523
INFO: iteration 7, average log likelihood -1.409514
INFO: iteration 8, average log likelihood -1.409506
INFO: iteration 9, average log likelihood -1.409498
INFO: iteration 10, average log likelihood -1.409490
INFO: EM with 100000 data points 10 iterations avll -1.409490
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.191277e+05
      1       7.021188e+05      -2.170088e+05 |       32
      2       6.895831e+05      -1.253574e+04 |       32
      3       6.844776e+05      -5.105535e+03 |       32
      4       6.815048e+05      -2.972733e+03 |       32
      5       6.796479e+05      -1.856885e+03 |       32
      6       6.783492e+05      -1.298686e+03 |       32
      7       6.774167e+05      -9.325939e+02 |       32
      8       6.767126e+05      -7.040724e+02 |       32
      9       6.761680e+05      -5.445431e+02 |       32
     10       6.757459e+05      -4.221513e+02 |       32
     11       6.754190e+05      -3.269215e+02 |       32
     12       6.751292e+05      -2.897953e+02 |       32
     13       6.748957e+05      -2.334653e+02 |       32
     14       6.746696e+05      -2.261434e+02 |       32
     15       6.744725e+05      -1.970746e+02 |       32
     16       6.743089e+05      -1.635401e+02 |       32
     17       6.741575e+05      -1.514845e+02 |       32
     18       6.740093e+05      -1.482028e+02 |       32
     19       6.738675e+05      -1.417536e+02 |       32
     20       6.737456e+05      -1.219142e+02 |       32
     21       6.736160e+05      -1.295621e+02 |       32
     22       6.734981e+05      -1.179696e+02 |       32
     23       6.733755e+05      -1.225733e+02 |       32
     24       6.732524e+05      -1.230467e+02 |       32
     25       6.731338e+05      -1.186437e+02 |       32
     26       6.730222e+05      -1.115623e+02 |       32
     27       6.729169e+05      -1.053315e+02 |       32
     28       6.728200e+05      -9.692889e+01 |       32
     29       6.727339e+05      -8.604718e+01 |       32
     30       6.726563e+05      -7.758638e+01 |       32
     31       6.725856e+05      -7.070968e+01 |       32
     32       6.725199e+05      -6.573646e+01 |       32
     33       6.724599e+05      -6.003563e+01 |       32
     34       6.724107e+05      -4.911802e+01 |       32
     35       6.723708e+05      -3.993731e+01 |       32
     36       6.723280e+05      -4.281902e+01 |       32
     37       6.722876e+05      -4.040468e+01 |       32
     38       6.722436e+05      -4.401902e+01 |       32
     39       6.721983e+05      -4.522396e+01 |       32
     40       6.721581e+05      -4.023748e+01 |       32
     41       6.721170e+05      -4.106833e+01 |       32
     42       6.720764e+05      -4.067404e+01 |       32
     43       6.720413e+05      -3.503299e+01 |       32
     44       6.720054e+05      -3.591261e+01 |       32
     45       6.719726e+05      -3.283817e+01 |       32
     46       6.719434e+05      -2.920088e+01 |       32
     47       6.719128e+05      -3.053749e+01 |       32
     48       6.718848e+05      -2.803870e+01 |       32
     49       6.718548e+05      -2.999475e+01 |       32
     50       6.718290e+05      -2.579446e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 671829.0040949073)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.421441
INFO: iteration 2, average log likelihood -1.416361
INFO: iteration 3, average log likelihood -1.414897
INFO: iteration 4, average log likelihood -1.413800
INFO: iteration 5, average log likelihood -1.412745
INFO: iteration 6, average log likelihood -1.411875
INFO: iteration 7, average log likelihood -1.411316
INFO: iteration 8, average log likelihood -1.411004
INFO: iteration 9, average log likelihood -1.410824
INFO: iteration 10, average log likelihood -1.410707
INFO: iteration 11, average log likelihood -1.410621
INFO: iteration 12, average log likelihood -1.410553
INFO: iteration 13, average log likelihood -1.410496
INFO: iteration 14, average log likelihood -1.410448
INFO: iteration 15, average log likelihood -1.410404
INFO: iteration 16, average log likelihood -1.410366
INFO: iteration 17, average log likelihood -1.410330
INFO: iteration 18, average log likelihood -1.410298
INFO: iteration 19, average log likelihood -1.410267
INFO: iteration 20, average log likelihood -1.410238
INFO: iteration 21, average log likelihood -1.410211
INFO: iteration 22, average log likelihood -1.410184
INFO: iteration 23, average log likelihood -1.410159
INFO: iteration 24, average log likelihood -1.410135
INFO: iteration 25, average log likelihood -1.410111
INFO: iteration 26, average log likelihood -1.410088
INFO: iteration 27, average log likelihood -1.410066
INFO: iteration 28, average log likelihood -1.410044
INFO: iteration 29, average log likelihood -1.410022
INFO: iteration 30, average log likelihood -1.410000
INFO: iteration 31, average log likelihood -1.409979
INFO: iteration 32, average log likelihood -1.409958
INFO: iteration 33, average log likelihood -1.409938
INFO: iteration 34, average log likelihood -1.409917
INFO: iteration 35, average log likelihood -1.409897
INFO: iteration 36, average log likelihood -1.409876
INFO: iteration 37, average log likelihood -1.409856
INFO: iteration 38, average log likelihood -1.409836
INFO: iteration 39, average log likelihood -1.409816
INFO: iteration 40, average log likelihood -1.409797
INFO: iteration 41, average log likelihood -1.409777
INFO: iteration 42, average log likelihood -1.409757
INFO: iteration 43, average log likelihood -1.409738
INFO: iteration 44, average log likelihood -1.409719
INFO: iteration 45, average log likelihood -1.409700
INFO: iteration 46, average log likelihood -1.409681
INFO: iteration 47, average log likelihood -1.409663
INFO: iteration 48, average log likelihood -1.409645
INFO: iteration 49, average log likelihood -1.409628
INFO: iteration 50, average log likelihood -1.409611
INFO: EM with 100000 data points 50 iterations avll -1.409611
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.235745   -0.510201      0.284418   â€¦  -0.322555     0.0438712   0.466135 
 -0.93743     0.0017708     0.119345       0.0526626   -0.536025    0.030376 
 -0.129526   -0.0519656     0.118114      -0.11457     -0.0694876   0.0710021
  0.471295    0.0721203    -0.200073      -0.423657    -0.430472   -0.0364769
 -0.317879    0.0505493    -0.59744        0.303906    -0.302265   -0.867861 
 -0.010368   -0.293401      0.059826   â€¦  -0.0890206    0.265239    0.399108 
  0.344274    0.403467      0.0818512      0.093019     0.992378   -0.356954 
  0.810788    0.168604     -0.121711      -0.0583111   -0.466377   -0.238014 
  0.473543    0.0139691    -0.180263       0.50423      0.460089    0.142318 
 -0.708371    0.219498      0.413304       0.00235674  -0.485483    0.303519 
  â‹®                                    â‹±                            â‹®        
  0.0530772   0.118355      0.588663      -0.529557    -0.153752    0.0708309
 -0.312194   -0.570135      0.185843      -0.224609    -0.421461    0.338467 
  0.262013    0.33483      -0.357198   â€¦  -0.0372428    0.491117   -0.184346 
 -0.134464    0.536139     -0.400232       0.171156    -0.078482    0.288396 
  0.124199   -0.172795      0.385548      -0.41042     -0.168899   -0.356632 
  0.111769    0.128102     -0.394931      -0.171071    -0.210089   -0.268251 
 -0.251676    0.1081        0.663902      -0.171335     0.298704    0.09443  
  0.101449   -0.480226     -0.414996   â€¦   0.230739     0.359063    0.110546 
 -0.214727   -0.000631544   0.0089629      0.507063    -0.0142179  -0.134401 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.409594
INFO: iteration 2, average log likelihood -1.409578
INFO: iteration 3, average log likelihood -1.409563
INFO: iteration 4, average log likelihood -1.409548
INFO: iteration 5, average log likelihood -1.409533
INFO: iteration 6, average log likelihood -1.409519
INFO: iteration 7, average log likelihood -1.409506
INFO: iteration 8, average log likelihood -1.409493
INFO: iteration 9, average log likelihood -1.409481
INFO: iteration 10, average log likelihood -1.409469
INFO: EM with 100000 data points 10 iterations avll -1.409469
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
