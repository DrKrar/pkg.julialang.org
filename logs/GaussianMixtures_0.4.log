>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.11.0
INFO: Installing FileIO v0.2.0
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.7.0
INFO: Installing JLD v0.6.6
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.0.5
INFO: Installing PDMats v0.5.1
INFO: Installing Rmath v0.1.4
INFO: Installing SHA v0.3.0
INFO: Installing ScikitLearnBase v0.2.1
INFO: Installing StatsBase v0.11.1
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.4.7
Commit ae26b25 (2016-09-18 16:17 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-101-generic #148-Ubuntu SMP Thu Oct 20 22:08:32 UTC 2016 x86_64 x86_64
Memory: 2.939281463623047 GB (651.01953125 MB free)
Uptime: 26117.0 sec
Load Avg:  0.9736328125  1.025390625  1.03466796875
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1273907 s       7262 s     114421 s     933990 s        117 s
#2  3500 MHz     761572 s        103 s     102906 s    1651804 s          2 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.4
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.8.0
19 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.4
 - Distances                     0.3.2
 - Distributions                 0.11.0
 - FileIO                        0.2.0
 - HDF5                          0.7.0
 - JLD                           0.6.6
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.0.5
 - PDMats                        0.5.1
 - Rmath                         0.1.4
 - SHA                           0.3.0
 - ScikitLearnBase               0.2.1
 - StatsBase                     0.11.1
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-905975.3860586091,[651.3888018268137,99348.6111981732],
[1651.783739817456 696.3162345854831 41.658581365277
 -2341.192480548097 -1030.1427698363696 596.2825811377645],

[
[4324.4933571987085 1599.832517182833 173.66838179470378
 1599.8325171828326 1182.9831887155763 -96.38274328981164
 173.66838179470375 -96.38274328981164 445.1530470399356],

[95571.81027197535 -1236.3377067848066 -283.58227779455734
 -1236.3377067848064 98275.28818818541 -700.2069112256906
 -283.5822777945573 -700.2069112256908 98892.39311729191]])
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.113761e+03
      1       8.567186e+02      -2.570429e+02 |        6
      2       7.830687e+02      -7.364983e+01 |        0
      3       7.830687e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 783.0687484339678)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.058547
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.813096
INFO: iteration 2, lowerbound -3.700513
INFO: iteration 3, lowerbound -3.573475
INFO: iteration 4, lowerbound -3.419652
INFO: iteration 5, lowerbound -3.255283
INFO: iteration 6, lowerbound -3.104369
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.982368
INFO: iteration 8, lowerbound -2.895611
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.831179
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.774330
INFO: iteration 11, lowerbound -2.737577
INFO: dropping number of Gaussions to 3
INFO: iteration 12, lowerbound -2.702087
INFO: iteration 13, lowerbound -2.653110
INFO: iteration 14, lowerbound -2.593663
INFO: iteration 15, lowerbound -2.525534
INFO: iteration 16, lowerbound -2.459446
INFO: iteration 17, lowerbound -2.404535
INFO: iteration 18, lowerbound -2.362842
INFO: iteration 19, lowerbound -2.332346
INFO: iteration 20, lowerbound -2.313077
INFO: iteration 21, lowerbound -2.307462
INFO: dropping number of Gaussions to 2
INFO: iteration 22, lowerbound -2.302927
INFO: iteration 23, lowerbound -2.299261
INFO: iteration 24, lowerbound -2.299256
INFO: iteration 25, lowerbound -2.299255
INFO: iteration 26, lowerbound -2.299254
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
[Wed 23 Nov 2016 12:36:38 PM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Wed 23 Nov 2016 12:36:39 PM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Wed 23 Nov 2016 12:36:39 PM UTC: EM with 272 data points 0 iterations avll -2.058547
5.8 data points per parameter
,Wed 23 Nov 2016 12:36:40 PM UTC: GMM converted to Variational GMM
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 1, lowerbound -3.813096
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 2, lowerbound -3.700513
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 3, lowerbound -3.573475
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 4, lowerbound -3.419652
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 5, lowerbound -3.255283
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 6, lowerbound -3.104369
,Wed 23 Nov 2016 12:36:41 PM UTC: dropping number of Gaussions to 7
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 7, lowerbound -2.982368
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 8, lowerbound -2.895611
,Wed 23 Nov 2016 12:36:41 PM UTC: dropping number of Gaussions to 5
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 9, lowerbound -2.831179
,Wed 23 Nov 2016 12:36:41 PM UTC: dropping number of Gaussions to 4
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 10, lowerbound -2.774330
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 11, lowerbound -2.737577
,Wed 23 Nov 2016 12:36:41 PM UTC: dropping number of Gaussions to 3
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 12, lowerbound -2.702087
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 13, lowerbound -2.653110
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 14, lowerbound -2.593663
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 15, lowerbound -2.525534
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 16, lowerbound -2.459446
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 17, lowerbound -2.404535
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 18, lowerbound -2.362842
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 19, lowerbound -2.332346
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 20, lowerbound -2.313077
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 21, lowerbound -2.307462
,Wed 23 Nov 2016 12:36:41 PM UTC: dropping number of Gaussions to 2
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 22, lowerbound -2.302927
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 23, lowerbound -2.299261
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 24, lowerbound -2.299256
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 25, lowerbound -2.299255
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 26, lowerbound -2.299254
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 27, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 28, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 29, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 30, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 31, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 32, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 33, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 34, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 35, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 36, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 37, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 38, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 39, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 40, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 41, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 42, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 43, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 44, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 45, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 46, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 47, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 48, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 49, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: iteration 50, lowerbound -2.299253
,Wed 23 Nov 2016 12:36:41 PM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398348,178.04509222601652]
β = [95.95490777398348,178.04509222601652]
m = [2.0002292577753473 53.851987172461165
 4.25030073326989 79.28686694436152]
ν = [97.95490777398348,180.04509222601652]
W = [
[0.3758763611948793 -0.008953123827346608
 0.0 0.012748664777409534],

[0.1840415554748424 -0.0076440490423271635
 0.0 0.008581705166333036]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999994
avll from stats: -0.9830497341862532
avll from llpg:  -0.9830497341862622
avll direct:     -0.9830497341862622
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0024714503365086
avll from llpg:  -1.0024714503365084
avll direct:     -1.0024714503365084
sum posterior: 100000.0
32x26 Array{Float64,2}:
 -0.00539526  -0.0215787     0.124317    …  -0.175044    -0.0425282 
  0.11535     -0.0804739    -0.0180834       0.046071    -0.160317  
  0.310417    -0.105707      0.00389834     -0.0212363   -0.0143035 
  0.0867729    0.000145723  -0.191157       -0.0377682    0.102526  
  0.0746664   -0.239045      0.0365606       0.154447    -0.0555392 
 -0.150964     0.0784251    -0.0383675   …   0.0597129    0.103655  
  0.00811149   0.118735      0.0846936      -0.0475411   -0.114776  
  0.0675852   -0.146201      0.191672        0.0460427    0.154476  
  0.0359787   -0.0925834    -0.00569937     -0.00762154   0.263574  
 -0.0338074   -0.117486     -0.166725       -0.161874    -0.337686  
  ⋮                                      ⋱                ⋮         
  9.07475e-5   0.163165      0.0153365      -0.0789476   -0.0586485 
  0.0563359    0.156488      0.0146699      -0.127726     0.00737735
 -0.0615422   -0.00846835    0.0388801   …  -0.0261259    0.034825  
 -0.099851     0.0116077     0.068536       -0.187786    -0.221277  
  0.125803    -0.0456692     0.0415155      -0.074708    -0.0067793 
  0.119735    -0.0560553     0.0374346       0.0439201    0.0347224 
 -0.0101042    0.00471751   -0.0804839      -0.140494    -0.144939  
 -0.147525     0.121571      0.0836626   …   0.102131     0.138486  
 -0.00832141  -0.0886162     0.00486798      0.0601789    0.023128  kind diag, method split
0: avll = -1.428162723358699
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.428270
INFO: iteration 2, average log likelihood -1.428156
INFO: iteration 3, average log likelihood -1.427225
INFO: iteration 4, average log likelihood -1.417515
INFO: iteration 5, average log likelihood -1.400229
INFO: iteration 6, average log likelihood -1.396485
INFO: iteration 7, average log likelihood -1.395795
INFO: iteration 8, average log likelihood -1.395370
INFO: iteration 9, average log likelihood -1.395020
INFO: iteration 10, average log likelihood -1.394715
INFO: iteration 11, average log likelihood -1.394466
INFO: iteration 12, average log likelihood -1.394270
INFO: iteration 13, average log likelihood -1.394109
INFO: iteration 14, average log likelihood -1.393969
INFO: iteration 15, average log likelihood -1.393849
INFO: iteration 16, average log likelihood -1.393750
INFO: iteration 17, average log likelihood -1.393668
INFO: iteration 18, average log likelihood -1.393600
INFO: iteration 19, average log likelihood -1.393545
INFO: iteration 20, average log likelihood -1.393499
INFO: iteration 21, average log likelihood -1.393461
INFO: iteration 22, average log likelihood -1.393430
INFO: iteration 23, average log likelihood -1.393405
INFO: iteration 24, average log likelihood -1.393383
INFO: iteration 25, average log likelihood -1.393366
INFO: iteration 26, average log likelihood -1.393351
INFO: iteration 27, average log likelihood -1.393338
INFO: iteration 28, average log likelihood -1.393328
INFO: iteration 29, average log likelihood -1.393319
INFO: iteration 30, average log likelihood -1.393311
INFO: iteration 31, average log likelihood -1.393305
INFO: iteration 32, average log likelihood -1.393300
INFO: iteration 33, average log likelihood -1.393296
INFO: iteration 34, average log likelihood -1.393292
INFO: iteration 35, average log likelihood -1.393289
INFO: iteration 36, average log likelihood -1.393286
INFO: iteration 37, average log likelihood -1.393283
INFO: iteration 38, average log likelihood -1.393281
INFO: iteration 39, average log likelihood -1.393278
INFO: iteration 40, average log likelihood -1.393276
INFO: iteration 41, average log likelihood -1.393274
INFO: iteration 42, average log likelihood -1.393273
INFO: iteration 43, average log likelihood -1.393271
INFO: iteration 44, average log likelihood -1.393270
INFO: iteration 45, average log likelihood -1.393268
INFO: iteration 46, average log likelihood -1.393267
INFO: iteration 47, average log likelihood -1.393266
INFO: iteration 48, average log likelihood -1.393265
INFO: iteration 49, average log likelihood -1.393264
INFO: iteration 50, average log likelihood -1.393263
INFO: EM with 100000 data points 50 iterations avll -1.393263
952.4 data points per parameter
1: avll = [-1.428270211925594,-1.4281559253074143,-1.4272249339365972,-1.4175152804830484,-1.400228668605086,-1.396484505783867,-1.395794880361742,-1.3953699849222472,-1.3950199836323753,-1.394714837597347,-1.394466471984311,-1.3942701577339034,-1.3941087898180902,-1.3939688718925796,-1.3938493565374477,-1.3937502475994614,-1.393668196568336,-1.393600479670142,-1.3935448115523583,-1.3934990812584513,-1.3934614907440883,-1.39343047742975,-1.3934047720032503,-1.3933833768170742,-1.393365507937545,-1.3933505535496378,-1.3933380321000441,-1.393327549635355,-1.393318774511449,-1.393311425105405,-1.3933052607713838,-1.3933000738811314,-1.393295683300492,-1.3932919288758179,-1.3932886669402855,-1.3932857693576215,-1.393283131724466,-1.3932806906458406,-1.393278428909648,-1.3932763512760984,-1.393274456227336,-1.3932727267317997,-1.3932711329076128,-1.3932696408792495,-1.393268229377247,-1.3932669058652492,-1.3932657030186653,-1.3932646553751544,-1.3932637798662542,-1.393263072440993]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.393408
INFO: iteration 2, average log likelihood -1.393290
INFO: iteration 3, average log likelihood -1.392908
INFO: iteration 4, average log likelihood -1.389281
INFO: iteration 5, average log likelihood -1.373424
INFO: iteration 6, average log likelihood -1.356951
INFO: iteration 7, average log likelihood -1.351893
INFO: iteration 8, average log likelihood -1.350157
INFO: iteration 9, average log likelihood -1.349265
INFO: iteration 10, average log likelihood -1.348688
INFO: iteration 11, average log likelihood -1.348279
INFO: iteration 12, average log likelihood -1.347966
INFO: iteration 13, average log likelihood -1.347706
INFO: iteration 14, average log likelihood -1.347475
INFO: iteration 15, average log likelihood -1.347260
INFO: iteration 16, average log likelihood -1.347049
INFO: iteration 17, average log likelihood -1.346840
INFO: iteration 18, average log likelihood -1.346637
INFO: iteration 19, average log likelihood -1.346444
INFO: iteration 20, average log likelihood -1.346265
INFO: iteration 21, average log likelihood -1.346099
INFO: iteration 22, average log likelihood -1.345949
INFO: iteration 23, average log likelihood -1.345811
INFO: iteration 24, average log likelihood -1.345683
INFO: iteration 25, average log likelihood -1.345575
INFO: iteration 26, average log likelihood -1.345500
INFO: iteration 27, average log likelihood -1.345446
INFO: iteration 28, average log likelihood -1.345403
INFO: iteration 29, average log likelihood -1.345368
INFO: iteration 30, average log likelihood -1.345338
INFO: iteration 31, average log likelihood -1.345312
INFO: iteration 32, average log likelihood -1.345287
INFO: iteration 33, average log likelihood -1.345264
INFO: iteration 34, average log likelihood -1.345242
INFO: iteration 35, average log likelihood -1.345222
INFO: iteration 36, average log likelihood -1.345202
INFO: iteration 37, average log likelihood -1.345183
INFO: iteration 38, average log likelihood -1.345165
INFO: iteration 39, average log likelihood -1.345148
INFO: iteration 40, average log likelihood -1.345132
INFO: iteration 41, average log likelihood -1.345118
INFO: iteration 42, average log likelihood -1.345105
INFO: iteration 43, average log likelihood -1.345093
INFO: iteration 44, average log likelihood -1.345082
INFO: iteration 45, average log likelihood -1.345072
INFO: iteration 46, average log likelihood -1.345063
INFO: iteration 47, average log likelihood -1.345054
INFO: iteration 48, average log likelihood -1.345045
INFO: iteration 49, average log likelihood -1.345037
INFO: iteration 50, average log likelihood -1.345029
INFO: EM with 100000 data points 50 iterations avll -1.345029
473.9 data points per parameter
2: avll = [-1.3934077061470669,-1.3932896349107817,-1.3929078267804942,-1.3892808559369456,-1.3734239729774844,-1.3569509342417838,-1.3518929551216416,-1.3501568916076376,-1.3492650596612348,-1.348688495430963,-1.3482789666664678,-1.347965845006772,-1.3477056107271501,-1.3474750634629948,-1.3472597724106083,-1.3470487086186465,-1.346840272666069,-1.3466368181088804,-1.3464439052072452,-1.346265446091662,-1.3460989861770007,-1.345949485032221,-1.3458114715202503,-1.345682792957849,-1.3455749624469504,-1.3454997292566804,-1.3454455667185616,-1.3454031588078348,-1.345368248548469,-1.3453382681067436,-1.3453115964460152,-1.3452871577773136,-1.3452641873087239,-1.3452423564176308,-1.3452216365361693,-1.3452019993945896,-1.3451832895159932,-1.3451653386719227,-1.3451482710894802,-1.3451324056347385,-1.345117940904433,-1.3451048576395106,-1.3450929862765757,-1.3450820974302689,-1.3450719821544865,-1.345062500824594,-1.3450535707649034,-1.3450451312508223,-1.3450371210747472,-1.345029495732751]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.345261
INFO: iteration 2, average log likelihood -1.345043
INFO: iteration 3, average log likelihood -1.344468
INFO: iteration 4, average log likelihood -1.338942
INFO: iteration 5, average log likelihood -1.320908
INFO: iteration 6, average log likelihood -1.306661
INFO: iteration 7, average log likelihood -1.301280
INFO: iteration 8, average log likelihood -1.298652
INFO: iteration 9, average log likelihood -1.297122
INFO: iteration 10, average log likelihood -1.296206
INFO: iteration 11, average log likelihood -1.295636
INFO: iteration 12, average log likelihood -1.295255
INFO: iteration 13, average log likelihood -1.294968
INFO: iteration 14, average log likelihood -1.294730
INFO: iteration 15, average log likelihood -1.294518
INFO: iteration 16, average log likelihood -1.294319
INFO: iteration 17, average log likelihood -1.294129
INFO: iteration 18, average log likelihood -1.293952
INFO: iteration 19, average log likelihood -1.293788
INFO: iteration 20, average log likelihood -1.293632
INFO: iteration 21, average log likelihood -1.293470
INFO: iteration 22, average log likelihood -1.293304
INFO: iteration 23, average log likelihood -1.293141
INFO: iteration 24, average log likelihood -1.292980
INFO: iteration 25, average log likelihood -1.292829
INFO: iteration 26, average log likelihood -1.292692
INFO: iteration 27, average log likelihood -1.292578
INFO: iteration 28, average log likelihood -1.292469
INFO: iteration 29, average log likelihood -1.292350
INFO: iteration 30, average log likelihood -1.292201
INFO: iteration 31, average log likelihood -1.291981
INFO: iteration 32, average log likelihood -1.291612
INFO: iteration 33, average log likelihood -1.290950
INFO: iteration 34, average log likelihood -1.289921
INFO: iteration 35, average log likelihood -1.289216
INFO: iteration 36, average log likelihood -1.288966
INFO: iteration 37, average log likelihood -1.288845
INFO: iteration 38, average log likelihood -1.288758
INFO: iteration 39, average log likelihood -1.288680
INFO: iteration 40, average log likelihood -1.288601
INFO: iteration 41, average log likelihood -1.288516
INFO: iteration 42, average log likelihood -1.288416
INFO: iteration 43, average log likelihood -1.288295
INFO: iteration 44, average log likelihood -1.288140
INFO: iteration 45, average log likelihood -1.287942
INFO: iteration 46, average log likelihood -1.287695
INFO: iteration 47, average log likelihood -1.287403
INFO: iteration 48, average log likelihood -1.287098
INFO: iteration 49, average log likelihood -1.286839
INFO: iteration 50, average log likelihood -1.286634
INFO: EM with 100000 data points 50 iterations avll -1.286634
236.4 data points per parameter
3: avll = [-1.345260626706272,-1.345042662842379,-1.3444675907179917,-1.3389424214701187,-1.3209083205646905,-1.3066610511939851,-1.3012796688972288,-1.2986515371654468,-1.2971219666575855,-1.2962056247431917,-1.2956359864316043,-1.2952546066002337,-1.2949676812529278,-1.2947303741181166,-1.2945184616954946,-1.2943194573518129,-1.2941293276215342,-1.2939516397379378,-1.293787943536827,-1.2936315719294895,-1.2934698022513997,-1.29330370406395,-1.2931408828882491,-1.2929798923219147,-1.292828844449458,-1.292692358419344,-1.2925776568137282,-1.2924691244184376,-1.2923498791545542,-1.2922011778272924,-1.2919811616127865,-1.291612471422502,-1.2909498867153628,-1.2899207994223338,-1.289215900186304,-1.2889658324175783,-1.2888447736490103,-1.2887576750178018,-1.2886798297800908,-1.2886014175129477,-1.2885158601667097,-1.2884164397854254,-1.2882949601811455,-1.2881403123706532,-1.2879424923613145,-1.2876951601656297,-1.2874030399354572,-1.2870983884004246,-1.286838775339264,-1.2866344248821115]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.286752
INFO: iteration 2, average log likelihood -1.286223
INFO: iteration 3, average log likelihood -1.283590
INFO: iteration 4, average log likelihood -1.262931
INFO: iteration 5, average log likelihood -1.225772
INFO: iteration 6, average log likelihood -1.204799
WARNING: Variances had to be floored 9 15
INFO: iteration 7, average log likelihood -1.194279
INFO: iteration 8, average log likelihood -1.207411
WARNING: Variances had to be floored 16
INFO: iteration 9, average log likelihood -1.194307
INFO: iteration 10, average log likelihood -1.197993
WARNING: Variances had to be floored 15
INFO: iteration 11, average log likelihood -1.189016
WARNING: Variances had to be floored 9
INFO: iteration 12, average log likelihood -1.196246
INFO: iteration 13, average log likelihood -1.198013
INFO: iteration 14, average log likelihood -1.189056
WARNING: Variances had to be floored 15 16
INFO: iteration 15, average log likelihood -1.184616
INFO: iteration 16, average log likelihood -1.200788
WARNING: Variances had to be floored 9
INFO: iteration 17, average log likelihood -1.198864
INFO: iteration 18, average log likelihood -1.202389
INFO: iteration 19, average log likelihood -1.190052
WARNING: Variances had to be floored 15
INFO: iteration 20, average log likelihood -1.183580
WARNING: Variances had to be floored 16
INFO: iteration 21, average log likelihood -1.189934
WARNING: Variances had to be floored 9
INFO: iteration 22, average log likelihood -1.191566
WARNING: Variances had to be floored 12 15
INFO: iteration 23, average log likelihood -1.188663
INFO: iteration 24, average log likelihood -1.198689
INFO: iteration 25, average log likelihood -1.183300
WARNING: Variances had to be floored 9 15 16
INFO: iteration 26, average log likelihood -1.176420
INFO: iteration 27, average log likelihood -1.201478
INFO: iteration 28, average log likelihood -1.195583
INFO: iteration 29, average log likelihood -1.188154
WARNING: Variances had to be floored 9
INFO: iteration 30, average log likelihood -1.179253
WARNING: Variances had to be floored 15
INFO: iteration 31, average log likelihood -1.183723
WARNING: Variances had to be floored 16
INFO: iteration 32, average log likelihood -1.186604
WARNING: Variances had to be floored 12
INFO: iteration 33, average log likelihood -1.186423
WARNING: Variances had to be floored 15
INFO: iteration 34, average log likelihood -1.185352
WARNING: Variances had to be floored 9
INFO: iteration 35, average log likelihood -1.187329
INFO: iteration 36, average log likelihood -1.188009
WARNING: Variances had to be floored 15 16
INFO: iteration 37, average log likelihood -1.179126
INFO: iteration 38, average log likelihood -1.193294
WARNING: Variances had to be floored 9
INFO: iteration 39, average log likelihood -1.191317
INFO: iteration 40, average log likelihood -1.194881
INFO: iteration 41, average log likelihood -1.182436
WARNING: Variances had to be floored 15
INFO: iteration 42, average log likelihood -1.176082
WARNING: Variances had to be floored 16
INFO: iteration 43, average log likelihood -1.183004
WARNING: Variances had to be floored 9
INFO: iteration 44, average log likelihood -1.185740
WARNING: Variances had to be floored 15
INFO: iteration 45, average log likelihood -1.184888
WARNING: Variances had to be floored 12
INFO: iteration 46, average log likelihood -1.184338
INFO: iteration 47, average log likelihood -1.185767
WARNING: Variances had to be floored 15 16
INFO: iteration 48, average log likelihood -1.176208
WARNING: Variances had to be floored 9
INFO: iteration 49, average log likelihood -1.191093
INFO: iteration 50, average log likelihood -1.199400
INFO: EM with 100000 data points 50 iterations avll -1.199400
118.1 data points per parameter
4: avll = [-1.2867524519318538,-1.2862234968248858,-1.2835904193479408,-1.262931496573546,-1.2257724763186688,-1.2047987119133334,-1.1942792676937262,-1.2074111280337867,-1.194306742596137,-1.1979928919780234,-1.1890159340433213,-1.1962456716265129,-1.1980132605804918,-1.189056303595723,-1.1846155369266498,-1.200788332535153,-1.1988635032701953,-1.2023887403559266,-1.1900516330957929,-1.1835800648217019,-1.1899344564485772,-1.1915662494598458,-1.188663484609009,-1.1986886493838529,-1.1833002527775907,-1.1764200297389549,-1.2014780636254185,-1.1955831807506878,-1.1881541769588086,-1.1792527074083246,-1.1837227545678448,-1.1866044488342422,-1.1864234758859071,-1.1853515191913795,-1.187329207139971,-1.1880091575929383,-1.1791255581328075,-1.193293803362217,-1.1913174621513325,-1.1948810378454156,-1.1824355622793785,-1.1760822928966113,-1.1830039774339574,-1.1857400246910306,-1.184888014939485,-1.184337712028631,-1.185766896928065,-1.1762078190197942,-1.1910934671140232,-1.1993997598019266]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.189426
INFO: iteration 2, average log likelihood -1.179367
WARNING: Variances had to be floored 17 29 30
INFO: iteration 3, average log likelihood -1.171178
WARNING: Variances had to be floored 3 18 31 32
INFO: iteration 4, average log likelihood -1.149297
WARNING: Variances had to be floored 3 24 28
INFO: iteration 5, average log likelihood -1.113385
WARNING: Variances had to be floored 3 29 30
INFO: iteration 6, average log likelihood -1.098652
WARNING: Variances had to be floored 3 18 23 24 28
INFO: iteration 7, average log likelihood -1.081119
WARNING: Variances had to be floored 3 8 31 32
INFO: iteration 8, average log likelihood -1.094848
WARNING: Variances had to be floored 3 17 28 29 30
INFO: iteration 9, average log likelihood -1.096075
WARNING: Variances had to be floored 3 5 18 24
INFO: iteration 10, average log likelihood -1.089686
WARNING: Variances had to be floored 3 28 31
INFO: iteration 11, average log likelihood -1.094179
WARNING: Variances had to be floored 3 18 23 24 29 30 32
INFO: iteration 12, average log likelihood -1.081003
WARNING: Variances had to be floored 3 8 28
INFO: iteration 13, average log likelihood -1.095040
WARNING: Variances had to be floored 3 5 18 29 30
INFO: iteration 14, average log likelihood -1.088306
WARNING: Variances had to be floored 3 24 28 32
INFO: iteration 15, average log likelihood -1.081057
WARNING: Variances had to be floored 3 18 23 29 30
INFO: iteration 16, average log likelihood -1.077405
WARNING: Variances had to be floored 3 5 8 24 28
INFO: iteration 17, average log likelihood -1.066579
WARNING: Variances had to be floored 3 29 30 32
INFO: iteration 18, average log likelihood -1.085665
WARNING: Variances had to be floored 3 18 23 24 28
INFO: iteration 19, average log likelihood -1.067632
WARNING: Variances had to be floored 3 5 29 30
INFO: iteration 20, average log likelihood -1.075064
WARNING: Variances had to be floored 3 8 28 32
INFO: iteration 21, average log likelihood -1.074696
WARNING: Variances had to be floored 3 18 24 29 30
INFO: iteration 22, average log likelihood -1.075001
WARNING: Variances had to be floored 3 5 23 28
INFO: iteration 23, average log likelihood -1.069724
WARNING: Variances had to be floored 3 18 24 29 30 32
INFO: iteration 24, average log likelihood -1.074928
WARNING: Variances had to be floored 3 8 28
INFO: iteration 25, average log likelihood -1.075128
WARNING: Variances had to be floored 3 5 18 23 24 29 30
INFO: iteration 26, average log likelihood -1.067276
WARNING: Variances had to be floored 3 28 32
INFO: iteration 27, average log likelihood -1.086032
WARNING: Variances had to be floored 3 29 30
INFO: iteration 28, average log likelihood -1.077072
WARNING: Variances had to be floored 3 5 8 18 24 28
INFO: iteration 29, average log likelihood -1.054574
WARNING: Variances had to be floored 3 23 29 30 32
INFO: iteration 30, average log likelihood -1.086591
WARNING: Variances had to be floored 3 18 24 28
INFO: iteration 31, average log likelihood -1.075476
WARNING: Variances had to be floored 3 5 29 30
INFO: iteration 32, average log likelihood -1.070846
WARNING: Variances had to be floored 3 8 18 23 24 28 32
INFO: iteration 33, average log likelihood -1.064281
WARNING: Variances had to be floored 3 29 30
INFO: iteration 34, average log likelihood -1.091770
WARNING: Variances had to be floored 3 5 28
INFO: iteration 35, average log likelihood -1.070581
WARNING: Variances had to be floored 3 18 24 29 30 32
INFO: iteration 36, average log likelihood -1.067546
WARNING: Variances had to be floored 3 8 23 28
INFO: iteration 37, average log likelihood -1.073069
WARNING: Variances had to be floored 3 18 24 29 30
INFO: iteration 38, average log likelihood -1.074717
WARNING: Variances had to be floored 3 5 28 32
INFO: iteration 39, average log likelihood -1.069253
WARNING: Variances had to be floored 3 18 23 24 29 30
INFO: iteration 40, average log likelihood -1.074213
WARNING: Variances had to be floored 3 8 28
INFO: iteration 41, average log likelihood -1.075156
WARNING: Variances had to be floored 3 29 30 32
INFO: iteration 42, average log likelihood -1.075891
WARNING: Variances had to be floored 3 5 18 24 28
INFO: iteration 43, average log likelihood -1.062639
WARNING: Variances had to be floored 3 23 29 30
INFO: iteration 44, average log likelihood -1.079771
WARNING: Variances had to be floored 3 8 18 24 28 32
INFO: iteration 45, average log likelihood -1.064019
WARNING: Variances had to be floored 3 29 30
INFO: iteration 46, average log likelihood -1.083707
WARNING: Variances had to be floored 3 5 18 23 24 28
INFO: iteration 47, average log likelihood -1.058361
WARNING: Variances had to be floored 3 29 30 32
INFO: iteration 48, average log likelihood -1.084243
WARNING: Variances had to be floored 3 8 28
INFO: iteration 49, average log likelihood -1.073257
WARNING: Variances had to be floored 3 18 24 29 30
INFO: iteration 50, average log likelihood -1.067135
INFO: EM with 100000 data points 50 iterations avll -1.067135
59.0 data points per parameter
5: avll = [-1.1894263629848463,-1.1793670512983214,-1.171177872764394,-1.1492971417552624,-1.1133851086544984,-1.0986515014293479,-1.0811194297835005,-1.094848386385272,-1.0960748868367405,-1.0896863406949109,-1.0941793405956055,-1.0810027904765784,-1.0950402986852366,-1.0883057257541056,-1.0810567749827005,-1.0774052674340313,-1.0665789526261136,-1.0856651920056848,-1.0676315861024803,-1.0750635335664598,-1.074695698560524,-1.0750008720422848,-1.0697238901879516,-1.0749279908512477,-1.075128062937499,-1.0672762222270151,-1.0860317490489348,-1.0770716402103642,-1.0545735837773775,-1.0865907636063425,-1.0754758949535987,-1.0708462999426078,-1.0642810077021538,-1.0917703090879254,-1.0705805569939488,-1.06754557966453,-1.0730694317645297,-1.074717126034822,-1.0692528804390722,-1.0742125851293385,-1.075155953327055,-1.075891307990351,-1.0626391380914588,-1.079770641503958,-1.0640187445027844,-1.0837073868045024,-1.0583609060153973,-1.0842426189897751,-1.0732569487345929,-1.067135209801466]
[-1.428162723358699,-1.428270211925594,-1.4281559253074143,-1.4272249339365972,-1.4175152804830484,-1.400228668605086,-1.396484505783867,-1.395794880361742,-1.3953699849222472,-1.3950199836323753,-1.394714837597347,-1.394466471984311,-1.3942701577339034,-1.3941087898180902,-1.3939688718925796,-1.3938493565374477,-1.3937502475994614,-1.393668196568336,-1.393600479670142,-1.3935448115523583,-1.3934990812584513,-1.3934614907440883,-1.39343047742975,-1.3934047720032503,-1.3933833768170742,-1.393365507937545,-1.3933505535496378,-1.3933380321000441,-1.393327549635355,-1.393318774511449,-1.393311425105405,-1.3933052607713838,-1.3933000738811314,-1.393295683300492,-1.3932919288758179,-1.3932886669402855,-1.3932857693576215,-1.393283131724466,-1.3932806906458406,-1.393278428909648,-1.3932763512760984,-1.393274456227336,-1.3932727267317997,-1.3932711329076128,-1.3932696408792495,-1.393268229377247,-1.3932669058652492,-1.3932657030186653,-1.3932646553751544,-1.3932637798662542,-1.393263072440993,-1.3934077061470669,-1.3932896349107817,-1.3929078267804942,-1.3892808559369456,-1.3734239729774844,-1.3569509342417838,-1.3518929551216416,-1.3501568916076376,-1.3492650596612348,-1.348688495430963,-1.3482789666664678,-1.347965845006772,-1.3477056107271501,-1.3474750634629948,-1.3472597724106083,-1.3470487086186465,-1.346840272666069,-1.3466368181088804,-1.3464439052072452,-1.346265446091662,-1.3460989861770007,-1.345949485032221,-1.3458114715202503,-1.345682792957849,-1.3455749624469504,-1.3454997292566804,-1.3454455667185616,-1.3454031588078348,-1.345368248548469,-1.3453382681067436,-1.3453115964460152,-1.3452871577773136,-1.3452641873087239,-1.3452423564176308,-1.3452216365361693,-1.3452019993945896,-1.3451832895159932,-1.3451653386719227,-1.3451482710894802,-1.3451324056347385,-1.345117940904433,-1.3451048576395106,-1.3450929862765757,-1.3450820974302689,-1.3450719821544865,-1.345062500824594,-1.3450535707649034,-1.3450451312508223,-1.3450371210747472,-1.345029495732751,-1.345260626706272,-1.345042662842379,-1.3444675907179917,-1.3389424214701187,-1.3209083205646905,-1.3066610511939851,-1.3012796688972288,-1.2986515371654468,-1.2971219666575855,-1.2962056247431917,-1.2956359864316043,-1.2952546066002337,-1.2949676812529278,-1.2947303741181166,-1.2945184616954946,-1.2943194573518129,-1.2941293276215342,-1.2939516397379378,-1.293787943536827,-1.2936315719294895,-1.2934698022513997,-1.29330370406395,-1.2931408828882491,-1.2929798923219147,-1.292828844449458,-1.292692358419344,-1.2925776568137282,-1.2924691244184376,-1.2923498791545542,-1.2922011778272924,-1.2919811616127865,-1.291612471422502,-1.2909498867153628,-1.2899207994223338,-1.289215900186304,-1.2889658324175783,-1.2888447736490103,-1.2887576750178018,-1.2886798297800908,-1.2886014175129477,-1.2885158601667097,-1.2884164397854254,-1.2882949601811455,-1.2881403123706532,-1.2879424923613145,-1.2876951601656297,-1.2874030399354572,-1.2870983884004246,-1.286838775339264,-1.2866344248821115,-1.2867524519318538,-1.2862234968248858,-1.2835904193479408,-1.262931496573546,-1.2257724763186688,-1.2047987119133334,-1.1942792676937262,-1.2074111280337867,-1.194306742596137,-1.1979928919780234,-1.1890159340433213,-1.1962456716265129,-1.1980132605804918,-1.189056303595723,-1.1846155369266498,-1.200788332535153,-1.1988635032701953,-1.2023887403559266,-1.1900516330957929,-1.1835800648217019,-1.1899344564485772,-1.1915662494598458,-1.188663484609009,-1.1986886493838529,-1.1833002527775907,-1.1764200297389549,-1.2014780636254185,-1.1955831807506878,-1.1881541769588086,-1.1792527074083246,-1.1837227545678448,-1.1866044488342422,-1.1864234758859071,-1.1853515191913795,-1.187329207139971,-1.1880091575929383,-1.1791255581328075,-1.193293803362217,-1.1913174621513325,-1.1948810378454156,-1.1824355622793785,-1.1760822928966113,-1.1830039774339574,-1.1857400246910306,-1.184888014939485,-1.184337712028631,-1.185766896928065,-1.1762078190197942,-1.1910934671140232,-1.1993997598019266,-1.1894263629848463,-1.1793670512983214,-1.171177872764394,-1.1492971417552624,-1.1133851086544984,-1.0986515014293479,-1.0811194297835005,-1.094848386385272,-1.0960748868367405,-1.0896863406949109,-1.0941793405956055,-1.0810027904765784,-1.0950402986852366,-1.0883057257541056,-1.0810567749827005,-1.0774052674340313,-1.0665789526261136,-1.0856651920056848,-1.0676315861024803,-1.0750635335664598,-1.074695698560524,-1.0750008720422848,-1.0697238901879516,-1.0749279908512477,-1.075128062937499,-1.0672762222270151,-1.0860317490489348,-1.0770716402103642,-1.0545735837773775,-1.0865907636063425,-1.0754758949535987,-1.0708462999426078,-1.0642810077021538,-1.0917703090879254,-1.0705805569939488,-1.06754557966453,-1.0730694317645297,-1.074717126034822,-1.0692528804390722,-1.0742125851293385,-1.075155953327055,-1.075891307990351,-1.0626391380914588,-1.079770641503958,-1.0640187445027844,-1.0837073868045024,-1.0583609060153973,-1.0842426189897751,-1.0732569487345929,-1.067135209801466]
32x26 Array{Float64,2}:
  0.00579      0.025534    -0.0622934    …  -0.14767     -0.149277  
 -0.0132304   -0.0374927   -0.119719        -0.130712    -0.158205  
 -0.00942477  -0.0943305   -0.00476598       0.0550565    0.0137454 
  0.0471989   -0.1516       0.194835         0.0404629    0.171823  
  0.036314    -0.123836    -0.0427184        0.169255     0.033168  
 -0.0346772    0.00592361   0.000381324  …  -0.0786369    0.0867564 
  0.0957724    0.0390105    0.108727        -0.0703179    0.0371683 
  0.00119181   0.157509     0.0218686       -0.0700472   -0.0466532 
 -0.00811649  -0.0684656    0.141487        -0.00196071  -0.146445  
  0.291221     0.221369    -0.040921         0.100698     0.0562363 
  ⋮                                      ⋱                ⋮         
  0.0399952   -0.116735     0.0608639        0.119176     0.129045  
  0.0391327   -0.0674064   -0.0966967       -0.0278329   -0.0115341 
  0.0803558   -0.202381     0.00350621   …   0.0796703   -0.0403265 
 -0.0614985   -0.0643718   -0.0616603        0.163537     0.176196  
  0.216582    -0.0623844    0.106835         0.130348     0.00506295
  0.153698    -0.0786585   -0.0172398        0.0451973   -0.146637  
 -0.0352205   -0.0826665   -0.0172077        0.0102952   -0.154985  
 -0.00172437   0.116239     0.0774114    …  -0.0324664   -0.0937486 
 -0.0763485   -0.00607362   0.0661772       -0.203456    -0.274377  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 3 5 23 28 32
INFO: iteration 1, average log likelihood -1.066708
WARNING: Variances had to be floored 3 5 18 23 24 28 29 30 32
INFO: iteration 2, average log likelihood -1.047847
WARNING: Variances had to be floored 3 5 8 23 28 32
INFO: iteration 3, average log likelihood -1.061575
WARNING: Variances had to be floored 3 5 18 23 24 28 29 30 32
INFO: iteration 4, average log likelihood -1.050912
WARNING: Variances had to be floored 3 5 23 28 32
INFO: iteration 5, average log likelihood -1.063149
WARNING: Variances had to be floored 3 5 8 18 23 24 28 29 30 32
INFO: iteration 6, average log likelihood -1.045664
WARNING: Variances had to be floored 3 5 23 28 32
INFO: iteration 7, average log likelihood -1.066626
WARNING: Variances had to be floored 3 5 18 23 24 28 29 30 32
INFO: iteration 8, average log likelihood -1.047376
WARNING: Variances had to be floored 3 5 8 23 28 32
INFO: iteration 9, average log likelihood -1.061366
WARNING: Variances had to be floored 3 5 18 23 24 28 29 30 32
INFO: iteration 10, average log likelihood -1.050878
INFO: EM with 100000 data points 10 iterations avll -1.050878
59.0 data points per parameter
kind diag, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.827299e+05
      1       6.963405e+05      -1.863894e+05 |       32
      2       6.673678e+05      -2.897270e+04 |       32
      3       6.538176e+05      -1.355019e+04 |       32
      4       6.467967e+05      -7.020898e+03 |       32
      5       6.432238e+05      -3.572933e+03 |       32
      6       6.412738e+05      -1.950005e+03 |       32
      7       6.397584e+05      -1.515417e+03 |       32
      8       6.382237e+05      -1.534660e+03 |       32
      9       6.366888e+05      -1.534848e+03 |       32
     10       6.353218e+05      -1.367011e+03 |       32
     11       6.343469e+05      -9.749002e+02 |       32
     12       6.337673e+05      -5.795916e+02 |       32
     13       6.333864e+05      -3.808991e+02 |       32
     14       6.331035e+05      -2.829050e+02 |       32
     15       6.328408e+05      -2.627028e+02 |       32
     16       6.326444e+05      -1.964472e+02 |       32
     17       6.325282e+05      -1.161458e+02 |       32
     18       6.324728e+05      -5.548937e+01 |       32
     19       6.324359e+05      -3.685490e+01 |       31
     20       6.324082e+05      -2.774137e+01 |       31
     21       6.323849e+05      -2.321597e+01 |       31
     22       6.323673e+05      -1.761981e+01 |       30
     23       6.323497e+05      -1.762290e+01 |       30
     24       6.323317e+05      -1.797908e+01 |       30
     25       6.323152e+05      -1.655752e+01 |       32
     26       6.322971e+05      -1.803114e+01 |       31
     27       6.322822e+05      -1.495974e+01 |       30
     28       6.322700e+05      -1.214831e+01 |       29
     29       6.322599e+05      -1.017467e+01 |       30
     30       6.322539e+05      -5.902775e+00 |       31
     31       6.322457e+05      -8.256080e+00 |       27
     32       6.322397e+05      -6.004105e+00 |       26
     33       6.322353e+05      -4.389388e+00 |       28
     34       6.322302e+05      -5.110162e+00 |       26
     35       6.322227e+05      -7.479680e+00 |       26
     36       6.322135e+05      -9.250481e+00 |       25
     37       6.322074e+05      -6.016819e+00 |       26
     38       6.322027e+05      -4.705019e+00 |       21
     39       6.321977e+05      -5.037936e+00 |       22
     40       6.321940e+05      -3.676558e+00 |       22
     41       6.321895e+05      -4.494605e+00 |       25
     42       6.321839e+05      -5.633362e+00 |       22
     43       6.321794e+05      -4.541741e+00 |       23
     44       6.321760e+05      -3.377419e+00 |       19
     45       6.321729e+05      -3.049664e+00 |       22
     46       6.321701e+05      -2.842509e+00 |       17
     47       6.321682e+05      -1.886898e+00 |       17
     48       6.321665e+05      -1.731644e+00 |       14
     49       6.321651e+05      -1.343994e+00 |       16
     50       6.321636e+05      -1.548014e+00 |       15
K-means terminated without convergence after 50 iterations (objv = 632163.5728059236)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.344068
INFO: iteration 2, average log likelihood -1.311228
INFO: iteration 3, average log likelihood -1.274924
INFO: iteration 4, average log likelihood -1.228420
WARNING: Variances had to be floored 11
INFO: iteration 5, average log likelihood -1.175966
INFO: iteration 6, average log likelihood -1.143994
WARNING: Variances had to be floored 9 19 21 23 26 27
INFO: iteration 7, average log likelihood -1.087208
WARNING: Variances had to be floored 1 6 11 29
INFO: iteration 8, average log likelihood -1.128631
WARNING: Variances had to be floored 2
INFO: iteration 9, average log likelihood -1.140773
WARNING: Variances had to be floored 30
INFO: iteration 10, average log likelihood -1.090054
WARNING: Variances had to be floored 6 9 11 19 26
INFO: iteration 11, average log likelihood -1.055448
WARNING: Variances had to be floored 1 21 27 29
INFO: iteration 12, average log likelihood -1.109130
WARNING: Variances had to be floored 2
INFO: iteration 13, average log likelihood -1.104090
WARNING: Variances had to be floored 9 11 19 23 30
INFO: iteration 14, average log likelihood -1.065466
WARNING: Variances had to be floored 6 26
INFO: iteration 15, average log likelihood -1.117746
WARNING: Variances had to be floored 27
INFO: iteration 16, average log likelihood -1.103064
WARNING: Variances had to be floored 1 2 9 11 19 21
INFO: iteration 17, average log likelihood -1.061630
WARNING: Variances had to be floored 23 29
INFO: iteration 18, average log likelihood -1.109277
WARNING: Variances had to be floored 6 26 30
INFO: iteration 19, average log likelihood -1.097006
WARNING: Variances had to be floored 18 19
INFO: iteration 20, average log likelihood -1.101962
WARNING: Variances had to be floored 9 11
INFO: iteration 21, average log likelihood -1.070956
WARNING: Variances had to be floored 1 2 6 21 23 26 27
INFO: iteration 22, average log likelihood -1.058201
WARNING: Variances had to be floored 19 30
INFO: iteration 23, average log likelihood -1.130969
WARNING: Variances had to be floored 11
INFO: iteration 24, average log likelihood -1.113476
WARNING: Variances had to be floored 9 29
INFO: iteration 25, average log likelihood -1.079789
WARNING: Variances had to be floored 2 6 19 26 27
INFO: iteration 26, average log likelihood -1.071529
WARNING: Variances had to be floored 1 11 21 30
INFO: iteration 27, average log likelihood -1.102345
INFO: iteration 28, average log likelihood -1.118686
WARNING: Variances had to be floored 9 29
INFO: iteration 29, average log likelihood -1.068198
WARNING: Variances had to be floored 2 6 11 18 19 23 26 27
INFO: iteration 30, average log likelihood -1.070182
INFO: iteration 31, average log likelihood -1.138320
WARNING: Variances had to be floored 1 21
INFO: iteration 32, average log likelihood -1.079733
WARNING: Variances had to be floored 9 11 29 30
INFO: iteration 33, average log likelihood -1.057947
WARNING: Variances had to be floored 2 6 18 19 23 26 27
INFO: iteration 34, average log likelihood -1.099191
INFO: iteration 35, average log likelihood -1.139462
WARNING: Variances had to be floored 11
INFO: iteration 36, average log likelihood -1.089431
WARNING: Variances had to be floored 1 2 9 19 21 29
INFO: iteration 37, average log likelihood -1.048850
WARNING: Variances had to be floored 6 18 23 26 27 30
INFO: iteration 38, average log likelihood -1.099485
WARNING: Variances had to be floored 11
INFO: iteration 39, average log likelihood -1.133953
INFO: iteration 40, average log likelihood -1.107712
WARNING: Variances had to be floored 9 19 29
INFO: iteration 41, average log likelihood -1.052932
WARNING: Variances had to be floored 1 6 11 18 21 23 26 27 30
INFO: iteration 42, average log likelihood -1.057970
WARNING: Variances had to be floored 2
INFO: iteration 43, average log likelihood -1.142229
WARNING: Variances had to be floored 19
INFO: iteration 44, average log likelihood -1.113715
WARNING: Variances had to be floored 9 11
INFO: iteration 45, average log likelihood -1.086113
WARNING: Variances had to be floored 6 18 26 27 29
INFO: iteration 46, average log likelihood -1.071679
WARNING: Variances had to be floored 1 2 19 21 23 30
INFO: iteration 47, average log likelihood -1.078184
WARNING: Variances had to be floored 11
INFO: iteration 48, average log likelihood -1.125718
WARNING: Variances had to be floored 9
INFO: iteration 49, average log likelihood -1.105385
WARNING: Variances had to be floored 6 18 27
INFO: iteration 50, average log likelihood -1.089176
INFO: EM with 100000 data points 50 iterations avll -1.089176
59.0 data points per parameter
32x26 Array{Float64,2}:
  0.0485287  -0.111743     0.0574355   …   0.108389     0.131516 
  0.149749    0.0402772    0.0655316      -0.0777372    0.0178891
  0.291446    0.224166    -0.0393879       0.100701     0.058077 
 -0.227467   -0.327895    -0.226885        0.189525    -0.0973491
 -0.151087    0.0830612   -0.0397403       0.0548171    0.0836206
  0.0927871  -0.0796479   -0.0172028   …   0.0346957   -0.149212 
  0.0212077  -0.12318      0.0926274       0.0492077    0.0934323
 -0.0871171  -0.00245045   0.0659823       0.0250443    0.0557698
  0.0364305  -0.116062    -0.0382867       0.16         0.0215783
  0.104161   -0.0252739   -0.0540435      -0.0784314    0.050108 
  ⋮                                    ⋱                ⋮        
 -0.0381292  -0.0227866   -0.029131       -0.108315    -0.0534401
  0.100411   -0.0090968   -0.0709886      -0.0811433    0.0029529
  0.29698    -0.115155    -0.0159602   …  -0.0302879   -0.0108465
 -0.0770175  -0.00585499   0.0689315      -0.207622    -0.272597 
  0.0534218  -0.0788359    0.00367743     -0.166041     0.109721 
  0.253647   -0.0789397    0.00720036      0.140606    -0.149499 
  0.166761   -0.0455894    0.0283501      -0.0932972    0.147208 
  0.137432    0.164132     0.198072    …   0.00472417  -0.0443423
 -0.0152709  -0.113878     0.0722472      -0.0777026   -0.150099 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
WARNING: Variances had to be floored 11 19 26
INFO: iteration 1, average log likelihood -1.086338
WARNING: Variances had to be floored 1 2 9 11 19 21 23 26 29
INFO: iteration 2, average log likelihood -1.042399
WARNING: Variances had to be floored 6 11 19 26
INFO: iteration 3, average log likelihood -1.063766
WARNING: Variances had to be floored 1 2 9 11 18 19 21 23 26 30
INFO: iteration 4, average log likelihood -1.037264
WARNING: Variances had to be floored 11 19 26 29
INFO: iteration 5, average log likelihood -1.066790
WARNING: Variances had to be floored 1 2 6 9 11 19 21 23 26
INFO: iteration 6, average log likelihood -1.040670
WARNING: Variances had to be floored 11 19 26
INFO: iteration 7, average log likelihood -1.065069
WARNING: Variances had to be floored 1 2 9 11 19 21 23 26 29 30
INFO: iteration 8, average log likelihood -1.014946
WARNING: Variances had to be floored 6 11 19 26
INFO: iteration 9, average log likelihood -1.054133
WARNING: Variances had to be floored 1 2 9 11 19 21 23 26
INFO: iteration 10, average log likelihood -1.033224
INFO: EM with 100000 data points 10 iterations avll -1.033224
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.0132627   -0.0929719   …  -0.150971    -0.0629436  -0.0632684
  0.015355     0.0690431      -0.0490673   -0.0371019  -0.0998063
 -0.0110214   -0.0622657       0.136517     0.1684      0.035083 
 -0.0451764   -0.126708       -0.0636997   -0.0361293  -0.131244 
 -0.0232083   -0.198022       -0.00315491  -0.036086   -0.0848964
 -0.0248263   -0.0108803   …  -0.00549771  -0.054207   -0.0827347
  0.151848     0.0299569       0.0598906   -0.205271   -0.129739 
  0.0926585   -0.0770652      -0.0175297    0.0347773   0.0643466
  0.075135    -0.0286218      -0.0813977   -0.0115992   0.0561152
  0.226608     0.0480874      -0.153826    -0.0321787   0.0803667
  ⋮                        ⋱                            ⋮        
  0.0367909    0.0162742      -0.0106517    0.0344036   0.133144 
  0.00851575  -0.00720606     -0.00301641   0.0431719   0.0203044
 -0.0676729    0.0167253   …   0.0854317    0.158677    0.172601 
 -0.015684    -0.0817168      -0.135012    -0.0537536  -0.0712359
 -0.0360159   -0.0425081       0.0830769   -0.0197521  -0.0401327
  0.0472364   -0.00774349     -0.019494    -0.0835095  -0.0257673
 -0.0272842   -0.0261495       0.0394885   -0.020621    0.0351682
  0.0882189    0.0119489   …  -0.139791    -0.0958368   0.0340388
  0.180031     0.128641        0.0196121   -0.083295    0.0108038kind full, method split
0: avll = -1.4196290318055655
INFO: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419650
INFO: iteration 2, average log likelihood -1.419601
INFO: iteration 3, average log likelihood -1.419572
INFO: iteration 4, average log likelihood -1.419541
INFO: iteration 5, average log likelihood -1.419500
INFO: iteration 6, average log likelihood -1.419433
INFO: iteration 7, average log likelihood -1.419289
INFO: iteration 8, average log likelihood -1.418937
INFO: iteration 9, average log likelihood -1.418142
INFO: iteration 10, average log likelihood -1.416821
INFO: iteration 11, average log likelihood -1.415492
INFO: iteration 12, average log likelihood -1.414734
INFO: iteration 13, average log likelihood -1.414448
INFO: iteration 14, average log likelihood -1.414356
INFO: iteration 15, average log likelihood -1.414325
INFO: iteration 16, average log likelihood -1.414314
INFO: iteration 17, average log likelihood -1.414309
INFO: iteration 18, average log likelihood -1.414307
INFO: iteration 19, average log likelihood -1.414306
INFO: iteration 20, average log likelihood -1.414305
INFO: iteration 21, average log likelihood -1.414305
INFO: iteration 22, average log likelihood -1.414304
INFO: iteration 23, average log likelihood -1.414304
INFO: iteration 24, average log likelihood -1.414303
INFO: iteration 25, average log likelihood -1.414303
INFO: iteration 26, average log likelihood -1.414302
INFO: iteration 27, average log likelihood -1.414302
INFO: iteration 28, average log likelihood -1.414302
INFO: iteration 29, average log likelihood -1.414302
INFO: iteration 30, average log likelihood -1.414301
INFO: iteration 31, average log likelihood -1.414301
INFO: iteration 32, average log likelihood -1.414301
INFO: iteration 33, average log likelihood -1.414301
INFO: iteration 34, average log likelihood -1.414301
INFO: iteration 35, average log likelihood -1.414300
INFO: iteration 36, average log likelihood -1.414300
INFO: iteration 37, average log likelihood -1.414300
INFO: iteration 38, average log likelihood -1.414300
INFO: iteration 39, average log likelihood -1.414300
INFO: iteration 40, average log likelihood -1.414300
INFO: iteration 41, average log likelihood -1.414300
INFO: iteration 42, average log likelihood -1.414300
INFO: iteration 43, average log likelihood -1.414300
INFO: iteration 44, average log likelihood -1.414300
INFO: iteration 45, average log likelihood -1.414300
INFO: iteration 46, average log likelihood -1.414300
INFO: iteration 47, average log likelihood -1.414300
INFO: iteration 48, average log likelihood -1.414300
INFO: iteration 49, average log likelihood -1.414300
INFO: iteration 50, average log likelihood -1.414300
INFO: EM with 100000 data points 50 iterations avll -1.414300
952.4 data points per parameter
1: avll = [-1.419649598549372,-1.4196009351532133,-1.4195722088528335,-1.419540622166172,-1.4194997983554285,-1.4194327013866659,-1.4192889341427284,-1.4189368256127632,-1.4181416543218048,-1.4168205799467062,-1.4154919826437913,-1.414733588678472,-1.4144483006307071,-1.4143558477160012,-1.4143249843021994,-1.4143137973792217,-1.4143092956317793,-1.4143071940029222,-1.414306002453618,-1.4143051848237735,-1.4143045425062881,-1.414303998954149,-1.414303522520341,-1.4143030984187417,-1.4143027184146644,-1.414302376986555,-1.414302069871537,-1.4143017934971576,-1.4143015447461598,-1.4143013208483808,-1.4143011193225288,-1.4143009379385734,-1.4143007746895033,-1.4143006277680232,-1.4143004955463652,-1.4143003765583986,-1.4143002694836133,-1.414300173132718,-1.4143000864346678,-1.41430000842497,-1.4142999382351409,-1.4142998750831977,-1.414299818265087,-1.4142997671469553,-1.4142997211581831,-1.4142996797851028,-1.4142996425653411,-1.4142996090827158,-1.4142995789626387,-1.4142995518679762]
INFO: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.414320
INFO: iteration 2, average log likelihood -1.414269
INFO: iteration 3, average log likelihood -1.414240
INFO: iteration 4, average log likelihood -1.414210
INFO: iteration 5, average log likelihood -1.414177
INFO: iteration 6, average log likelihood -1.414143
INFO: iteration 7, average log likelihood -1.414106
INFO: iteration 8, average log likelihood -1.414069
INFO: iteration 9, average log likelihood -1.414032
INFO: iteration 10, average log likelihood -1.413998
INFO: iteration 11, average log likelihood -1.413966
INFO: iteration 12, average log likelihood -1.413938
INFO: iteration 13, average log likelihood -1.413913
INFO: iteration 14, average log likelihood -1.413891
INFO: iteration 15, average log likelihood -1.413871
INFO: iteration 16, average log likelihood -1.413852
INFO: iteration 17, average log likelihood -1.413833
INFO: iteration 18, average log likelihood -1.413815
INFO: iteration 19, average log likelihood -1.413795
INFO: iteration 20, average log likelihood -1.413775
INFO: iteration 21, average log likelihood -1.413753
INFO: iteration 22, average log likelihood -1.413729
INFO: iteration 23, average log likelihood -1.413703
INFO: iteration 24, average log likelihood -1.413676
INFO: iteration 25, average log likelihood -1.413648
INFO: iteration 26, average log likelihood -1.413618
INFO: iteration 27, average log likelihood -1.413589
INFO: iteration 28, average log likelihood -1.413560
INFO: iteration 29, average log likelihood -1.413532
INFO: iteration 30, average log likelihood -1.413507
INFO: iteration 31, average log likelihood -1.413484
INFO: iteration 32, average log likelihood -1.413463
INFO: iteration 33, average log likelihood -1.413445
INFO: iteration 34, average log likelihood -1.413429
INFO: iteration 35, average log likelihood -1.413416
INFO: iteration 36, average log likelihood -1.413404
INFO: iteration 37, average log likelihood -1.413394
INFO: iteration 38, average log likelihood -1.413385
INFO: iteration 39, average log likelihood -1.413378
INFO: iteration 40, average log likelihood -1.413371
INFO: iteration 41, average log likelihood -1.413365
INFO: iteration 42, average log likelihood -1.413359
INFO: iteration 43, average log likelihood -1.413354
INFO: iteration 44, average log likelihood -1.413350
INFO: iteration 45, average log likelihood -1.413346
INFO: iteration 46, average log likelihood -1.413342
INFO: iteration 47, average log likelihood -1.413338
INFO: iteration 48, average log likelihood -1.413335
INFO: iteration 49, average log likelihood -1.413331
INFO: iteration 50, average log likelihood -1.413328
INFO: EM with 100000 data points 50 iterations avll -1.413328
473.9 data points per parameter
2: avll = [-1.414319854487236,-1.4142691508662535,-1.414239848783072,-1.414209688537993,-1.414177356205446,-1.4141425603042788,-1.4141058739575327,-1.4140685063646412,-1.414031944763698,-1.4139975420281363,-1.413966195722254,-1.4139382233726363,-1.4139134288605582,-1.4138912717216219,-1.413871043600661,-1.4138519985405564,-1.4138334284704834,-1.4138146986988986,-1.4137952626977663,-1.4137746712176105,-1.4137525847903016,-1.4137287933059126,-1.413703241531692,-1.413676054741656,-1.4136475543857132,-1.413618251523809,-1.4135888079943464,-1.4135599635778016,-1.4135324401588352,-1.413506845351183,-1.4134836011412424,-1.4134629147611244,-1.4134447933409295,-1.4134290895731543,-1.4134155594320819,-1.4134039156071856,-1.4133938675748474,-1.413385146356727,-1.4133775164358222,-1.4133707788621575,-1.4133647693026896,-1.4133593537738884,-1.4133544237402587,-1.4133498914585427,-1.413345685935931,-1.413341749588545,-1.413338035553106,-1.4133345055554853,-1.4133311282324899,-1.4133278778136469]
INFO: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.413337
INFO: iteration 2, average log likelihood -1.413283
INFO: iteration 3, average log likelihood -1.413236
INFO: iteration 4, average log likelihood -1.413181
INFO: iteration 5, average log likelihood -1.413115
INFO: iteration 6, average log likelihood -1.413038
INFO: iteration 7, average log likelihood -1.412952
INFO: iteration 8, average log likelihood -1.412863
INFO: iteration 9, average log likelihood -1.412779
INFO: iteration 10, average log likelihood -1.412702
INFO: iteration 11, average log likelihood -1.412635
INFO: iteration 12, average log likelihood -1.412576
INFO: iteration 13, average log likelihood -1.412525
INFO: iteration 14, average log likelihood -1.412481
INFO: iteration 15, average log likelihood -1.412443
INFO: iteration 16, average log likelihood -1.412411
INFO: iteration 17, average log likelihood -1.412384
INFO: iteration 18, average log likelihood -1.412361
INFO: iteration 19, average log likelihood -1.412341
INFO: iteration 20, average log likelihood -1.412323
INFO: iteration 21, average log likelihood -1.412306
INFO: iteration 22, average log likelihood -1.412291
INFO: iteration 23, average log likelihood -1.412277
INFO: iteration 24, average log likelihood -1.412263
INFO: iteration 25, average log likelihood -1.412249
INFO: iteration 26, average log likelihood -1.412235
INFO: iteration 27, average log likelihood -1.412222
INFO: iteration 28, average log likelihood -1.412208
INFO: iteration 29, average log likelihood -1.412194
INFO: iteration 30, average log likelihood -1.412181
INFO: iteration 31, average log likelihood -1.412167
INFO: iteration 32, average log likelihood -1.412153
INFO: iteration 33, average log likelihood -1.412139
INFO: iteration 34, average log likelihood -1.412125
INFO: iteration 35, average log likelihood -1.412111
INFO: iteration 36, average log likelihood -1.412097
INFO: iteration 37, average log likelihood -1.412083
INFO: iteration 38, average log likelihood -1.412069
INFO: iteration 39, average log likelihood -1.412055
INFO: iteration 40, average log likelihood -1.412041
INFO: iteration 41, average log likelihood -1.412028
INFO: iteration 42, average log likelihood -1.412015
INFO: iteration 43, average log likelihood -1.412002
INFO: iteration 44, average log likelihood -1.411990
INFO: iteration 45, average log likelihood -1.411978
INFO: iteration 46, average log likelihood -1.411967
INFO: iteration 47, average log likelihood -1.411956
INFO: iteration 48, average log likelihood -1.411945
INFO: iteration 49, average log likelihood -1.411935
INFO: iteration 50, average log likelihood -1.411925
INFO: EM with 100000 data points 50 iterations avll -1.411925
236.4 data points per parameter
3: avll = [-1.4133371660281446,-1.413283134807408,-1.4132359827665082,-1.4131811306169446,-1.4131151546685692,-1.4130375688188943,-1.4129515194048794,-1.4128630433171443,-1.4127785128837278,-1.4127020219979853,-1.4126347308117397,-1.4125760414598334,-1.4125249920265759,-1.4124808591243696,-1.4124430845918892,-1.4124110327734074,-1.41238388698821,-1.4123607122695587,-1.4123405830362774,-1.4123226859806477,-1.412306366596694,-1.4122911291581914,-1.4122766122797143,-1.4122625578324666,-1.4122487827632193,-1.4122351571616694,-1.4122215886466913,-1.4122080119029485,-1.4121943819952036,-1.4121806702791277,-1.4121668620024213,-1.4121529549297878,-1.412138958502396,-1.4121248931651542,-1.412110789582472,-1.4120966875352419,-1.4120826343657573,-1.4120686829240656,-1.4120548890690867,-1.41204130887836,-1.4120279957999469,-1.4120149980178873,-1.4120023562885804,-1.41199010244422,-1.4119782586672156,-1.4119668375371126,-1.411955842758349,-1.4119452704078672,-1.4119351105043234,-1.411925348696738]
INFO: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.411925
INFO: iteration 2, average log likelihood -1.411876
INFO: iteration 3, average log likelihood -1.411834
INFO: iteration 4, average log likelihood -1.411788
INFO: iteration 5, average log likelihood -1.411734
INFO: iteration 6, average log likelihood -1.411669
INFO: iteration 7, average log likelihood -1.411593
INFO: iteration 8, average log likelihood -1.411504
INFO: iteration 9, average log likelihood -1.411406
INFO: iteration 10, average log likelihood -1.411302
INFO: iteration 11, average log likelihood -1.411197
INFO: iteration 12, average log likelihood -1.411096
INFO: iteration 13, average log likelihood -1.411001
INFO: iteration 14, average log likelihood -1.410916
INFO: iteration 15, average log likelihood -1.410839
INFO: iteration 16, average log likelihood -1.410772
INFO: iteration 17, average log likelihood -1.410713
INFO: iteration 18, average log likelihood -1.410661
INFO: iteration 19, average log likelihood -1.410616
INFO: iteration 20, average log likelihood -1.410577
INFO: iteration 21, average log likelihood -1.410541
INFO: iteration 22, average log likelihood -1.410510
INFO: iteration 23, average log likelihood -1.410481
INFO: iteration 24, average log likelihood -1.410455
INFO: iteration 25, average log likelihood -1.410431
INFO: iteration 26, average log likelihood -1.410408
INFO: iteration 27, average log likelihood -1.410387
INFO: iteration 28, average log likelihood -1.410367
INFO: iteration 29, average log likelihood -1.410348
INFO: iteration 30, average log likelihood -1.410330
INFO: iteration 31, average log likelihood -1.410313
INFO: iteration 32, average log likelihood -1.410297
INFO: iteration 33, average log likelihood -1.410281
INFO: iteration 34, average log likelihood -1.410266
INFO: iteration 35, average log likelihood -1.410251
INFO: iteration 36, average log likelihood -1.410237
INFO: iteration 37, average log likelihood -1.410223
INFO: iteration 38, average log likelihood -1.410210
INFO: iteration 39, average log likelihood -1.410198
INFO: iteration 40, average log likelihood -1.410186
INFO: iteration 41, average log likelihood -1.410174
INFO: iteration 42, average log likelihood -1.410163
INFO: iteration 43, average log likelihood -1.410152
INFO: iteration 44, average log likelihood -1.410142
INFO: iteration 45, average log likelihood -1.410132
INFO: iteration 46, average log likelihood -1.410123
INFO: iteration 47, average log likelihood -1.410114
INFO: iteration 48, average log likelihood -1.410105
INFO: iteration 49, average log likelihood -1.410097
INFO: iteration 50, average log likelihood -1.410089
INFO: EM with 100000 data points 50 iterations avll -1.410089
118.1 data points per parameter
4: avll = [-1.4119253348557321,-1.41187617929075,-1.411834177681898,-1.4117879893510945,-1.4117339659532984,-1.4116693852496633,-1.4115927165095605,-1.411504141386653,-1.4114058828506317,-1.411301932170823,-1.4111971023476513,-1.411095837013823,-1.4110013799430974,-1.410915567231937,-1.4108390567183033,-1.410771682638287,-1.410712763006353,-1.410661331993168,-1.410616315691141,-1.410576661231918,-1.410541419591512,-1.4105097849150778,-1.4104811000080708,-1.4104548412392075,-1.4104305949796752,-1.4104080338668301,-1.4103868970104902,-1.4103669751484689,-1.4103481000573859,-1.4103301369646646,-1.410312978813728,-1.410296541592426,-1.4102807602903242,-1.4102655853000674,-1.4102509792128308,-1.4102369140095166,-1.4102233686547023,-1.4102103270869577,-1.4101977765827804,-1.4101857064590015,-1.4101741070717595,-1.4101629690683684,-1.4101522828501043,-1.4101420382077348,-1.4101322240963607,-1.4101228285210838,-1.4101138385096685,-1.4101052401523892,-1.4100970186925519,-1.4100891586537185]
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.410091
INFO: iteration 2, average log likelihood -1.410038
INFO: iteration 3, average log likelihood -1.409989
INFO: iteration 4, average log likelihood -1.409935
INFO: iteration 5, average log likelihood -1.409871
INFO: iteration 6, average log likelihood -1.409794
INFO: iteration 7, average log likelihood -1.409703
INFO: iteration 8, average log likelihood -1.409597
INFO: iteration 9, average log likelihood -1.409480
INFO: iteration 10, average log likelihood -1.409355
INFO: iteration 11, average log likelihood -1.409227
INFO: iteration 12, average log likelihood -1.409100
INFO: iteration 13, average log likelihood -1.408978
INFO: iteration 14, average log likelihood -1.408863
INFO: iteration 15, average log likelihood -1.408757
INFO: iteration 16, average log likelihood -1.408660
INFO: iteration 17, average log likelihood -1.408572
INFO: iteration 18, average log likelihood -1.408493
INFO: iteration 19, average log likelihood -1.408420
INFO: iteration 20, average log likelihood -1.408354
INFO: iteration 21, average log likelihood -1.408294
INFO: iteration 22, average log likelihood -1.408238
INFO: iteration 23, average log likelihood -1.408187
INFO: iteration 24, average log likelihood -1.408138
INFO: iteration 25, average log likelihood -1.408093
INFO: iteration 26, average log likelihood -1.408051
INFO: iteration 27, average log likelihood -1.408011
INFO: iteration 28, average log likelihood -1.407973
INFO: iteration 29, average log likelihood -1.407937
INFO: iteration 30, average log likelihood -1.407902
INFO: iteration 31, average log likelihood -1.407869
INFO: iteration 32, average log likelihood -1.407838
INFO: iteration 33, average log likelihood -1.407807
INFO: iteration 34, average log likelihood -1.407778
INFO: iteration 35, average log likelihood -1.407750
INFO: iteration 36, average log likelihood -1.407723
INFO: iteration 37, average log likelihood -1.407698
INFO: iteration 38, average log likelihood -1.407674
INFO: iteration 39, average log likelihood -1.407651
INFO: iteration 40, average log likelihood -1.407629
INFO: iteration 41, average log likelihood -1.407608
INFO: iteration 42, average log likelihood -1.407589
INFO: iteration 43, average log likelihood -1.407571
INFO: iteration 44, average log likelihood -1.407553
INFO: iteration 45, average log likelihood -1.407537
INFO: iteration 46, average log likelihood -1.407522
INFO: iteration 47, average log likelihood -1.407508
INFO: iteration 48, average log likelihood -1.407494
INFO: iteration 49, average log likelihood -1.407481
INFO: iteration 50, average log likelihood -1.407469
INFO: EM with 100000 data points 50 iterations avll -1.407469
59.0 data points per parameter
5: avll = [-1.4100911068526756,-1.4100376039132085,-1.4099892523981898,-1.4099353724346018,-1.409871473051123,-1.4097944803239917,-1.409702943497418,-1.4095973692486812,-1.4094802037322962,-1.4093553233862361,-1.4092272310761635,-1.4091002665974848,-1.4089780334032076,-1.4088630979830477,-1.4087569318217852,-1.408660033006129,-1.408572155800831,-1.4084925780983666,-1.4084203487028701,-1.4083544769353409,-1.4082940510366675,-1.4082382921399115,-1.4081865616449196,-1.4081383417825373,-1.4080932058958684,-1.4080507900420143,-1.4080107725229658,-1.4079728633980964,-1.4079368026721086,-1.4079023649888942,-1.4078693695047215,-1.4078376912238317,-1.4078072641140327,-1.4077780686087633,-1.4077501093388123,-1.407723395866327,-1.407697932830636,-1.4076737172177773,-1.4076507380210177,-1.407628976085298,-1.407608404233398,-1.407588987834911,-1.407570685542493,-1.4075534501515237,-1.407537229808445,-1.4075219695773853,-1.4075076130321607,-1.4074941035078727,-1.4074813848876002,-1.407469402045632]
[-1.4196290318055655,-1.419649598549372,-1.4196009351532133,-1.4195722088528335,-1.419540622166172,-1.4194997983554285,-1.4194327013866659,-1.4192889341427284,-1.4189368256127632,-1.4181416543218048,-1.4168205799467062,-1.4154919826437913,-1.414733588678472,-1.4144483006307071,-1.4143558477160012,-1.4143249843021994,-1.4143137973792217,-1.4143092956317793,-1.4143071940029222,-1.414306002453618,-1.4143051848237735,-1.4143045425062881,-1.414303998954149,-1.414303522520341,-1.4143030984187417,-1.4143027184146644,-1.414302376986555,-1.414302069871537,-1.4143017934971576,-1.4143015447461598,-1.4143013208483808,-1.4143011193225288,-1.4143009379385734,-1.4143007746895033,-1.4143006277680232,-1.4143004955463652,-1.4143003765583986,-1.4143002694836133,-1.414300173132718,-1.4143000864346678,-1.41430000842497,-1.4142999382351409,-1.4142998750831977,-1.414299818265087,-1.4142997671469553,-1.4142997211581831,-1.4142996797851028,-1.4142996425653411,-1.4142996090827158,-1.4142995789626387,-1.4142995518679762,-1.414319854487236,-1.4142691508662535,-1.414239848783072,-1.414209688537993,-1.414177356205446,-1.4141425603042788,-1.4141058739575327,-1.4140685063646412,-1.414031944763698,-1.4139975420281363,-1.413966195722254,-1.4139382233726363,-1.4139134288605582,-1.4138912717216219,-1.413871043600661,-1.4138519985405564,-1.4138334284704834,-1.4138146986988986,-1.4137952626977663,-1.4137746712176105,-1.4137525847903016,-1.4137287933059126,-1.413703241531692,-1.413676054741656,-1.4136475543857132,-1.413618251523809,-1.4135888079943464,-1.4135599635778016,-1.4135324401588352,-1.413506845351183,-1.4134836011412424,-1.4134629147611244,-1.4134447933409295,-1.4134290895731543,-1.4134155594320819,-1.4134039156071856,-1.4133938675748474,-1.413385146356727,-1.4133775164358222,-1.4133707788621575,-1.4133647693026896,-1.4133593537738884,-1.4133544237402587,-1.4133498914585427,-1.413345685935931,-1.413341749588545,-1.413338035553106,-1.4133345055554853,-1.4133311282324899,-1.4133278778136469,-1.4133371660281446,-1.413283134807408,-1.4132359827665082,-1.4131811306169446,-1.4131151546685692,-1.4130375688188943,-1.4129515194048794,-1.4128630433171443,-1.4127785128837278,-1.4127020219979853,-1.4126347308117397,-1.4125760414598334,-1.4125249920265759,-1.4124808591243696,-1.4124430845918892,-1.4124110327734074,-1.41238388698821,-1.4123607122695587,-1.4123405830362774,-1.4123226859806477,-1.412306366596694,-1.4122911291581914,-1.4122766122797143,-1.4122625578324666,-1.4122487827632193,-1.4122351571616694,-1.4122215886466913,-1.4122080119029485,-1.4121943819952036,-1.4121806702791277,-1.4121668620024213,-1.4121529549297878,-1.412138958502396,-1.4121248931651542,-1.412110789582472,-1.4120966875352419,-1.4120826343657573,-1.4120686829240656,-1.4120548890690867,-1.41204130887836,-1.4120279957999469,-1.4120149980178873,-1.4120023562885804,-1.41199010244422,-1.4119782586672156,-1.4119668375371126,-1.411955842758349,-1.4119452704078672,-1.4119351105043234,-1.411925348696738,-1.4119253348557321,-1.41187617929075,-1.411834177681898,-1.4117879893510945,-1.4117339659532984,-1.4116693852496633,-1.4115927165095605,-1.411504141386653,-1.4114058828506317,-1.411301932170823,-1.4111971023476513,-1.411095837013823,-1.4110013799430974,-1.410915567231937,-1.4108390567183033,-1.410771682638287,-1.410712763006353,-1.410661331993168,-1.410616315691141,-1.410576661231918,-1.410541419591512,-1.4105097849150778,-1.4104811000080708,-1.4104548412392075,-1.4104305949796752,-1.4104080338668301,-1.4103868970104902,-1.4103669751484689,-1.4103481000573859,-1.4103301369646646,-1.410312978813728,-1.410296541592426,-1.4102807602903242,-1.4102655853000674,-1.4102509792128308,-1.4102369140095166,-1.4102233686547023,-1.4102103270869577,-1.4101977765827804,-1.4101857064590015,-1.4101741070717595,-1.4101629690683684,-1.4101522828501043,-1.4101420382077348,-1.4101322240963607,-1.4101228285210838,-1.4101138385096685,-1.4101052401523892,-1.4100970186925519,-1.4100891586537185,-1.4100911068526756,-1.4100376039132085,-1.4099892523981898,-1.4099353724346018,-1.409871473051123,-1.4097944803239917,-1.409702943497418,-1.4095973692486812,-1.4094802037322962,-1.4093553233862361,-1.4092272310761635,-1.4091002665974848,-1.4089780334032076,-1.4088630979830477,-1.4087569318217852,-1.408660033006129,-1.408572155800831,-1.4084925780983666,-1.4084203487028701,-1.4083544769353409,-1.4082940510366675,-1.4082382921399115,-1.4081865616449196,-1.4081383417825373,-1.4080932058958684,-1.4080507900420143,-1.4080107725229658,-1.4079728633980964,-1.4079368026721086,-1.4079023649888942,-1.4078693695047215,-1.4078376912238317,-1.4078072641140327,-1.4077780686087633,-1.4077501093388123,-1.407723395866327,-1.407697932830636,-1.4076737172177773,-1.4076507380210177,-1.407628976085298,-1.407608404233398,-1.407588987834911,-1.407570685542493,-1.4075534501515237,-1.407537229808445,-1.4075219695773853,-1.4075076130321607,-1.4074941035078727,-1.4074813848876002,-1.407469402045632]
32x26 Array{Float64,2}:
 -0.123881     0.1766     -0.120623    0.0298102  …  -0.0768796    0.0368526
 -0.373088    -0.0396769  -0.569242    0.124552      -0.189221     0.385805 
 -0.623036    -0.257424   -0.178013    0.250178      -0.1163       0.317752 
  0.078787    -0.0310836  -0.560587    0.255085       0.407339    -0.175341 
 -0.0452731   -0.0315186  -0.0654436   0.0880709     -0.00235076  -0.122759 
 -0.00550254  -0.108677   -0.070416   -0.0585109  …   0.0749941   -0.111088 
 -0.0249119   -0.0717725   0.16002     0.0370524     -0.176294     0.178669 
  0.302879     0.0320256  -0.0813368  -0.126396      -0.165866     0.421229 
 -0.371143     0.409366    0.301498   -0.0867123     -0.296021     0.0733844
 -0.08413     -0.533298    0.167136    0.325347      -0.186222    -0.344454 
  ⋮                                               ⋱                ⋮        
 -0.0549429    0.535356    0.265083   -0.201924      -0.549731     0.402569 
 -0.747421     0.654918   -0.330574    0.582544      -0.490934    -0.442797 
  0.126017    -0.0199768  -0.086833   -0.0326344  …   0.0157194    0.051239 
 -0.267426    -0.672668   -0.394358    0.274235       0.628946    -0.763301 
 -0.298906     0.573148    0.175553    0.327549       0.223965    -0.980649 
 -0.323841     0.0111972  -0.0886356   0.0988275      0.611385     0.0404055
  0.309495    -0.375663   -0.295639   -0.477892       0.360356    -0.122337 
  0.728078     0.0978678   0.100697   -0.131961   …   0.0999512   -0.0538831
  0.86008     -0.203617    0.375219   -0.889641       0.473029     0.283924 INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407458
INFO: iteration 2, average log likelihood -1.407447
INFO: iteration 3, average log likelihood -1.407437
INFO: iteration 4, average log likelihood -1.407428
INFO: iteration 5, average log likelihood -1.407419
INFO: iteration 6, average log likelihood -1.407410
INFO: iteration 7, average log likelihood -1.407402
INFO: iteration 8, average log likelihood -1.407394
INFO: iteration 9, average log likelihood -1.407386
INFO: iteration 10, average log likelihood -1.407379
INFO: EM with 100000 data points 10 iterations avll -1.407379
59.0 data points per parameter
kind full, method kmeans
INFO: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.140306e+05
      1       6.994419e+05      -2.145887e+05 |       32
      2       6.867642e+05      -1.267774e+04 |       32
      3       6.823826e+05      -4.381562e+03 |       32
      4       6.800792e+05      -2.303459e+03 |       32
      5       6.786216e+05      -1.457583e+03 |       32
      6       6.775426e+05      -1.078995e+03 |       32
      7       6.767384e+05      -8.042159e+02 |       32
      8       6.761076e+05      -6.307510e+02 |       32
      9       6.755666e+05      -5.410374e+02 |       32
     10       6.750938e+05      -4.728156e+02 |       32
     11       6.747056e+05      -3.881354e+02 |       32
     12       6.743602e+05      -3.454404e+02 |       32
     13       6.740769e+05      -2.832702e+02 |       32
     14       6.737940e+05      -2.829136e+02 |       32
     15       6.735200e+05      -2.739593e+02 |       32
     16       6.732669e+05      -2.531349e+02 |       32
     17       6.730418e+05      -2.251245e+02 |       32
     18       6.728381e+05      -2.036400e+02 |       32
     19       6.726471e+05      -1.910110e+02 |       32
     20       6.724717e+05      -1.754479e+02 |       32
     21       6.723081e+05      -1.635841e+02 |       32
     22       6.721617e+05      -1.463730e+02 |       32
     23       6.720361e+05      -1.256010e+02 |       32
     24       6.719266e+05      -1.095447e+02 |       32
     25       6.718251e+05      -1.014724e+02 |       32
     26       6.717321e+05      -9.304550e+01 |       32
     27       6.716377e+05      -9.441162e+01 |       32
     28       6.715472e+05      -9.050203e+01 |       32
     29       6.714708e+05      -7.637292e+01 |       32
     30       6.714062e+05      -6.462767e+01 |       32
     31       6.713461e+05      -6.008942e+01 |       32
     32       6.713011e+05      -4.492096e+01 |       32
     33       6.712593e+05      -4.187433e+01 |       32
     34       6.712211e+05      -3.816414e+01 |       32
     35       6.711843e+05      -3.675895e+01 |       32
     36       6.711514e+05      -3.292582e+01 |       32
     37       6.711242e+05      -2.718753e+01 |       32
     38       6.710932e+05      -3.103952e+01 |       32
     39       6.710614e+05      -3.177793e+01 |       32
     40       6.710305e+05      -3.093326e+01 |       32
     41       6.710000e+05      -3.052248e+01 |       32
     42       6.709670e+05      -3.293749e+01 |       32
     43       6.709357e+05      -3.134188e+01 |       32
     44       6.709090e+05      -2.669646e+01 |       32
     45       6.708833e+05      -2.566262e+01 |       32
     46       6.708588e+05      -2.455841e+01 |       32
     47       6.708346e+05      -2.418925e+01 |       32
     48       6.708129e+05      -2.166815e+01 |       32
     49       6.707913e+05      -2.163835e+01 |       32
     50       6.707663e+05      -2.493417e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 670766.3310324955)
INFO: K-means with 32000 data points using 50 iterations
37.0 data points per parameter
INFO: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.419846
INFO: iteration 2, average log likelihood -1.414582
INFO: iteration 3, average log likelihood -1.413056
INFO: iteration 4, average log likelihood -1.411877
INFO: iteration 5, average log likelihood -1.410717
INFO: iteration 6, average log likelihood -1.409774
INFO: iteration 7, average log likelihood -1.409189
INFO: iteration 8, average log likelihood -1.408871
INFO: iteration 9, average log likelihood -1.408687
INFO: iteration 10, average log likelihood -1.408564
INFO: iteration 11, average log likelihood -1.408473
INFO: iteration 12, average log likelihood -1.408399
INFO: iteration 13, average log likelihood -1.408336
INFO: iteration 14, average log likelihood -1.408282
INFO: iteration 15, average log likelihood -1.408233
INFO: iteration 16, average log likelihood -1.408188
INFO: iteration 17, average log likelihood -1.408148
INFO: iteration 18, average log likelihood -1.408110
INFO: iteration 19, average log likelihood -1.408074
INFO: iteration 20, average log likelihood -1.408040
INFO: iteration 21, average log likelihood -1.408009
INFO: iteration 22, average log likelihood -1.407978
INFO: iteration 23, average log likelihood -1.407949
INFO: iteration 24, average log likelihood -1.407922
INFO: iteration 25, average log likelihood -1.407895
INFO: iteration 26, average log likelihood -1.407870
INFO: iteration 27, average log likelihood -1.407846
INFO: iteration 28, average log likelihood -1.407823
INFO: iteration 29, average log likelihood -1.407800
INFO: iteration 30, average log likelihood -1.407779
INFO: iteration 31, average log likelihood -1.407759
INFO: iteration 32, average log likelihood -1.407740
INFO: iteration 33, average log likelihood -1.407722
INFO: iteration 34, average log likelihood -1.407705
INFO: iteration 35, average log likelihood -1.407688
INFO: iteration 36, average log likelihood -1.407672
INFO: iteration 37, average log likelihood -1.407656
INFO: iteration 38, average log likelihood -1.407642
INFO: iteration 39, average log likelihood -1.407627
INFO: iteration 40, average log likelihood -1.407614
INFO: iteration 41, average log likelihood -1.407600
INFO: iteration 42, average log likelihood -1.407587
INFO: iteration 43, average log likelihood -1.407575
INFO: iteration 44, average log likelihood -1.407562
INFO: iteration 45, average log likelihood -1.407550
INFO: iteration 46, average log likelihood -1.407539
INFO: iteration 47, average log likelihood -1.407527
INFO: iteration 48, average log likelihood -1.407516
INFO: iteration 49, average log likelihood -1.407505
INFO: iteration 50, average log likelihood -1.407495
INFO: EM with 100000 data points 50 iterations avll -1.407495
59.0 data points per parameter
32x26 Array{Float64,2}:
 -0.043348    0.247601    0.49217    …   0.377091    -0.247905   -0.171483 
  0.712619   -0.150238    0.30822        0.431814    -0.163402    0.750226 
  0.146041   -0.147337    0.107656       0.530754     0.341693   -0.4478   
 -0.406745    0.151064    0.0695186     -0.30639     -0.257086   -0.0284606
 -0.0444962  -1.02766    -0.323383      -0.268118    -0.14201     0.573369 
 -0.178543   -0.385387    0.331549   …  -0.00683579   0.161341    0.0159632
 -0.296822    0.474794   -0.110246       0.623775    -0.175673   -1.08614  
 -0.191198    0.0417781  -0.0848672      0.253237     0.0254077  -0.263081 
 -0.0138502   0.202337    0.120588      -0.45789     -0.249531    0.375708 
 -0.221763   -0.635698   -0.0653866     -0.238341    -0.446578    0.482616 
  ⋮                                  ⋱                            ⋮        
 -0.183956    0.431576    0.159632       0.340362     0.343593   -0.207968 
 -0.0526911  -0.0867348  -0.0747073     -0.0222401    0.0751627   0.101986 
  0.25694     0.173558    0.240699   …  -0.536311    -0.0329296   0.112056 
  0.480028   -0.243613   -0.462081      -0.624942     0.285038   -0.384073 
 -0.0351815  -0.842388   -0.164247      -0.0625373    0.47547    -0.73685  
  0.465255   -0.193872    0.260254      -0.117323     0.0827178  -0.155869 
  0.13846     0.0646468  -0.0309334     -0.187464    -0.0505202  -0.175777 
  0.1037     -0.0428289  -0.0951904  …  -0.166591    -0.386059    0.51347  
  0.311669    0.389013   -0.495938      -0.0837792    0.143802   -0.14774  INFO: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
INFO: iteration 1, average log likelihood -1.407485
INFO: iteration 2, average log likelihood -1.407475
INFO: iteration 3, average log likelihood -1.407465
INFO: iteration 4, average log likelihood -1.407455
INFO: iteration 5, average log likelihood -1.407446
INFO: iteration 6, average log likelihood -1.407437
INFO: iteration 7, average log likelihood -1.407428
INFO: iteration 8, average log likelihood -1.407420
INFO: iteration 9, average log likelihood -1.407411
INFO: iteration 10, average log likelihood -1.407403
INFO: EM with 100000 data points 10 iterations avll -1.407403
59.0 data points per parameter
INFO: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.408999e+04
      1       7.823675e+03      -6.266314e+03 |        0
      2       7.823675e+03       0.000000e+00 |        0
K-means converged with 2 iterations (objv = 7823.675494229463)
INFO: K-means with 900 data points using 2 iterations
150.0 data points per parameter
INFO: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
INFO: iteration 1, average log likelihood -2.043155
INFO: iteration 2, average log likelihood -2.043154
INFO: iteration 3, average log likelihood -2.043154
INFO: iteration 4, average log likelihood -2.043154
INFO: iteration 5, average log likelihood -2.043154
INFO: iteration 6, average log likelihood -2.043154
INFO: iteration 7, average log likelihood -2.043154
INFO: iteration 8, average log likelihood -2.043154
INFO: iteration 9, average log likelihood -2.043154
INFO: iteration 10, average log likelihood -2.043154
INFO: EM with 900 data points 10 iterations avll -2.043154
81.8 data points per parameter
INFO: GaussianMixtures tests passed

>>> End of log
