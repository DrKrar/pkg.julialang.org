>>> 'Pkg.add("Mamba")' log
INFO: Cloning cache of BinDeps from git://github.com/JuliaLang/BinDeps.jl.git
INFO: Cloning cache of Cairo from git://github.com/JuliaLang/Cairo.jl.git
INFO: Cloning cache of Graphs from git://github.com/JuliaLang/Graphs.jl.git
INFO: Cloning cache of Mamba from git://github.com/brian-j-smith/Mamba.jl.git
INFO: Cloning cache of SHA from git://github.com/staticfloat/SHA.jl.git
INFO: Cloning cache of URIParser from git://github.com/JuliaWeb/URIParser.jl.git
INFO: Installing ArrayViews v0.6.2
INFO: Installing BinDeps v0.3.14
INFO: Installing Cairo v0.2.28
INFO: Installing Calculus v0.1.9
INFO: Installing Codecs v0.1.4
INFO: Installing Color v0.4.7
INFO: Installing Compose v0.3.13
INFO: Installing Contour v0.0.7
INFO: Installing DataArrays v0.2.17
INFO: Installing DataFrames v0.6.8
INFO: Installing DataStructures v0.3.11
INFO: Installing Dates v0.4.4
INFO: Installing Distances v0.2.0
INFO: Installing Distributions v0.8.2
INFO: Installing Docile v0.5.13
INFO: Installing DualNumbers v0.1.3
INFO: Installing FixedPointNumbers v0.0.9
INFO: Installing GZip v0.2.17
INFO: Installing Gadfly v0.3.13
INFO: Installing Graphics v0.1.1
INFO: Installing Graphs v0.5.5
INFO: Installing Grid v0.3.10
INFO: Installing Hexagons v0.0.3
INFO: Installing ImmutableArrays v0.0.9
INFO: Installing Iterators v0.1.8
INFO: Installing KernelDensity v0.1.1
INFO: Installing Loess v0.0.3
INFO: Installing Mamba v0.6.0
INFO: Installing NaNMath v0.0.2
INFO: Installing Optim v0.4.2
INFO: Installing PDMats v0.3.5
INFO: Installing Reexport v0.0.2
INFO: Installing SHA v0.0.4
INFO: Installing Showoff v0.0.4
INFO: Installing SortingAlgorithms v0.0.5
INFO: Installing StatsBase v0.7.0
INFO: Installing StatsFuns v0.1.1
INFO: Installing URIParser v0.0.5
INFO: Installing WoodburyMatrices v0.1.1
INFO: Building Cairo
WARNING: beginswith is deprecated, use startswith instead.
 in depwarn at ./deprecated.jl:63
 in beginswith at deprecated.jl:30
 in available_versions at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:116
 in package_available at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:111
 in can_provide at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:590
 in _find_library at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:451
 in allf at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:604
 in satisfy! at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:672 (repeats 2 times)
 in anonymous at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:775
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in evalfile at loading.jl:212 (repeats 2 times)
 in anonymous at pkg/entry.jl:652
 in cd at ./file.jl:22
 in build! at pkg/entry.jl:651
 in build at pkg/entry.jl:663
 in resolve at ./pkg/entry.jl:472
 in edit at pkg/entry.jl:26
 in anonymous at task.jl:446
while loading /home/vagrant/.julia/v0.4/Cairo/deps/build.jl, in expression starting on line 144
WARNING: beginswith is deprecated, use startswith instead.
 in depwarn at ./deprecated.jl:63
 in beginswith at deprecated.jl:30
 in available_versions at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:124
 in package_available at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:111
 in can_provide at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:590
 in _find_library at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:451
 in allf at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:604
 in satisfy! at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:672 (repeats 2 times)
 in anonymous at /home/vagrant/.julia/v0.4/BinDeps/src/dependencies.jl:775
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in evalfile at loading.jl:212 (repeats 2 times)
 in anonymous at pkg/entry.jl:652
 in cd at ./file.jl:22
 in build! at pkg/entry.jl:651
 in build at pkg/entry.jl:663
 in resolve at ./pkg/entry.jl:472
 in edit at pkg/entry.jl:26
 in anonymous at task.jl:446
while loading /home/vagrant/.julia/v0.4/Cairo/deps/build.jl, in expression starting on line 144
INFO: Package database updated

>>> 'Pkg.test("Mamba")' log
Julia Version 0.4.0-dev+6477
Commit dce9d18* (2015-08-02 23:54 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Core(TM) i7-4960HQ CPU @ 2.60GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing Mamba
Running tests:

>>> Testing ../doc/tutorial/line.jl

WARNING: module DataStructures should explicitly import < from Base
WARNING: module DataStructures should explicitly import <= from Base
WARNING: module JSON should explicitly import colon from Base
WARNING: module JSON should explicitly import colon from Base
WARNING: `require` is deprecated, use `using` or `import` instead
 in depwarn at ./deprecated.jl:63
 in require at deprecated.jl:648
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in require at ./loading.jl:145
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in require at ./loading.jl:145
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in anonymous at no file:5
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in process_options at ./client.jl:308
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/Compose/src/Compose.jl, in expression starting on line 131
WARNING: `require` is deprecated, use `using` or `import` instead
 in depwarn at ./deprecated.jl:63
 in require at deprecated.jl:648
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in require at ./loading.jl:145
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in require at ./loading.jl:145
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in anonymous at no file:5
 in include at ./boot.jl:254
 in include_from_node1 at ./loading.jl:196
 in process_options at ./client.jl:308
 in _start at ./client.jl:411
while loading /home/vagrant/.julia/v0.4/Compose/src/Compose.jl, in expression starting on line 156
WARNING: module Gadfly should explicitly import / from Base
WARNING: module Gadfly should explicitly import / from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import + from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import / from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import - from Base
WARNING: module Gadfly should explicitly import * from Base

WARNING: deprecated syntax "zip (" at /home/vagrant/.julia/v0.4/Gadfly/src/scale.jl:797.
Use "zip(" instead.

WARNING: deprecated syntax "< (" at /home/vagrant/.julia/v0.4/Graphs/src/dijkstra_spath.jl:23.
Use "<(" instead.
WARNING: module Graphs should explicitly import < from Base

WARNING: deprecated syntax "< (" at /home/vagrant/.julia/v0.4/Graphs/src/prim_mst.jl:24.
Use "<(" instead.
digraph MambaModel {
	"y" [shape="ellipse", fillcolor="gray85", style="filled"];
	"mu" [shape="diamond", fillcolor="gray85", style="filled"];
		"mu" -> "y";
	"s2" [shape="ellipse"];
		"s2" -> "y";
	"beta" [shape="ellipse"];
		"beta" -> "mu";
	"xmat" [shape="box", fillcolor="gray85", style="filled"];
		"xmat" -> "mu";
}
MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:25:22 of 0:25:23 remaining]
Chain 1:  10% [0:00:23 of 0:00:25 remaining]
Chain 1:  20% [0:00:13 of 0:00:16 remaining]
Chain 1:  30% [0:00:09 of 0:00:13 remaining]
Chain 1:  40% [0:00:07 of 0:00:11 remaining]
Chain 1:  50% [0:00:05 of 0:00:10 remaining]
Chain 1:  60% [0:00:04 of 0:00:09 remaining]
Chain 1:  70% [0:00:03 of 0:00:09 remaining]
Chain 1:  80% [0:00:02 of 0:00:09 remaining]
Chain 1:  90% [0:00:01 of 0:00:08 remaining]
Chain 1: 100% [0:00:00 of 0:00:08 remaining]

Chain 2:   0% [0:00:08 of 0:00:08 remaining]
Chain 2:  10% [0:00:05 of 0:00:05 remaining]
Chain 2:  20% [0:00:04 of 0:00:06 remaining]
Chain 2:  30% [0:00:04 of 0:00:05 remaining]
Chain 2:  40% [0:00:03 of 0:00:05 remaining]
Chain 2:  50% [0:00:03 of 0:00:06 remaining]
Chain 2:  60% [0:00:02 of 0:00:06 remaining]
Chain 2:  70% [0:00:02 of 0:00:06 remaining]
Chain 2:  80% [0:00:01 of 0:00:06 remaining]
Chain 2:  90% [0:00:01 of 0:00:06 remaining]
Chain 2: 100% [0:00:00 of 0:00:06 remaining]

Chain 3:   0% [0:00:11 of 0:00:11 remaining]
Chain 3:  10% [0:00:06 of 0:00:07 remaining]
Chain 3:  20% [0:00:05 of 0:00:06 remaining]
Chain 3:  30% [0:00:04 of 0:00:05 remaining]
Chain 3:  40% [0:00:03 of 0:00:06 remaining]
Chain 3:  50% [0:00:03 of 0:00:05 remaining]
Chain 3:  60% [0:00:02 of 0:00:05 remaining]
Chain 3:  70% [0:00:02 of 0:00:05 remaining]
Chain 3:  80% [0:00:01 of 0:00:05 remaining]
Chain 3:  90% [0:00:01 of 0:00:05 remaining]
Chain 3: 100% [0:00:00 of 0:00:05 remaining]

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:16 of 0:00:16 remaining]
Chain 1:  10% [0:00:08 of 0:00:09 remaining]
Chain 1:  20% [0:00:07 of 0:00:08 remaining]
Chain 1:  30% [0:00:06 of 0:00:08 remaining]
Chain 1:  40% [0:00:05 of 0:00:08 remaining]
Chain 1:  50% [0:00:04 of 0:00:08 remaining]
Chain 1:  60% [0:00:03 of 0:00:08 remaining]
Chain 1:  70% [0:00:02 of 0:00:08 remaining]
Chain 1:  80% [0:00:02 of 0:00:08 remaining]
Chain 1:  90% [0:00:01 of 0:00:08 remaining]
Chain 1: 100% [0:00:00 of 0:00:08 remaining]

Chain 2:   0% [0:00:17 of 0:00:17 remaining]
Chain 2:  10% [0:00:07 of 0:00:08 remaining]
Chain 2:  20% [0:00:07 of 0:00:08 remaining]
Chain 2:  30% [0:00:06 of 0:00:08 remaining]
Chain 2:  40% [0:00:05 of 0:00:08 remaining]
Chain 2:  50% [0:00:04 of 0:00:08 remaining]
Chain 2:  60% [0:00:03 of 0:00:08 remaining]
Chain 2:  70% [0:00:02 of 0:00:08 remaining]
Chain 2:  80% [0:00:02 of 0:00:08 remaining]
Chain 2:  90% [0:00:01 of 0:00:08 remaining]
Chain 2: 100% [0:00:00 of 0:00:08 remaining]

Chain 3:   0% [0:00:10 of 0:00:10 remaining]
Chain 3:  10% [0:00:05 of 0:00:06 remaining]
Chain 3:  20% [0:00:04 of 0:00:05 remaining]
Chain 3:  30% [0:00:04 of 0:00:05 remaining]
Chain 3:  40% [0:00:03 of 0:00:05 remaining]
Chain 3:  50% [0:00:03 of 0:00:06 remaining]
Chain 3:  60% [0:00:03 of 0:00:06 remaining]
Chain 3:  70% [0:00:02 of 0:00:06 remaining]
Chain 3:  80% [0:00:01 of 0:00:06 remaining]
Chain 3:  90% [0:00:01 of 0:00:06 remaining]
Chain 3: 100% [0:00:00 of 0:00:06 remaining]

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:09:28 of 0:09:28 remaining]
Chain 1:  10% [0:00:06 of 0:00:06 remaining]
Chain 1:  20% [0:00:03 of 0:00:03 remaining]
Chain 1:  30% [0:00:02 of 0:00:02 remaining]
Chain 1:  40% [0:00:01 of 0:00:02 remaining]
Chain 1:  50% [0:00:01 of 0:00:01 remaining]
Chain 1:  60% [0:00:01 of 0:00:01 remaining]
Chain 1:  70% [0:00:00 of 0:00:01 remaining]
Chain 1:  80% [0:00:00 of 0:00:01 remaining]
Chain 1:  90% [0:00:00 of 0:00:01 remaining]
Chain 1: 100% [0:00:00 of 0:00:01 remaining]

Chain 2:   0% [0:00:00 of 0:00:00 remaining]
Chain 2:  10% [0:00:00 of 0:00:01 remaining]
Chain 2:  20% [0:00:00 of 0:00:01 remaining]
Chain 2:  30% [0:00:00 of 0:00:00 remaining]
Chain 2:  40% [0:00:00 of 0:00:00 remaining]
Chain 2:  50% [0:00:00 of 0:00:00 remaining]
Chain 2:  60% [0:00:00 of 0:00:00 remaining]
Chain 2:  70% [0:00:00 of 0:00:00 remaining]
Chain 2:  80% [0:00:00 of 0:00:00 remaining]
Chain 2:  90% [0:00:00 of 0:00:00 remaining]
Chain 2: 100% [0:00:00 of 0:00:00 remaining]

Chain 3:   0% [0:00:01 of 0:00:01 remaining]
Chain 3:  10% [0:00:01 of 0:00:01 remaining]
Chain 3:  20% [0:00:00 of 0:00:01 remaining]
Chain 3:  30% [0:00:00 of 0:00:01 remaining]
Chain 3:  40% [0:00:00 of 0:00:01 remaining]
Chain 3:  50% [0:00:00 of 0:00:00 remaining]
Chain 3:  60% [0:00:00 of 0:00:00 remaining]
Chain 3:  70% [0:00:00 of 0:00:00 remaining]
Chain 3:  80% [0:00:00 of 0:00:00 remaining]
Chain 3:  90% [0:00:00 of 0:00:00 remaining]
Chain 3: 100% [0:00:00 of 0:00:00 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Gelman, Rubin, and Brooks Diagnostic:
              PSRF 97.5%
          s2 1.008 1.016
     beta[1] 1.009 1.010
     beta[2] 1.009 1.010
Multivariate 1.006   NaN

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Geweke Diagnostic:
First Window Fraction = 0.1
Second Window Fraction = 0.5

        Z-score p-value
     s2   1.710  0.0872
beta[1]   1.237  0.2162
beta[2]  -1.568  0.1168

        Z-score p-value
     s2  -1.428  0.1534
beta[1]  -1.457  0.1452
beta[2]   1.752  0.0797

        Z-score p-value
     s2   0.583  0.5596
beta[1]   0.550  0.5824
beta[2]  -0.440  0.6597

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Heidelberger and Welch Diagnostic:
Target Halfwidth Ratio = 0.1
Alpha = 0.05

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
     s2     738            1  0.0700 1.00825202 0.094300432    1
beta[1]     251            1  0.0680 0.57366275 0.053311283    1
beta[2]     738            1  0.0677 0.81285744 0.015404173    1

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
     s2     251            1  0.4435  1.4635400 0.588158612    0
beta[1]     251            1  0.1356  0.6293320 0.065092099    0
beta[2]     251            1  0.0711  0.7934633 0.019215278    1

        Burn-in Stationarity p-value    Mean     Halfwidth  Test
     s2     251            1  0.6664  0.9942853 0.127959523    0
beta[1]     251            1  0.0515  0.5883602 0.058928034    0
beta[2]    1225            1  0.1479  0.8086080 0.018478999    1

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Raftery and Lewis Diagnostic:
Quantile (q) = 0.025
Accuracy (r) = 0.005
Probability (s) = 0.95

        Thinning Burn-in    Total   Nmin Dependence Factor
     s2        2     257       8689 3746         2.3195408
beta[1]        2     267      17897 3746         4.7776295
beta[2]        2     267      17897 3746         4.7776295

        Thinning Burn-in    Total   Nmin Dependence Factor
     s2        2     257 8.3450×10³ 3746         2.2277096
beta[1]        4     271 2.1759×10⁴ 3746         5.8085958
beta[2]        4     275 2.8795×10⁴ 3746         7.6868660

        Thinning Burn-in    Total   Nmin Dependence Factor
     s2        2     255 7.8770×10³ 3746         2.1027763
beta[1]        2     269 2.0647×10⁴ 3746         5.5117459
beta[2]        2     263 1.4523×10⁴ 3746         3.8769354

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean       SD       Naive SE       MCSE       ESS   
     s2 1.2203777 2.00876760 0.0166104638 0.101798287  389.3843
beta[1] 0.5971183 1.14894446 0.0095006014 0.016925598 4607.9743
beta[2] 0.8017036 0.34632566 0.0028637608 0.004793345 4875.0000

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
     s2  0.17091385 0.383671702 0.65371989 1.2206381 6.0313970
beta[1] -1.74343373 0.026573102 0.59122696 1.1878720 2.8308472
beta[2]  0.12168742 0.628297573 0.80357822 0.9719441 1.5051573

         95% Lower  95% Upper
     s2  0.08338409 3.8706865
beta[1] -1.75436235 2.8109571
beta[2]  0.09721501 1.4733163

             s2         beta[1]      beta[2]  
     s2  1.000000000  0.027467317 -0.024489462
beta[1]  0.027467317  1.000000000 -0.905245029
beta[2] -0.024489462 -0.905245029  1.000000000

           Lag 2       Lag 10        Lag 20       Lag 100   
     s2 0.85931351   0.568056917  0.3248136852   0.024157524
beta[1] 0.24521566  -0.021411797 -0.0077424153  -0.044989417
beta[2] 0.20402485  -0.019107846  0.0033980453  -0.053869216

           Lag 2       Lag 10        Lag 20       Lag 100   
     s2 0.92905843   0.761339226    0.58455868  0.0050215824
beta[1] 0.28180489  -0.031007672    0.03930888  0.0394895028
beta[2] 0.25905976  -0.017946010    0.03613043  0.0227758214

           Lag 2       Lag 10        Lag 20       Lag 100   
     s2 0.68812720  0.2420402859   0.080495078 -0.0290205896
beta[1] 0.38634357 -0.0029361782  -0.032310111  0.0028806786
beta[2] 0.32822879 -0.0056670786  -0.020100663 -0.0062622517

             Change Rate
          s2       1.000
     beta[1]       0.844
     beta[2]       0.844
Multivariate       1.000

MCMC Processing of 4875 Iterations x 3 Chains...

Chain 1:   0% [0:00:01 of 0:00:01 remaining]
Chain 1:  10% [0:00:00 of 0:00:00 remaining]
Chain 1:  20% [0:00:00 of 0:00:00 remaining]
Chain 1:  30% [0:00:00 of 0:00:00 remaining]
Chain 1:  40% [0:00:00 of 0:00:00 remaining]
Chain 1:  50% [0:00:00 of 0:00:00 remaining]
Chain 1:  60% [0:00:00 of 0:00:00 remaining]
Chain 1:  70% [0:00:00 of 0:00:00 remaining]
Chain 1:  80% [0:00:00 of 0:00:00 remaining]
Chain 1:  90% [0:00:00 of 0:00:00 remaining]
Chain 1: 100% [0:00:00 of 0:00:00 remaining]

Chain 2:   0% [0:00:00 of 0:00:00 remaining]
Chain 2:  10% [0:00:00 of 0:00:00 remaining]
Chain 2:  20% [0:00:00 of 0:00:00 remaining]
Chain 2:  30% [0:00:00 of 0:00:00 remaining]
Chain 2:  40% [0:00:00 of 0:00:00 remaining]
Chain 2:  50% [0:00:00 of 0:00:00 remaining]
Chain 2:  60% [0:00:00 of 0:00:00 remaining]
Chain 2:  70% [0:00:00 of 0:00:00 remaining]
Chain 2:  80% [0:00:00 of 0:00:00 remaining]
Chain 2:  90% [0:00:00 of 0:00:00 remaining]
Chain 2: 100% [0:00:00 of 0:00:00 remaining]

Chain 3:   0% [0:00:00 of 0:00:00 remaining]
Chain 3:  10% [0:00:00 of 0:00:00 remaining]
Chain 3:  20% [0:00:00 of 0:00:00 remaining]
Chain 3:  30% [0:00:00 of 0:00:00 remaining]
Chain 3:  40% [0:00:00 of 0:00:00 remaining]
Chain 3:  50% [0:00:00 of 0:00:00 remaining]
Chain 3:  60% [0:00:00 of 0:00:00 remaining]
Chain 3:  70% [0:00:00 of 0:00:00 remaining]
Chain 3:  80% [0:00:00 of 0:00:00 remaining]
Chain 3:  90% [0:00:00 of 0:00:00 remaining]
Chain 3: 100% [0:00:00 of 0:00:00 remaining]

      DIC    Effective Parameters
pD 13.828540            1.1661193
pV 22.624104            5.5639015

Iterations = 1000:5000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 2001

Empirical Posterior Estimates:
           Mean        SD      Naive SE      MCSE       ESS   
beta[1] 0.62445845 1.0285709 0.013275474 0.023818436 1864.8416
beta[2] 0.79392648 0.3096614 0.003996712 0.006516677 2001.0000

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
beta[1] -1.53050898 0.076745702 0.61120944 1.2174641 2.6906753
beta[2]  0.18846617 0.618849048 0.79323126 0.9619767 1.4502109

MCMC Simulation of 5000 Iterations x 3 Chains...

Chain 1:   0% [0:00:04 of 0:00:04 remaining]
Chain 1:  10% [0:00:02 of 0:00:03 remaining]
Chain 1:  20% [0:00:02 of 0:00:02 remaining]
Chain 1:  30% [0:00:02 of 0:00:03 remaining]
Chain 1:  40% [0:00:02 of 0:00:03 remaining]
Chain 1:  50% [0:00:01 of 0:00:03 remaining]
Chain 1:  60% [0:00:01 of 0:00:03 remaining]
Chain 1:  70% [0:00:01 of 0:00:03 remaining]
Chain 1:  80% [0:00:01 of 0:00:03 remaining]
Chain 1:  90% [0:00:00 of 0:00:03 remaining]
Chain 1: 100% [0:00:00 of 0:00:03 remaining]

Chain 2:   0% [0:00:04 of 0:00:04 remaining]
Chain 2:  10% [0:00:02 of 0:00:02 remaining]
Chain 2:  20% [0:00:01 of 0:00:02 remaining]
Chain 2:  30% [0:00:01 of 0:00:02 remaining]
Chain 2:  40% [0:00:01 of 0:00:02 remaining]
Chain 2:  50% [0:00:01 of 0:00:02 remaining]
Chain 2:  60% [0:00:01 of 0:00:02 remaining]
Chain 2:  70% [0:00:00 of 0:00:02 remaining]
Chain 2:  80% [0:00:00 of 0:00:02 remaining]
Chain 2:  90% [0:00:00 of 0:00:02 remaining]
Chain 2: 100% [0:00:00 of 0:00:02 remaining]

Chain 3:   0% [0:00:03 of 0:00:03 remaining]
Chain 3:  10% [0:00:02 of 0:00:03 remaining]
Chain 3:  20% [0:00:02 of 0:00:02 remaining]
Chain 3:  30% [0:00:01 of 0:00:02 remaining]
Chain 3:  40% [0:00:01 of 0:00:02 remaining]
Chain 3:  50% [0:00:01 of 0:00:02 remaining]
Chain 3:  60% [0:00:01 of 0:00:02 remaining]
Chain 3:  70% [0:00:01 of 0:00:02 remaining]
Chain 3:  80% [0:00:00 of 0:00:02 remaining]
Chain 3:  90% [0:00:00 of 0:00:02 remaining]
Chain 3: 100% [0:00:00 of 0:00:02 remaining]

Iterations = 252:15000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 7375

Empirical Posterior Estimates:
           Mean        SD      Naive SE       MCSE         ESS   
     s2 1.18804077 1.8242532 0.0122643204 0.0705706433  668.22405
beta[1] 0.60607045 1.1325151 0.0076138158 0.0151607887 5580.13138
beta[2] 0.79889862 0.3404041 0.0022885118 0.0042685197 6359.67614

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
     s2  0.17064475 0.383671702 0.66008221 1.2298254 5.6586154
beta[1] -1.77373832 0.033286013 0.60310302 1.1960601 2.8503372
beta[2]  0.12794221 0.619227290 0.79748963 0.9702821 1.5080653

Object of type "Mamba.Model"
-------------------------------------------------------------------------------
y:
An unmonitored node of type "5-element Mamba.ArrayStochastic{1}"
[1.0,3.0,3.0,3.0,5.0]

Distribution:
IsoNormal(
dim: 5
μ: [3.2384475887755166,5.286627296564756,7.334807004353996,9.382986712143236,11.431166419932476]
Σ: [1.1830434911443408 0.0 0.0 0.0 0.0
 0.0 1.1830434911443408 0.0 0.0 0.0
 0.0 0.0 1.1830434911443408 0.0 0.0
 0.0 0.0 0.0 1.1830434911443408 0.0
 0.0 0.0 0.0 0.0 1.1830434911443408]
)

Function:
AST(:($(Expr(:lambda, Any[:(model::(top(getfield))(Mamba,:Model))], Any[Any[Any[:model,:Any,18],Any[:mu,:Any,18],Any[:s2,:Any,18]],Any[],0,Any[]], :(begin 
        model = (top(typeassert))(model,Mamba.Model)
        mu = (Mamba.getindex)(model,:mu)
        s2 = (Mamba.getindex)(model,:s2)
        return (Mamba.MvNormal)(mu,(Mamba.sqrt)(s2))
    end)))))

Source Nodes:
[:mu,:s2]

Target Nodes:
Symbol[]
-------------------------------------------------------------------------------
s2:
A monitored node of type "Mamba.ScalarStochastic"
1.1830434911443408

Distribution:
Distributions.InverseGamma(
invd: Distributions.Gamma(α=0.001, β=1000.0)
β: 0.001
)

Function:
AST(:($(Expr(:lambda, Any[:(model::(top(getfield))(Mamba,:Model))], Any[Any[Any[:model,:Any,18]],Any[],0,Any[]], :(begin 
        model = (top(typeassert))(model,Mamba.Model)
        return (Mamba.InverseGamma)(0.001,0.001)
    end)))))

Source Nodes:
Symbol[]

Target Nodes:
[:y]
-------------------------------------------------------------------------------
xmat:
[1.0 1.0
 1.0 2.0
 1.0 3.0
 1.0 4.0
 1.0 5.0]
-------------------------------------------------------------------------------
beta:
A monitored node of type "2-element Mamba.ArrayStochastic{1}"
[1.1902678809862768,2.04817970778924]

Distribution:
ZeroMeanIsoNormal(
dim: 2
μ: [0.0,0.0]
Σ: [1000.0 0.0
 0.0 1000.0]
)

Function:
AST(:($(Expr(:lambda, Any[:(model::(top(getfield))(Mamba,:Model))], Any[Any[Any[:model,:Any,18]],Any[],0,Any[]], :(begin 
        model = (top(typeassert))(model,Mamba.Model)
        return (Mamba.MvNormal)(2,(Mamba.sqrt)(1000))
    end)))))

Source Nodes:
Symbol[]

Target Nodes:
[:mu,:y]
-------------------------------------------------------------------------------
mu:
An unmonitored node of type "5-element Mamba.ArrayLogical{1}"
[3.2384475887755166,5.286627296564756,7.334807004353996,9.382986712143236,11.431166419932476]
Function:
AST(:($(Expr(:lambda, Any[:(model::(top(getfield))(Mamba,:Model))], Any[Any[Any[:model,:Any,18],Any[:xmat,:Any,18],Any[:beta,:Any,18]],Any[],0,Any[]], :(begin 
        model = (top(typeassert))(model,Mamba.Model)
        xmat = (Mamba.getindex)(model,:xmat)
        beta = (Mamba.getindex)(model,:beta)
        return xmat * beta
    end)))))

Source Nodes:
[:xmat,:beta]

Target Nodes:
[:y]

>>> Testing ../doc/samplers/amm.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE       MCSE       ESS   
b0 0.67372957 1.07776604 0.0152419136 0.064652461 277.89381
b1 0.77112512 0.32135034 0.0045445801 0.017982404 319.34640
s2 1.29658296 2.18979550 0.0309683849 0.139974432 244.74267

Quantiles:
       2.5%        25.0%       50.0%      75.0%     97.5%  
b0 -1.451022943 0.069490369 0.65978541 1.19631191 3.1685322
b1  0.050258268 0.611291896 0.79094107 0.94652458 1.4132212
s2  0.174653274 0.389575233 0.65132492 1.31853897 6.8337311


>>> Testing ../doc/samplers/amwg.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean       SD      Naive SE       MCSE        ESS   
b0 0.5983881 1.5898262 0.0224835377 0.162560986  95.645964
b1 0.8006155 0.4358909 0.0061644284 0.042038394 107.513597
s2 2.2710644 9.1262030 0.1290640007 0.686946293 176.495925

Quantiles:
       2.5%       25.0%      50.0%      75.0%      97.5%  
b0 -2.17471713 0.03038741 0.67912808 1.30557650  3.3496859
b1  0.03755749 0.60096712 0.77599921 0.96011511  1.7513752
s2  0.16901125 0.39945048 0.70340929 1.47274298 13.3376638


>>> Testing ../doc/samplers/nuts.jl

Iterations = 1001:5000
Thinning interval = 1
Chains = 1
Samples per chain = 4000

Empirical Posterior Estimates:
      Mean        SD       Naive SE      MCSE       ESS   
b0 0.59242566 1.12664340 0.0178137962 0.07262530 240.65621
b1 0.79955933 0.34124494 0.0053955563 0.02021753 284.88937
s2 1.23041170 2.28573689 0.0361406736 0.10397815 483.24600

Quantiles:
       2.5%        25.0%       50.0%     75.0%     97.5%  
b0 -1.60156914 -0.018689413 0.55936277 1.1737069 2.9302371
b1  0.09581153  0.620652115 0.81772866 0.9840868 1.4803526
s2  0.20677131  0.401460055 0.67740807 1.2526098 5.6494793


>>> Testing ../doc/samplers/slice.jl

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE      MCSE       ESS   
b0 0.63272584 0.93606479 0.013237955 0.081599599 131.59390
b1 0.78761628 0.28902543 0.004087437 0.022846710 160.03862
s2 1.07396724 1.60963311 0.022763650 0.096229577 279.79287

Quantiles:
       2.5%       25.0%      50.0%     75.0%     97.5%  
b0 -1.42276867 0.09555760 0.64058736 1.1567408 2.6027365
b1  0.17034388 0.62081826 0.78876745 0.9500967 1.3801843
s2  0.17044047 0.35041045 0.58576505 1.1345926 5.1046853

Iterations = 1:5000
Thinning interval = 1
Chains = 1
Samples per chain = 5000

Empirical Posterior Estimates:
      Mean        SD       Naive SE      MCSE       ESS   
b0 0.59661489 0.86078729 0.012173371 0.068947243 155.86833
b1 0.79924975 0.27636461 0.003908386 0.020495292 181.82626
s2 1.08076089 1.56013009 0.022063571 0.077758779 402.55272

Quantiles:
       2.5%       25.0%       50.0%     75.0%     97.5%  
b0 -1.39487697 0.102185728 0.61013780 1.1271580 2.2617415
b1  0.27293503 0.634673470 0.79717410 0.9534172 1.4070905
s2  0.15919854 0.369553514 0.62171038 1.1910221 4.9682933


>>> Testing ../doc/mcmc/newunivardist.jl

MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:41 of 0:00:41 remaining]
Chain 1:  10% [0:00:11 of 0:00:12 remaining]
Chain 1:  20% [0:00:10 of 0:00:12 remaining]
Chain 1:  30% [0:00:08 of 0:00:12 remaining]
Chain 1:  40% [0:00:07 of 0:00:12 remaining]
Chain 1:  50% [0:00:06 of 0:00:12 remaining]
Chain 1:  60% [0:00:05 of 0:00:11 remaining]
Chain 1:  70% [0:00:03 of 0:00:12 remaining]
Chain 1:  80% [0:00:02 of 0:00:11 remaining]
Chain 1:  90% [0:00:01 of 0:00:11 remaining]
Chain 1: 100% [0:00:00 of 0:00:11 remaining]

Chain 2:   0% [0:00:16 of 0:00:16 remaining]
Chain 2:  10% [0:00:13 of 0:00:15 remaining]
Chain 2:  20% [0:00:12 of 0:00:15 remaining]
Chain 2:  30% [0:00:10 of 0:00:14 remaining]
Chain 2:  40% [0:00:08 of 0:00:14 remaining]
Chain 2:  50% [0:00:07 of 0:00:13 remaining]
Chain 2:  60% [0:00:05 of 0:00:13 remaining]
Chain 2:  70% [0:00:04 of 0:00:14 remaining]
Chain 2:  80% [0:00:03 of 0:00:14 remaining]
Chain 2:  90% [0:00:01 of 0:00:13 remaining]
Chain 2: 100% [0:00:00 of 0:00:14 remaining]

Chain 3:   0% [0:00:15 of 0:00:15 remaining]
Chain 3:  10% [0:00:12 of 0:00:13 remaining]
Chain 3:  20% [0:00:11 of 0:00:13 remaining]
Chain 3:  30% [0:00:09 of 0:00:13 remaining]
Chain 3:  40% [0:00:08 of 0:00:13 remaining]
Chain 3:  50% [0:00:06 of 0:00:12 remaining]
Chain 3:  60% [0:00:05 of 0:00:12 remaining]
Chain 3:  70% [0:00:04 of 0:00:12 remaining]
Chain 3:  80% [0:00:02 of 0:00:12 remaining]
Chain 3:  90% [0:00:01 of 0:00:12 remaining]
Chain 3: 100% [0:00:00 of 0:00:12 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean        SD       Naive SE       MCSE       ESS   
     s2 1.21355573 1.77421793 0.0146709766 0.071581268  614.3490
beta[1] 0.58240287 1.14230234 0.0094456779 0.018305636 3893.9689
beta[2] 0.80352012 0.34248004 0.0028319614 0.005181105 4369.4396

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
     s2  0.16868782 0.385631053 0.65901954 1.2756509 6.1752281
beta[1] -1.71534530 0.023088344 0.58077083 1.1524530 2.8274529
beta[2]  0.12368846 0.630518397 0.80241394 0.9732482 1.5135523


>>> Testing ../doc/mcmc/newmultivardist.jl

WARNING: replacing module Testing
MCMC Simulation of 10000 Iterations x 3 Chains...

Chain 1:   0% [0:00:31 of 0:00:31 remaining]
Chain 1:  10% [0:00:05 of 0:00:05 remaining]
Chain 1:  20% [0:00:04 of 0:00:05 remaining]
Chain 1:  30% [0:00:04 of 0:00:05 remaining]
Chain 1:  40% [0:00:03 of 0:00:05 remaining]
Chain 1:  50% [0:00:03 of 0:00:05 remaining]
Chain 1:  60% [0:00:02 of 0:00:05 remaining]
Chain 1:  70% [0:00:02 of 0:00:05 remaining]
Chain 1:  80% [0:00:01 of 0:00:05 remaining]
Chain 1:  90% [0:00:01 of 0:00:05 remaining]
Chain 1: 100% [0:00:00 of 0:00:05 remaining]

Chain 2:   0% [0:00:08 of 0:00:08 remaining]
Chain 2:  10% [0:00:05 of 0:00:05 remaining]
Chain 2:  20% [0:00:04 of 0:00:05 remaining]
Chain 2:  30% [0:00:03 of 0:00:05 remaining]
Chain 2:  40% [0:00:03 of 0:00:05 remaining]
Chain 2:  50% [0:00:02 of 0:00:05 remaining]
Chain 2:  60% [0:00:02 of 0:00:05 remaining]
Chain 2:  70% [0:00:01 of 0:00:05 remaining]
Chain 2:  80% [0:00:01 of 0:00:05 remaining]
Chain 2:  90% [0:00:00 of 0:00:05 remaining]
Chain 2: 100% [0:00:00 of 0:00:05 remaining]

Chain 3:   0% [0:00:03 of 0:00:03 remaining]
Chain 3:  10% [0:00:03 of 0:00:03 remaining]
Chain 3:  20% [0:00:02 of 0:00:03 remaining]
Chain 3:  30% [0:00:02 of 0:00:03 remaining]
Chain 3:  40% [0:00:02 of 0:00:03 remaining]
Chain 3:  50% [0:00:01 of 0:00:03 remaining]
Chain 3:  60% [0:00:01 of 0:00:03 remaining]
Chain 3:  70% [0:00:01 of 0:00:03 remaining]
Chain 3:  80% [0:00:01 of 0:00:03 remaining]
Chain 3:  90% [0:00:00 of 0:00:03 remaining]
Chain 3: 100% [0:00:00 of 0:00:03 remaining]

Iterations = 252:10000
Thinning interval = 2
Chains = 1,2,3
Samples per chain = 4875

Empirical Posterior Estimates:
           Mean       SD       Naive SE       MCSE         ESS   
     s2 1.1638187 1.61102871 0.0133215679 0.0632533846  648.69272
beta[1] 0.5788931 1.11232796 0.0091978202 0.0190480893 3410.06668
beta[2] 0.8052916 0.33546852 0.0027739833 0.0055032179 3715.95238

Quantiles:
            2.5%       25.0%       50.0%     75.0%     97.5%  
     s2  0.17208834 0.383853394 0.66064186 1.2465013 5.5621934
beta[1] -1.71161012 0.030043945 0.58723102 1.1464501 2.8420839
beta[2]  0.12334042 0.628821665 0.80501158 0.9749143 1.4853405

INFO: Mamba tests passed

>>> End of log
