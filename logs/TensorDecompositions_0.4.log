>>> 'Pkg.add("TensorDecompositions")' log
INFO: Cloning cache of TensorDecompositions from git://github.com/yunjhongwu/TensorDecompositions.jl.git
INFO: Installing ArrayViews v0.6.4
INFO: Installing Distributions v0.9.0
INFO: Installing FactCheck v0.4.3
INFO: Installing PDMats v0.4.1
INFO: Installing ProgressMeter v0.3.1
INFO: Installing StatsBase v0.8.1
INFO: Installing StatsFuns v0.2.2
INFO: Installing TensorDecompositions v0.1.0
INFO: Installing TensorOperations v0.4.1
INFO: Package database updated

>>> 'Pkg.test("TensorDecompositions")' log
Julia Version 0.4.5
Commit 2ac304d (2016-03-18 00:58 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing TensorDecompositions
Utilities
  > _row_unfold()
  > _col_unfold()
  > tensorcontractmatrices()
8 facts verified.
HO-SVD
  > no residuals calculation
  3.150083 seconds (4.47 M allocations: 207.782 MB, 1.52% gc time)
  > core reconstruction and residuals
  0.111911 seconds (93.40 k allocations: 4.935 MB)
  > core dimension equal to the original dimension
WARNING: Adjusting nev from 10 to 9
WARNING: Adjusting nev from 20 to 19
  0.054101 seconds (44.45 k allocations: 2.578 MB)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: size(factors.core) --> (10,20,5)
        Expected: (10,20,5)
        Occurred: (9,19,5)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: rel_residue(factors) --> less_than(1.0e-5)
        Expected: 0.8749576415323682 < 1.0e-5
Out of 8 total facts:
  Verified: 6
  Failed:   2
CANDECOMP
  > Incorrect method
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALdS method...
  > ALS (Alternating least squares)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALS method...
WARNING: Maximum number 100 of iterations exceeded.
  1.304931 seconds (404.50 k allocations: 48.868 MB, 1.16% gc time)
  > SGSD (Simultaneous generalized Schur decomposition)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP SGSD method...
INFO: Algorithm converged after 6 iterations.
  2.500585 seconds (915.82 k allocations: 45.220 MB, 0.63% gc time)
10 facts verified.
SS-HOPM
  > Dense representation
INFO: Algorithm converged after 28 iterations.
  0.686697 seconds (1.07 M allocations: 53.155 MB, 1.70% gc time)
  > Sparse representation
INFO: Algorithm converged after 12 iterations.
  0.098084 seconds (897.73 k allocations: 31.965 MB, 4.85% gc time)
4 facts verified.
Non-negative CANDECOMP
INFO: Algorithm converged after 9 iterations.
  0.320541 seconds (309.43 k allocations: 16.670 MB, 1.34% gc time)
  Failure :: (line:-1) :: fact was false
    Expression: rel_residue(factors) --> less_than(0.05)
      Expected: 0.1132559388930732 < 0.05
Out of 4 total facts:
  Verified: 3
  Failed:   1
Tensor-CUR
  > Small case
    > slab axis: 1
  2.290775 seconds (3.48 M allocations: 169.587 MB, 1.79% gc time)
    > slab axis: 2
  0.295917 seconds (209.08 k allocations: 12.819 MB)
    > slab axis: 3
  0.116441 seconds (62.81 k allocations: 5.267 MB)
  > Large case without reconstruction
  0.042105 seconds (11.55 k allocations: 6.789 MB)
13 facts verified.
PARAFAC2
WARNING: Maximum number 100 of iterations exceeded.
  0.506379 seconds (465.51 k allocations: 25.496 MB, 1.39% gc time)
5 facts verified.
Sparse (semi-)nonnegative Tucker decomposition
  > nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=68.00166877985491
INFO: Rescaling initial decomposition...
INFO: Initial residue=1913.1534109780941
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  0%|           |  ETA: 0:16:05[K[1GAlternating proximal gradient iterations  3%|           |  ETA: 0:01:04[K[1GAlternating proximal gradient iterations  5%|â–ˆ          |  ETA: 0:00:40[K[1GAlternating proximal gradient iterations  8%|â–ˆ          |  ETA: 0:00:29[K[1GAlternating proximal gradient iterations 10%|â–ˆ          |  ETA: 0:00:23[K[1GAlternating proximal gradient iterations 12%|â–ˆ          |  ETA: 0:00:19[K[1GAlternating proximal gradient iterations 15%|â–ˆâ–ˆ         |  ETA: 0:00:15[K[1GAlternating proximal gradient iterations 17%|â–ˆâ–ˆ         |  ETA: 0:00:13[K[1GAlternating proximal gradient iterations 19%|â–ˆâ–ˆ         |  ETA: 0:00:13[K[1GAlternating proximal gradient iterations 20%|â–ˆâ–ˆ         |  ETA: 0:00:12[K[1GAlternating proximal gradient iterations 22%|â–ˆâ–ˆ         |  ETA: 0:00:11[K[1GAlternating proximal gradient iterations 24%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:10[K[1GAlternating proximal gradient iterations 26%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:09[K[1GAlternating proximal gradient iterations 28%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:09[K[1GAlternating proximal gradient iterations 30%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:08[K[1GAlternating proximal gradient iterations 33%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:07[K[1GAlternating proximal gradient iterations 35%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:07[K[1GAlternating proximal gradient iterations 37%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:07[K[1GAlternating proximal gradient iterations 38%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 41%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[KINFO: Relative error below 0.0001 3 times in a row
INFO: spnntucker() converged in 965 iteration(s), 2 redo steps
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:06[K
 10.609499 seconds (13.49 M allocations: 2.255 GB, 3.57% gc time)
    Failure :: (line:-1) :: nonnegative decomposition :: fact was false
      Expression: rel_residue(tucker_spnn) --> less_than(0.05)
        Expected: 0.051855314624193675 < 0.05
INFO: Relative error of decomposition : 0.051855314624193675
  > semi-nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=115.92978180598605
INFO: Rescaling initial decomposition...
INFO: Initial residue=5553.874285269915
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  3%|           |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations  7%|â–ˆ          |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 10%|â–ˆ          |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 14%|â–ˆâ–ˆ         |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 18%|â–ˆâ–ˆ         |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 21%|â–ˆâ–ˆ         |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 25%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 27%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 29%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 31%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 35%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 38%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[K[1GMaximal number of iterations reached, might be not an optimal solution[K
INFO: Final relative error 0.06531835014697364
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
  3.968872 seconds (5.84 M allocations: 1.956 GB, 6.68% gc time)
INFO: Relative error of decomposition : 0.01253262547900655
Out of 2 total facts:
  Verified: 1
  Failed:   1
INFO: TensorDecompositions tests passed

>>> End of log
