>>> 'Pkg.add("TensorDecompositions")' log
INFO: Cloning cache of TensorDecompositions from git://github.com/yunjhongwu/TensorDecompositions.jl.git
INFO: Installing Distributions v0.9.0
INFO: Installing FactCheck v0.4.3
INFO: Installing PDMats v0.4.2
INFO: Installing ProgressMeter v0.3.2
INFO: Installing TensorDecompositions v0.1.0
INFO: Installing TensorOperations v0.4.1
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of TensorDecompositions
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("TensorDecompositions")' log
Julia Version 0.4.6
Commit 2e358ce (2016-06-19 17:16 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.3
INFO: Testing TensorDecompositions
Utilities
  > _row_unfold()
  > _col_unfold()
  > tensorcontractmatrices()
8 facts verified.
HO-SVD
  > no residuals calculation
  4.218993 seconds (4.34 M allocations: 202.139 MB, 1.42% gc time)
  > core reconstruction and residuals
  0.168792 seconds (95.08 k allocations: 5.015 MB)
  > core dimension equal to the original dimension
WARNING: Adjusting nev from 10 to 9
WARNING: Adjusting nev from 20 to 19
  0.062276 seconds (44.44 k allocations: 2.566 MB)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: size(factors.core) --> (10,20,5)
        Expected: (10,20,5)
        Occurred: (9,19,5)
    Failure :: (line:-1) :: core dimension equal to the original dimension :: fact was false
      Expression: rel_residue(factors) --> less_than(1.0e-5)
        Expected: 0.8648970352444324 < 1.0e-5
Out of 8 total facts:
  Verified: 6
  Failed:   2
CANDECOMP
  > Incorrect method
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALdS method...
  > ALS (Alternating least squares)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP ALS method...
WARNING: Maximum number 100 of iterations exceeded.
  1.170378 seconds (404.51 k allocations: 48.836 MB, 1.12% gc time)
  > SGSD (Simultaneous generalized Schur decomposition)
INFO: Initializing factor matrices...
INFO: Applying CANDECOMP SGSD method...
INFO: Algorithm converged after 4 iterations.
  2.317231 seconds (913.52 k allocations: 44.272 MB, 0.50% gc time)
10 facts verified.
SS-HOPM
  > Dense representation
INFO: Algorithm converged after 28 iterations.
  0.891351 seconds (1.07 M allocations: 53.144 MB, 1.21% gc time)
  > Sparse representation
INFO: Algorithm converged after 12 iterations.
  0.127809 seconds (898.61 k allocations: 32.017 MB, 5.83% gc time)
4 facts verified.
Non-negative CANDECOMP
INFO: Algorithm converged after 9 iterations.
  0.428920 seconds (309.53 k allocations: 16.672 MB, 0.93% gc time)
  Failure :: (line:-1) :: fact was false
    Expression: rel_residue(factors) --> less_than(0.05)
      Expected: 0.1132559388930732 < 0.05
Out of 4 total facts:
  Verified: 3
  Failed:   1
Tensor-CUR
  > Small case
    > slab axis: 1
  4.032432 seconds (3.48 M allocations: 169.753 MB, 1.53% gc time)
    > slab axis: 2
  0.369143 seconds (209.08 k allocations: 12.807 MB)
    > slab axis: 3
  0.112161 seconds (62.81 k allocations: 5.268 MB)
  > Large case without reconstruction
  0.046875 seconds (11.55 k allocations: 6.789 MB)
13 facts verified.
PARAFAC2
WARNING: Maximum number 100 of iterations exceeded.
  0.563197 seconds (462.08 k allocations: 25.433 MB, 1.16% gc time)
5 facts verified.
Sparse (semi-)nonnegative Tucker decomposition
  > nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=68.00166877985491
INFO: Rescaling initial decomposition...
INFO: Initial residue=1913.1534109780941
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  0%|           |  ETA: 0:15:36[K[1GAlternating proximal gradient iterations  5%|â–ˆ          |  ETA: 0:00:45[K[1GAlternating proximal gradient iterations  7%|â–ˆ          |  ETA: 0:00:31[K[1GAlternating proximal gradient iterations  9%|â–ˆ          |  ETA: 0:00:24[K[1GAlternating proximal gradient iterations 12%|â–ˆ          |  ETA: 0:00:19[K[1GAlternating proximal gradient iterations 16%|â–ˆâ–ˆ         |  ETA: 0:00:14[K[1GAlternating proximal gradient iterations 19%|â–ˆâ–ˆ         |  ETA: 0:00:12[K[1GAlternating proximal gradient iterations 22%|â–ˆâ–ˆ         |  ETA: 0:00:10[K[1GAlternating proximal gradient iterations 25%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:09[K[1GAlternating proximal gradient iterations 27%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:08[K[1GAlternating proximal gradient iterations 29%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:08[K[1GAlternating proximal gradient iterations 32%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:07[K[1GAlternating proximal gradient iterations 35%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 38%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:06[K[1GAlternating proximal gradient iterations 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:05[K[1GAlternating proximal gradient iterations 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[KINFO: Relative error below 0.0001 3 times in a row
INFO: spnntucker() converged in 965 iteration(s), 2 redo steps
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:06[K
 11.151054 seconds (13.61 M allocations: 2.262 GB, 3.39% gc time)
    Failure :: (line:-1) :: nonnegative decomposition :: fact was false
      Expression: rel_residue(tucker_spnn) --> less_than(0.05)
        Expected: 0.051855314624193675 < 0.05
INFO: Relative error of decomposition : 0.051855314624193675
  > semi-nonnegative decomposition
INFO: Using High-Order SVD to get initial decomposition...
INFO: Precomputing input tensor unfoldings...
INFO: |tensor|=115.92978180598605
INFO: Rescaling initial decomposition...
INFO: Initial residue=5553.874285269915
WARNING: 1: residue increase at redo step
WARNING: 1: residue increase at redo step
[1GAlternating proximal gradient iterations  2%|           |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations  5%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations  7%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations  9%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 11%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 14%|â–ˆ          |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 17%|â–ˆâ–ˆ         |  ETA: 0:00:04[K[1GAlternating proximal gradient iterations 20%|â–ˆâ–ˆ         |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 21%|â–ˆâ–ˆ         |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 24%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 26%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 28%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 30%|â–ˆâ–ˆâ–ˆ        |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 32%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 34%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 36%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 39%|â–ˆâ–ˆâ–ˆâ–ˆ       |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:03[K[1GAlternating proximal gradient iterations 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:02[K[1GAlternating proximal gradient iterations 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:01[K[1GAlternating proximal gradient iterations 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[K[1GAlternating proximal gradient iterations 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  ETA: 0:00:00[K[1GMaximal number of iterations reached, might be not an optimal solution[K
INFO: Final relative error 0.06531835014697364
[1GAlternating proximal gradient iterations100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:04[K
  4.394862 seconds (5.85 M allocations: 1.960 GB, 6.03% gc time)
INFO: Relative error of decomposition : 0.01253262547900655
Out of 2 total facts:
  Verified: 1
  Failed:   1
INFO: TensorDecompositions tests passed

>>> End of log
