>>> 'Pkg.add("Optim")' log
INFO: Installing Calculus v0.1.15
INFO: Installing DiffBase v0.0.2
INFO: Installing ForwardDiff v0.3.3
INFO: Installing LineSearches v0.1.2
INFO: Installing NaNMath v0.2.2
INFO: Installing Optim v0.7.3
INFO: Installing PositiveFactorizations v0.0.3
INFO: Package database updated

>>> 'Pkg.test("Optim")' log
Julia Version 0.6.0-dev.1662
Commit f27c6f3 (2016-12-23 02:28 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-105-generic #152-Ubuntu SMP Fri Dec 2 15:37:11 UTC 2016 x86_64 x86_64
Memory: 2.9392738342285156 GB (1193.40234375 MB free)
Uptime: 8348.0 sec
Load Avg:  1.03564453125  0.9609375  1.0556640625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3499 MHz     499306 s        118 s      53494 s     195411 s         11 s
#2  3499 MHz     159968 s         42 s      27512 s     630325 s          0 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.6
2 required packages:
 - JSON                          0.8.0
 - Optim                         0.7.3
7 additional packages:
 - Calculus                      0.1.15
 - Compat                        0.9.5
 - DiffBase                      0.0.2
 - ForwardDiff                   0.3.3
 - LineSearches                  0.1.2
 - NaNMath                       0.2.2
 - PositiveFactorizations        0.0.3
INFO: Testing Optim
Running tests:
 * types.jl
 * lsthrow.jl
Testing Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.BFGS{L<:Function,H<:Function}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.Newton
WARNING: maxabs(x) is deprecated, use maximum(abs,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in maxabs(::Array{Float64,2}) at ./deprecated.jl:50
 in default_tol at /home/vagrant/.julia/v0.6/PositiveFactorizations/src/cholesky.jl:271 [inlined]
 in ldltfact!(::Type{PositiveFactorizations.Positive}, ::Array{Float64,2}, ::Type{T}) at /home/vagrant/.julia/v0.6/PositiveFactorizations/src/cholesky.jl:75 (repeats 2 times)
 in update_state!(::Optim.TwiceDifferentiableFunction, ::Optim.NewtonState{Float64}, ::Optim.Newton) at /home/vagrant/.julia/v0.6/Optim/src/newton.jl:60
 in optimize(::Optim.TwiceDifferentiableFunction, ::Array{Float64,1}, ::Optim.Newton, ::Optim.Options{Void}) at /home/vagrant/.julia/v0.6/Optim/src/optimize.jl:200
 in optimize(::Optim.UnconstrainedProblems.#exponential, ::Array{Float64,1}, ::Optim.Newton, ::Optim.Options{Void}) at /home/vagrant/.julia/v0.6/Optim/src/optimize.jl:121
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/lsthrow.jl:11 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/lsthrow.jl, in expression starting on line 1
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.AcceleratedGradientDescent{L<:Function}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
Testing Optim.MomentumGradientDescent{L<:Function}
WARNING: Linesearch failed, using alpha = 0.0 and exiting optimization.
 * bfgs.jl
 * gradient_descent.jl
 * accelerated_gradient_descent.jl
Iter     Function value   Gradient norm 
     0     1.000000e+00     4.000000e+00
     1     5.397751e-01     2.518950e+00
 * momentum_gradient_descent.jl
 * grid_search.jl
 * l_bfgs.jl
 * levenberg_marquardt.jl
WARNING: levenberg_marquardt has been moved out of Optim.jl and into LsqFit.jl. Please adjust your code, and change your dependency to match this migration.
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:57
 in levenberg_marquardt(::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 11
WARNING: sumabs2(A,region) is deprecated, use sum(abs2,A,region) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,2}, ::Int64) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:88
 in levenberg_marquardt(::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 11
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:119
 in levenberg_marquardt(::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 11
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:133
 in levenberg_marquardt(::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 11
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:173
 in levenberg_marquardt(::#f_lm#12, ::#g_lm#13, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 11
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:57
 in levenberg_marquardt(::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 37
WARNING: sumabs2(A,region) is deprecated, use sum(abs2,A,region) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,2}, ::Int64) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:88
 in levenberg_marquardt(::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 37
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:119
 in levenberg_marquardt(::#frb#16, ::#grb#17, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 37
WARNING: Problem solving for delta_x: predicted residual increase.
18.95337979630715 (predicted_residual) >
3.6729087897253905 (residual) + 3.552713678800501e-15 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.83860477635018 (predicted_residual) >
2.9812894464055533 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.5347148551516008 (predicted_residual) >
2.1895906529240503 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.4662071702097417 (predicted_residual) >
2.0497617658979004 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
2.402223943602616 (predicted_residual) >
1.9102621894841052 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
1.9548243717543228 (predicted_residual) >
1.8272637677633554 (residual) + 2.220446049250313e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.289097004965162 (predicted_residual) >
1.7676814916153436 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.5282850316144354 (predicted_residual) >
0.43569220875204495 (residual) + 1.1102230246251565e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.38479244475307006 (predicted_residual) >
0.3191560404065722 (residual) + 5.551115123125783e-17 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.0867292689898465 (predicted_residual) >
0.07825577278289107 (residual) + 1.3877787807814457e-17 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
0.05060004314422784 (predicted_residual) >
0.04864792336713843 (residual) + 6.938893903907228e-18 (eps)
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::##10#19, ::Calculus.#g#5{##10#19,Symbol}, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:119
 in levenberg_marquardt(::##10#19, ::Calculus.#g#5{##10#19,Symbol}, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:27
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 60
WARNING: sumabs2(x) is deprecated, use sum(abs2,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in sumabs2(::Array{Float64,1}) at ./deprecated.jl:50
 in #levenberg_marquardt#65(::Float64, ::Float64, ::Int64, ::Float64, ::Bool, ::Array{Float64,1}, ::Array{Float64,1}, ::Function, ::##11#21, ::Calculus.#g#5{##11#21,Symbol}, ::Array{Float64,1}) at /home/vagrant/.julia/v0.6/Optim/src/levenberg_marquardt.jl:119
 in (::Optim.#kw##levenberg_marquardt)(::Array{Any,1}, ::Optim.#levenberg_marquardt, ::##11#21, ::Calculus.#g#5{##11#21,Symbol}, ::Array{Float64,1}) at ./<missing>:0
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/levenberg_marquardt.jl, in expression starting on line 83
WARNING: Problem solving for delta_x: predicted residual increase.
3.367145765531822 (predicted_residual) >
3.3582265009251535 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.368047096437963 (predicted_residual) >
3.3671457655318497 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.368137102143122 (predicted_residual) >
3.3680470964379685 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.3681461013780565 (predicted_residual) >
3.3681371021431215 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.3681470013030252 (predicted_residual) >
3.3681461013780583 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.6257200158428846 (predicted_residual) >
3.621898322415225 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.634856357157668 (predicted_residual) >
3.6257200158435996 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.6357709240137304 (predicted_residual) >
3.63485635715762 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.6358622472109134 (predicted_residual) >
3.6357709240137353 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.6358713782030714 (predicted_residual) >
3.635862247210918 (residual) + 4.440892098500626e-16 (eps)
WARNING: Problem solving for delta_x: predicted residual increase.
3.6358722912177237 (predicted_residual) >
3.635871378203067 (residual) + 4.440892098500626e-16 (eps)
     0     4.093196e+03              NaN
 * lambda: 10.0

     1     2.798224e+03     5.199044e+02
 * g(x): 519.9043679444208
 * lambda: 1.0
 * dx: [-1.37537,-2.26849,-0.516919]

     2     4.992133e+02     2.193666e+02
 * g(x): 219.36656868579476
 * lambda: 0.1
 * dx: [-3.33453,-5.79199,-2.0025]

     3     9.266003e+00     2.104323e+01
 * g(x): 21.043228273647596
 * lambda: 0.010000000000000002
 * dx: [-0.157349,1.53033,-2.12792]

     4     9.815963e-01     3.012647e-01
 * g(x): 0.3012647255195926
 * lambda: 0.0010000000000000002
 * dx: [-0.0853385,1.42208,-0.344097]

     5     9.379170e-01     7.194056e-03
 * g(x): 0.007194056050522674
 * lambda: 0.00010000000000000003
 * dx: [0.0577301,0.095152,-0.0171907]

     6     9.379163e-01     7.827368e-07
 * g(x): 7.82736797932948e-7
 * lambda: 1.0000000000000004e-5
 * dx: [0.000258738,-0.000143761,-8.19913e-5]

     7     9.379163e-01     7.419870e-12
 * g(x): 7.419870273750462e-12
 * lambda: 1.0000000000000004e-6
 * dx: [9.76933e-8,-9.59555e-8,-7.41911e-9]

 * newton.jl
 * newton_trust_region.jl
 * cg.jl
 * nelder_mead.jl
 * optimize.jl
 * simulated_annealing.jl
 * particle_swarm.jl
 * api.jl
Iter     Function value   Gradient norm 
     0     1.000000e+00     2.000000e+00
 * Current step size: 1.0
 * g(x): [-2.0,0.0]
 * ~inv(H): [1.0 0.0; 0.0 1.0]
 * x: [0.0,0.0]
     1     8.415971e-01     1.578600e+00
 * Current step size: 0.042768077654337065
 * g(x): [-1.5786,-1.46329]
 * ~inv(H): [12.2608 3.47244; 3.47244 1.0]
 * x: [0.0855362,0.0]
     2     6.928766e-01     1.076526e+01
 * Current step size: 0.01143894820261991
 * g(x): [6.59004,-10.7653]
 * ~inv(H): [0.0975543 0.0556186; 0.0556186 0.0403018]
 * x: [0.365059,0.0794421]
     3     4.336347e-01     1.082559e+00
 * Current step size: 0.5289383775238637
 * g(x): [-1.08256,-0.342414]
 * ~inv(H): [0.086429 0.0613833; 0.0613833 0.0486031]
 * x: [0.341713,0.115056]
     4     3.268654e-01     1.203708e+00
 * Current step size: 0.7832069592846927
 * g(x): [-0.0983968,-1.20371]
 * ~inv(H): [0.278428 0.213952; 0.213952 0.168913]
 * x: [0.431455,0.180135]
     5     2.989460e-01     1.820631e+00
 * Current step size: 0.10324029716686389
 * g(x): [0.599899,-1.82063]
 * ~inv(H): [0.177273 0.152973; 0.152973 0.135601]
 * x: [0.460872,0.2033]
     6     2.380606e-01     3.824597e+00
 * Current step size: 0.5242180516622564
 * g(x): [3.31788,-3.8246]
 * ~inv(H): [0.117499 0.114329; 0.114329 0.114488]
 * x: [0.551122,0.284612]
     7     1.377832e-01     4.305388e+00
 * Current step size: 2.654333836482214
 * g(x): [4.30539,-3.65706]
 * ~inv(H): [0.105591 0.128794; 0.128794 0.168365]
 * x: [0.676971,0.440004]
     8     9.932907e-02     1.240226e+00
 * Current step size: 0.5277472177097148
 * g(x): [-1.24023,0.445925]
 * ~inv(H): [0.120479 0.164949; 0.164949 0.23082]
 * x: [0.685625,0.472311]
     9     6.543213e-02     6.765640e-01
 * Current step size: 0.8017424505942204
 * g(x): [0.502941,-0.676564]
 * ~inv(H): [0.366262 0.514598; 0.514598 0.726543]
 * x: [0.74645,0.553804]
    10     5.511958e-02     1.419213e+00
 * Current step size: 0.16297281487330761
 * g(x): [1.41921,-1.21117]
 * ~inv(H): [0.211473 0.312469; 0.312469 0.464599]
 * x: [0.773169,0.591735]
Iter     Function value   Gradient norm 
     0     1.000000e+00     2.000000e+00
 * Current step size: 1.0
 * g(x): [-2.0,0.0]
 * ~inv(H): [1.0 0.0; 0.0 1.0]
 * x: [0.0,0.0]
     1     8.415971e-01     1.578600e+00
 * Current step size: 0.042768077654337065
 * g(x): [-1.5786,-1.46329]
 * ~inv(H): [12.2608 3.47244; 3.47244 1.0]
 * x: [0.0855362,0.0]
     2     6.928766e-01     1.076526e+01
 * Current step size: 0.01143894820261991
 * g(x): [6.59004,-10.7653]
 * ~inv(H): [0.0975543 0.0556186; 0.0556186 0.0403018]
 * x: [0.365059,0.0794421]
     3     4.336347e-01     1.082559e+00
 * Current step size: 0.5289383775238637
 * g(x): [-1.08256,-0.342414]
 * ~inv(H): [0.086429 0.0613833; 0.0613833 0.0486031]
 * x: [0.341713,0.115056]
     4     3.268654e-01     1.203708e+00
 * Current step size: 0.7832069592846927
 * g(x): [-0.0983968,-1.20371]
 * ~inv(H): [0.278428 0.213952; 0.213952 0.168913]
 * x: [0.431455,0.180135]
     5     2.989460e-01     1.820631e+00
 * Current step size: 0.10324029716686389
 * g(x): [0.599899,-1.82063]
 * ~inv(H): [0.177273 0.152973; 0.152973 0.135601]
 * x: [0.460872,0.2033]
     6     2.380606e-01     3.824597e+00
 * Current step size: 0.5242180516622564
 * g(x): [3.31788,-3.8246]
 * ~inv(H): [0.117499 0.114329; 0.114329 0.114488]
 * x: [0.551122,0.284612]
     7     1.377832e-01     4.305388e+00
 * Current step size: 2.654333836482214
 * g(x): [4.30539,-3.65706]
 * ~inv(H): [0.105591 0.128794; 0.128794 0.168365]
 * x: [0.676971,0.440004]
     8     9.932907e-02     1.240226e+00
 * Current step size: 0.5277472177097148
 * g(x): [-1.24023,0.445925]
 * ~inv(H): [0.120479 0.164949; 0.164949 0.23082]
 * x: [0.685625,0.472311]
     9     6.543213e-02     6.765640e-01
 * Current step size: 0.8017424505942204
 * g(x): [0.502941,-0.676564]
 * ~inv(H): [0.366262 0.514598; 0.514598 0.726543]
 * x: [0.74645,0.553804]
    10     5.511958e-02     1.419213e+00
 * Current step size: 0.16297281487330761
 * g(x): [1.41921,-1.21117]
 * ~inv(H): [0.211473 0.312469; 0.312469 0.464599]
 * x: [0.773169,0.591735]
    11     4.013082e-02     3.376464e+00
 * Current step size: 0.7692406779958673
 * g(x): [3.37646,-2.22554]
 * ~inv(H): [0.16596 0.260826; 0.260826 0.41284]
 * x: [0.833422,0.683464]
    12     6.980795e-03     5.135785e-01
 * Current step size: 4.153824060425805
 * g(x): [-0.513578,0.189509]
 * ~inv(H): [0.372794 0.635081; 0.635081 1.08853]
 * x: [0.916988,0.841814]
    13     4.822164e-03     1.639696e+00
 * Current step size: 0.43568592755685387
 * g(x): [1.6397,-0.919736]
 * ~inv(H): [0.21278 0.385121; 0.385121 0.700513]
 * x: [0.947968,0.894044]
    14     1.768810e-03     4.107685e-01
 * Current step size: 2.042291166259496
 * g(x): [-0.410769,0.17126]
 * ~inv(H): [0.303376 0.580128; 0.580128 1.11429]
 * x: [0.958824,0.920199]
    15     4.218795e-04     1.186910e-01
 * Current step size: 0.8328229696007655
 * g(x): [0.118691,-0.0811141]
 * ~inv(H): [0.490374 0.945393; 0.945393 1.82672]
 * x: [0.979865,0.959729]
    16     9.522312e-05     3.374010e-01
 * Current step size: 0.8498104659755683
 * g(x): [0.337401,-0.1739]
 * ~inv(H): [0.436789 0.860303; 0.860303 1.69847]
 * x: [0.995571,0.990291]
    17     1.824025e-06     2.888770e-02
 * Current step size: 1.456401071694573
 * g(x): [-0.0288877,0.0132835]
 * ~inv(H): [0.494558 0.985152; 0.985152 1.96745]
 * x: [0.998824,0.997716]
    18     3.847551e-09     1.733584e-03
 * Current step size: 0.9445083346822327
 * g(x): [0.00173358,-0.00090904]
 * ~inv(H): [0.495163 0.988462; 0.988462 1.978]
 * x: [0.999958,0.999911]
    19     6.629175e-13     2.322282e-05
 * Current step size: 1.0664072842242067
 * g(x): [2.32228e-5,-1.10116e-5]
 * ~inv(H): [0.503249 1.00615; 1.00615 2.01662]
 * x: [1.0,1.0]
    20     1.745741e-19     1.175798e-08
 * Current step size: 0.986714750685407
 * g(x): [-1.1758e-8,6.16125e-9]
 * ~inv(H): [0.499855 0.999694; 0.999694 2.00436]
 * x: [1.0,1.0]
    21     5.374115e-30     9.015011e-14
 * Current step size: 1.0006216777739572
 * g(x): [9.01501e-14,-4.44089e-14]
 * ~inv(H): [0.499855 0.999694; 0.999694 2.00436]
 * x: [1.0,1.0]
Iter     Function value    √(Σ(yᵢ-ȳ)²)/n 
------   --------------    --------------
     0     9.506641e-01     4.576214e-02
 * step_type: initial
 * centroid: [0.0125,0.0]
     1     9.506641e-01     2.023096e-02
 * step_type: outside contraction
 * centroid: [0.0125,0.0]
     2     9.506641e-01     2.172172e-02
 * step_type: expansion
 * centroid: [0.021875,-0.00625]
     3     9.262175e-01     5.243757e-02
 * step_type: expansion
 * centroid: [0.0453125,-0.009375]
     4     8.292372e-01     4.259749e-02
 * step_type: reflection
 * centroid: [0.0820313,-0.0109375]
     5     8.292372e-01     4.265507e-02
 * step_type: reflection
 * centroid: [0.11875,-0.0125]
     6     8.138907e-01     3.109209e-02
 * step_type: reflection
 * centroid: [0.135156,-0.0046875]
     7     7.569606e-01     3.215435e-02
 * step_type: reflection
 * centroid: [0.151562,0.003125]
     8     7.382898e-01     2.418419e-02
 * step_type: reflection
 * centroid: [0.167969,0.0109375]
     9     6.989376e-01     2.426367e-02
 * step_type: reflection
 * centroid: [0.184375,0.01875]
    10     6.800415e-01     2.124416e-02
 * step_type: reflection
 * centroid: [0.200781,0.0265625]
    11     6.475000e-01     1.809652e-02
 * step_type: reflection
 * centroid: [0.217187,0.034375]
    12     6.377042e-01     2.151280e-02
 * step_type: reflection
 * centroid: [0.233594,0.0421875]
    13     5.977620e-01     1.648361e-02
 * step_type: reflection
 * centroid: [0.25,0.05]
    14     5.977620e-01     2.780850e-02
 * step_type: reflection
 * centroid: [0.266406,0.0578125]
    15     5.476196e-01     2.340189e-02
 * step_type: inside contraction
 * centroid: [0.246094,0.0671875]
    16     5.476196e-01     1.487609e-02
 * step_type: reflection
 * centroid: [0.270757,0.0679371]
    17     5.165822e-01     2.056105e-02
 * step_type: reflection
 * centroid: [0.287163,0.0757496]
    18     4.977511e-01     8.300336e-03
 * step_type: reflection
 * centroid: [0.303569,0.0835621]
    19     4.977511e-01     2.460350e-02
 * step_type: expansion
 * centroid: [0.319975,0.0913746]
    20     4.470030e-01     2.134752e-02
 * step_type: inside contraction
 * centroid: [0.315794,0.105875]
    21     4.470030e-01     2.758615e-02
 * step_type: expansion
 * centroid: [0.334359,0.109532]
    22     3.970669e-01     6.347518e-02
 * step_type: expansion
 * centroid: [0.374363,0.134235]
    23     2.945174e-01     4.615543e-02
 * step_type: inside contraction
 * centroid: [0.435328,0.177087]
    24     2.945174e-01     3.809765e-02
 * step_type: outside contraction
 * centroid: [0.418178,0.175807]
    25     2.945174e-01     6.120849e-02
 * step_type: expansion
 * centroid: [0.439622,0.198434]
    26     2.028943e-01     3.814177e-02
 * step_type: outside contraction
 * centroid: [0.510383,0.256281]
    27     2.028943e-01     2.033749e-02
 * step_type: inside contraction
 * centroid: [0.558807,0.297567]
    28     2.028943e-01     1.224326e-02
 * step_type: outside contraction
 * centroid: [0.558807,0.297567]
    29     2.028943e-01     2.171812e-02
 * step_type: expansion
 * centroid: [0.575202,0.314743]
    30     1.658335e-01     1.698053e-02
 * step_type: reflection
 * centroid: [0.589031,0.335579]
    31     1.658335e-01     2.736366e-02
 * step_type: expansion
 * centroid: [0.602859,0.356415]
    32     1.089062e-01     2.469437e-02
 * step_type: reflection
 * centroid: [0.649477,0.411603]
    33     1.089062e-01     1.937227e-02
 * step_type: inside contraction
 * centroid: [0.696095,0.466792]
    34     1.089062e-01     1.528363e-02
 * step_type: reflection
 * centroid: [0.666515,0.433031]
    35     1.089062e-01     1.330356e-02
 * step_type: reflection
 * centroid: [0.653874,0.42402]
    36     1.089062e-01     1.491784e-02
 * step_type: reflection
 * centroid: [0.670815,0.448769]
    37     8.521561e-02     1.037548e-02
 * step_type: inside contraction
 * centroid: [0.700395,0.48253]
    38     8.521561e-02     9.321927e-03
 * step_type: reflection
 * centroid: [0.69668,0.48256]
    39     8.521561e-02     8.326755e-03
 * step_type: reflection
 * centroid: [0.71362,0.507309]
    40     6.759106e-02     7.254579e-03
 * step_type: inside contraction
 * centroid: [0.734276,0.532028]
    41     6.759106e-02     1.090885e-02
 * step_type: expansion
 * centroid: [0.735712,0.537277]
    42     5.180423e-02     8.711934e-03
 * step_type: reflection
 * centroid: [0.761841,0.577026]
    43     4.726293e-02     1.307535e-02
 * step_type: expansion
 * centroid: [0.78797,0.616775]
    44     2.207682e-02     1.072049e-02
 * step_type: inside contraction
 * centroid: [0.832475,0.686522]
    45     2.207682e-02     9.769055e-03
 * step_type: expansion
 * centroid: [0.829657,0.685888]
    46     1.902687e-02     5.845739e-03
 * step_type: reflection
 * centroid: [0.871751,0.760942]
    47     8.435730e-03     7.291009e-03
 * step_type: expansion
 * centroid: [0.913845,0.835996]
    48     1.277968e-03     3.308060e-03
 * step_type: inside contraction
 * centroid: [0.982122,0.960663]
    49     1.277968e-03     2.966401e-03
 * step_type: inside contraction
 * centroid: [0.971462,0.946891]
    50     1.277968e-03     8.392380e-04
 * step_type: inside contraction
 * centroid: [0.987575,0.97335]
    51     1.277968e-03     6.520787e-04
 * step_type: inside contraction
 * centroid: [0.987575,0.97335]
    52     1.271632e-03     2.138461e-04
 * step_type: reflection
 * centroid: [0.992544,0.984906]
    53     8.211969e-04     4.377739e-04
 * step_type: inside contraction
 * centroid: [0.997512,0.996462]
    54     2.036581e-04     2.795646e-04
 * step_type: inside contraction
 * centroid: [1.01909,1.03798]
    55     2.036581e-04     2.601891e-05
 * step_type: inside contraction
 * centroid: [0.999206,0.998567]
    56     2.036581e-04     7.183578e-05
 * step_type: inside contraction
 * centroid: [0.999206,0.998567]
    57     8.444117e-05     6.903285e-05
 * step_type: inside contraction
 * centroid: [1.00932,1.01831]
    58     4.019684e-05     1.812548e-05
 * step_type: inside contraction
 * centroid: [1.00321,1.00685]
    59     4.019684e-05     1.793986e-05
 * step_type: reflection
 * centroid: [1.00219,1.00449]
    60     2.175330e-05     1.342990e-05
 * step_type: inside contraction
 * centroid: [0.996426,0.993114]
    61     7.384674e-06     5.930672e-06
 * step_type: inside contraction
 * centroid: [0.998952,0.997822]
    62     7.384674e-06     2.776279e-06
 * step_type: inside contraction
 * centroid: [1.00029,1.00068]
    63     6.393606e-06     1.589405e-06
 * step_type: inside contraction
 * centroid: [0.999983,0.999918]
    64     3.628577e-06     2.403931e-06
 * step_type: inside contraction
 * centroid: [0.998178,0.996438]
    65     5.087648e-07     1.282629e-06
 * step_type: outside contraction
 * centroid: [0.999777,0.99962]
    66     5.087648e-07     5.065110e-07
 * step_type: inside contraction
 * centroid: [1.0008,1.00163]
    67     5.087648e-07     3.665532e-07
 * step_type: reflection
 * centroid: [1.00018,1.0004]
    68     3.419763e-07     9.090210e-08
 * step_type: inside contraction
 * centroid: [1.00005,1.00008]
    69     2.976187e-07     1.245959e-07
 * step_type: inside contraction
 * centroid: [0.999639,0.999298]
    70     5.829625e-08     1.049977e-07
 * step_type: inside contraction
 * centroid: [1.00004,1.0001]
    71     5.829625e-08     1.805558e-08
 * step_type: inside contraction
 * centroid: [0.999962,0.999922]
    72     5.829625e-08     2.664886e-08
 * step_type: inside contraction
 * centroid: [0.999962,0.999922]
    73     3.143234e-08     1.532154e-08
 * step_type: inside contraction
 * centroid: [1.00008,1.00016]
    74     2.216802e-08     9.739938e-09
 * step_type: inside contraction
 * centroid: [0.999889,0.999787]
 * golden_section.jl
 * brent.jl
 * type_stability.jl
WARNING: maxabs(x) is deprecated, use maximum(abs,x) instead.
 in depwarn(::String, ::Symbol) at ./deprecated.jl:64
 in maxabs(::Array{Float32,2}) at ./deprecated.jl:50
 in default_tol at /home/vagrant/.julia/v0.6/PositiveFactorizations/src/cholesky.jl:271 [inlined]
 in ldltfact!(::Type{PositiveFactorizations.Positive}, ::Array{Float32,2}, ::Type{T}) at /home/vagrant/.julia/v0.6/PositiveFactorizations/src/cholesky.jl:75 (repeats 2 times)
 in update_state!(::Optim.TwiceDifferentiableFunction, ::Optim.NewtonState{Float32}, ::Optim.Newton) at /home/vagrant/.julia/v0.6/Optim/src/newton.jl:60
 in optimize(::Optim.TwiceDifferentiableFunction, ::Array{Float32,1}, ::Optim.Newton, ::Optim.Options{Void}) at /home/vagrant/.julia/v0.6/Optim/src/optimize.jl:200
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/type_stability.jl:48 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in macro expansion; at /home/vagrant/.julia/v0.6/Optim/test/runtests.jl:42 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:532
 in include(::String) at ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:292
 in _start() at ./client.jl:356
while loading /home/vagrant/.julia/v0.6/Optim/test/type_stability.jl, in expression starting on line 1
 * array.jl
 * constrained.jl
 * callbacks.jl
 * precon.jl
Test a basic preconditioning example
N = 10
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 890, f_calls = 890
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 23, f_calls = 23
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITHOUT preconditioning : g_calls = 49, f_calls = 73
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITH preconditioning : g_calls = 11, f_calls = 16
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 33, f_calls = 33
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 25, f_calls = 25
N = 50
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 3501, f_calls = 3501
    (gradient descent is not expected to converge)
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 12, f_calls = 12
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITHOUT preconditioning : g_calls = 185, f_calls = 276
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITH preconditioning : g_calls = 7, f_calls = 10
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 386, f_calls = 386
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 15, f_calls = 15
N = 250
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 3502, f_calls = 3502
    (gradient descent is not expected to converge)
Optim.GradientDescent{L<:Function,T,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 9, f_calls = 9
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITHOUT preconditioning : g_calls = 1371, f_calls = 1993
Optim.ConjugateGradient{T,Tprep<:Union{Function,Void},L<:Function} WITH preconditioning : g_calls = 5, f_calls = 7
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITHOUT preconditioning : g_calls = 1283, f_calls = 1283
Optim.LBFGS{T,L<:Function,Tprep<:Union{Function,Void}} WITH preconditioning : g_calls = 12, f_calls = 12
 * initial_convergence.jl
 * extrapolate.jl
--------------------
Rosenbrock Example: 
--------------------
LBFGS Default Options: g_calls = 157, f_calls = 157
CG Default Options: g_calls = 65, f_calls = 86
LBFGS + Backtracking + Extrapolation: g_calls = 23, f_calls = 52
--------------------------------------
p-Laplacian Example (preconditioned): 
--------------------------------------
LBFGS Default Options: g_calls = 15, f_calls = 15
CG Default Options: g_calls = 10, f_calls = 13
LBFGS + Backtracking + Extrapolation: g_calls = 9, f_calls = 18
INFO: Optim tests passed

>>> End of log
