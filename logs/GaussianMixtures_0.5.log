>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.4
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.1.0
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StaticArrays v0.0.6
INFO: Installing StatsBase v0.10.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.5.0
Commit 3c9d753 (2016-09-19 18:14 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.9392929077148438 GB (605.703125 MB free)
Uptime: 23835.0 sec
Load Avg:  1.021484375  1.02490234375  1.05712890625
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1571804 s       5775 s     117476 s     564047 s         37 s
#2  3500 MHz     388474 s        347 s      70171 s    1854463 s          3 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.1
20 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.4
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.1.0
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StaticArrays                  0.0.6
 - StatsBase                     0.10.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-2.6862254562912076e6,[98408.8,1591.21],
[1545.38 -1617.07 -2144.28; -1802.98 1975.43 1588.91],

Array{Float64,2}[
[96687.7 1654.84 721.198; 1654.84 96322.7 -1869.76; 721.198 -1869.76 98521.0],

[3190.87 -1734.76 -1216.99; -1734.76 3490.63 1592.33; -1216.99 1592.33 2409.29]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.173105e+03
      1       1.131080e+03      -1.042026e+03 |        7
      2       1.066605e+03      -6.447483e+01 |        2
      3       1.017938e+03      -4.866650e+01 |        2
      4       9.925110e+02      -2.542751e+01 |        2
      5       9.626141e+02      -2.989688e+01 |        2
      6       9.562864e+02      -6.327700e+00 |        0
      7       9.562864e+02       0.000000e+00 |        0
K-means converged with 7 iterations (objv = 956.2863999235315)
INFO: K-means with 272 data points using 7 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.066904
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.785237
INFO: iteration 2, lowerbound -3.639284
INFO: iteration 3, lowerbound -3.486521
INFO: iteration 4, lowerbound -3.315089
INFO: iteration 5, lowerbound -3.143834
INFO: iteration 6, lowerbound -2.998340
INFO: dropping number of Gaussions to 6
INFO: iteration 7, lowerbound -2.875761
INFO: iteration 8, lowerbound -2.784635
INFO: dropping number of Gaussions to 5
INFO: iteration 9, lowerbound -2.731864
INFO: dropping number of Gaussions to 4
INFO: iteration 10, lowerbound -2.692291
INFO: dropping number of Gaussions to 3
INFO: iteration 11, lowerbound -2.646306
INFO: iteration 12, lowerbound -2.599870
INFO: iteration 13, lowerbound -2.554059
INFO: iteration 14, lowerbound -2.508155
INFO: iteration 15, lowerbound -2.464855
INFO: iteration 16, lowerbound -2.425646
INFO: iteration 17, lowerbound -2.390490
INFO: iteration 18, lowerbound -2.358775
INFO: iteration 19, lowerbound -2.331504
INFO: iteration 20, lowerbound -2.312884
INFO: iteration 21, lowerbound -2.307507
INFO: dropping number of Gaussions to 2
INFO: iteration 22, lowerbound -2.302924
INFO: iteration 23, lowerbound -2.299260
INFO: iteration 24, lowerbound -2.299256
INFO: iteration 25, lowerbound -2.299254
INFO: iteration 26, lowerbound -2.299254
INFO: iteration 27, lowerbound -2.299253
INFO: iteration 28, lowerbound -2.299253
INFO: iteration 29, lowerbound -2.299253
INFO: iteration 30, lowerbound -2.299253
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Sun 02 Oct 2016 10:59:24 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Sun 02 Oct 2016 10:59:26 AM UTC: K-means with 272 data points using 7 iterations
11.3 data points per parameter
,Sun 02 Oct 2016 10:59:27 AM UTC: EM with 272 data points 0 iterations avll -2.066904
5.8 data points per parameter
,Sun 02 Oct 2016 10:59:27 AM UTC: GMM converted to Variational GMM
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 1, lowerbound -3.785237
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 2, lowerbound -3.639284
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 3, lowerbound -3.486521
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 4, lowerbound -3.315089
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 5, lowerbound -3.143834
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 6, lowerbound -2.998340
,Sun 02 Oct 2016 10:59:29 AM UTC: dropping number of Gaussions to 6
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 7, lowerbound -2.875761
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 8, lowerbound -2.784635
,Sun 02 Oct 2016 10:59:29 AM UTC: dropping number of Gaussions to 5
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 9, lowerbound -2.731864
,Sun 02 Oct 2016 10:59:29 AM UTC: dropping number of Gaussions to 4
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 10, lowerbound -2.692291
,Sun 02 Oct 2016 10:59:29 AM UTC: dropping number of Gaussions to 3
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 11, lowerbound -2.646306
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 12, lowerbound -2.599870
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 13, lowerbound -2.554059
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 14, lowerbound -2.508155
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 15, lowerbound -2.464855
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 16, lowerbound -2.425646
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 17, lowerbound -2.390490
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 18, lowerbound -2.358775
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 19, lowerbound -2.331504
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 20, lowerbound -2.312884
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 21, lowerbound -2.307507
,Sun 02 Oct 2016 10:59:29 AM UTC: dropping number of Gaussions to 2
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 22, lowerbound -2.302924
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 23, lowerbound -2.299260
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 24, lowerbound -2.299256
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 25, lowerbound -2.299254
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 26, lowerbound -2.299254
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 27, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 28, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 29, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 30, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 31, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 32, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 33, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 34, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 35, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 36, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 37, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 38, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 39, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 40, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 41, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 42, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 43, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 44, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 45, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 46, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 47, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 48, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 49, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: iteration 50, lowerbound -2.299253
,Sun 02 Oct 2016 10:59:29 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.045,95.9549]
Î² = [178.045,95.9549]
m = [4.2503 79.2869; 2.00023 53.852]
Î½ = [180.045,97.9549]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.184042 -0.00764405; 0.0 0.00858171],

[0.375876 -0.00895312; 0.0 0.0127487]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -0.9994186233110258
ERROR: LoadError: LoadError: OutOfMemoryError()
 in _elementwise(::Base.#-, ::Type{Float64}, ::Array{Float64,2}, ::Array{Float64,2}) at ./arraymath.jl:57
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.5/GaussianMixtures/src/train.jl:297
 in macro expansion; at /home/vagrant/.julia/v0.5/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:488 (repeats 2 times)
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GaussianMixtures/test/train.jl, in expression starting on line 2
while loading /home/vagrant/.julia/v0.5/GaussianMixtures/test/runtests.jl, in expression starting on line 7
==========================[ ERROR: GaussianMixtures ]===========================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.5/GaussianMixtures/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: GaussianMixtures had test errors
 in #test#61(::Bool, ::Function, ::Array{AbstractString,1}) at ./pkg/entry.jl:740
 in (::Base.Pkg.Entry.#kw##test)(::Array{Any,1}, ::Base.Pkg.Entry.#test, ::Array{AbstractString,1}) at ./<missing>:0
 in (::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}})() at ./pkg/dir.jl:31
 in cd(::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}, ::String) at ./file.jl:59
 in #cd#1(::Array{Any,1}, ::Function, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./pkg/dir.jl:31
 in (::Base.Pkg.Dir.#kw##cd)(::Array{Any,1}, ::Base.Pkg.Dir.#cd, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./<missing>:0
 in #test#3(::Bool, ::Function, ::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in test(::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in eval(::Module, ::Any) at ./boot.jl:234
 in process_options(::Base.JLOptions) at ./client.jl:239
 in _start() at ./client.jl:318

>>> End of log
