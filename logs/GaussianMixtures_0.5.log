>>> 'Pkg.add("GaussianMixtures")' log
INFO: Installing BinDeps v0.4.5
INFO: Installing Blosc v0.1.7
INFO: Installing Calculus v0.1.15
INFO: Installing Clustering v0.7.0
INFO: Installing Distances v0.3.2
INFO: Installing Distributions v0.10.2
INFO: Installing FileIO v0.1.2
INFO: Installing GaussianMixtures v0.1.0
INFO: Installing HDF5 v0.6.6
INFO: Installing JLD v0.6.4
INFO: Installing LegacyStrings v0.1.1
INFO: Installing NearestNeighbors v0.1.0
INFO: Installing PDMats v0.4.2
INFO: Installing Rmath v0.1.3
INFO: Installing SHA v0.2.1
INFO: Installing ScikitLearnBase v0.1.1
INFO: Installing StaticArrays v0.0.5
INFO: Installing StatsBase v0.10.0
INFO: Installing StatsFuns v0.3.1
INFO: Installing URIParser v0.1.6
INFO: Building Blosc
INFO: Building Rmath
INFO: Building HDF5
INFO: Package database updated
INFO: METADATA is out-of-date â€” you may not have the latest version of GaussianMixtures
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GaussianMixtures")' log
Julia Version 0.5.0
Commit 3c9d753 (2016-09-19 18:14 UTC)
Platform Info:
  System: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
           Ubuntu 14.04.5 LTS
  uname: Linux 3.13.0-96-generic #143-Ubuntu SMP Mon Aug 29 20:15:20 UTC 2016 x86_64 x86_64
Memory: 2.4471054077148438 GB (607.5859375 MB free)
Uptime: 24463.0 sec
Load Avg:  1.025390625  1.044921875  1.08984375
Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz: 
       speed         user         nice          sys         idle          irq
#1  3500 MHz    1562993 s        930 s     153029 s     561674 s         44 s
#2  3500 MHz     524203 s       3694 s      78150 s    1716524 s         19 s

  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
Environment:
  TERM = vt100
  LD_LIBRARY_PATH = :/usr/local/lib/
  PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/home/vagrant/julia/bin/
  JAVA_HOME = /usr/lib/jvm/java-7-oracle
  HOME = /home/vagrant

Package Directory: /home/vagrant/.julia/v0.5
2 required packages:
 - GaussianMixtures              0.1.0
 - JSON                          0.7.1
20 additional packages:
 - BinDeps                       0.4.5
 - Blosc                         0.1.7
 - Calculus                      0.1.15
 - Clustering                    0.7.0
 - Compat                        0.9.2
 - Distances                     0.3.2
 - Distributions                 0.10.2
 - FileIO                        0.1.2
 - HDF5                          0.6.6
 - JLD                           0.6.4
 - LegacyStrings                 0.1.1
 - NearestNeighbors              0.1.0
 - PDMats                        0.4.2
 - Rmath                         0.1.3
 - SHA                           0.2.1
 - ScikitLearnBase               0.1.1
 - StaticArrays                  0.0.5
 - StatsBase                     0.10.0
 - StatsFuns                     0.3.1
 - URIParser                     0.1.6
INFO: Testing GaussianMixtures
INFO: Testing Data
(100000,-1.4649489680323116e6,[29179.6,70820.4],
[-8653.04 -12641.5 12572.8; 8956.11 12189.0 -12571.6],

Array{Float64,2}[
[55149.2 11029.7 -11568.9; 11029.7 45417.1 -4721.3; -11568.9 -4721.3 36244.4],

[44402.7 -10913.0 11700.0; -10913.0 54193.5 5015.65; 11700.0 5015.65 63766.3]])
WARNING: rmprocs: process 1 not removed
INFO: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.131862e+03
      1       8.308581e+02      -3.010043e+02 |        5
      2       7.906716e+02      -4.018654e+01 |        0
      3       7.906716e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 790.6715829286036)
INFO: K-means with 272 data points using 3 iterations
11.3 data points per parameter
INFO: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
INFO: EM with 272 data points 0 iterations avll -2.056204
5.8 data points per parameter
INFO: iteration 1, lowerbound -3.752668
INFO: iteration 2, lowerbound -3.603036
INFO: iteration 3, lowerbound -3.441827
INFO: iteration 4, lowerbound -3.267864
INFO: iteration 5, lowerbound -3.104874
INFO: iteration 6, lowerbound -2.976184
INFO: dropping number of Gaussions to 7
INFO: iteration 7, lowerbound -2.889782
INFO: dropping number of Gaussions to 5
INFO: iteration 8, lowerbound -2.827725
INFO: dropping number of Gaussions to 4
INFO: iteration 9, lowerbound -2.779838
INFO: iteration 10, lowerbound -2.757355
INFO: dropping number of Gaussions to 3
INFO: iteration 11, lowerbound -2.739795
INFO: iteration 12, lowerbound -2.717546
INFO: iteration 13, lowerbound -2.693256
INFO: iteration 14, lowerbound -2.662882
INFO: iteration 15, lowerbound -2.626749
INFO: iteration 16, lowerbound -2.586063
INFO: iteration 17, lowerbound -2.542877
INFO: iteration 18, lowerbound -2.499736
INFO: iteration 19, lowerbound -2.458893
INFO: iteration 20, lowerbound -2.421482
INFO: iteration 21, lowerbound -2.387366
INFO: iteration 22, lowerbound -2.356192
INFO: iteration 23, lowerbound -2.329489
INFO: iteration 24, lowerbound -2.311862
INFO: iteration 25, lowerbound -2.307688
INFO: dropping number of Gaussions to 2
INFO: iteration 26, lowerbound -2.302918
INFO: iteration 27, lowerbound -2.299259
INFO: iteration 28, lowerbound -2.299256
INFO: iteration 29, lowerbound -2.299254
INFO: iteration 30, lowerbound -2.299254
INFO: iteration 31, lowerbound -2.299253
INFO: iteration 32, lowerbound -2.299253
INFO: iteration 33, lowerbound -2.299253
INFO: iteration 34, lowerbound -2.299253
INFO: iteration 35, lowerbound -2.299253
INFO: iteration 36, lowerbound -2.299253
INFO: iteration 37, lowerbound -2.299253
INFO: iteration 38, lowerbound -2.299253
INFO: iteration 39, lowerbound -2.299253
INFO: iteration 40, lowerbound -2.299253
INFO: iteration 41, lowerbound -2.299253
INFO: iteration 42, lowerbound -2.299253
INFO: iteration 43, lowerbound -2.299253
INFO: iteration 44, lowerbound -2.299253
INFO: iteration 45, lowerbound -2.299253
INFO: iteration 46, lowerbound -2.299253
INFO: iteration 47, lowerbound -2.299253
INFO: iteration 48, lowerbound -2.299253
INFO: iteration 49, lowerbound -2.299253
INFO: iteration 50, lowerbound -2.299253
INFO: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
GaussianMixtures.History[Fri 30 Sep 2016 11:09:54 AM UTC: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
,Fri 30 Sep 2016 11:09:55 AM UTC: K-means with 272 data points using 3 iterations
11.3 data points per parameter
,Fri 30 Sep 2016 11:09:56 AM UTC: EM with 272 data points 0 iterations avll -2.056204
5.8 data points per parameter
,Fri 30 Sep 2016 11:09:57 AM UTC: GMM converted to Variational GMM
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 1, lowerbound -3.752668
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 2, lowerbound -3.603036
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 3, lowerbound -3.441827
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 4, lowerbound -3.267864
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 5, lowerbound -3.104874
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 6, lowerbound -2.976184
,Fri 30 Sep 2016 11:09:59 AM UTC: dropping number of Gaussions to 7
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 7, lowerbound -2.889782
,Fri 30 Sep 2016 11:09:59 AM UTC: dropping number of Gaussions to 5
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 8, lowerbound -2.827725
,Fri 30 Sep 2016 11:09:59 AM UTC: dropping number of Gaussions to 4
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 9, lowerbound -2.779838
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 10, lowerbound -2.757355
,Fri 30 Sep 2016 11:09:59 AM UTC: dropping number of Gaussions to 3
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 11, lowerbound -2.739795
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 12, lowerbound -2.717546
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 13, lowerbound -2.693256
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 14, lowerbound -2.662882
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 15, lowerbound -2.626749
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 16, lowerbound -2.586063
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 17, lowerbound -2.542877
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 18, lowerbound -2.499736
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 19, lowerbound -2.458893
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 20, lowerbound -2.421482
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 21, lowerbound -2.387366
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 22, lowerbound -2.356192
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 23, lowerbound -2.329489
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 24, lowerbound -2.311862
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 25, lowerbound -2.307688
,Fri 30 Sep 2016 11:09:59 AM UTC: dropping number of Gaussions to 2
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 26, lowerbound -2.302918
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 27, lowerbound -2.299259
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 28, lowerbound -2.299256
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 29, lowerbound -2.299254
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 30, lowerbound -2.299254
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 31, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 32, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 33, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 34, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 35, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 36, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 37, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 38, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 39, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 40, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 41, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 42, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 43, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 44, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 45, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 46, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 47, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 48, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 49, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: iteration 50, lowerbound -2.299253
,Fri 30 Sep 2016 11:09:59 AM UTC: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.045,95.9549]
Î² = [178.045,95.9549]
m = [4.2503 79.2869; 2.00023 53.852]
Î½ = [180.045,97.9549]
W = UpperTriangular{Float64,Array{Float64,2}}[
[0.184042 -0.00764405; 0.0 0.00858171],

[0.375876 -0.00895312; 0.0 0.0127487]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.00000000004
avll from stats: -1.0108051395807058
ERROR: LoadError: LoadError: OutOfMemoryError()
 in .*(::Float64, ::Array{Float64,2}) at ./arraymath.jl:70
 in llpg(::GaussianMixtures.GMM{Float64,Array{Float64,2}}, ::Array{Float64,2}) at /home/vagrant/.julia/v0.5/GaussianMixtures/src/train.jl:297
 in macro expansion; at /home/vagrant/.julia/v0.5/GaussianMixtures/test/train.jl:13 [inlined]
 in anonymous at ./<missing>:?
 in include_from_node1(::String) at ./loading.jl:488 (repeats 2 times)
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GaussianMixtures/test/train.jl, in expression starting on line 2
while loading /home/vagrant/.julia/v0.5/GaussianMixtures/test/runtests.jl, in expression starting on line 7
==========================[ ERROR: GaussianMixtures ]===========================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --depwarn=yes --check-bounds=yes --code-coverage=none --color=no --compilecache=yes /home/vagrant/.julia/v0.5/GaussianMixtures/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: GaussianMixtures had test errors
 in #test#61(::Bool, ::Function, ::Array{AbstractString,1}) at ./pkg/entry.jl:740
 in (::Base.Pkg.Entry.#kw##test)(::Array{Any,1}, ::Base.Pkg.Entry.#test, ::Array{AbstractString,1}) at ./<missing>:0
 in (::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}})() at ./pkg/dir.jl:31
 in cd(::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}, ::String) at ./file.jl:59
 in #cd#1(::Array{Any,1}, ::Function, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./pkg/dir.jl:31
 in (::Base.Pkg.Dir.#kw##cd)(::Array{Any,1}, ::Base.Pkg.Dir.#cd, ::Function, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1},N}) at ./<missing>:0
 in #test#3(::Bool, ::Function, ::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in test(::String, ::Vararg{String,N}) at ./pkg/pkg.jl:258
 in eval(::Module, ::Any) at ./boot.jl:234
 in process_options(::Base.JLOptions) at ./client.jl:239
 in _start() at ./client.jl:318

>>> End of log
