>>> 'Pkg.add("GradientBoost")' log
INFO: Cloning cache of GradientBoost from https://github.com/svs14/GradientBoost.jl.git
INFO: Installing DataStructures v0.4.2
INFO: Installing DecisionTree v0.3.11
INFO: Installing Distributions v0.8.9
INFO: Installing FactCheck v0.4.2
INFO: Installing GLM v0.5.0
INFO: Installing GradientBoost v0.0.1
INFO: Installing PDMats v0.3.6
INFO: Package database updated

>>> 'Pkg.test("GradientBoost")' log
Julia Version 0.5.0-dev+2440
Commit 2bb94d6 (2016-02-01 02:22 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1
INFO: Testing GradientBoost
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:20
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:20
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_bl.jl:14
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_bl.jl:14

WARNING: deprecated syntax "{a=>b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:28.
Use "Dict{Any,Any}(a=>b, ...)" instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:14
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:14
WARNING: Union(args...) is deprecated, use Union{args...} instead.
 in depwarn(Base.#depwarn, ASCIIString, Symbol) at ./deprecated.jl:64
 in Type(Type{Union}, Type{DecisionTree.Leaf}, Type{DecisionTree.Node}) at ./deprecated.jl:50
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in eval at ./boot.jl:267
 [inlined code] from ./sysimg.jl:14
 in require at ./loading.jl:348
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in process_options at ./client.jl:244
 in _start at ./client.jl:300
while loading /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl, in expression starting on line 90
WARNING: The `=>` syntax is deprecated, use `-->` instead
Util functions
  > err_must_be_overriden throws an error
  > weighted_median works
  > holdout returns proportional partitions
WARNING: int(x::AbstractFloat) is deprecated, use round(Int,x) instead.
 in depwarn(Base.#depwarn, ASCIIString, Symbol) at ./deprecated.jl:64
 in int(Base.#int, Float64) at ./deprecated.jl:50
 [inlined code] from /home/vagrant/.julia/v0.5/GradientBoost/src/util.jl:42
 in #19(TestRunner.TestUtil.##19#46) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl:44
 in context(FactCheck.#context, TestRunner.TestUtil.##19#46, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in #1(TestRunner.TestUtil.##1#28) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl:41
 in facts(FactCheck.#facts, TestRunner.TestUtil.##1#28, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in process_options at ./client.jl:244
 in _start at ./client.jl:300
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl, in expression starting on line 6
12 facts verified.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:14.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:21.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:28.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:66.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:71.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:76.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:82.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:87.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:92.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:100.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:111.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:116.
Use "Any[a,b, ...]" instead.
Loss functions
  > not implemented functions throw an error
  > LeastSquares loss works
  > LeastSquares negative_gradient works
  > LeastSquares minimizing_scalar works
  > LeastAbsoluteDeviation loss works
  > LeastAbsoluteDeviation negative_gradient works
  > LeastAbsoluteDeviation minimizing_scalar works
  > BinomialDeviance loss works
    Failure :: (line:727) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 0.6265233750364456 ≅ 0.626523
    Failure :: (line:727) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 1.6265233750364456 ≅ 1.626523
    Failure :: (line:727) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 1.6265233750364456 ≅ 1.626523
    Failure :: (line:727) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 2.6265233750364456 ≅ 2.626523
    Failure :: (line:727) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 2.6265233750364456 ≅ 2.626523
  > BinomialDeviance negative_gradient works
    Failure :: (line:727) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [0.2689414213699951,0.2689414213699951] ≅ [0.268941,0.268941]
    Failure :: (line:727) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [0.2689414213699951,-0.7310585786300049] ≅ [0.268941,-0.731059]
    Failure :: (line:727) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,0.2689414213699951] ≅ [-0.731059,0.268941]
    Failure :: (line:727) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,-0.7310585786300049] ≅ [-0.731059,-0.731059]
    Failure :: (line:727) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,-0.7310585786300049] ≅ [-0.731059,-0.731059]
  > BinomialDeviance minimizing_scalar works
Out of 48 total facts:
  Verified: 38
  Failed:   10
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
Gradient Boost
  > not implemented functions throw an error
  > stochastic_gradient_boost works
  > fit returns model
  > predict works
  > create_sample_indices works
WARNING: [a] concatenation is deprecated; use collect(a) instead
 in depwarn(Base.#depwarn, ASCIIString, Symbol) at ./deprecated.jl:64
 in oldstyle_vcat_warning at ./abstractarray.jl:29
 [inlined code] from ./abstractarray.jl:32
 in #16(TestRunner.TestGB.##16#45) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:85
 in context(FactCheck.#context, TestRunner.TestGB.##16#45, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in #4(TestRunner.TestGB.##4#33) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:83
 in facts(FactCheck.#facts, TestRunner.TestGB.##4#33, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in process_options at ./client.jl:244
 in _start at ./client.jl:300
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl, in expression starting on line 45
    Failure :: (line:727) :: create_sample_indices works :: fact was false
      Expression: length(indices) --> 3
        Expected: 3
        Occurred: 2
    Failure :: (line:727) :: create_sample_indices works :: fact was false
      Expression: length(unique(indices)) --> 3
        Expected: 3
        Occurred: 2
Out of 12 total facts:
  Verified: 10
  Failed:   2

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:51.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:82.
Use "Any[a,b, ...]" instead.
GB Decision Tree
  > build_base_func works
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
    Error :: (line:727) :: build_base_func works
      Expression: predictions --> roughly(expected)
      MethodError: `isapprox` has no method matching isapprox(::Array{Any,1}, ::Array{Any,1})
       [inlined code] from ./boot.jl:331
       in #20(FactCheck.##20#21{Array{Any,1},Array{Any,1}}, Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/helpers.jl:34
       in #3(TestRunner.TestGBDecisionTree.##3#25, Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:263
       in do_fact(FactCheck.#do_fact, TestRunner.TestGBDecisionTree.##4#26, Expr, Symbol, FactCheck.ResultMetadata) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:333
       [inlined code] from ./boot.jl:331
       in #2(TestRunner.TestGBDecisionTree.##2#24) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:52
       in context(FactCheck.#context, TestRunner.TestGBDecisionTree.##2#24, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
       in #1(TestRunner.TestGBDecisionTree.##1#23) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:27
       in facts(FactCheck.#facts, TestRunner.TestGBDecisionTree.##1#23, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
       in include at ./boot.jl:264
       in include_from_node1 at ./loading.jl:417
       in include at ./boot.jl:264
       in include_from_node1 at ./loading.jl:417
       in process_options at ./client.jl:244
       in _start at ./client.jl:300
  > instance_to_node indexes
  > update_regions! updates terminal regions on tree
    Failure :: (line:727) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[0.5]
        Occurred: 0.5
    Failure :: (line:727) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[4.5]
        Occurred: 4.5
    Failure :: (line:727) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[4.5]
        Occurred: 4.5
  > LeastAbsoluteDeviation fit_best_constant works
  > BinomialDeviance fit_best_constant works
Out of 12 total facts:
  Verified: 8
  Failed:   3
  Errored:  1

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:75.
Use "Any[a,b, ...]" instead.
GB Learner
  > not implemented functions throw an error
  > build_base_func works
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
    Error :: (line:727) :: build_base_func works
      Expression: predictions --> roughly(expected)
      MethodError: `isapprox` has no method matching isapprox(::Array{Any,1}, ::Array{Any,1})
       [inlined code] from ./boot.jl:331
       in #20(FactCheck.##20#21{Array{Any,1},Array{Any,1}}, Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/helpers.jl:34
       in #8(TestRunner.TestGBBaseLearner.##8#23, Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:263
       in do_fact(FactCheck.#do_fact, TestRunner.TestGBBaseLearner.##9#24, Expr, Symbol, FactCheck.ResultMetadata) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:333
       [inlined code] from ./boot.jl:331
       in #7(TestRunner.TestGBBaseLearner.##7#22) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:76
       in context(FactCheck.#context, TestRunner.TestGBBaseLearner.##7#22, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
       in #3(TestRunner.TestGBBaseLearner.##3#18) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:46
       in facts(FactCheck.#facts, TestRunner.TestGBBaseLearner.##3#18, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
       in include at ./boot.jl:264
       in include_from_node1 at ./loading.jl:417
       in include at ./boot.jl:264
       in include_from_node1 at ./loading.jl:417
       in process_options at ./client.jl:244
       in _start at ./client.jl:300
  > LeastSquares fit_best_constant works
  > LeastAbsoluteDeviation fit_best_constant works
    Failure :: (line:727) :: LeastAbsoluteDeviation fit_best_constant works :: fact was false
      Expression: actual --> roughly(expected)
        Expected: -0.3333333333333333 ≅ -0.333333
  > BinomialDeviance fit_best_constant throws error
Out of 6 total facts:
  Verified: 4
  Failed:   1
  Errored:  1
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:18
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:18
Machine Learning API
  > not implemented functions throw an error
  > fit! on Float64 arrays works
ERROR: LoadError: LoadError: MethodError: `build_tree` has no method matching build_tree(::Array{Any,1}, ::Array{Float64,2}, ::Int64, ::Int64)
Closest candidates are:
  build_tree{T<:Float64,U<:Real}(!Matched::Array{T<:Float64,1}, ::Array{U<:Real,2}, ::Any, ::Any)
  build_tree(::Array{T,1}, ::Array{T,2}, ::Any)
  build_tree{T<:Float64,U<:Real}(!Matched::Array{T<:Float64,1}, ::Array{U<:Real,2}, ::Any)
  ...
 in build_base_func(GradientBoost.GB.#build_base_func, GradientBoost.GBDecisionTree.GBDT, Array{Float64,2}, Array{Float64,1}, Array{Any,1}, Array{Any,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:42
 in stochastic_gradient_boost(GradientBoost.GB.#stochastic_gradient_boost, GradientBoost.GBDecisionTree.GBDT, Array{Float64,2}, Array{Float64,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:66
 [inlined code] from /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:77
 in fit!(GradientBoost.ML.#fit!, GradientBoost.ML.GBLearner, Array{Float64,2}, Array{Float64,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/ml.jl:45
 in #5(TestRunner.TestML.##5#29) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:31
 in context(FactCheck.#context, TestRunner.TestML.##5#29, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in #1(TestRunner.TestML.##1#25) at /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:28
 in facts(FactCheck.#facts, TestRunner.TestML.##1#25, ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in include at ./boot.jl:264
 in include_from_node1 at ./loading.jl:417
 in process_options at ./client.jl:244
 in _start at ./client.jl:300
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl, in expression starting on line 18
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/runtests.jl, in expression starting on line 11
============================[ ERROR: GradientBoost ]============================

failed process: Process(`/home/vagrant/julia/bin/julia --check-bounds=yes --code-coverage=none --color=no /home/vagrant/.julia/v0.5/GradientBoost/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Base.Pkg.PkgError("GradientBoost had test errors")
 in #test#55(Base.Pkg.Entry.##test#55, Bool, Any, Array{AbstractString,1}) at ./pkg/entry.jl:671
 [inlined code] from ./boot.jl:331
 in #2(Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}) at ./pkg/dir.jl:31
 in cd(Base.Filesystem.#cd, Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}, UTF8String) at ./file.jl:47
 in #cd#1(Base.Pkg.Dir.##cd#1, Array{Any,1}, Any, Any, Array{AbstractString,1}, Vararg{Array{AbstractString,1}}) at ./pkg/dir.jl:31
 [inlined code] from ./boot.jl:331
 in #test#4(Base.Pkg.##test#4, Bool, Any, ASCIIString, Vararg{ASCIIString}) at ./pkg.jl:228
 in eval at ./boot.jl:267
 [inlined code] from ./sysimg.jl:14
 in process_options at ./client.jl:221
 in _start at ./client.jl:300

>>> End of log
