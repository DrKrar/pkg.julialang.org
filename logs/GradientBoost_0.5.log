>>> 'Pkg.add("GradientBoost")' log
INFO: Cloning cache of GradientBoost from https://github.com/svs14/GradientBoost.jl.git
INFO: Installing DataStructures v0.4.3
INFO: Installing DecisionTree v0.3.11
INFO: Installing Distributions v0.8.10
INFO: Installing FactCheck v0.4.2
INFO: Installing GLM v0.5.0
INFO: Installing GradientBoost v0.0.1
INFO: Installing PDMats v0.4.0
INFO: Package database updated
INFO: METADATA is out-of-date — you may not have the latest version of GradientBoost
INFO: Use `Pkg.update()` to get the latest versions of your packages

>>> 'Pkg.test("GradientBoost")' log
Julia Version 0.5.0-dev+3184
Commit fb283c6 (2016-03-17 08:49 UTC)
Platform Info:
  System: Linux (x86_64-unknown-linux-gnu)
  CPU: Intel(R) Xeon(R) CPU E3-1241 v3 @ 3.50GHz
  WORD_SIZE: 64
  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Nehalem)
  LAPACK: libopenblas64_
  LIBM: libopenlibm
  LLVM: libLLVM-3.7.1 (ORCJIT, haswell)
INFO: Testing GradientBoost
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:20
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:20
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_bl.jl:14
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_bl.jl:14

WARNING: deprecated syntax "{a=>b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:28.
Use "Dict{Any,Any}(a=>b, ...)" instead.
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:14
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:14
WARNING: Union(args...) is deprecated, use Union{args...} instead.
 [inlined code] from ./error.jl:26
 in depwarn(::ASCIIString, ::Symbol) at ./deprecated.jl:64
 in Union(::Type{DecisionTree.Leaf}, ::Type{DecisionTree.Node}) at ./deprecated.jl:50
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in eval(::Module, ::Any) at ./boot.jl:267
 [inlined code] from ./sysimg.jl:14
 in require(::Symbol) at ./loading.jl:348
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::UTF8String) at ./loading.jl:417
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl, in expression starting on line 90
WARNING: The `=>` syntax is deprecated, use `-->` instead
Util functions
  > err_must_be_overriden throws an error
  > weighted_median works
  > holdout returns proportional partitions
WARNING: int(x::AbstractFloat) is deprecated, use round(Int,x) instead.
 [inlined code] from ./error.jl:26
 in depwarn(::ASCIIString, ::Symbol) at ./deprecated.jl:64
 in int(::Float64) at ./deprecated.jl:50
 [inlined code] from /home/vagrant/.julia/v0.5/GradientBoost/src/util.jl:41
 in (::TestRunner.TestUtil.##19#46)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl:44
 in context(::TestRunner.TestUtil.##19#46, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in (::TestRunner.TestUtil.##1#28)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl:41
 in facts(::TestRunner.TestUtil.##1#28, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::UTF8String) at ./loading.jl:417
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_util.jl, in expression starting on line 6
12 facts verified.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:14.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:21.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:28.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:66.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:71.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:76.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:82.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:87.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:92.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:100.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:111.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_loss.jl:116.
Use "Any[a,b, ...]" instead.
Loss functions
  > not implemented functions throw an error
  > LeastSquares loss works
  > LeastSquares negative_gradient works
  > LeastSquares minimizing_scalar works
  > LeastAbsoluteDeviation loss works
  > LeastAbsoluteDeviation negative_gradient works
  > LeastAbsoluteDeviation minimizing_scalar works
  > BinomialDeviance loss works
    Failure :: (line:26) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 0.6265233750364456 ≅ 0.626523
    Failure :: (line:26) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 1.6265233750364456 ≅ 1.626523
    Failure :: (line:26) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 1.6265233750364456 ≅ 1.626523
    Failure :: (line:26) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 2.6265233750364456 ≅ 2.626523
    Failure :: (line:26) :: BinomialDeviance loss works :: fact was false
      Expression: loss(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: 2.6265233750364456 ≅ 2.626523
  > BinomialDeviance negative_gradient works
    Failure :: (line:26) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [0.2689414213699951,0.2689414213699951] ≅ [0.268941,0.268941]
    Failure :: (line:26) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [0.2689414213699951,-0.7310585786300049] ≅ [0.268941,-0.731059]
    Failure :: (line:26) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,0.2689414213699951] ≅ [-0.731059,0.268941]
    Failure :: (line:26) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,-0.7310585786300049] ≅ [-0.731059,-0.731059]
    Failure :: (line:26) :: BinomialDeviance negative_gradient works :: fact was false
      Expression: negative_gradient(lf,y_examples[i],y_pred_examples[i]) --> roughly(expected[i])
        Expected: [-0.7310585786300049,-0.7310585786300049] ≅ [-0.731059,-0.731059]
  > BinomialDeviance minimizing_scalar works
Out of 48 total facts:
  Verified: 38
  Failed:   10
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:9
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:45
Gradient Boost
  > not implemented functions throw an error
  > stochastic_gradient_boost works
  > fit returns model
  > predict works
  > create_sample_indices works
WARNING: [a] concatenation is deprecated; use collect(a) instead
 [inlined code] from ./error.jl:26
 in depwarn(::ASCIIString, ::Symbol) at ./deprecated.jl:64
 in oldstyle_vcat_warning(::Int64) at ./abstractarray.jl:29
 [inlined code] from ./abstractarray.jl:32
 in (::TestRunner.TestGB.##16#45)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:85
 in context(::TestRunner.TestGB.##16#45, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in (::TestRunner.TestGB.##4#33)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl:83
 in facts(::TestRunner.TestGB.##4#33, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::UTF8String) at ./loading.jl:417
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb.jl, in expression starting on line 45
    Failure :: (line:26) :: create_sample_indices works :: fact was false
      Expression: length(indices) --> 3
        Expected: 3
        Occurred: 2
    Failure :: (line:26) :: create_sample_indices works :: fact was false
      Expression: length(unique(indices)) --> 3
        Expected: 3
        Occurred: 2
Out of 12 total facts:
  Verified: 10
  Failed:   2

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:51.
Use "Any[a,b, ...]" instead.

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:82.
Use "Any[a,b, ...]" instead.
GB Decision Tree
  > build_base_func works
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:26
    Error :: (line:26) :: build_base_func works
      Expression: predictions --> roughly(expected)
      MethodError: no method matching isapprox(::Array{Any,1}, ::Array{Any,1})
       [inlined code] from ./boot.jl:331
       in (::FactCheck.##20#21{Array{Any,1},Array{Any,1}})(::Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/helpers.jl:34
       in (::TestRunner.TestGBDecisionTree.##3#25)(::Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:263
       in do_fact(::TestRunner.TestGBDecisionTree.##4#26, ::Expr, ::Symbol, ::FactCheck.ResultMetadata) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:333
       [inlined code] from ./boot.jl:331
       in (::TestRunner.TestGBDecisionTree.##2#24)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:52
       in context(::TestRunner.TestGBDecisionTree.##2#24, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
       in (::TestRunner.TestGBDecisionTree.##1#23)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_dt.jl:27
       in facts(::TestRunner.TestGBDecisionTree.##1#23, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
       in include(::ASCIIString) at ./boot.jl:264
       in include_from_node1(::ASCIIString) at ./loading.jl:417
       in include(::ASCIIString) at ./boot.jl:264
       in include_from_node1(::UTF8String) at ./loading.jl:417
       in process_options(::Base.JLOptions) at ./client.jl:262
       in _start() at ./client.jl:318
  > instance_to_node indexes
  > update_regions! updates terminal regions on tree
    Failure :: (line:26) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[0.5]
        Occurred: 0.5
    Failure :: (line:26) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[4.5]
        Occurred: 4.5
    Failure :: (line:26) :: update_regions! updates terminal regions on tree :: fact was false
      Expression: old_pred ./ 2.0 --> new_pred
        Expected: Any[4.5]
        Occurred: 4.5
  > LeastAbsoluteDeviation fit_best_constant works
  > BinomialDeviance fit_best_constant works
Out of 12 total facts:
  Verified: 8
  Failed:   3
  Errored:  1

WARNING: deprecated syntax "{a,b, ...}" at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:75.
Use "Any[a,b, ...]" instead.
GB Learner
  > not implemented functions throw an error
  > build_base_func works
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:25
    Error :: (line:26) :: build_base_func works
      Expression: predictions --> roughly(expected)
      MethodError: no method matching isapprox(::Array{Any,1}, ::Array{Any,1})
       [inlined code] from ./boot.jl:331
       in (::FactCheck.##20#21{Array{Any,1},Array{Any,1}})(::Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/helpers.jl:34
       in (::TestRunner.TestGBBaseLearner.##8#23)(::Array{Any,1}) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:263
       in do_fact(::TestRunner.TestGBBaseLearner.##9#24, ::Expr, ::Symbol, ::FactCheck.ResultMetadata) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:333
       [inlined code] from ./boot.jl:331
       in (::TestRunner.TestGBBaseLearner.##7#22)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:76
       in context(::TestRunner.TestGBBaseLearner.##7#22, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
       in (::TestRunner.TestGBBaseLearner.##3#18)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_gb_bl.jl:46
       in facts(::TestRunner.TestGBBaseLearner.##3#18, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
       in include(::ASCIIString) at ./boot.jl:264
       in include_from_node1(::ASCIIString) at ./loading.jl:417
       in include(::ASCIIString) at ./boot.jl:264
       in include_from_node1(::UTF8String) at ./loading.jl:417
       in process_options(::Base.JLOptions) at ./client.jl:262
       in _start() at ./client.jl:318
  > LeastSquares fit_best_constant works
  > LeastAbsoluteDeviation fit_best_constant works
    Failure :: (line:26) :: LeastAbsoluteDeviation fit_best_constant works :: fact was false
      Expression: actual --> roughly(expected)
        Expected: -0.3333333333333333 ≅ -0.333333
  > BinomialDeviance fit_best_constant throws error
Out of 6 total facts:
  Verified: 4
  Failed:   1
  Errored:  1
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:18
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:18
WARNING: Base.FloatingPoint is deprecated, use AbstractFloat instead.
  likely near /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:18
Machine Learning API
  > not implemented functions throw an error
  > fit! on Float64 arrays works
ERROR: LoadError: LoadError: MethodError: no method matching build_tree(::Array{Any,1}, ::Array{Float64,2}, ::Int64, ::Int64)
Closest candidates are:
  build_tree{T<:Float64,U<:Real}(!Matched::Array{T<:Float64,1}, ::Array{U<:Real,2}, ::Any, ::Any)
  build_tree(::Array{T,1}, ::Array{T,2}, ::Any)
  build_tree{T<:Float64,U<:Real}(!Matched::Array{T<:Float64,1}, ::Array{U<:Real,2}, ::Any)
  ...
 in build_base_func(::GradientBoost.GBDecisionTree.GBDT, ::Array{Float64,2}, ::Array{Float64,1}, ::Array{Any,1}, ::Array{Any,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/gb_dt.jl:42
 [inlined code] from ./abstractarray.jl:476
 in stochastic_gradient_boost(::GradientBoost.GBDecisionTree.GBDT, ::Array{Float64,2}, ::Array{Float64,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:57
 [inlined code] from /home/vagrant/.julia/v0.5/GradientBoost/src/gb.jl:77
 in fit!(::GradientBoost.ML.GBLearner, ::Array{Float64,2}, ::Array{Float64,1}) at /home/vagrant/.julia/v0.5/GradientBoost/src/ml.jl:45
 in (::TestRunner.TestML.##5#29)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:31
 in context(::TestRunner.TestML.##5#29, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:474
 in (::TestRunner.TestML.##1#25)() at /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl:28
 in facts(::TestRunner.TestML.##1#25, ::ASCIIString) at /home/vagrant/.julia/v0.5/FactCheck/src/FactCheck.jl:448
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::ASCIIString) at ./loading.jl:417
 in include(::ASCIIString) at ./boot.jl:264
 in include_from_node1(::UTF8String) at ./loading.jl:417
 in process_options(::Base.JLOptions) at ./client.jl:262
 in _start() at ./client.jl:318
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/test_ml.jl, in expression starting on line 18
while loading /home/vagrant/.julia/v0.5/GradientBoost/test/runtests.jl, in expression starting on line 11
============================[ ERROR: GradientBoost ]============================

failed process: Process(`/home/vagrant/julia/bin/julia -Cx86-64 -J/home/vagrant/julia/lib/julia/sys.so --compile=yes --check-bounds=yes --code-coverage=none --color=no /home/vagrant/.julia/v0.5/GradientBoost/test/runtests.jl`, ProcessExited(1)) [1]

================================================================================
ERROR: Base.Pkg.PkgError("GradientBoost had test errors")
 in #test#55(::Bool, ::Any, ::Array{AbstractString,1}) at ./pkg/entry.jl:671
 [inlined code] from ./boot.jl:331
 in (::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}})() at ./pkg/dir.jl:31
 in cd(::Base.Pkg.Dir.##2#3{Array{Any,1},Base.Pkg.Entry.#test,Tuple{Array{AbstractString,1}}}, ::ASCIIString) at ./file.jl:48
 in #cd#1(::Array{Any,1}, ::Any, ::Any, ::Array{AbstractString,1}, ::Vararg{Array{AbstractString,1}}) at ./pkg/dir.jl:31
 [inlined code] from ./boot.jl:331
 in #test#3(::Bool, ::Any, ::ASCIIString, ::Vararg{ASCIIString}) at ./pkg.jl:228
 in eval(::Module, ::Any) at ./boot.jl:267
 [inlined code] from ./sysimg.jl:14
 in process_options(::Base.JLOptions) at ./client.jl:239
 in _start() at ./client.jl:318

>>> End of log
